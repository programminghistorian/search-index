[



  {
    "id": 0,
    "url": "http://localhost:4000/es/lecciones/administracion-de-datos-en-r",
    "title": "Administración de datos en R",
    "body": "\nAdministración de datos en R\n\nContenidos\n\n\n  Requisitos\n  Objetivos de la lección\n  Introducción\n  Un ejemplo de dplyr en acción\n  Línea de operaciones\n  Necesitamos un nuevo conjunto de datos\n  ¿Qué es Dplyr?    \n      select (seleccionar)\n      filter (filtrar)\n      mutate (mutar)\n      arrange(ordenar)\n      summarise (resumir)\n    \n  \n  Poniéndolo todo junto\n  Conclusión\n  Recursos adicionales en español\n\n\nRequisitos\nEn esta lección asumimos que tienes cierto conocimiento sobre R. Si no has completado el tutorial de datos tabulares básicos con R, te recomendamos hacerlo. Saber otro lenguaje de programación también te será útil. Si necesitas un lugar donde empezar, recomendamos trabajar con los excelentes tutoriales sobre Python en The Programming Historian en español.\n\nObjetivos de la lección\nAl final de la lección,\n\n  sabrás cómo trabajar con datos ordenados y su importancia.\n  entenderás el paquete dplyr y podrás usarlo para manipular y administrar datos.\n  conocerás la línea de operaciones de R y observarás su utilidad para crear código más legible.\n  aprenderás las bases del análisis exploratorio de datos a través de algunos ejemplos básicos de manipulación de datos.\n\n\nIntroducción\nLos datos que puedes encontrar disponibles en red raramente están en el formato necesario para su análisis y necesitarás manipularlos antes de explorar las preguntas que te interesan. ¡Esto puede llevar más tiempo que el análisis! En este tutorial vamos a aprender algunas técnicas básicas de manipulación, manejo y administración de tus datos en R. Más específicamente, vamos a seguir la filosofía de “datos limpios” o “tidy data” articulada por Hadley Wickham.\n\nSegún Wickham, los datos están “limpios” cuando cumplen tres criterios:\n\n  Cada observación está en una fila.\n  Cada variable está en una columna.\n  Cada valor tiene su propia celda.\n\n\nPrestar atención a estos criterios nos permite identificar datos organizados o desorganizados. También nos ofrece un esquema estándar y un conjunto de herramientas para limpiar alguna de las formas más comunes en que un conjunto de datos puede estar “desordenado”, como por ejemplo si:\n\n  los títulos de las columnas son valores en vez de nombres de variables.\n  hay múltiples variables en una columna.\n  las variables están en las filas y en las columnas.\n  hay unidades observacionales de diferente tipo guardadas en la misma tabla.\n  una única unidad observacional está guardada en varias tablas.\n\n\nTal vez lo más importante sea que tener nuestros datos en este formato nos permite usar una colección de paquetes del “tidyverse” que están diseñados para trabajar específicamente con datos limpios. Asegurándonos de que nuestros datos de entrada y de salida están ordenados, podemos usar un pequeño conjunto de herramientas para resolver un amplio número de preguntas. Además, podemos combinar, manipular y dividir conjuntos de datos ordenados como creamos más conveniente.\n\nEn este tutorial nos enfocamos en el paquete dplyr de tidyverse pero merece la pena mencionar otros que nos encontraremos por el camino:\n\nmagittr: Este paquete nos da acceso al el operador %&gt;% y hace nuestro código más fácilmente de leer.\nggplot2: Este paquete utiliza  “la gramática de gráficos”1 para ofrecer una manera fácil de visualizar nuestros datos.\nreadr: Este paquete da acceso a un método más rápido y racionalizado para importar datos rectangulares (una tabla), como son los archivos CSV (valores separados por comas).\ntibble: Este paquete nos permite reconceptualizar el formato data frame (marco o tabla de datos) para que sea más fácil trabajar con ellos e imprimirlos.\n\nSi todavía no lo has hecho, deberías instalar y cargar “tidyverse” antes de empezar. Además, asegúrate de tener la versión más reciente de R y de la plataforma R Studio correspondientes a tu sistema operativo.\n\nCopia el siguiente código en R Studio. Para ejecutarlo tienes que marcar las líneas y clicar Ctrl+Intro (Cmd+Intro en Mac OS):\n\n# Instala y carga la biblioteca tidyverse\n# No te preocupes si esto toma un tiempo\n\n&gt; install.packages(\"tidyverse\")\n&gt; library(tidyverse)\n\n\nUn ejemplo de dplyr en acción\nVeamos un ejemplo de cómo dyplr nos puede ayudar a los historiadores. Vamos a cargar los datos del censo decenal de 1790 a 2010 de Estados Unidos. Descarga los datos haciendo click aquí2 y ponlos en la carpeta que vas a utilizar para trabajar en los ejemplos de este tutorial.\n\nComo los datos están en un archivo CSV, vamos a usar el comando de lectura read_csv() en el paquete readr de “tidyverse”.\n\nLa función read_csv (leer archivo de valores separados por comas) toma la ruta del archivo que queremos importar como una variable, así que asegúrate de escribirlo correctamente.\n\n# Importar el archivo CSV y guardarlo como importacion_poblacion_estados_eeuu\n# Asegúrate de tener la ruta correcta al archivo\n\nimportacion_poblacion_estados_eeuu &lt;-read_csv(\"ejemplo_introductorio_estados.csv\")\n\n\nUna vez que importas los datos, verás que hay tres columnas: una para la población, otra para el año y otra para el estado. Estos datos ya están en un formato limpio y nos dan multitud de opciones para explorarlos.\n\nPara el particular, vamos a visualizar el crecimiento de la población de California y Nueva York para conocer mejor de la migración del oeste.3 Vamos a usar dplyr para filtrar los datos que contienen solo la información de los estados que nos interesan y ggplot2 para visualizar dichos datos. Este ejercicio es solo un ejemplo para que te hagas una idea de lo que puede hacer dplyr, así que no te preocupes si no entiendes el código en este momento.\n\n# Filtrar solo los estados de California y Nueva York\npoblacion_california_nueva_york &lt;- importacion_poblacion_estados_eeuu %&gt;%\n  filter(estado %in% c(\"California\", \"Nueva York\"))\n\n# Visualizar las poblaciones de California y Nueva York\nggplot(data=poblacion_california_nueva_york, aes(x=año, y=poblacion, color=estado)) +\n  geom_line() +\n  geom_point()\n\n\n\n    \n\n    Gráfico de la población de los estados de California y de Nueva York\n\n\n\n\nComo podemos ver, la población de California ha crecido de forma considerable en comparación con la de Nueva York. Aunque este ejemplo pueda parecer obvio si conoces la historia de migración en los Estados Unidos, el código nos ofrece la base sobre la que podemos elaborar multitud de preguntas similares. Por ejemplo, con un cambio rápido en el código podemos crear un gráfico similar con dos estados diferentes como Mississippi y Virginia.\n\n# Filtrar solo los estados de Mississippi y Virginia\npoblacion_mississipi_y_virginia &lt;- importacion_poblacion_estados_eeuu %&gt;%\n  filter(estado %in% c(\"Mississippi\", \"Virginia\"))\n\n# Visualizar las poblaciones de Mississippi y Virginia\nggplot(data=poblacion_mississipi_y_virginia, aes(x=año, y=poblacion, color=estado)) +\n  geom_line() +\n  geom_point()\n\n\n\n    \n\n    Gráfico de la población de los estados de Mississippi y de Virginia\n\n\n\n\nHacer cambios rápidos en el código y reanalizar nuestros datos es una parte fundamental del análisis exploratorio de datos (AED, o EDA por sus siglas en inglés). En vez de tratar de “probar” una hipótesis, el análisis exploratorio de datos nos ayuda a entender nuestros datos mejor y a hacernos preguntas sobre ellos. Para los historiadores el AED ofrece una forma de saber cuándo indagar más en un tema y cuando dejarlo a un lado, y esto es en el área en el que R sobresale.\n\nLínea de operaciones\nAntes de ver dplyr, tenemos que entender lo que es la línea de operaciones %&gt;% en R porque la vamos a utilizar mucho en nuestros ejemplos. Como decíamos, la línea de operaciones es parte del paquete  magittr creado por Stefan Milton Bache y Hadley Wickham y está incluida en tidyverse. Su nombre es un homenaje al pintor surrealista Rene Magritte y su famosa obra “La traición de las imágenes”, que muestra una pipa con las palabras “esto no es una pipa” debajo, en francés.\n\nLa línea de operaciones te permite pasar lo que está a su izquierda como la primera variable en una función especificada a la derecha. Aunque pueda parecer extraño al principio, una vez que lo aprendas verás que hace tu código más fácil de leer al evitar declaraciones anidadas. No te preocupes si esto te resulta un poco complicado ahora. Será más fácil una vez que trabajemos con ejemplos.\n\nDigamos que nos interesa saber la raíz cuadrada del valor de cada población y luego queremos sumar todas las raíces cuadradas antes de calcular la media. Obviamente, esto no es una medida útil pero demuestra cuán rápido puede complicarse la lectura del código de R. Normalmente, anidaríamos las siguientes declaraciones:\n\nmean(sum(sqrt(importacion_poblacion_estados_eeuu$poblacion)))\n\n## [1] 1256925\n\n\nComo ves, con tantos comandos anidados es difícil recordar cuántos paréntesis necesitas y hace que el código sea complicado de leer. Para mitigar esto algunas personas crean vectores temporales entre la llamada a cada función.\n\n# Calcular la raíz cuadrada de la población de cada estado\nvector_raiz_cuadrada_poblacion_estados &lt;- sqrt(importacion_poblacion_estados_eeuu$poblacion)\n\n# Calcular la suma de las raíces cuadradas de la variable temporal\nsuma_del_vector_raices_cuadradas_poblacion_estados &lt;- sum(vector_raiz_cuadrada_poblacion_estados)\n\n# Calcular la media de la variable temporal\nmedia_suma_del_vector_raices_cuadradas_poblacion_estados &lt;- mean(suma_del_vector_raices_cuadradas_poblacion_estados)\n\n# Mostrar la mediana\nmedia_suma_del_vector_raices_cuadradas_poblacion_estados\n\n## [1] 1256925\n\n\nAunque vas a obtener la misma respuesta, esto es mucho más legible. Sin embargo, puede llenar tu espacio de trabajo con basura si olvidas borrar los vectores temporales. La línea de operaciones hace todo esto por ti. Aquí está el mismo código con la línea de operador pipe:\n\nimportacion_poblacion_estados_eeuu$poblacion%&gt;%sqrt%&gt;%sum%&gt;%mean\n\n## [1] 1256925\n\nEsto es mucho más fácil de leer e incluso lo podrías hacer más claro escribiéndolo en diferentes líneas\n\n# Asegúrate de poner el operador al final de la línea\nimportacion_poblacion_estados_eeuu$poblacion%&gt;%\n  sqrt%&gt;%\n  sum%&gt;%\n  mean\n\n## [1] 1256925\n\n\nPor favor, nota que los vectores o marcos de datos que la línea de operación crea son descartados cuando se completa la operación. Si quieres guardarlos, tienes que pasarlos a una nueva variable:\n\nvector_raiz_y_suma_permanente_poblacion_estados &lt;- importacion_poblacion_estados_eeuu$poblacion%&gt;%sqrt%&gt;%sum%&gt;%mean\nvector_raiz_y_suma_permanente_poblacion_estados\n\n## [1] 1256925\n\n\nNecesitamos un nuevo conjunto de datos\nAhora que entendemos la línea de operaciones, estamos preparados para empezar a mirar y administrar otro conjunto de datos. Desafortunadamente, para los historiadores, solo hay unos pocos conjuntos disponibles - ¡a lo mejor tú nos puedas ayudar a cambiar esto haciendo los tuyos públicos! Aquí contamos con el paquete history data (datos históricos) creado por Lincoln Mullen.\n\nVamos a instalar y cargar el paquete:\n\n# Instalar el paquete historydata\ninstall.packages(\"historydata\")\n\n# Cargar el paquete historydata\nlibrary(historydata)\n\n\nEste paquete contiene ejemplos de conjuntos de datos históricos - el ejemplo anterior con datos del censo del EEUU fue tomado de este paquete (y modificado por la traductora). A lo largo de este tutorial, vamos a trabajar con el conjunto de early_colleges (primeras_universidades) que contiene datos sobre las universidades fundadas antes de 1848.4 Lo primero que vamos a hacer es cargar los datos y leerlos:\n\n# Asegúrate de que has instalado y cargado el paquete historydata antes de nada\n\ndata(early_colleges)\nearly_colleges\n\n# A tibble: 65 x 6\n   college                original_name         city          state established sponsorship\n   &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n 1 Harvard                NA                    Cambridge     MA           1636 Congregational; after 1805 …\n 2 William and Mary       NA                    Williamsburg  VA           1693 Anglican\n 3 Yale                   NA                    New Haven     CT           1701 Congregational\n 4 Pennsylvania, Univ. of NA                    Philadelphia  PA           1740 Nondenominational\n 5 Princeton              College of New Jersey Princeton     NJ           1746 Presbyterian\n 6 Columbia               King's College        New York      NY           1754 Anglican\n 7 Brown                  NA                    Providence    RI           1765 Baptist\n 8 Rutgers                Queen's College       New Brunswick NJ           1766 Dutch Reformed\n 9 Dartmouth              NA                    Hanover       NH           1769 Congregational\n10 Charleston, Coll. Of   NA                    Charleston    SC           1770 Anglican\n# ... with 55 more rows\n\nComo puedes ver, este conjunto de datos contiene el nombre actual de la universidad (original_name), la ciudad (city) y el estado (state) en que fue fundada, la fecha en que se fundó (established), y la entidad responsable de su patrocinio (sponsorship). Como ya hemos dicho, antes de poder trabajar con un conjunto de datos, es importante pensar en cómo organizar los datos. Veamos si alguno de estos datos no está en formato “limpio” (“tidy”). ¿Puedes ver alguna celda que no concuerde con los tres criterio de datos limpios?\n\nSi piensas que se trata deel patrocinio de Harvard, estás en lo cierto. Además de señalar el patrocinio original, también menciona que cambió de patrocinador en 1805. Normalmente uno quiere mantener toda la información posible sobre los datos, pero para propósitos de este tutorial, vamos a cambiar la columna para tener solo el patrocinador inicial.\n\nearly_colleges[1,6] &lt;- \"Congregational\"\nearly_colleges\n\n# A tibble: 65 x 6\n   college                original_name         city          state established sponsorship\n   &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n 1 Harvard                NA                    Cambridge     MA           1636 Congregational\n 2 William and Mary       NA                    Williamsburg  VA           1693 Anglican\n 3 Yale                   NA                    New Haven     CT           1701 Congregational\n 4 Pennsylvania, Univ. of NA                    Philadelphia  PA           1740 Nondenominational\n 5 Princeton              College of New Jersey Princeton     NJ           1746 Presbyterian\n 6 Columbia               King's College        New York      NY           1754 Anglican\n 7 Brown                  NA                    Providence    RI           1765 Baptist\n 8 Rutgers                Queen's College       New Brunswick NJ           1766 Dutch Reformed\n 9 Dartmouth              NA                    Hanover       NH           1769 Congregational\n10 Charleston, Coll. Of   NA                    Charleston    SC           1770 Anglican\n# ... with 55 more rows\n\nAhora que tenemos nuestros datos en formato limpio, podemos formatearlos a través del paquete dplyr.\n\n¿Qué es Dplyr?\nDplyr es otra parte de tidyverse que proporciona funciones para manipular y transformar tu datos. Dado que nuestros datos van a seguir estando ordenados (tidy), solamente necesitamos un conjunto pequeño de herramientas para explorarlo. Comparándolo con el R Base, el uso de dplyr es más rápido y garantiza que si los datos introducidos (input) están ordenados los datos que obtendremos (output) también lo estarán. Quizás de manera más importante, dplyr hace nuestro código fácil de leer y utiliza “verbos” que son, en su mayoría, intuitivos (para el hablante de inglés). Cada función en dplyr corresponde a estos verbos, siendo los cinco principales filtrar (filter), seleccionar (select), ordenar (arrange), mutar (mutate) y resumir (summarise - con ortografía de inglés británico- o summarize - con ortografía de inglés de EEUU-). Vamos a ver cada una de ellas para entender su funcionamiento en la práctica.\n\nselect (seleccionar)\nSi miramos el conjunto early_colleges (primeras_universidades), podemos ver que hay muchos “NA” en la columna de nombres originales. NA significa que los datos no están disponibles (del inglés not available), y quizás queramos ver nuestros datos sin esta columna. La función select() de dplyr nos posibilita esto precisamente. Toma el marco de datos que quieres manipular como el primer argumento, seguido de la lista indicando qué columnas queremos mantener:\n\n# Deshazte de la columna de nombres originales (\"original_name\") usando select()\n# Nota que no tienes que añadir el símbolo $ (dólar) al nombre de la columna al final de early_colleges porque `dplyr` asume que \",\" (una coma) representa Y (AND en inglés) automáticamente\n\nselect(early_colleges, college, city, state, established, sponsorship)\n\n# A tibble: 65 x 5\n   college                city          state established sponsorship\n   &lt;chr&gt;                  &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n 1 Harvard                Cambridge     MA           1636 Congregational\n 2 William and Mary       Williamsburg  VA           1693 Anglican\n 3 Yale                   New Haven     CT           1701 Congregational\n 4 Pennsylvania, Univ. of Philadelphia  PA           1740 Nondenominational\n 5 Princeton              Princeton     NJ           1746 Presbyterian\n 6 Columbia               New York      NY           1754 Anglican\n 7 Brown                  Providence    RI           1765 Baptist\n 8 Rutgers                New Brunswick NJ           1766 Dutch Reformed\n 9 Dartmouth              Hanover       NH           1769 Congregational\n10 Charleston, Coll. Of   Charleston    SC           1770 Anglican\n# ... with 55 more rows\n\n\nEscribamos también esto mismo usando la línea de operador %&gt;%:\n\nearly_colleges%&gt;%\n    select(college, city, state, established, sponsorship)\n\n# A tibble: 65 x 5\n   college                city          state established sponsorship\n   &lt;chr&gt;                  &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n 1 Harvard                Cambridge     MA           1636 Congregational\n 2 William and Mary       Williamsburg  VA           1693 Anglican\n 3 Yale                   New Haven     CT           1701 Congregational\n 4 Pennsylvania, Univ. of Philadelphia  PA           1740 Nondenominational\n 5 Princeton              Princeton     NJ           1746 Presbyterian\n 6 Columbia               New York      NY           1754 Anglican\n 7 Brown                  Providence    RI           1765 Baptist\n 8 Rutgers                New Brunswick NJ           1766 Dutch Reformed\n 9 Dartmouth              Hanover       NH           1769 Congregational\n10 Charleston, Coll. Of   Charleston    SC           1770 Anglican\n# ... with 55 more rows\n\n\nHacer referencia a cada una de las columnas que queremos mantener para deshacernos de una es un tanto tedioso. Podemos usar el símbolo de restar (-) para indicar que queremos descartar una columna, con su nombre.\n\nearly_colleges%&gt;%\n    select(-original_name)\n\n    # A tibble: 65 x 5\n       college                city          state established sponsorship\n       &lt;chr&gt;                  &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n     1 Harvard                Cambridge     MA           1636 Congregational\n     2 William and Mary       Williamsburg  VA           1693 Anglican\n     3 Yale                   New Haven     CT           1701 Congregational\n     4 Pennsylvania, Univ. of Philadelphia  PA           1740 Nondenominational\n     5 Princeton              Princeton     NJ           1746 Presbyterian\n     6 Columbia               New York      NY           1754 Anglican\n     7 Brown                  Providence    RI           1765 Baptist\n     8 Rutgers                New Brunswick NJ           1766 Dutch Reformed\n     9 Dartmouth              Hanover       NH           1769 Congregational\n    10 Charleston, Coll. Of   Charleston    SC           1770 Anglican\n    # ... with 55 more rows\n\n\nfilter (filtrar)\n\nLa función filter() hace lo mismo que la función select pero en vez de escoger el nombre de la columna, la podemos usar para filtrar filas usando un test de requisitos. Por ejemplo, podemos ver todas las universidades que existían antes del cambio de siglo:\n\nearly_colleges%&gt;%\n    filter(established &lt; 1800)\n\n    # A tibble: 20 x 6\n       college                  original_name         city           state established sponsorship\n       &lt;chr&gt;                    &lt;chr&gt;                 &lt;chr&gt;          &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n     1 Harvard                  NA                    Cambridge      MA           1636 Congregational\n     2 William and Mary         NA                    Williamsburg   VA           1693 Anglican\n     3 Yale                     NA                    New Haven      CT           1701 Congregational\n     4 Pennsylvania, Univ. of   NA                    Philadelphia   PA           1740 Nondenominational\n     5 Princeton                College of New Jersey Princeton      NJ           1746 Presbyterian\n     6 Columbia                 King's College        New York       NY           1754 Anglican\n     7 Brown                    NA                    Providence     RI           1765 Baptist\n     8 Rutgers                  Queen's College       New Brunswick  NJ           1766 Dutch Reformed\n     9 Dartmouth                NA                    Hanover        NH           1769 Congregational\n    10 Charleston, Coll. Of     NA                    Charleston     SC           1770 Anglican\n    11 Hampden-Sydney           NA                    Hampden-Sydney VA           1775 Presbyterian\n    12 Transylvania             NA                    Lexington      KY           1780 Disciples of Christ\n    13 Georgia, Univ. of        NA                    Athens         GA           1785 Secular\n    14 Georgetown               NA                    Washington     DC           1789 Roman Catholic\n    15 North Carolina, Univ. of NA                    Chapel Hill    NC           1789 Secular\n    16 Vermont, Univ. of        NA                    Burlington     VT           1791 Nondenominational\n    17 Williams                 NA                    Williamstown   MA           1793 Congregational\n    18 Tennessee, Univ. of      Blount College        Knoxville      TN           1794 Secular\n    19 Union College            NA                    Schenectady    NY           1795 Presbyterian with Congre…\n    20 Marietta                 NA                    Marietta       OH           1797 Congregational\n\n\nmutate (mutar)\n\nEl comando mutate nos permite añadir una columna al conjunto de datos. Ahora mismo, tenemos la ciudad y el estado en dos columnas diferentes. Podemos usar el comando de pegar (paste) para combinar dos cadenas de caracteres y especificar un separador. Pongámoslas en una única columna llamada “location” (lugar):\n\nearly_colleges%&gt;%mutate(location=paste(city,state,sep=\",\"))\n\n# A tibble: 65 x 7\n   college                original_name         city          state established sponsorship       location\n   &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;\n 1 Harvard                NA                    Cambridge     MA           1636 Congregational    Cambridge,MA\n 2 William and Mary       NA                    Williamsburg  VA           1693 Anglican          Williamsburg,VA\n 3 Yale                   NA                    New Haven     CT           1701 Congregational    New Haven,CT\n 4 Pennsylvania, Univ. of NA                    Philadelphia  PA           1740 Nondenominational Philadelphia,PA\n 5 Princeton              College of New Jersey Princeton     NJ           1746 Presbyterian      Princeton,NJ\n 6 Columbia               King's College        New York      NY           1754 Anglican          New York,NY\n 7 Brown                  NA                    Providence    RI           1765 Baptist           Providence,RI\n 8 Rutgers                Queen's College       New Brunswick NJ           1766 Dutch Reformed    New Brunswick,NJ\n 9 Dartmouth              NA                    Hanover       NH           1769 Congregational    Hanover,NH\n10 Charleston, Coll. Of   NA                    Charleston    SC           1770 Anglican          Charleston,SC\n# ... with 55 more rows\n\n\nRecuerda que dplyr no guarda los datos ni manipula el original. Al contrario, crea marcos de datos temporales en cada paso. Si quieres guardarlos, tienes que crear una variable permanente con &lt;-:\n\nprimeras_universidades_con_localizacion &lt;- early_colleges%&gt;%\n  mutate(location=paste(city, state, sep=\",\"))\n\n# Observa la nueva tabla con la localización añadida\nprimeras_universidades_con_localizacion\n\n# A tibble: 65 x 7\n   college                original_name         city          state established sponsorship       location\n   &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;         &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;\n 1 Harvard                NA                    Cambridge     MA           1636 Congregational    Cambridge,MA\n 2 William and Mary       NA                    Williamsburg  VA           1693 Anglican          Williamsburg,VA\n 3 Yale                   NA                    New Haven     CT           1701 Congregational    New Haven,CT\n 4 Pennsylvania, Univ. of NA                    Philadelphia  PA           1740 Nondenominational Philadelphia,PA\n 5 Princeton              College of New Jersey Princeton     NJ           1746 Presbyterian      Princeton,NJ\n 6 Columbia               King's College        New York      NY           1754 Anglican          New York,NY\n 7 Brown                  NA                    Providence    RI           1765 Baptist           Providence,RI\n 8 Rutgers                Queen's College       New Brunswick NJ           1766 Dutch Reformed    New Brunswick,NJ\n 9 Dartmouth              NA                    Hanover       NH           1769 Congregational    Hanover,NH\n10 Charleston, Coll. Of   NA                    Charleston    SC           1770 Anglican          Charleston,SC\n# ... with 55 more rows\n\n\narrange(ordenar)\n\nLa función arrange nos permite ordenar nuestras columnas de una nueva forma. Ahora mismo, las universidades están organizadas por año en orden ascendiente. Pongámoslas en el orden descendiente de fundación desde, en este caso, el fin de la guerra con México en 1848.5\n\nearly_colleges %&gt;%\n   arrange(desc(established))\n\n# A tibble: 65 x 6\n   college               original_name city        state established sponsorship\n   &lt;chr&gt;                 &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;\n 1 Wisconsin, Univ. of   NA            Madison     WI           1848 Secular\n 2 Earlham               NA            Richmond    IN           1847 Quaker\n 3 Beloit                NA            Beloit      WI           1846 Congregational\n 4 Bucknell              NA            Lewisburg   PA           1846 Baptist\n 5 Grinnell              NA            Grinnell    IA           1846 Congregational\n 6 Mount Union           NA            Alliance    OH           1846 Methodist\n 7 Louisiana, Univ. of   NA            New Orleans LA           1845 Secular\n 8 U.S. Naval Academy    NA            Annapolis   MD           1845 Secular\n 9 Mississipps, Univ. of NA            Oxford      MI           1844 Secular\n10 Holy Cross            NA            Worchester  MA           1843 Roman Catholic\n# ... with 55 more rows\n\n\nsummarise (resumir)\n\nLa última función clave en dplyr es summarise() - en ortografía británica (con ‘s’) o en estadounidense (con ‘z’). summarise() toma una función u operación y generalmente se usa para crear un data frame que contiene los datos estadísticos de resumen y que podemos visualizar en forma de gráfico. Aquí la vamos a usar para calcular el año promedio en que se fundaron las universidades antes de 1848.\n\nearly_colleges%&gt;%summarise(mean(established))\n\n# A tibble: 1 x 1\n  `mean(established)`\n                &lt;dbl&gt;\n1            1809.831\n\n\n\nPoniéndolo todo junto\n\nAhora que hemos aprendido los cinco verbos principales para dplyr, podemos usarlos para crear rápidas visualizaciones de nuestros datos. Vamos a crear un gráfico de barras mostrando el número de universidades laicas y religiosas antes de la Guerra de EEUU de 18126:\n\nuniversidades_seculares_antes_1812 &lt;- early_colleges%&gt;%\n  filter(established &lt; 1812)%&gt;%\n  mutate(es_laica=ifelse(sponsorship!=\"Secular\", \"no\", \"si\"))\n\nPrimero, se ejecuta la función de filtrado para escoger aquellas universidades establecidas antes de 1812. Luego, en la función mutate la función interna ifelse (if…else… o si…si no…) genera un test de verdadero (TRUE) o falso (FALSE) sobre los valores de la columna “sponsorship” y genera otra columna “es_laica” con los resultados; tal que “si el valor en la columna no es igual a (!=) “Secular” añade un “no” en la nueva columna, si dice “Secular” añade un “si”, repitiendo la operación para cada fila, en este caso para cada universidad [N. de la T.].\n\nAhora podemos visualizar los datos:\n\nggplot(universidades_seculares_antes_1812) +\n  geom_bar(aes(x=es_laica, fill=es_laica))+\n  labs(title=\"Tipo de universidad antes de 1812\", x=\"¿Es laica la universidad?\", y=\"Recuento\")\n\n\n\n    \n\n    Número de universidades laicas y religiosas antes de la Guerra de 1812\n\n\n\n\nDe nuevo, haciendo un cambio rápido en nuestro código, podemos también mirar el número de universidades laicas y religiosas después del comienzo de la Guerra de 1812:\n\nuniversidades_seculares_despues_1812&lt;-early_colleges%&gt;%\n  filter(established &gt; 1812)%&gt;%\n  mutate(es_laica=ifelse(sponsorship!=\"Secular\", \"no\", \"si\"))\n\nggplot(universidades_seculares_despues_1812) +\n  geom_bar(aes(x=es_laica, fill=es_laica))+\n  labs(x=\"¿Es laica la universidad?\", y=\"Recuento\")\n\n\n\n    \n\n    Número de universidades laicas y religiosas después de la Guerra de 1812\n\n\n\n\nConclusión\nEste tutorial debería darte una idea de cómo organizar y manipular tus datos en R. Más adelante quizás quieras visualizar tus datos de alguna otra forma. Te recomiendo que empieces por explorar el paquete ggplot2 (ver abajo) porque su conjunto de herramientas funciona muy bien con dplyr. Además, puede que quieras examinar alguna otra función de las que viene con dplyr para mejorar tus habilidades. En todo caso, esto te proporciona una buena base sobre la que construir para abarcar algunos de los problemas comunes que encontrarás.\n\nRecursos adicionales en español\n\n\n  \n    R para Análisis Científicos Reproducibles de Software Carpentry (2018) tiene más información sobre cómo utilizar dplyr para tus datos.\n  \n  \n    Esta “Guía rápida de visualización de datos con ggplot2” u hoja de referencia de ggplot2 (cheatheet) tiene un buen resumen de las funciones del paquete para la visualización de datos. La proporciona y actualiza el equipo de RStudio (2016).\n  \n  \n    Tanto la Guía  para  la  Presentación  de  Gráficos  Estadísticos, del Instituto  Nacional  de Estadística e Informática (2009) así como la Gramática de las gráficas: Pistas para mejorar las representaciones de datos de Joaquín Sevilla Moróder ofrecen explicaciones de cómo presentar tus datos y errores a evitar.\n  \n\n\n\n  \n    \n      En el tutorial original se hace referencia al libro “The Grammar of Graphics” (2005) de Wilkinson. &#8617;\n    \n    \n      Este listado contiene el censo de la población de cada estado desde 1790, es decir, a partir de la formación de los Estados Unidos de América. De esta manera, el listado comienza con 15 estados (los 13 primeros estados eran ya parte del país desde su independencia en 1776, pero no se ratificó su admisión hasta la Constitución de 1787), los del noreste y parte del sureste, a los que se van añadiendo territorios (que luego se convertirán en estado) a lo largo de los siglos XIX y XX, hasta llegar a la actual división territorial del país: 50 estados, un distrito federal y varios territorios no incorporados (Puerto Rico aparece en este censo pero no es un estado como tal, sino un estado libre asociado o territorio). Se han traducido los datos originales (en inglés) al español. [N. de la T.] &#8617;\n    \n    \n      La migración hacia el oeste de los Estados Unidos se dio durante el siglo XIX a partir de la compra de Luisiana (a Francia) y hasta su llegada a la costa Pacífico, despojando a los norteamericanos nativos de sus tierras mediante la violencia. Nótese, además, que California fue incorporada a los Estados Unidos en 1850, tras su cesión por parte de México al finalizar la guerra entre ambos países (1846-1848) por el Tratado de Guadalupe Hidalgo. &#8617;\n    \n    \n      No traducimos estos conjunto pero, por suerte, los datos son bastante intuitivos al tratarse de nombres propios, ciudades, años e iglesias cuyos nombres son cognados entre inglés y español (Anglican por anglicana, Presbyterian por presbiteriana, etc.) [N.de la T.] &#8617;\n    \n    \n      La también llamada Guerra Mexico-Americana fue la guerra librada entre los Estados Unidos y México desde 1846 hasta la firma del Tratado de Guadalupe Hidalgo en 1848 y la cesión mexicana. &#8617;\n    \n    \n      La Guerra de 1812, o guerra anglo-estadounidense, enfrentó a los EEUU contra el Reino Unido al tratar los primeros de conquistar los territorios coloniales de los segundos. Finalizó en 1815. &#8617;\n    \n  \n\n\nEste tutorial explora la manera en que los académicos pueden administrar datos de forma ordenada, entender paquetes de R para manipular los datos y llevar a cabo un análisis básico de datos.\n\n"
  },


  {
    "id": 1,
    "url": "http://localhost:4000/es/lecciones/analisis-de-corpus-con-antconc",
    "title": "Análisis de corpus con AntConc",
    "body": "\nAnálisis de corpus con AntConc\nIntroducción\n\nEl análisis de corpus es un tipo de análisis de textos que permite hacer comparaciones a gran escala entre objetos presentes en los mismos —esto es, aquello que se conoce como lectura distante—. Lo anterior hace posible apreciar fenómenos que no necesariamente se hacen visibles cuando leemos. Si, por ejemplo, dispones de una colección de documentos, es posible que desearas encontrar patrones de uso gramatical o frases de aparición recurrente en la misma. También puede ser que quisieras hallar frases cuya probabilidad de aparición fuese más alta o más baja en la obra de un autor, o bien en un tipo determinado de textos; clases particulares de estructuras gramaticales; o muchos ejemplos de un concepto particular en una gran cantidad de documentos que se encuentran enmarcados en cierto contexto. En este sentido, el análisis de corpus resulta muy útil para demostrar hipótesis sobre textos, o para triangular resultados obtenidos a través de otras metodologías de análisis textual basadas en herramientas digitales.\n\nAl finalizar este tutorial, tendrás la capacidad de:\n\n\n  Crear o descargar un corpus de textos.\n  Realizar una búsqueda de palabras clave en contexto.\n  Identificar patrones respecto de una palabra determinada.\n  Utilizar criterios de búsqueda más específicos.\n  Revisar diferencias estadísticamente significativas entre corpus.\n  Efectuar comparaciones multimodales a través de metodologías de análisis propias de la lingüística de corpus.\n\n\nEs posible que te hayas acercado a la ejecución de análisis como el que se describe aquí si has realizado alguna de las siguientes tareas:\n\n\n  Búsqueda de todas las apariciones de un término específico en un archivo PDF o un documento de Microsoft Word®.\n  Uso de Voyant Tools para revisar patrones en un texto.\n  Lectura y desarrollo de los tutoriales de introducción a Python disponibles en The Programming Historian.\n\n\nEn muchos sentidos, Voyant es una puerta de entrada a la realización de análisis más sofisticados y replicables, ya que la naturaleza de tipo “házlo tú mismo” de los scripts en Python o R puede no ser atractiva para todos. AntConc llena este vacío en tanto se propone como una aplicación informática independiente para el análisis lingüístico de textos, la cual se encuentra disponible de forma gratuita para los sistemas operativos Windows, Mac OS X y Linux (funciona, por tanto, en múltiples plataformas), y es objeto de actualizaciones permanentes por parte de su creador, Laurence Anthony1; si bien existen otras aplicaciones para efectuar análisis de concordancias lingüísticas, se resaltan de AntConc las dos cualidades señaladas (para acceder a recursos adicionales sobre esta temática, véase An Introductory Bibliography to Corpus Linguistics).\n\nEn este tutorial se presentan varias maneras diferentes de acercarse a un corpus de textos. Es importante tener en cuenta que las metodologías de lingüística de corpus no funcionan en todas las situaciones. Con esto, conforme sigas los pasos propuestos, es conveniente que reflexiones sobre la tarea que estés realizando y cómo puede ser de utilidad para responder una pregunta específica en relación con los datos de los que dispongas. En este sentido, si bien la presente lección está construida bajo la metodología “haz esto y luego esto para lograr X”, no siempre es necesario seguir en orden estricto los pasos que se muestran aquí: se brinda en este espacio una síntesis general de algunos de los métodos disponibles para realizar análisis de esta naturaleza, en lugar de una receta única para el éxito.\n\nDescargas necesarias para el desarrollo de este tutorial\n\n\n  \n    Programa: AntConc2.\n\n    Descomprime el archivo del programa (si fuere necesario) e inícialo. Las capturas de pantalla presentadas aquí pueden diferir ligeramente de la versión de AntConc que utilices (y del sistema operativo, desde luego), pero los procedimientos son más o menos los mismos en todas las plataformas y versiones recientes de la aplicación. Este tutorial fue escrito teniendo como referente una versión específica (bastante antigua) de AntConc, en tanto consideramos que resulta más fácil de usar para fines introductorios. Puedes emplear la versión más reciente para desarrollar el tutorial si lo tienes a bien; pero, si deseas seguir los pasos con la misma información que presentamos en las capturas de pantalla de esta lección, es necesario que descargues la versión específica que empleamos aquí (3.2.4).\n  \n  \n    Corpus de prueba: descarga este archivo zip de reseñas cinematográficas (escritas en inglés).\n  \n\n\nPresentación sintética de las temáticas abordadas en la lección\n\n\n  Trabajar con archivos de texto plano\n  Interfaz de usuario y carga de corpus en AntConc\n  Búsqueda de palabras clave en contexto\n  Búsqueda avanzada de palabras clave en contexto\n  Colocaciones y listas de palabras\n  Comparación de corpus\n  Discusión: hacer comparaciones significativas\n  Recursos adicionales\n\n\nTrabajar con archivos de texto plano\n\n\n  AntConc solo funciona con archivos de texto plano de extensión .txt (por ejemplo, “Hamlet.txt”); no puede leer archivos de extensiones .doc, .docx o .pdf. Por lo tanto, si dispones de documentos de este tipo, deberás convertirlos en archivos .txt.\n  La aplicación tiene la capacidad de trabajar con archivos XML (no te preocupes si los desconoces) guardados con la extensión .txt.\n\n\nVisita tu portal de noticias favorito y accede a un artículo (su naturaleza no importa, siempre que se componga mayoritariamente de texto). Luego, selecciona todo el texto (encabezado, pie de página, cuerpo, etc.), haz clic derecho y selecciona “copiar”. Después, abre un editor de texto como Bloc de notas (Windows) o TextEdit (Mac OS X) y pega allí el texto que copiaste.\n\nExisten otros editores de texto de uso gratuito, tales como Notepad++ (Windows) o TextWrangler (Mac OS X), que ostentan funciones más avanzadas y son particularmente útiles para hacer una gran cantidad de tareas de limpieza de texto. Con esto último hacemos referencia a eliminar datos paratextuales tales como el texto boilerplate (información que incluye elementos como el título de la página, los datos del editor, etc.), el cual aparece de forma reiterada en muchos artículos. Si, por el contrario, conservas esta información, los datos se verán comprometidos, por cuanto el programa de análisis de texto tomará en cuenta estos términos en recuentos de palabras, análisis estadísticos y relaciones léxicas. A este respecto podrías considerar, por ejemplo, la posibilidad de eliminar los encabezados y pies de página estándar que aparecen en cada página (véase el tutorial Limpieza de datos con OpenRefine para más información sobre cómo automatizar esta tarea). Ahora bien, en corpus de menor tamaño podría ser más conveniente que tú mismo hicieras dicha labor; de esa manera, adquirirás una mejor percepción de tu corpus.\n\n\n  Guarda el artículo como un archivo .txt en el escritorio. Cabría la posibilidad de que hicieras labores adicionales de limpieza del texto, tales como la remoción de los datos del autor (elimínalos y guarda el archivo nuevamente). Recuerda en este sentido que toda la información que permanezca en el archivo puede y será tomada en cuenta por el programa de análisis de texto.\n  Ve al escritorio y verifica que puedas encontrar el archivo de texto que guardaste.\n\n\nMediante la ejecución repetida de las tareas anteriores se construye un corpus de archivos de texto plano; esta labor suele implicar el abordaje de asuntos relacionados con muestreo, representatividad y organización. Recuerda: es necesario que cada archivo de tu corpus sea de texto plano para que AntConc pueda interpretarlo. A este respecto, se acostumbra nombrar los archivos con la extensión .txt para reconocer fácilmente su naturaleza.\n\nComo lo supondrás, crear un corpus significativo puede resultar bastante tedioso si este se compone archivo por archivo, en especial si pretendes analizar un conjunto extenso de documentos. Por lo tanto, es muy común hacer web scraping (esto es, usar un programa sencillo para tomar archivos de la web de forma automatizada) para construir el corpus; si deseas obtener más información acerca de los conceptos y técnicas asociados a dicha labor, consulta las lecciones Scraping with Beautiful Soup y Automatic Downloading with wget, disponibles en The Programming Historian. Para efectos de este tutorial, en lugar de componer el corpus documento por documento, vamos a utilizar uno ya existente, compuesto por reseñas cinematográficas y tomado del Natural Language Processing Toolkit (NLTK). Este corpus se compone de 2000 reseñas, organizadas por su carácter —positivo o negativo—; abordaremos aquí un pequeño subconjunto de ellas (200 de cada categoría).\n\nLa construcción de corpus es un campo de estudio en sí mismo. Para más información sobre este tópico, sugerimos consultar “Representativeness in Corpus Design”, Literary and Linguistic Computing, 8 (4): 243-257; y Developing Linguistic Corpora: a Guide to Good Practice3.\n\nPrimeros pasos con AntConc: interfaz de usuario y carga de corpus en la aplicación\n\nAl iniciarse, AntConc se verá como en la siguiente imagen:\n\n\n    \n\n    Ventana principal de AntConc\n\n\n\n\nEn el costado izquierdo de la pantalla principal hay un cuadro que enlista todos los archivos cargados del corpus, el cual usaremos más adelante.\n\nLa parte superior de la aplicación consta de 7 pestañas:\n\n\n  Concordance (concordancia): muestra lo que se conoce como keyword in context view (vista de palabras clave en contexto [KWIC, por sus iniciales en inglés]), cuyos resultados se obtienen mediante la barra de búsqueda.\n  Concordance Plot (mapa de concordancia): presenta una visualización muy sencilla de los resultados de la búsqueda de palabras clave en contexto. Las apariciones del término buscado se representarán como pequeñas líneas negras dentro de un rectángulo que representa la extensión total de cada archivo analizado.\n  File View (vista de archivo): brinda una vista del archivo completo en la que se resaltan las apariciones del término buscado, con lo cual se obtiene una visión más amplia del contexto en el que este aparece.\n  Clusters (clústeres): muestra palabras que aparecen juntas muy frecuentemente.\n  Collocates (colocaciones): mientras que la pestaña anterior muestra palabras que definitivamente aparecen juntas en el corpus, esta presenta aquellas que tienen una alta probabilidad de estarlo.\n  Word List (lista de palabras): muestra todas las palabras del corpus.\n  Keyword List (lista de palabras clave): presenta los resultados de comparaciones entre dos corpus.\n\n\nDado su carácter introductorio, este tutorial solo brinda una mirada superficial a lo que se puede hacer con AntConc. En consecuencia, solo nos concentraremos aquí en las funciones de las pestañas Concordance, Collocates, Keywords y Word List.\n\nCarga de corpus\n\nTal como sucede con cualquier otro programa informático, comenzaremos por ir a  “File” – “Open” (“Archivo” – Abrir); pero en lugar de abrir solo un archivo, haremos lo propio con la carpeta que contiene todos los documentos que constituyen el corpus. AntConc permite abrir directorios completos; en consecuencia, si ya tienes conocimiento y te sientes cómodo trabajando de esta manera, puedes abrir la carpeta “All reviews” (“Todas las reseñas”) y pasar directamente a la sección de análisis de este tutorial 4.\n\n\n    \n\n    Apertura de una carpeta.\n\n\n\n\n\n  Recuerda que guardamos los archivos en el escritorio; dirígete entonces a esa ubicación en el menú desplegable.\n\n\n\n    \n\n    Apertura de una carpeta localizada en el escritorio.\n\n\n\n\n\n  Una vez en el escritorio, elige la carpeta “movie reviews from ntlk” (“reseñas cienmatográficas del ntlk”):\n\n\n\n    \n\n    Localización de la carpeta movie reviews from nltk\n\n\n\n\n\n  Ahora, selecciona la carpeta “Negative reviews” (“Reseñas negativas”) y haz clic en “OK”. Hecho esto, deberían cargarse 200 archivos de texto en la columna izquierda del programa —confírmalo mediante la casilla “Total No.”—.\n\n\n\n    \n\n    Carga de la carpeta Negative Reviews.\n\n\n\n\n\n  Repite el mismo proceso para cargar la carpeta “Positive Reviews” (“Reseñas positivas”). Con esto, deberías tener 400 textos en la columna “Corpus Files”.\n\n\n\n    \n\n    Carga de la carpeta Positive Reviews.\n\n\n\n\n\n    \n\n    Conjunto completo de reseñas cargadas en el programa.\n\n\n\n\nBúsqueda de palabras clave en contexto\n\nComenzar con una búsqueda básica\n\nUna de las labores en las cuales se destacan las herramientas de análisis de corpus como AntConc radica en encontrar patrones en el uso de la lengua que nos resulta difícil identificar como lectores. Nos es complicado rastrear palabras pequeñas y en apariencia poco importantes, tales como ‘yo’, ‘él’, ‘ella’, ‘un’ y ‘es’ porque son muy comunes, pero los computadores son muy buenos para realizar esta labor. Estos términos, que en lingüística reciben el nombre de palabras funcionales —se conocen como palabras vacías (stopwords) en el ámbito de las humanidades digitales—, suelen constituir indicadores estilísticos muy claros en materias de autoría y género en los textos. En consecuencia, tales palabras pueden ser términos de búsqueda bastante potentes por sí solos, o bien combinados con términos que se relacionen en mayor medida con el contenido (content-driven terms), lo cual ayuda al investigador a identificar patrones que tal vez no haya detectado previamente.\n\nEn la pestaña Concordance, escribe la palabra ‘the’ en el cuadro de búsqueda ubicado en la parte inferior y haz clic en “Start”. Acto seguido, el programa mostrará cada una de las apariciones de dicho término en el corpus de reseñas cinematográficas, así como el contexto en el que estas se presentan. Esto recibe el nombre de “visor de palabras clave en contexto” (keywords in context viewer).\n\n\n    \n\n    The es una palabra común en la lengua inglesa.\n\n\n\n\nLa palabra buscada aparece 14.618 veces en el corpus según la casilla Concordance Hits, que se encuentra en la parte inferior de la pestaña.\n\nComo se indicó anteriormente, la lista KWIC resulta una buena forma de comenzar a buscar patrones. Aunque la cantidad de información suministrada con la búsqueda es aún muy grande, ¿qué tipo de palabras aparecen cerca de ‘the’?\n\nAhora, prueba a hacer una búsqueda del término ‘a’; tanto este último como ‘the’ son artículos en la lengua inglesa, pero el primero es definido y el segundo indefinido; y los resultados arrojados por la búsqueda ilustrarán esa diferencia.\n\nLlegados a este punto, ya debes estar familiarizado con las líneas de texto que componen la vista KWIC. Ahora, realiza una nueva búsqueda, esta vez de la palabra ‘shot’: los resultados mostrarán las apariciones del término tanto en la función sintáctica de sustantivo (por ejemplo, “line up the shot”) como en la de verbo conjugado (por ejemplo, “this scene was shot carefully”).\n\n¿Qué ves? Entendemos que esta puede ser una forma de identificar patrones difícil de intepretar. Intenta presionar el botón amarillo “Sort” (clasificar): ¿qué sucede al hacerlo?\n\n\n    \n\n    Palabras que aparecen junto a shot.\n\n\n\n\nPuedes ajustar la forma en que AntConc ordena la información encontrada si cambias los parámetros que en la imagen anterior aparecen encerrados en el círculo de color rojo: L corresponde a izquierda (left) y R a derecha (right); lo anterior puede extenderse hasta 5 posiciones en cualquier dirección. Los valores por defecto de la aplicación son 1 izquierda (1L), 2 derecha (2R), 3 derecha (3R); pero puedes alterarlos, por ejemplo, a 3 izquierda (3L), 2 izquierda (2L), 1 derecha (1R) (en aras de obtener frases o trigramas que finalicen con el término buscado) si haces clic en las flechas hacia arriba y abajo que se encuentran junto a los parámetros. Si no deseas realizar este tipo de clasificación, puedes omitirla (dejar los valores predeterminados 1L, 2R y 3R) o dejar todos los parámetros con el valor 0. Cabe la posibilidad de generar clasificaciones menos lineales, como 4L, 3R, 5R, que arrojarían como resultado mucha más información del contexto. El programa puede tardar un poco en mostrar este tipo de clasificaciones, por lo que sugerimos tener paciencia al efectuarlas. Si no estás seguro de cuáles serán los resultados arrojados por la búsqueda, haz clic en “Sort” para ver qué ocurre y efectúa los ajustes a los que haya lugar según tus necesidades.\n\nOperadores de búsqueda\n\nOperador * (comodín)\n\nEl operador * (que sirve para buscar 0 o más caracteres) puede ayudar a encontrar las formas de sustantivos en singular y plural, por ejemplo.\n\nTarea: busca qualit* y ordena los resultados. ¿Qué tiende a preceder y seguir a las palabras ‘quality’ y ‘qualities’? Una pista: son vocablos diferentes con contextos de uso distintos; identifica patrones de uso mediante la búsqueda KWIC.\n\nPara obtener una lista completa de los operadores comodín disponibles y su función, revisa “Global Settings” – “Wildcard Settings”.\n\n\n    \n\n    Configuración de operadores de búsqueda.\n\n\n\n\nPara conocer la diferencia entre los operadores * y ?, busca th*n y luego th?n. Estas dos búsquedas, que a simple vista parecieran muy similares, arrojan resultados distintos.\n\nEl operador ? es más específico que *, así:\n\nwom?n – ‘women’ y ‘woman’.\n\nm?n – ‘man’, ‘men’ y ‘min’.\n\nUna búsqueda de m*n, en cambio, no es útil porque se obtendrán resultados que incluirán ‘mean’, ‘melon’, etc.\n\nTarea: compara los resultados de las búsquedas de wom?n y m?n.\n\n\n  \n    Ordena los resultados de cada búsqueda de manera que arrojen datos significativos (por ejemplo, configurar los parámetros de la búsqueda en 0, 1L y 2L)\n  \n  \n    Haz clic en “File” – “Save Output to Text File” y guarda el archivo (no olvides agregar la extensión .txt al nombre del mismo).\n  \n\n\n\n  Sugerencia: durante la exploración en tu investigación, generarás muchos documentos como este para efectos de consulta. Es conveniente, por tanto, nombrar los archivos de tal manera que se describa lo que estos contienen (por ejemplo, “wom?n-results.txt” en lugar de “antconc-results.txt”).\n\n\n\n    \n\n    Opción Save output as text file.\n\n\n\n\n\n    \n\n    Cuadro de diálogo Save As.\n\n\n\n\nCon lo anterior, puedes abrir el archivo de texto plano generado por el programa en un editor de texto; es posible que debas ampliar la ventana de la aplicación para que este sea legible.\n\n\n    \n\n    Archivo de resultados de búsqueda KWIC exportado por Antconc, tal como se muestra en un editor de texto.\n\n\n\n\nRealiza el proceso anterior con los resultados de las dos búsquedas y compara los archivos de texto generados. ¿Qué fenómenos puedes ver?\n\nOperador | (“o”)\n\nTarea: busca she|he.\n\nAhora, busca las dos palabras anteriores por separado: ¿cuántas veces aparece ‘she’ en comparación con ‘he’?\n\nLa palabra ‘she’ (ella) aparece en mucha menor cantidad que ‘he’ (él). ¿Por qué? ¡Esa es una pregunta de investigación! Una buena manera de ampliar este cuestionamiento podría radicar en ordenar la búsqueda anterior para identificar patrones de uso de las palabras en cuestión, y revisar si las mismas están seguidas de algún verbo en particular.\n\nTarea: a modo de práctica, busca una palabra que te interese, ordena los resultados de formas diferentes, usa los operadores comodín y exporta los datos obtenidos como archivos de texto plano. He aquí un interrogante orientador: ¿qué tipo de patrones puedes observar? ¿Puedes explicarlos?\n\nColocaciones y listas de palabras\nDespués de haber analizado las líneas de resultados de la vista KWIC en busca de patrones, ¿no te gustaría que hubiera una forma de que el computador te brindara una lista de palabras que aparecen más frecuentemente con la palabra clave buscada?\n\nBuenas noticias: existe una manera de obtener esta información en AntConc; está disponible en la pestaña Collocates (colocaciones). Al hacer clic en la misma, aparecerá un mensaje por medio del cual la aplicación dirá que necesita crear una lista de palabras. Haz clic en “OK” y el programa lo hará automáticamente.\n\n\n  Nota: solo recibirás este aviso cuando no hayas creado una lista de palabras.\n\n\n\n    \n\n    Mensaje de advertencia para indicar la necesidad de generar una lista de palabras.\n\n\n\n\nAhora, intenta generar la lista de colocaciones para el término ‘she’.\n\nLos resultados sin clasificar parecerán comenzar con palabras funcionales (palabras con las que se construyen frases) y luego pasarán a palabras de contenido (términos que dan sentido al texto): las primeras son las más frecuentes en inglés, en tanto funcionan mayormente como elementos para construir frases. Versiones más recientes de AntConc suelen incluir el término buscado como primer resultado, posiblemente porque está presente en el texto y se quiere hallar palabras que puedan aparecer junto a él.\n\nAlgunas personas podrían tener la intención de prescindir de esta clase de palabras mediante el uso de una lista de palabras funcionales (esta es una labor común cuando se hace modelado de tópicos). Desde nuestra óptica, no promovemos esta práctica porque los computadores se destacan, justamente, en la identificación de palabras con alta frecuencia de aparición; tal como se expresó anteriormente, tendemos a pasarlas por alto. Los computadores —y en especial las aplicaciones como AntConc—, pueden mostrar dónde aparecen o no estas palabras, y esa información puede ser de interés, especialmente en colecciones de texto de gran envergadura (como se vio con las búsquedas de ‘a’, ‘she’ y ‘he’).\n\nNo obstante, en el caso de la lengua inglesa, la frecuencia de aparición de la letra ‘s’ en el corpus también puede ser bastante alta, en tanto representa el posesivo ʼs (la aplicación no toma en cuenta el apóstrofo), pero AntConc la toma como otra palabra. Asimismo, la forma ʼt puede aparecer junto al verbo ‘do’ por cuanto conforman la contracción donʼt; la alta frecuencia de su aparición conjunta los convierte en colocaciones altamente probables.\n\nTarea: genera la lista de colocaciones para las búsquedas de m?n y wom?n. Ahora, ordénalas de acuerdo con su frecuencia de aparición respecto del parámetro 1L.\nLos resultados muestran lo que, en teoría, hace que un hombre (man) o una mujer (woman) sea “digno de mostrarse en el cine”:\n\n  las mujeres deben ser “bellas” (beautiful), “sofisticadas” (sophisticated) o estar “embarazadas” (pregnant).\n  Los hombres tienen que estar, en cierto modo, fuera de lo común: deben ser “santos” (holy), “negros” (black) o “viejos” (old).\n\n\nLo anterior no alude directamente a las películas, sino a la forma como se escribe sobre ellas en las reseñas, y puede llevar a cuestionamientos más sutiles, tales como “¿de qué manera se describen los roles de las mujeres en las comedias románticas en las reseñas escritas por hombres frente a las escritas por mujeres?”\n\nComparación de corpus\n\nUno de los tipos de análisis más potentes radica en comparar el corpus propio con uno de referencia más extenso.\n\nPara este ejercicio, hemos tomado reseñas de filmes en los que Steven Spielberg ha estado involucrado (como director o productor). Podemos compararlos con un corpus de referencia de películas de toda una gama de directores.\n\nAsegúrate de pensar cuidadosamente sobre las características que podría tener un corpus de referencia para tu propia investigación (por ejemplo, un estudio del lenguaje de Agatha Christie en sus últimos años funcionaría muy bien como un corpus de análisis para compararlo con un corpus de referencia de todas sus novelas). Recuerda que, como lo expresamos anteriormente, la construcción del corpus es un subcampo en sí mismo.\n\n\n  Dirígete a “Settings” – “Tool preferences” – “Keyword List”.\n  Asegúrate de que la casilla de verificación “Use raw files” esté seleccionada en el menú “Reference Corpus”.\n  Haz clic en el botón “Add Directory” y selecciona la carpeta que contiene los archivos del corpus de referencia.\n  Verifica que dispongas de la lista completa de archivos en el listado que se mostrará.\n\n\n\n    \n\n    Carga de un corpus de referencia.\n\n\n\n\n\n  Haz clic en el botón “Load” y espera que el programa cargue los archivos; una vez la casilla de verificación “Loaded” esté marcada, haz clic en “Apply”.\n\n\nExiste la posibilidad de intercambiar los roles del corpus de referencia y los archivos principales (es decir, dar al primero la función de los segundos y viceversa) por medio del botón “Swap Ref/Main Files”; en este punto vale la pena experimentar con esta opción y comparar los resultados obtenidos.\n\n\n  Si estás utilizando una versión más reciente del programa, el botón anterior puede llamarse “Swap with Target Files”. Adicionalmente, cualesquiera sean los datos que vayas a utilizar como corpus de referencia, asegúrate de que estos se carguen correctamente en AntConc (esto es, haz clic en el botón “Load” cada vez que cargues o intercambies un corpus).\n\n\n\n  Dirígete a la pestaña “Keyword list” y una vez allí, presiona el botón “Start” (sin escribir nada en la casilla de búsqueda). Si intercambiaste el corpus de referencia con los archivos objeto del análisis, el programa anunciará la necesidad de crear una nueva lista de palabras antes de generar la lista de palabras clave. Esta se compondrá de aquellos términos que resulten mucho más “inusuales” —de aparición menos probable en terminos estadísticos— en el corpus que se está viendo vs. el de referencia.\n\n\n\n  Keyness (calidad de la palabra clave): corresponde a la frecuencia de aparición de una palabra en el texto cuando se la compara con su frecuencia en un corpus de referencia, “de tal suerte que la probabilidad estadística, calculada mediante un procedimiento determinado, es menor o igual que el valor p especificado por el usuario” (información tomada de este sitio). Para profundizar sobre los detalles estadísticos de este tópico, sugerimos revisar la sección sobre el mismo en la página 7 del archivo Readme de AntConc.\n\n\n¿Cuáles son nuestras palabras clave?\n\n\n    \n\n    Spielberg vs. reseñas cinematográficas.\n\n\n\n\nDiscusión: hacer comparaciones significativas\n\nEs importante tener en cuenta que la forma en que se organicen los archivos de texto para la investigación tendrá efectos en el tipo de interrogantes que puedan surgir de los mismos, así como en los resultados que se obtengan del análisis. A este respecto, recuerda que la comparación realizada aquí entre reseñas negativas y positivas es extremadamente simple; si se quisiere, podrían efectuarse comparaciones adicionales con otros subconjuntos de reseñas, lo cual daría pie a la formulación de interrogantes muy distintos.\n\nAsí entonces, los archivos que se dispongan en el corpus determinarán los resultados obtenidos. Reiteramos que los temas de representatividad y muestreo son muy relevantes en este sentido: no siempre es necesario o ideal utilizar todo un conjunto de datos, incluso si se dispone de él. En este punto, realmente cabe preguntarse por la manera como estos métodos de análisis textual ayudan a generar preguntas de investigación.\n\nSi se piensa, por ejemplo, en el funcionamiento de las reseñas cinematográficas en tanto género discursivo, puede dirigirse la atención hacia oposiciones como las siguientes:\n\n\n  Reseñas cinematográficas vs. reseñas musicales\n  Reseñas cinematográficas vs. reseñas de libros\n  Reseñas cinematográficas vs. noticias deportivas\n  Reseñas cinematográficas vs. noticias en general\n\n\nCada una de estas comparaciones aportará información distinta y puede derivar en preguntas de investigación diferentes, tales como:\n\n\n  \n    ¿En qué difieren las reseñas cinematográficas de otros tipos de reseñas de productos mediáticos?\n  \n  ¿En qué se diferencian las reseñas cinematográficas de otros tipos de escritos susceptibles de publicarse?\n  ¿Cómo se comparan las reseñas de películas con otros géneros de escritura, tales como la crónica deportiva?\n  ¿Qué tienen en común las reseñas cinematográficas y las musicales?\n\n\nDesde luego, puede darse la vuelta a estos cuestionamientos para generar nuevas preguntas:\n\n\n  \n    ¿En qué se diferencian las reseñas bibliográficas de las cinematográficas?\n  \n  ¿En qué difieren las reseñas musicales de las cinematográficas?\n  ¿Qué tienen en común los artículos que se publican en la prensa escrita?\n  ¿En qué se asemejan las reseñas cinematográficas a otros tipos de escritos susceptibles de publicarse?\n\n\nEn síntesis, vale la pena pensar en:\n\n\n  Por qué se quiere comparar dos corpus.\n  Qué tipo de consultas da lugar a preguntas de investigación significativas.\n  Principios de construcción de corpus: muestreo y capacidad de asegurar que se obtengan datos representativos.\n\n\nRecursos adicionales\n\nA Short Bibliography on Corpus Linguistics\n\nUna versión más sencilla de este tutorial, concebida para usuarios con pocos conocimientos de computación (en inglés).\n\nGuía rápida de análisis de corpus con AntConc, publicada por la Universidad de Alicante (2015).\n\nNotas de traducción\n\n\n  \n    \n      Investigador y docente de la Universidad de Waseda (Japón). &#8617;\n    \n    \n      La interfaz del programa solo está disponible en inglés. &#8617;\n    \n    \n      Dos materiales en español pueden ser de utilidad si se desea profundizar en esta témática: de un lado, la conferencia Aproximación al concepto de representatividad de corpus; y de otro, la obra Explotación de los córpora textuales informatizados para la creación de bases de datos terminológicas basadas en el conocimiento. &#8617;\n    \n    \n      Si se requiere trabajar con corpus en cuyos textos se emplean caracteres especiales (como es el caso de los documentos escritos en lengua española), es imperativo prestar atención a la codificación con la cual se guardaron los archivos que los componen. Por defecto, AntConc está configurado para operar con documentos de texto plano con codificación Unicode (UTF-8). Así entonces, es preciso verificar en el editor de texto que estos se hayan guardado atendiendo a lo anterior, o bien cambiar los parámetros de importación de archivos en el programa según las necesidades (por ejemplo, trabajar con archivos codificados en ANSI). &#8617;\n    \n  \n\n\nEl análisis de corpus permite hacer comparaciones a gran escala entre objetos presentes en los textos; es decir, lo que se conoce como lectura distante.\n\n"
  },


  {
    "id": 2,
    "url": "http://localhost:4000/es/lecciones/analisis-temporal-red",
    "title": "Análisis de redes temporal en R\n",
    "body": "\nAnálisis de redes temporal en R\n\n\nContenidos\n\n\n  Introducción\n  Objetivos de la lección\n  Prerrequisitos\n  Paquetes para el análisis temporal de redes\n  Obtener tus datos    \n      Red estática inicial        \n          Listado de vínculos\n          Lista de nodos\n        \n      \n      Tomar decisiones complicadas: convertir datos históricos en un conjunto de datos TNA\n    \n  \n  Visualizaciones estáticas    \n      Crear una animación\n    \n  \n  Más allá de la bola de pelo: la métrica de redes dinámicas    \n      Cambiar la centralidad\n      Pensar en términos temporales: conjuntos alcanzables\n    \n  \n  Conclusión\n  Lecturas complementarias\n  Referencias\n\n\nIntroducción\nSi estás leyendo este tutorial seguramente ya tendrás experiencia en modelar datos de humanidades en forma de red. Quizás seas un/a historiador/a de religión investigando las redes de correspondencia de la Sociedad Religiosa de los Amigos o cuáqueros, en las que los nodos representan a los emisores y los receptores de las cartas y los vínculos representan los intercambios epistolares. O quizás seas un/a historiador/a del arte que estudia una red compuesta de diseñadores de medios impresos y grabadores, con conexiones derivadas de su colaboración en libros. Probablemente hayas visualizado y analizado tu red estática, pero a lo mejor crees que hay algo que estás pasando por alto o que algo está mal. Puede que la red te parezca más grande y robusta de lo que te parecía al obtener los datos de los archivos, o quizás las medidas de centralidad de tus nodos no tienen mucho sentido en el contexto histórico concreto en que existieron.\n\nEn realidad la mayoría de las redes históricas cambian a lo largo del tiempo. Hay momentos en los que pueden crecer, encogerse o disolverse por completo. Los actores y los objetos entran y salen de estas redes a lo largo de su existencia. Las personas o las cosas pueden tener un protagonismo destacado durante periodos breves de tiempo -un día, un año o una década- pero raramente comienzan y terminan su existencia dentro de una red en dicha posición. ¿No sería estupendo si pudieras mostrar estos cambios y desarrollos en tus visualizaciones y análisis de una red?\n\nEl análisis de redes temporal (Temporal Network Analysis o TNA por sus siglas en inglés), también conocido como análisis de redes sociales temporal (Temporal Social Network Analysis o TSNA) o análisis de redes dinámico (Dynamic Network Analysis o DNA), es justo lo que estás buscando.\n\nEl análisis de redes temporal es un acercamiento bastante nuevo fuera de los campos de la epidemiología o del análisis de redes sociales. Este tutorial introduce métodos para la visualización y análisis de redes temporal mediante el uso de unos paquetes escritos para el lenguaje de programación estadístico R. Al paso al que el análisis de redes se está desarrollando, pronto habrá formas más intuitivas para producir visualizaciones y análisis similares, así como métricas de interés completamente nuevas. Por estas razones, este tutorial se enfoca tanto en los principios de creación, visualización y análisis de redes temporal (el por qué) como en la técnica particular que permite alcanzar dichos objetivos (el cómo). También resalta algunas de las simplificaciones poco afortunadas que los historiadores deben realizar al preparar los datos para el análisis temporal de redes, un área en la que nuestra disciplina puede aportar nuevas aproximaciones en el análisis temporal de redes.\n\nUna de las formas básicas de argumentación histórica es identificar, describir y analizar cambios en un fenómeno o un conjunto de fenómenos que ocurren a lo largo del tiempo. La premisa para este tutorial es que cuando los historiadores estudiamos redes deberíamos, en la medida de lo posible, reconocer e investigar cómo las redes cambian con el tiempo.\n\nObjetivos de la lección\nEn este tutorial aprenderás:\n\n  Los tipos de datos necesarios para el modelado de una red temporal.\n  Cómo visualizar una red temporal usando el paquete NDTV de R.\n  Cómo cuantificar y visualizar algunas medidas relevantes a nivel de la red y de los nodos que describen redes temporales usando el paquete TSNA de R.\n\n\nPrerrequisitos\nEste tutorial asume que tienes:\n\n  Un conocimiento básico de la visualización y el análisis de redes estáticas, algo que puedes aprender con tutoriales de Programming Historian como De la hermenéutica a las redes de datos: Extracción de datos y visualización de redes en fuentes históricas y Exploring and Analyzing Network Data with Python (en inglés).\n  R Studio con la versión 3.0 o superior de R instalado.\n  Un entendimiento básico de cómo utilizar R para modificar tus datos. Te recomendamos revisar el excelente tutorial Datos tabulares en R.\n\n\nPaquetes para el análisis temporal de redes\nMientras sigues este tutorial te recomiendo que escribas el código en el archivo de comandos (script) de R para poder guardarlo y editarlo a medida que trabajas. Puedes ejecutar la línea de código o selección de este script usando un atajo del teclado (Ctrl+Intro en Windows y Linux, Command+Intro en Mac).\n\nEn este tutorial usaremos dos paquetes para el análisis temporal de redes. El primero y el más importante de todos es el paquete tsna. Estas herramientas para el análisis temporal de redes (Tools for Temporal Social Network Analysis) extienden las funciones del paquete de análisis de redes sociales (sna) para el modelaje y análisis de redes longitudinales (sinónimo de temporal).\n\nEl segundo paquete, ndtv, sirve para visualizar redes temporales. Acrónimo de visualizaciones dinámicas de redes temporales (Network Dynamic Temporal Visualizations), ndtv muestra los datos de redes temporales como películas, animaciones interactivas u otras representaciones de estructuras relacionales y atributos cambiantes.\n\nAmbos paquetes extienden y dependen del paquete networkDynamic, que provee una estructura de datos robusta para almacenar y manipular datos de redes temporales. Se instalará automáticamente cuando instales uno de los otros dos paquetes, así que no te preocupes por su instalación individual. Nota para los usuarios de Mac: para instalar estos paquetes correctamente puede que sea necesaria la instalación de las Herramientas de desarrollo de línea de comando Xcode si todavía no las tienes.\n\nUtiliza la función install.packages() de la siguiente manera:\n\ninstall.packages(\"sna\")\ninstall.packages(\"tsna\")\ninstall.packages(\"ndtv\")\n\nPara asegurarte de que los paquetes están instalados y cargados cuando utilizas los comandos de R, utiliza la función library() al comienzo de tu código:\n\nlibrary(sna)\nlibrary(tsna)\nlibrary(ndtv)\n\n\nObtener tus datos\n\nRed estática inicial\nDigamos que ya tienes una red estática basada en un archivo de intercambios epistolares, colaboraciones artísticas o la matriculación en cursos de las escuelas culinarias del siglo XIX. Cualquiera que sea el contenido de tu red estática, podemos pensar en dos partes que componen el conjunto de datos:\n\n\n  Una lista que contiene todos los nodos (o vértices -términos que vamos a usar de forma indistinta en este tutorial-)\n  Una lista de conexiones que contiene una de las conexiones1\n\n\nPara evitar que este tutorial sea demasiado abstracto, voy a utilizar un ejemplo concreto durante toda la lección. Este conjunto de datos describe la colaboración entre talleres franceses de manuscritos góticos iluminados de entre 1260 y 1320.2 La lista de nodos de este conjunto de datos es simplemente una lista larga de talleres. Los nombres de estos talleres no son muy importantes. En unos pocos casos en el colofón (una parte de texto al final del manuscrito que describe las circunstancia de su producción) se menciona el nombre del iluminador. En la mayoría de los casos, sin embargo, estos nombres han sido asignados por académicos basándose en la ciudad o región en que el taller estaba situado, o por algún manuscrito famoso que produjo.\n\nTodos los paquetes de R de este tutorial asumen que tu red es unimodal - esto es, que todos los nodos son el mismo tipo de cosa-, y lo mismo ocurre con las conexiones. Tal y como explicó Scott Weingart, los historiadores frecuentemente comienzan con datos multimodales o bimodales. Si quieres producir datos cuantitativos relevantes de tu red con las herramientas disponibles, tienes que convertir (o “proyectar”) una red bimodal a una red unimodal. El conjunto de datos que usamos de ejemplo en este tutorial no es una excepción. Comenzó como una lista de talleres y de los manuscritos a los que contribuyeron. Primero modelé estos datos en forma de una red bimodal que consistía en talleres y manuscritos. Luego convertí la red bimodal a una red unimodal, en la que cada nodo representa un iluminador o un taller.3 Cada vínculo indica la contribución de dos o más talleres a uno o varios manuscritos. Por esta razón, a veces un manuscrito puede estar representado por múltiples vínculos y un vínculo puede representar múltiples manuscritos.\n\nLa diferencia entre una red estática y una temporal dinámica es la cantidad de información contenida en las listas de nodos y vínculos. Para convertir una red estática en una temporal, necesitas añadir información temporal a ambas listas. Básicamente, tenemos que proveer un rango de tiempo que representa el periodo en que existen cada vínculo y cada nodo.\n\nListado de vínculos\nUn listado de vínculos sin dirección contiene tres columnas de datos: un identificador único para el vínculo, un nodo de origen o tail (uno de los talleres implicados) y un nodo de destino o head (otro taller implicado) por cada vínculo. Algo así:\n\n\n  \n    \n      edge.id\n      tail\n      head\n    \n  \n  \n    \n      1\n      2\n      12\n    \n    \n      2\n      2\n      5\n    \n    \n      3\n      2\n      17\n    \n    \n      …\n      …\n      …\n    \n    \n      142\n      97\n      73\n    \n  \n\n\nAdemás de esta información, una lista de vértices o aristas temporales debe contener como mínimo dos partes más de información: el momento en que un vínculo comienza su existencia, también conocido como el onset o inicio del vínculo, y cuándo desaparece ese vínculo, esto es, su terminus o término. Los paquetes NDTV y TSNA que vamos a usar en este tutorial presuponen que tus datos incluyen el onset, el terminus, el tail, el head y un edge id. Dependiendo de cómo conceptualices tu red, puede que el inicio y el término del intervalo de tiempo que conecta dos nodos sea o relativamente breve o prolongado, y en este último caso el comienzo y el final implican una serie de eventos en la relación. Para los talleres de manuscritos, la lista de vínculos temporales es así:\n\n\n  \n    \n      onset\n      terminus\n      tail\n      head\n      onset.censored\n      terminus.censored\n      duration\n      edge.id\n    \n  \n  \n    \n      1300.0\n      1301.0\n      10\n      11\n      FALSE\n      FALSE\n      1\n      1\n    \n    \n      1300.0\n      1301.0\n      10\n      12\n      FALSE\n      FALSE\n      1\n      2\n    \n    \n      1320.0\n      1321.0\n      10\n      30\n      FALSE\n      FALSE\n      1\n      3\n    \n    \n      …\n      …\n      …\n      …\n      …\n      …\n      …\n      …\n    \n    \n      1319.0\n      1320.0\n      99\n      100\n      FALSE\n      FALSE\n      1\n      108\n    \n  \n\n\nLa primera colaboración en esta lista tuvo lugar entre los talleres 10 y 11 entre los años 1300 y 1301, y duró un año (en realidad no sabemos cuánto tardaron ambos talleres en producir el manuscrito juntos, esto es una aproximación), etc. A lo mejor te preguntes qué son las columnas onset.censored y terminus.censored aquí. En el análisis temporal de redes censurar es una forma de ignorar el comienzo y el final de un vínculo o un nodo. Esta capacidad para ignorar el inicio o el término de un elemento puede ser útil a la hora de modelar tipos específicos de redes temporales, para crear visualizaciones cumulativas o para limpiar tu código, entre otras cosas. Para este tutorial no censuraremos nada [Nota de la T.: para no censurar se indica con la palabra FALSE, y para censurar con la palabra TRUE].\n\nLista de nodos\nEn la mayoría de los análisis de redes estáticas, una lista de nodos es simplemente una lista de todos los elementos que están conectados. Es una lista de identificación por números de cada nodo.\n\n\n  \n    \n      node.id\n    \n    \n      1\n    \n    \n      2\n    \n    \n      3\n    \n    \n      …\n    \n    \n      106\n    \n  \n\n\nEn una red temporal, sin embargo, los actores y los objetos entran y salen de la red todo el tiempo. Puede que nuestros talleres de iluminadores generaran libros preciosos durante dos, cinco o incluso treinta años y medio. Para reflejar el surgimiento y la desaparición de dichos talleres, necesitamos un onset (punto de inicio), un terminus (punto de desaparición), y la duration (duración) de cada uno de ellos. El paquete de R que estamos utilizando espera un conjunto de datos como este:\n\n\n  \n    \n      onset\n      terminus\n      vertex.id\n      onset.censored\n      terminus.censored\n      duration\n    \n  \n  \n    \n      1280.0\n      1311.0\n      1\n      FALSE\n      FALSE\n      31\n    \n    \n      1288.5\n      1311.0\n      2\n      FALSE\n      FALSE\n      22.5\n    \n    \n      1257.5\n      1290.0\n      3\n      FALSE\n      FALSE\n      32.5\n    \n    \n      …\n      …\n      …\n      …\n      …\n      …\n    \n    \n      1267.0\n      1277.0\n      106\n      FALSE\n      FALSE\n      10.0\n    \n  \n\n\nAquí, el segundo taller comienza su actividad alrededor de 1288 y cesa de colaborar sobre 1311, dándole un periodo de vida de unos 22,5 años. Puesto que no tenemos registros de archivo que documenten cuando se formó o disolvió cada taller, estos tres números son una aproximación basada en las fechas asociadas con su primera y su última colaboración en un manuscrito.\n\nTomar decisiones complicadas: convertir datos históricos en un conjunto de datos TNA\nModelar la producción de manuscritos medievales como una red temporal implica adentrarse en el terreno de la aproximación. En este sentido, es bastante frecuente que los historiadores tengan que modelar eventos o procesos históricos como redes dinámicas. Los académicos deben tomar algunas decisiones para modelar datos históricos relativamente directos de alguna forma para que las herramientas de análisis de redes temporales puedan aceptar los datos.\n\nSi estás estudiando una red de correspondencia, tendrás que decidir si el inicio y el término van a representar el comienzo y el final en una serie de intercambios entre dos personas, o el comienzo y el final de un único intercambio. Si te interesan las cartas de forma individual, el inicio podría, teóricamente, representar el momento en que la carta fue comenzada, completada o enviada, mientras que el término podría representar el momento en que fue recibida o leída. Puede que solamente tengas la información de la fecha en que una carta fue escrita, en cuyo caso tendrá que servir tanto de inicio como de término.\n\nComo historiadores, solo podemos ser tan específicos y consistentes como lo sean nuestras fuentes. Una red temporal puede reflejar con más exactitud el proceso histórico revelado en tus fuentes que una red estática, pero en realidad ambos son modelos imperfectos. Tienes que considerar bien tus posibilidades antes de tomar una decisión sobre cómo vas a combinar la complejidad e incertidumbre inherentes a los datos históricos. Es buena idea que tomes nota de estas decisiones y su razonamiento para usar en una sección de metodología, un apéndice o una nota a pie de página cuando presentes tus conclusiones.\n\nLos manuscritos medievales iluminados son un buen ejemplo de cuán complicados son los datos históricos. En algunos casos se puede fechar los manuscritos por un único año en el colofón (una nota breve al comienzo o final del texto sobre la producción del manuscrito). Puede que los historiadores del arte que han dedicado toda su carrera al estudio de estos manuscritos solo se sientan cómodos fechando los manuscritos por décadas (por ejemplo, de la década de 1290) o incluso un tiempo de varias décadas (entre 1275 y 1300). Para el propósito de este tutorial he creado un conjunto de datos temporales haciendo la media de estos rangos de tiempo y usándolos como el inicio de cada colaboración, fijando su término a un año desde el inicio. Esto no es una solución ideal, pero tampoco es arbitraria o injustificable.4\n\nVisualizaciones estáticas\nAhora que tenemos una idea de dónde provienen los datos para la red temporal y cómo está estructurada, podemos empezar a visualizar y analizar la red. Primero cargamos nuestra red como una lista estática de vínculos, a la que hemos llamado VinculosEstaticosPH con sus atributos de vértice asociados, aquí llamados AtributosVerticesPH. Descarga la lista de vínculos estática y cárgala en R usando el comando read.csv() (leer archivo separado por comas). En vez de recordar la ruta al archivo, puedes abrir una ventana que te deje navegar visualmente al archivo usando la función file.choose():\n#Importar datos de red estática\nVinculosEstaticosPH &lt;- read.csv(file.choose())\n\nDespués utiliza la misma función para cargar los atributos de los vértices en R.\nAtributosVerticesPH &lt;- read.csv( file.choose(), stringsAsFactors = FALSE\n)\n\n\nAhora que tenemos los datos básicos en R, podemos ver la red:\n# Hacer y visualizar nuestra red estática\nla_red &lt;- network(\n  VinculosEstaticosPH,\n  vertex.attr = AtributosVerticesPH,\n  vertex.attrnames = c(\"id.vertice\", \"nombre\", \"region\"), directed = FALSE,\n  bipartite = FALSE\n)\nplot(la_red)\n\nEsto debería producir algo parecido a esta imagen - una red de nodos y vínculos que muestra cada taller y colaboración del período de sesenta años capturado en los datos de los manuscritos:\n\n\n    \n\n    Una visualización estática de la red\n\n\n\n\nAhora hagamos nuestra red dinámica. Primero, tenemos que importar los datos temporales asociados con los vínculos dinámicos y los nodos dinámicos.\n# Importar datos temporales de la red\nPHNodosDinamicos &lt;- read.csv(file.choose())\nPHVinculosDinamicos &lt;- read.csv(file.choose())\n\n\nUna vez que hayamos importado los datos temporales, podemos añadirlos a la red estática que habíamos creado más arriba para formar una red dinámica, usando la función networkDynamic() (red dinámica):\n# Crear una red temporal\ncolaboraciones_dinamicas &lt;- networkDynamic(\n  la_red,\n  edge.spells = PHDynamicEdges,\n  vertex.spells = PHDynamicNodes\n)\n\nLa función networkDynamic() toma como su primer argumento la red estática ya creada, y le añade los datos temporales para los vértices y los nodos. Probablemente sea una buena idea comprobar la red dinámica para asegurarse de que todo está correcto mediante la función network.dynamic.check() (comprobar red dinámica).\n# Comprobar los datos en la red temporal\nnetwork.dynamic.check(colaboraciones_dinamicas)\n\nSi todo ha ido bien, mostrará una serie de comprobaciones, todas con el valor TRUE.\n\nAhora que hemos creado una red dinámica ¡podemos convertirla en un gráfico para ver como se ve!\n# Crear gráfico del objeto de red dinámica como imagen estática\nplot(colaboraciones_dinamicas)\n\nEsto produce… algo que, de manera decepcionante, se parece a la red estática de más arriba.\n\n\n    \n\n    Una visualización decepcionante de la red dinámica\n\n\n\n\nEsto es porque la función plot() (gráfico) produce una imagen estática de la red dinámica al completo. Para poder ver las transformaciones temporales dentro de la red, necesitamos usar una visualización diferente que divida la red en partes temporales sucesivas. Una forma de hacer esto es con la función filmstrip() (tira de película).\n# Visualizar nuestra red dinámica como una tira fílmica\nfilmstrip(colaboraciones_dinamicas, displaylabels = FALSE)\n\n[Nota de la T: Aquí indicamos que no muestre las etiquetas mediante displaylabels].\n\n¡Ahora tenemos algo! Esto nos da una muestra de cómo la red se desarrolla a lo largo del tiempo, tomando muestras en algunos momentos clave a lo largo de su vida.\n\n\n    \n\n    Una visualización de la red dinámica en fragmentos\n\n\n\n\nPuesto que, relativamente, las colaboraciones entre talleres era poco frecuente, esta tira fílmica es demasiado escasa para que podamos entender cómo las colaboraciones en la red emergieron y cambiaron durante el tiempo. Para poder ver estos cambios, vamos a utilizar una animación que muestra el intervalo cambiante del período de sesenta años y agrega todas las colaboraciones dentro de ese intervalo.\n\nCrear una animación\nA pesar de que los fenómenos históricos que estamos modelando son continuos, la mayoría de los acercamientos a la visualización y el análisis de redes convierten la red dinámica continuada en una serie de redes estáticas, conocidas como segmentos de redes, que representan el estado acumulado de la red en un espacio temporal concreto - 10 años, o 1 año, o 1 día-. Estas partes pueden estar conectadas de forma secuencial, como fragmentos de una película.\n\nHacer una animación así es algo complicado, así que el paquete NDTV hace el cálculo matemático detrás de dicha animación desde la representación de la animación en sí. Primero, computariza la animación según unos parámetros que le dicen cuándo empezar, parar, cuánto avanzar entre fragmentos, y de cuánto tiempo queremos que esté compuesto cada intervalo. Dependiendo de cuán grande sea tu red, esta función puede tomar un tiempo en ejecutarse.\n# Calcular cómo visualizar una versión animada de la red dinámica\ncompute.animation(\n  colaboraciones_dinamicas,\n  animation.mode = \"kamadakawai\",\n  slice.par = list(\n    start = 1260,\n    end = 1300,\n    interval = 1,\n    aggregate.dur = 20,\n    rule = \"any\"\n    )\n)\n\nVeamos lo que es cada parámetro. Hay unas cuantas formas de ejecutar el diseño de nuestra animación, así que hemos decidido usar un algoritmo de fuerza dirigida conocido como Kamada Kawai.5 Establecemos el año de inicio (start) en 1260 y el de finalización (end) en 1320, y que el intervalo (interval) entre cada animación sean fragmentos de un año. Puesto que las colaboraciones entre talleres es infrecuente o durante un período relativamente corto de tiempo (al menos en nuestra aproximación), hemos agregado los vínculos (aggregate.dur) mostrados en cada fragmento durante un periodo significativo de tiempo, 20 años en este caso.\n\nUna vez que NDTV haya creado la animación, puedes generar una página web con esta animación con la función render.d3movie() (reproducir película). Como la función compute.animation() (ejecutar animación) de arriba, este paso puede tomar algo de tiempo dependiendo del tamaño de tu red.\n#Crear y abrir la animación en un navegador web\nrender.d3movie(\n  colaboraciones_dinamicas,\n  displaylabels = FALSE,\n  # Esta función `slide` crea las etiquetas\n  vertex.tooltip = function(slice) {\n    paste(\n      \"&lt;b&gt;Nombre:&lt;/b&gt;\", (slice %v% \"nombre\"),\n      \"&lt;br&gt;\",\n      \"&lt;b&gt;Región:&lt;/b&gt;\", (slice %v% \"region\")\n    )\n  }\n)\n\nEsto debería generar una página web con una visualización interactiva de tu red temporal y abrirla en tu navegador por defecto. Puede que la consola de R Studio muestre algunos mensajes de aviso, pero estos solo especifican que si hay valores múltiples en los atributos de los vértices, la función render.d3movie() utiliza el primer atributo en el tiempo para cada vértice. Si todo ha ido bien, debería verse así:\n\n\n    \n\n    \n\n\n\n\nLas etiquetas por defecto son simplemente el número de identificación de cada vértice, así que lo hemos desconectado (FALSE). El parámetro vertex.tooltip de esta función puede dar algo de miedo, pero básicamente proporciona a cada fragmento de la animación la información sobre la herramienta correcta para que podamos ver el nombre y la región de cada vértice cuando hacemos clic en ellos.\n\nMás allá de la bola de pelo: la métrica de redes dinámicas\nEsta animación funciona de maravilla para nuestra red de talleres de manuscritos porque es pequeña y las colaboraciones en un tiempo dado fueron escasas. Para comparar diferentes momentos, sin embargo, las métricas cuantificables para la red o para nodos individuales puede ser más útil que una visualización animada.\n\nPuede que queramos saber cuándo surgieron las colaboraciones entre talleres a lo largo de la duración de nuestros datos.\n# Ver gráfico de la formación de vínculos a lo largo del tiempo\nplot(tEdgeFormation(colaboraciones_dinamicas, time.interval = .25))\n\nEl gráfico debería verse así:\n\n\n    \n\n    Formación de vínculos en la red de talleres, 1260-1320\n\n\n\n\nNuestra animación podría darnos una idea intuitiva de que la mayoría de las colaboraciones se dieron entre 1280 y 1300, pero este gráfico de la formación de vínculos proporciona información más concreta. Al establecer el intervalo de muestras cada 6 meses (medio año), podemos ver exactamente cuándo y cómo tuvieron lugar muchas colaboraciones entre los talleres.\n\nCambiar la centralidad\nSi bien no todo lo que se puede hacer con el análisis de redes estáticas se puede replicar con los paquetes para el análisis de redes temporales en R, sí se pueden hacer la mayoría de los cálculos comunes para las propiedades de redes. Al igual que puedes analizar la centralidad a nivel de nodo o del conjunto de una red estática, puedes analizar cómo cambia la centralidad a lo largo del tiempo con el análisis de redes temporal. En vez de estudiar la centralidad de un taller o de un iluminador de manuscritos durante los sesenta años de nuestros datos, puede que tenga sentido investigar cómo cambia la centralidad de la red cada año, o si tus datos son escasos como los nuestros sobre manuscritos, puedes tomar un período de veinte años para ver los cambios.\n\n#Calcular y crear el gráfico de la centralidad de intermediación de la red\nIntermediacionDinamica &lt;- tSnaStats(\n  colaboraciones_dinamicas,\n  snafun = \"centralization\",\n  start = 1260,\n  end = 1320,\n  time.interval = 1,\n  aggregate.dur = 20,\n  FUN = \"betweenness\"\n)\nplot(IntermediacionDinamica, xlab=\"Tiempo\")\n\n\nEsto genera un gráfico de la centralización agregada cambiante de la red, que muestra cómo la centralización intermedia de la red de manuscritos en colaboración alcanza su punto máximo alrededor del año 1280 y cae alrededor de 1300. [Nota de la T.: Añadimos xlab= para cambiar la etiqueta del eje-x o eje horizontal].\n\n\n    \n\n    Centralidad de intermediación de la red de talleres, 1260-1320\n\n\n\n\nTambién es posible calcular y crear el gráfico de la métricas a nivel de nodo a medida que cambian con el tiempo usando la función tSnaStat(), pero es una función computacional intensiva y producirá errores si los nodos aparecen y desaparecen de la red.\n\nPensar en términos temporales: conjuntos alcanzables\nAgregar un componente cronológico a las mediciones de red estática podría ser suficiente para convencerte de que el análisis de la red temporal merece un esfuerzo extra para tu proyecto. Pero el análisis de redes temporal también te permite analizar propiedades que solo ocurren en redes con información temporal.\n\nEn una red temporal, puesto que los nodos y los vínculos aparecen y desaparecen todo el tiempo, puede ser útil saber no sólo cuántos nodos pueden conectarse con un nodo en un momento específico, sino que también podemos saber cuántos nodos estaban o estarán conectados a un nodo concreto a lo largo de la existencia de la red. Estos grupos pasados y futuros son conocidos como conjuntos accesibles hacia atrás y conjuntos alcanzables hacia adelante, respectivamente.\n\nEl tamaño de estos conjuntos añade información importante a los cálculos de centralidad, dependiendo de si un taller vino a ocupar una posición central en la red cerca del comienzo o del final del período que estamos observando, el impacto real que podría haber tenido en la comunidad es totalmente diferente. Puede ser útil pensar en esto en términos epidemiológicos: una persona que se infecta con la enfermedad de una epidemia relativamente pronto podría tener un impacto mucho mayor en su propagación que una persona que se infecta relativamente tarde.\n\nPara analizar nuestra red de talleres de iluminadores, podemos preguntarnos qué talleres pudieron tener un mayor impacto en las modas de producción de manuscritos como consecuencia de su propia colaboración y las colaboraciones entre los iluminadores y los talleres que colaboraron con ellos, etc. Este grupo de todos los talleres e iluminadores que tocaron directa e indirectamente es conocido como el conjunto alcanzable hacia adelante.\n\nPara calcular el tamaño del conjunto alcanzable hacia adelante de cada nodo, podemos usar la función tReach() en nuestra red. Por defecto, esta función calcula el tamaño de un conjunto accesible hacia adelante de un nodo dado, por tanto, para calcular el conjunto hacia atrás simplemente especificamos la dirección con direction = \"bkwd\" (de backward).\n# Calcular y guardar el tamaño de los conjuntos hacia delante y hacia atrás de cada nodo\nconjunto_futuro &lt;- tReach(colaboraciones_dinamicas)\nconjunto_pasado &lt;- tReach(colaboraciones_dinamicas, direction = \"bkwd\")\nplot(conjunto_futuro, conjunto_pasado)\n\nEsto produce un gráfico de los tamaños de los conjuntos accesibles hacia adelante y hacia atrás para cada taller o iluminador. A partir de este gráfico podemos tener una idea de quién estaba en posición de tener un mayor impacto en la red en función del alcance hacia adelante y quién estaba bien conectado con sus predecesores en función de sus colaboraciones.\n\n\n    \n\n    Tamaño de conjuntos accesibles hacia adelante y hacia atrás de talleres/iluminadores\n\n\n\n\nTambién podemos visualizar estos conjuntos utilizando la función tPath() para encontrar la ruta que conecta un nodo concreto a sus conjuntos hacia atrás y hacia adelante, y la función plotPaths() para crear un gráfico donde se represente en el conjunto de la red. En el siguiente ejemplo, vamos a escoger un único taller - el de Hospitaller Master, seleccionado por su identificación de vértice número 3 - y visualizamos su conjunto accesible hacia adelante (con “fwd” de forward).\n\n# Calcular y crear gráfico del conjunto futuro para el nodo nº3 (Hospitaller Master)\nHospitaller_futuro &lt;- tPath(\n  colaboraciones_dinamicas,\n  v = 3,\n  direction = \"fwd\"\n)\nplotPaths(\n  colaboraciones_dinamicas,\n  Hospitaller_futuro,\n  displaylabels = FALSE,\n  vertex.col = \"white\"\n)\n\nEsto produce una visualización del alcance de Hospitaller Master y su taller hacia futuro basado en la cronología de sus colaboraciones.\n\n\n    \n\n    La ruta de acceso hacia delante de Hospitaller Master, con etiquetas del tiempo transcurrido en los vínculos\n\n\n\n\nPodemos ver que Hospitaller Master tenía una posición favorable para tener un impacto considerable en el futuro de la iluminación de manuscritos en la región de París a través de su trabajo colaborativo. Este potencial de impacto se debió no sólo a su posición dentro de la red, sino también al desarrollo de la red en el tiempo.\n\nSi las etiquetas numéricas que muestran el tiempo transcurrido por cada colaboración te molesta, puedes hacerlas transparentes añadiendo  edge.lable.col = rgb (0,0,0,0) (color de la etiqueta del vínculo = valor de color 0) a la función plotPaths().\n\n\n    \n\n    La ruta de acceso hacia delante de Hospitaller Master, sin la etiqueta de los vínculos\n\n\n\n\nSi, por otro lado, nos interesara ver la red de colaboración entre talleres que preparó el camino para el surgimiento de Hospitaller Master, podemos ver su conjunto accesible hacia atrás. Usando tpath() de nuevo, usamos direction = \"bkwd\" y type = \"latest.depart\" para encontrar las rutas formadas por colaboraciones anteriores en manuscritos. Para distinguir visualmente esto de su alcance hacia el futuro, usamos la propiedad path.col para poner en azul las rutas del pasado en vez de rojo.\n\n# Calcular y crear gráfico del conjunto pasado para el nodo nº3 (Hospitaller Master)\nHospitaller_pasado &lt;- tPath(\n  colaboraciones_dinamicas,\n  v = 3,\n  direction = \"bkwd\",\n  type = 'latest.depart'\n)\nplotPaths(\n  colaboraciones_dinamicas,\n  Hospitaller_pasado,\n  path.col = rgb(0, 97, 255, max=255, alpha=166),\n  displaylabels = FALSE,\n  edge.label.col = rgb(0,0,0,0),\n  vertex.col = \"white\"\n)\n\nEl resultado será algo así:\n\n\n    \n\n    La ruta de acceso hacia el pasado de Hospitaller Master\n\n\n\n\nPodemos ver que el conjunto accesible hacia atrás de Hospitaller Master era un grupo central en la comunidad de talleres parisinos. Debido a que este taller participó activamente en producciones colaborativas entre alrededor de 1260 y 1290, durante la primera mitad del período que estamos estudiando, puede que no nos sorprenda del todo que su alcance hacia futuro sea mayor que su alcance hacia el pasado. Sin embargo, dada la centralidad de Hospitaller Master, ambos conjuntos pueden parecer más pequeños de lo esperado.\n\nAl igual que las métricas realizadas con anterioridad a las redes temporales, estas rutas hacia adelante y hacia atrás proporcionan un contrapunto a las métricas de red estáticas. En el caso de los iluminadores franceses del medievo, podríamos observar que algunos talleres con una centralidad relativamente alta tienen conjuntos hacia futuro pequeños pero conjuntos del pasado grandes. Estos iluminadores colaboraron activamente con otros talleres durante el último tercio del período en cuestión. Esto puede ayudarnos a contextualizar cualquier conclusión que extraigamos de su centralidad.\n\nSi ya habíamos observado ciertas características dentro de los manuscritos producidos por Hospitaller Master y sus colaboradores, estos conjuntos nos pueden ayudar a formular nuevas preguntas sobre si él fue el origen de ideas y técnicas innovadoras, o si jugó un papel importante en diseminarlas. Como siempre, es importante tener en cuenta que las métricas de redes como el grado de centralidad y sus alcances representan el potencial de transmisión de ideas y conceptos más que una transmisión concreta como tal.6\n\nConclusión\nVamos a dar un paso atrás y reflexionar sobre lo que hemos aprendido. En este momento tenemos una idea de cómo estructurar los datos de la red temporal y qué tipo de decisiones tenemos que tomar para producirlos. Hemos aprendido a crear visualizaciones dinámicas y estáticas que muestran los cambios de una red en el tiempo. Sabemos que las métricas de redes estáticas, como el alcance, toman diferentes propiedades en el contexto de redes temporales. Podemos ver el tamaño del alcance pasado y futuro de cada nodo en un gráfico y visualizar las rutas que forman estos conjuntos.\n\nSi hay algo que espero que hayas aprendido con este tutorial es la idea de que agregar datos temporales a los nodos y a los vínculos transforma una herramienta general de las ciencias sociales en un método útil para la argumentación histórica. La comparación de estructuras de red y las métricas para comparar intervalos de tiempo les da significación histórica que puede ser difícil o imposible de discernir en los análisis de redes sociales estáticos tradicionales.\n\nEste tutorial ha presentado solo algunas de las muchas herramientas y técnicas que se pueden usar para el análisis de redes temporal. Un área especialmente interesante de este campo es la simulación dinámica que modela la transmisión de algo como, por ejemplo, una enfermedad o una idea entre individuos dentro de una red temporal. Si eso te suena interesante, echa un vistazo al paquete EpiModel (en inglés) u otras herramientas creadas por los epidemiólogos para modelar la difusión dentro de redes dinámicas.\n\nDependiendo de los datos históricos con los que estés trabajando, el análisis de redes temporal te puede ofrecer ideas importantes sobre cómo las propiedades de los nodos, sus vínculos y la red en su conjunto cambian a lo largo del tiempo. Tanto si decides o no dar el salto al análisis de redes temporal, es útil recordar que las redes de todo tipo son fenómenos históricos que emergen, se desarrollan, se transforman más allá de su reconocimiento y desaparecen con el transcurso del tiempo.\n\nLecturas complementarias\nSi has hecho este tutorial pero todavía te sientes más cómodo/a usando una interfaz gráfica de usuario en vez de un entorno de programación como R Studio, hay algunos tutoriales de Gephi que presentan algunos conceptos básicos:\n\n\n  Crear una red dinámica simple (en inglés) de Clément Levallois.\n  Convertir una red con fechas en una red dinámica (en inglés) de Clément Levallois.\n  Ken Cherven hace un buen recorrido por el Análisis de Redes Dinámico con Gephi en su libro Mastering Gephi Network Visualization (2015)\n\n\nSi tienes más ganas de realizar análisis de redes temporal con R, este tutorial (en inglés) de Skye Bender-deMoll explica funciones adicionales y propiedades de los paquetes que hemos usado. Me sirvió como guía para aprender sobre el análisis de redes temporal, inspirándome a escribir este tutorial.\n\nTambién puedes adentrarte en la documentación de los paquetes networkDynamic, TSNA y NDTV.\n\nReferencias\n\n\n  \n    \n      Se pueden representar estos datos en otros formatos (como por ejemplo con una matriz de adyacencia o una lista de adyacencia) pero para el propósito de transformar redes estáticas en dinámicas, conceptualizar y manipular los datos de la red en forma de una lista de nodos y conexiones puede ser más sencillo. &#8617;\n    \n    \n      Estos datos forman la base de un proyecto en el que estoy trabajando con Maeve Doyle, quien me ha ayudado a dar forma y mejorar mi idea sobre el análisis temporal de redes. Provienen de un catálogo multivolumen magnífico de manuscritos franceses góticos, de Alison Stones. Stones, Alison. 2013. Gothic manuscripts: 1260-1320. London: Harvey Miller Publishers. &#8617;\n    \n    \n      Puesto que necesitas conservar datos temporales asociados con cada conexión, convertir una red bimodal a una unimodal para realizar un análisis temporal es algo más complicado que hacer una representación estática de una red bimodal. &#8617;\n    \n    \n      Hay muchas formas de saber cuánta variación se perderá en las diferentes métricas de análisis de la red como consecuencia de esta decisión, pero son algo complicadas para incluirlas aquí. &#8617;\n    \n    \n      Gracias a Rachel Starry por esta referencia, así como a los comentarios a un borrador de este tutorial. Kamada, T., and S. Kawai. 1989. “An Algorithm for Drawing General Undirected Graphs.” Information Processing Letters 31.1: 7-15. &#8617;\n    \n    \n      Recomiendo el excelente ensayo “How Reliable are Centrality Measures for Data Collected from Fragmentary and Heterogeneous Historical Sources? A Case Study” de Marten Düring (en inglés), pues demuestra claramente que los actores históricos que ocupaban posiciones centrales en las redes sociales tenían el potencial de usar sus conexiones o su control sobre las conexiones de otros de maneras únicas, pero no siempre tenían la motivación para hacerlo. Düring, Marten. “How Reliable Are Centrality Measures for Data Collected from Fragmentary and Heterogeneous Historical Sources? A Case Study.” In The Connected Past. Challenges to Network Studies in Archaeology and History, edited by Tom Brughmans, Anna Collar, and Fiona Coward, 85–102. Oxford: Oxford Publishing, 2016. &#8617;\n    \n  \n\n\nAprende a utilizar R para analizar cómo cambian las redes a lo largo del tiempo.\n\n"
  },


  {
    "id": 3,
    "url": "http://localhost:4000/es/lecciones/analisis-voyant-tools",
    "title": "Análisis de corpus con Voyant Tools\n",
    "body": "\nAnálisis de corpus con Voyant Tools\n\n\nContenidos\n\n\n  Análisis de corpus con Voyant Tools    \n      Análisis de corpus\n      Qué aprenderás en este tutorial\n      Creando un corpus en texto plano        \n          1. Buscar textos\n          2. Copiar en editor de texto plano\n          3. Guardar archivo            \n              En Windows:\n              En Mac:\n              En Linux\n            \n          \n        \n      \n      Cargar el corpus\n      Explorando el corpus        \n          Sumario de los documentos: características básicas de tu conjunto de textos            \n              Número de textos, palabras y palabras únicas                \n                  Actividad\n                \n              \n              Extensión de documentos                \n                  Actividad 2\n                \n              \n              Densidad del vocabulario                \n                  Actividad 3\n                \n              \n              Palabras por oración                \n                  Actividad 4\n                \n              \n            \n          \n          Cirrus y sumario: frecuencias y filtros de palabras vacías            \n              Frecuencias sin filtro                \n                  Actividad 5\n                \n              \n              Palabras vacías                \n                  Actividad 6\n                \n              \n              Frecuencias con palabras vacías filtradas                \n                  Actividad 7\n                \n              \n            \n          \n          Términos            \n              Frecuencia normalizada\n              Asimetría estadística\n              Palabras diferenciadas                \n                  Actividad 8\n                \n              \n            \n          \n          Palabras en contexto            \n              Actividad 9\n              Exportando las tablas\n            \n          \n        \n      \n      Respuestas a las actividades        \n          Actividad 1\n          Actividad 2\n          Actividad 3\n          Actividad 4\n          Actividad 5\n        \n      \n      Bibliografía\n      Notas al pie\n    \n  \n\n\nAnálisis de corpus con Voyant Tools\n\nEn este tutorial se aprenderá cómo organizar un conjunto de textos para la investigación; es decir, se aprenderán los pasos básicos de la creación de un corpus. También se aprenderán las métricas principales del análisis cuantitativo de textos. Para este fin, se ensañará a usar una plataforma que no requiere instalación (sólo conexión a Internet): Voyant Tools (Sinclair y Rockwell, 2016). Este tutorial está pensado como un primer paso en una serie cada vez más compleja de métodos de la lingüística de corpus. En este sentido, podría considerarse este texto como una de las opciones para el análisis de corpus que puedes encontrar en PH (ver por ejemplo: “Análisis de corpus con Antconc”).\n\nAnálisis de corpus\n\nEl análisis de corpus es un tipo de análisis de contenido que permite hacer comparaciones a gran escala sobre un conjunto de textos o corpus.\n\nDesde el inicio de la informática, tanto lingüistas computacionales como especialistas de la recuperación de la información han creado y utilizado software para apreciar patrones que no son evidentes en una lectura tradicional o bien para corroborar hipótesis que intuían al leer ciertos textos pero que requerían de trabajos laboriosos, costosos y mecánicos. Por ejemplo, para obtener los patrones de uso y decaimiento de ciertos términos en una época dada era necesario contratar a personas que revisaran manualmente un texto y anotaran cuántas veces aparecía el término buscado. Muy pronto, al observar las capacidades de “contar” que tenían las computadoras, estos especialistas no tardaron en escribir programas que facilitaran la tarea de crear listas de frecuencias o tablas de concordancia (es decir, tablas con los contextos izquierdos y derechos de un término). El programa que aprenderás a usar en este tutorial, se inscribe en este contexto.\n\nQué aprenderás en este tutorial\n\nVoyant Tools es una herramienta basada en Web que no requiere de la instalación de ningún tipo de software especializado pues funciona en cualquier equipo con conexión a Internet.\n\nComo se ha dicho en este otro tutorial, esta herramienta es una buena puerta de entrada a otros métodos más complejos.\n\nAl finalizar este tutorial, tendrás la capacidad de:\n\n\n  Armar un corpus en texto plano\n  Cargar tu corpus en Voyant Tools\n  Entender y aplicar diferentes técnicas de segmentación de corpus\n  Identificar características básicas de tu conjunto de textos:\n    \n      Extensión de los documentos subidos\n      Densidad léxica (llamada densidad de vocabulario en la plataforma)\n      Promedio de palabras por oración\n    \n  \n  Leer y entender diferentes estadísticas sobre los vocablos: frecuencia absoluta, frecuencia normalizada, asimetría estadística y palabras diferenciadas\n  Buscar palabras clave en contexto y exportar los datos y las visualizaciones en diferentes formatos (csv, png, html)\n\n\nCreando un corpus en texto plano\n\nSi bien VoyantTools puede trabajar con muchos tipos de formato (HTML, XML, PDF, RTF, y MS Word), en este tutorial utilizaramos el texto plano (.txt). El texto plano tienen tres ventajas fundamentales: no tiene ningún tipo de formato adicional, no requiere un programa especial y tampoco conocimiento extra. Los pasos para crear un corpus en texto plano son:\n\n1. Buscar textos\nLo primero que debes hacer es buscar la información que te interesa. Para este tutorial, Riva Quiroga y yo preparamos un corpus de los discursos anuales de presidentes de Argentina, Chile, Colombia, México y Perú1 entre 2006 y 2010, es decir dos años antes y después de la crisis económica de 2008. Este corpus ha sido liberado con una licencia Creative Commons CC BY 4.0 y puedes usarlo siempre y cuando cites la fuente usando el siguiente identificador:\n\n\n2. Copiar en editor de texto plano\nUna vez localizada la información, el segundo paso es copiar el texto que te interesa desde la primera palabra dicha hasta la última y guardarla en un editor de texto sin formato. Por ejemplo:\n\n  en Windows podría guardarse en Bloc de Notas\n  en Mac, en TextEdit;\n  y en Linux, en Gedit.\n\n\n3. Guardar archivo\n\nCuando guardes el texto debes considerar tres cosas esenciales:\n\nLo primero es guardar tus textos en UTF-8, que es un formato de codificación estándar para el español y otros idiomas.\n\n\n  ¿Qué es utf-8? Si bien en nuestra pantalla vemos que al teclear una “É” aprece una “É”; para una computadora “É” es una serie de ceros y unos que son interpretados en imagen depiendo del “traductor” o “codificador” que se esté usando. El codificador que contiene códigos binarios para todas los caracteres que se usan en el español es UTF-8. Siguiendo con el ejemplo “11000011”, es una cadena de ocho bits –es decir, ocho espacios de información– que en UTF-8 son interpretados como “É”\n\n\nEn Windows:\n\n\n    \n\n    Guardar en UTF-8 en Windows: 1) Abrir Bloc de Notas, 2) Después de pegar o escribir el texto, dar clic en ‘Guardar como’ 3) En la ventana de ‘codificiación’ seleccionar ‘UTF-8’ 4) Elegir nombre de archivo y guardar como .txt (Torresblanca, 2014)\n\n\n\n\nEn Mac:\n\n\n    \n\n    Guardar en UTF-8 en Mac: 1) Abrir TextEdit 2) Pegar el texto que se desea guardar 3) Convertir a texto plano (opcin en el menú de ‘Formato’) 4) Al guardar, seleccionar el encoding ‘UTF-8’ (Creative Corner, 2016)\n\n\n\n\nEn Linux\n\n\n    \n\n    Guardar en UTF-8 en Ubuntu: 1) Abrir Gedit 2) Después de pegar el texto, al guardar, seleccionar ‘UTF-8’ en la ventana de ‘Codificación de caracteres’\n\n\n\n\nLa segunda es que el nombre de tu archivo no debe contener acentos ni espacios, esto asegurará que pueda ser abierto en otros sistemas operativos\n\n\n  ¿Por qué evitar acentos y espacios en los nombres de archivo? Por razones similares a el inciso anterior, un archivo que se llame Ébano.txt no siempre será entendido de forma correcta por todos los sistemas operativos pues varios tienen otro codificador por defecto. Muchos usan ASCII, por ejemplo, que sólo tiene siete bits de manera que el último bit (1) de “11000011” es interpretado como el inicio del siguiente caracter y se descuadra la interpretación.\n\n\nLa tercera es integrar metadatos de contexto (v.g. fecha, género, autor, origen) en el nombre del archivo que te permitan partir tu corpus según diferentes criterios y también leer mejor los resultados. Para este tutorial hemos nombrado los archivos con el año del discurso presidencial, el\ncódigo del país (ISO 3166-1 alfa-2) y el apellido de quien profirió el discurso.\n\n\n  2007_mx_calderon.txt tiene el año del discurso dividido con un guión bajo, el código de dos letras del país (México = mx) y el apellido del presidente que dictó el discurso, Calderón, (sin acentos ni eñes)\n\n\nCargar el corpus\n\nEn la página de entrada de Voyant Tools encontrarás cuatro opciones sencillas para cargar textos.2 Las dos primeras opciones están en el cuadro blanco. En este cuadro puedes pegar directamente un texto que hayas copiado de algún lugar; o bien, pegar direcciones web –separadas por comas– de los sitios en donde se encuentren los textos que quieres analizar.\nUna tercera opción es dar clic en “Abrir” y seleccionar alguno de los dos corpus que Voyant tiene precargados (las obras de Shakespeare o las novelas de Austen: ambos en inglés).\n\nPor último, está la opción que usaremos en este tutorial, en la que puedes cargar directamente los documentos que tengas en tu computadora. En este caso subiremos el corpus completo de discursos presidenciales.\n\nPara cargar los materiales pulsa sobre el icono que dice “Cargar”, abre tu explorador de archivos y, dejando presionada la tecla ‘Shift’ selecciona todos los archivos que deseas analizar.\n\n\n    \n\n    Cargar documentos\n\n\n\n\nExplorando el corpus\n\nUna vez cargados todos los archivos llegarás a la ‘interfaz’ (‘skin’) que tiene cinco herramientas por defecto. A continuación, una breve explicación de cada una de estas herramientas:\n\n\n  Cirrus: nube de palabras que muestra los términos más frecuentes\n\n\n\n    \n\n    Cirrus\n\n\n\n\nLector: espacio para la revisión y lectura de los textos completos con una gráfica de barras que indica la cantidad de texto que tiene cada documento\n\n\n    \n\n    Lector\n\n\n\n\n\n  Tendencias: gráfico de distribución que muestra los términos en todo el corpus (o dentro de un documento cuando sólo se carga uno)\n\n\n\n    \n\n    Tendencias\n\n\n\n\n\n  Sumario: proporciona una visión general de ciertas estadísticas textuales del corpus actual\n\n\n\n    \n\n    Sumario\n\n\n\n\n\n  Contextos: concordancia que muestra cada ocurrencia de una palabra clave con un poco de contexto circundante\n\n\n\n    \n\n    Contextos\n\n\n\n\nSumario de los documentos: características básicas de tu conjunto de textos\n\nUna de las ventanas más informativas de Voyant es la del sumario. Aquí obtenemos una vista de pájaro sobre algunas estadísticas de nuestro corpus por lo que funciona como un buen punto de partida. En las siguientes secciones obtendrás una explicación de las diferentes medidas que aparecen en esta ventana.\n\nNúmero de textos, palabras y palabras únicas\nLa primera frase que leemos se ve algo como esto:\n\n\n  Este corpus tiene 25 documentos con 261,032  total de palabras y 18,550 formulario de palabra única. Creado  hace 8 horas atrás [el texto es producto de una traducción semi-automática del inglés y por eso se lee raro]\n\n\nDe entrada con esta información sabemos exactamente cuántos documentos distintos fueron cargados (25); cuántas palabras hay en total (261,032); y cuántas palabras únicas existen (18,550).\n\n\n  En las siguientes líneas encontrarás nueve actividades que pueden ser resueltas en grupos o individualmente. Cinco de ellas tienen respuestas al final del texto para servir de guía. Las últimas cuatro están abiertas a la reflexión/discusión de quienes las lleven a cabo\n\n\nActividad\n\nSi nuestro corpus estuviera compuesto de dos documentos; uno que dijera: “tengo hambre”; y otro que dijera: “tengo sueño”. ¿Qué información aparecería en la primera línea del sumario? Completa:\n\nEste corpus tiene _ documentos con un total de palabras de _ y _ palabras únicas.\n\nExtensión de documentos\nLo segundo que vemos es la sección de “extensión del documento”. Ahí aparece lo siguiente:\n\n\n  Más largo:  2008_cl_bachelet (20702);  2007_ar_kircher (20390);  2006_ar_kircher (18619);  2010_cl_pinera (16982);  2007_cl_bachelet (15514)\n  Más corto:  2006_pe_toledo (1289);  2006_mx_fox (2450);  2008_mx_calderon (3317);  2006_co_uribe (4709);  2009_co_uribe (5807)\n\n\nActividad 2\n\n  ¿Qué podemos concluir sobre los textos más largos y los más cortos considerando los metadatos en el nombre del archivo (año, país, presidente)?\n  ¿Para qué nos sirve saber la longitud de los textos?\n\n\nDensidad del vocabulario\n\nLa densidad de vocubulario se mide dividiendo el número de palabras únicas entre el número de palabras totales. Entre más cercano a uno es el índice de densidad quiere decir que el vocabulario tiene mayor variedad de palabras, es decir, que es más denso.\n\nActividad 3\n\n1) Calcula la densidad de las siguientes estrofas, compara y comenta:\n\n\n  Estrofa 1. De “Hombres necios que acusáis” de Sor Juana Inés de la Cruz\n    \n      ¿Qué humor puede ser más raro\nque el que, falto de consejo,\nél mismo empaña el espejo,\ny siente que no esté claro?\n    \n  \n  Estrofa 2. De “Despacito” de Erika Ender, Luis Fonsi y Daddy Yankee\n    \n      Pasito a pasito, suave suavecito\nNos vamos pegando poquito a poquito\nCuando tú me besas con esa destreza\nVeo que eres malicia con delicadeza\n    \n  \n\n\n2) Lee los datos de densidad léxica de los documentos de nuestro corpus, ¿qué te dicen?\n\n\n  Más alto:  2006_pe_toledo (0.404);  2006_co_uribe (0.340);  2009_co_uribe (0.336);  2008_co_uribe (0.334);  2006_mx_fox (0.328)\n  Más bajo:  2008_cl_bachelet (0.192);  2007_mx_calderon (0.192);  2007_ar_kircher (0.206);  2007_pe_garcia (0.214);  2010_ar_fernandez (0.217)\n\n\n3) Compáralos con la información sobre su extensión, ¿qué notas?\n\nPalabras por oración\n\nLa forma en que Voyant calcula la longitud de las oraciones debe considerarse muy aproximada, especialmente por lo complicado que es distinguir entre el final de una abreviatura y el de una oración o de otros usos de la puntuación (por ejemplo, en algunos casos un punto y coma marca el límite entre oraciones). El análisis de las oraciones es realizado por una plantilla con instrucciones o ‘clase’ del lenguaje de programación Java que se llama BreakIterator.\n\nActividad 4\n\n1) Observa las estadísticas de palabras por oración (ppo) y contesta: ¿qué patrón o patrones puedes observar si consideras el índice de “ppo” y los metadatos de país, presidente y año contenidos en el nombre del documento?\n\n2) Da clic sobre los nombre de algunos documentos que te interesen por su índice de “ppo”. Dirige tu mirada a la ventana de “Lector” y lee algunas líneas, ¿leer el texto original agrega información nueva a tu lectura de los datos? Comenta por qué.\n\nCirrus y sumario: frecuencias y filtros de palabras vacías\n\nYa que tenemos una idea de algunas características globales de nuestros documentos, es momento de que empecemos con las características de los términos en nuestro corpus y uno de los puntos de entrada más comunes es entender qué significa analizar un texto a partir de sus frecuencias.\n\nFrecuencias sin filtro\n\nEl primer aspecto con el que vamos a trabajar es con el de frecuencia bruta y para esto utilizaremos la ventana de Cirrus.\n\nActividad 5\n\n1) ¿Qué palabras son las más frecuente en el corpus?\n\n2) ¿Qué nos dicen estas palabras del corpus?, ¿son significativas todas?\n\n\n  Tip pasa el mouse sobre las palabras para obtener sus frecuencias derecho\n\n\nPalabras vacías\nLa importancia no es un valor intrínseco y dependerá siempre de nuestros intereses. Justo por eso Voyant ofrece la opción de filtrar ciertas palabras. Un procedimiento común para obtener palabras relevantes es el de filtrar las unidades léxicas gramaticales o palabras vacías: artículos, preposiciones, interjecciones, pronombres, etc. (Peña y Peña, 2015).\n\nActividad 6\n\n1) ¿Qué palabras vacías están en la nube de palabras?\n\n2) ¿Cuáles eliminarías y por qué?\n\nVoyant tiene ya cargada una lista de stop words o palabras vacías del español; no obstante, nosotros podemos editarla de la siguiente manera:\n1) Colocamos nuestro cursor enor superior derecha de la ventana de Cirrus y damos clic sobre el icono que parece un interruptor.\n\n\n    \n\n    Abrir opciones\n\n\n\n\n2) Aparecerá una ventana con diferentes opciones, seleccionamos la primera “Editar lista”\n\n\n    \n\n    Editar lista\n\n\n\n\n3) Agregamos las palabras “vacías”, siempre separadas por un salto de línea (tecla enter)\n\n\n    \n\n    Quitar palabras vacías\n\n\n\n\n4) Una vez que hayamos añadido las palabras que deseamos filtrar damos clic en “salvar” (sic).\n\n\n  Cuidado: por defecto está seleccionada una caja que dice “Aplicar a todo”; si ésta se deja seleccionada el filtrado de palabras afectará las métricas de todas las otras herramientas. Es muy importante que documentes tus decisiones. Una buena práctica es guardar la lista de palabras vacías en un archivo de texto (.txt) Para este tutorial hemos creado una lista de palabras para filtrar y la puedes usar si así lo quieres, sólo recuerda que esto afectará tus resultados. Por ejemplo: en la lista de palabras filtradas incluí “todas” y “todos”, habrá personas para las que estas palabras podrían ser interesantes dado que muestran que “todos” es mucho más utilizado que “todas” y esto podría darnos pistas sobre el uso de lenguaje incluyente.\n\n\nFrecuencias con palabras vacías filtradas\nVolvamos entonces a esta sección del sumario. Como dijimos en el iniciso anterior las palabras filtradas afectan otros campos de Voyant. En este caso, si dejaste seleccionada la caja de “Aplicar a todo”, en la lista que aparece debajo de la leyenda: Palabra más frecuente en el corpus , se mostrarán las palabras que se repiten más sin contar aquéllas que fueron filtradas. En mi caso, muestra:\n\n\n  social (437); nacional (427); nuestro (393); inversión (376); ley (369)\n\n\nActividad 7\n\n\n  \n    Reflexiona sobre estas palabras y piensa qué información te proporcionan y cómo se distingue esta información de la que obtienes viendo la nube de palabras.\n  \n  \n    Si estás en un grupo discute las diferencias de tus resultados con los de los demás\n  \n\n\nTérminos\n\nSi bien las frecuencias pueden decirnos algo sobre nuestros textos, existen muchas variables que pueden hacer que estos números sean poco significativos. En los siguientes apartados se explicarán diferentes estadísticas que pueden obtenerse en la pestaña o solapa de “Términos” que está a la izquierda del botón de “Cirrus” en la disposición default de Voyant.\n\nFrecuencia normalizada\n\nEn el apartado anterior hemos observado la “frecuencia bruta” de las palabras. Sin embargo, si tuviéramos un corpus de seis palabras y otro de 3,000 palabras, las frecuencias brutas son poco informativas. Tres palabras en un corpus de seis palabras representa 50% del total, tres palabras en un corpus de 6,000 representan el 0.1% del total.\nPara evitar la sobre-representación de un término, los lingüistas han ideado otra medida que se llama: “frecuencia relativa normalizada”.\nÉsta se calcula de la siguiente manera:\nFrecuencia Bruta * 1,000,000 / Número total de palabras.\nAnalicemos un verso como ejemplo. Tomemos la frase: “pero mi corazón dice que no, dice que no”, que tiene ocho palabras en total. Si calculamos su frecuencia bruta y relativa tenemos que:\n\n\n  \n    \n      palabra\n      frecuencia bruta\n      frecuencia normalizada\n    \n  \n  \n    \n      corazón\n      1\n      1*1,000,000/8 = 125,000\n    \n    \n      dice\n      2\n      2*1,000,000/8 = 111,000\n    \n  \n\n\n¿Cuál es la ventaja de esto? Que si tuviéramos un corpus en el que la palabra corazón tuviera la misma proporción, por ejemplo 1,000 ocurrencias entre 8,000 palabras; si bien la frecuencia bruta es muy distinta, la frecuencia normalizada sería la misma, pues 1,000*1,000,000/8,000 también es 125,000.\n\nVeamos cómo funciona esto en Voyant Tools:\n\n  En la sección de Cirrus (la nube de palabras), damos clic sobre ‘Terms’ o ‘Términos’. Esto abrirá una tabla que por defecto tiene tres columnas: Términos (con la lista de palabras en los documentos, sin las filtradas), Contar (con la ‘frecuencia bruta o neta’ de cada término) y Tendencia (con una gráfica de la distribución de una palabra tomando su frecuencia relativa). Para obtener información sobre la frecuencia relativa de un término, en la barra de los nombres de columna, en el extremo derecho, se da clic sobre el triángulo que ofrece más opciones y en ‘Columnas’ se selecciona la opción ‘Relativo’ como se muestra en la imagen a continuación:\n\n\n\n    \n\n    Frecuencia relativa\n\n\n\n\n\n  Si ordenas las columnas en orden descendiente como lo harías en un programa de hojas de cálculo, observarás que el orden de la frecuencia bruta (‘Contar’) y la frecuencia relativa (‘Relativo’) el orden es el mismo. ¿Para qué nos sirve entonces esta medida? Para cuando comparamos diferentes corpus. Un corpus es un conjunto de textos con algo en común. En este caso, Voyant está interpretando todos los discursos como un solo corpus. Si quisiéramos que cada cada país fuera un corpus distinto, tendríamos que guardar nuestro texto en una tabla, en HTML o en XML, donde los metadatos estuvieran expresados en columnas (en el caso de la tabla) o en etiquetas (en el caso de HTML o XML).3\n\n\nAsimetría estadística\n\nAunque la frecuencia relativa no sirve para entender la distribución de nuestro corpus, existe una medida que sí nos da información sobre qué tan constante es un término a lo largo de nuestros documentos: la asimetría estadística.\n\nEsta medida nos da una idea de la distribución de probabilidad de una variable sin tener que hacer su representación gráfica. La forma en que se calcula es observando las desviaciones de una frecuencia con respecto a la media, para obtener si son mayores las que ocurren a la derecha de la media (asimetría negativa) que las de la izquierda (asimetría positiva). Entre más cercano a cero sea el grado de la asimetría estadística, significa que la distribución de ese término es más regular (es decir que ocurre con una media muy similar en todos los documentos). Algo que no es muy intuitivo es que si un término tiene una asimetría estadística con números positivos significan que ese término está por debajo de la media, y entre más grande el número más asimétrico es el término (es decir, que ocurre muchísimo en un documento pero que casi no ocurre en el corpus). Los números negativos, por el contrario, indican que ese término tiende a estar por arriba de la media.\n\n\n    \n\n    Asimetría estadística\n\n\n\n\nPara obtener esta medida en Voyant, tenemos que repetir los pasos que hicimos para obtener la frencuencia relativa, pero esta vez seleccionar “Oblicuidad” (“Skew”).  Esta medida nos permite observar entonces, que la palabra “crisis” por ejemplo, a pesar de tener una alta frecuencia, no sólo no tiene una frecuencia constante a lo largo del corpus, sino que ésta tiende a estar por debajo de la media pues su asimetría estadística es positiva (1.9).\n\nPalabras diferenciadas\n\nComo tal vez ya sospechas, la información más interesante generalmente no se encuentra dentro de las palabras más frecuentes, pues éstas tienden a ser también las más evidentes. En el campo de la recuperación de la información se han inventado otras medidas que permiten ubicar los términos que hacen que un documento se distinga de otro. Una de las medidas más usadas se llama tf-idf (del inglés term frequency – inverse document frequency). Esta medida busca expresar numéricamente qué tan relevante es un documento en una colección determinada; es decir, en una colección de textos sobre “manzanas” la palabra manzana puede ocurrir muchas veces, pero no nos dicen nada nuevo sobre la colección, por lo que no queremos saber la frecuencia bruta de las palabras (term frequency, frecuencia de término) pero sopesarla en qué tan única o común es en la colección dada (inverse document frequency, frecuencia inversa de documento).\n\nEn Voyant el tf-idf se calcula de la siguiente manera:\n\nFrecuencia Bruta  (tf) / Número de Palabras (N)  * log10 ( Número de Documentos / Número de veces que aparece el término en los documentos)\n\n\n    \n\n    Fórmula de TF-IDF\n\n\n\n\nActividad 8\n\nObserva las palabras diferenciadas  (comparado con el resto del corpus) de cada uno de los documentos y anota qué hipótesis puedes derivar de ellas\n\n\n  2006_ar_kircher:  uruguay  (12),  2004  (13),  2005  (31),  plata  (7),  inclusión  (16).\n  2006_cl_bachelet:  innovación  (15),  rodrigo  (8),  alegremente  (4),  barrios  (9),  cobre  (10).\n  2006_co_uribe:  tutela  (5),  reelección  (6),  regalías  (7),  iva  (6),  publicación  (5).\n  2006_mx_fox:  atenta  (5),  apego  (5),  federalismo  (3),  intransigencia  (2),  fundamento  (3).\n  2006_pe_toledo:  entrego  (5),  señor  (14),  señora  (5),  amigo  (5),  tracemos  (2).\n  2007_ar_kircher:  2006  (65),  mercosur  (12),  uruguay  (9),  provincias  (16),  interanual  (5).\n  2007_cl_bachelet:  macrozona  (7),  deudores  (12),  cuna  (9),  subvención  (10),  pesimismo  (4).\n  2007_co_uribe:  guerrilla  (10),  sindicalistas  (7),  paramilitares  (8),  inversionista  (10),  despeje  (7).\n  2007_mx_calderon:  igualar  (9),  transformar  (19),  tortilla  (4),  acuíferos  (4),  miseria  (10).\n  2007_pe_garcia:  huancavelica  (9),  redistribución  (10),  callao  (8),  407  (4),  lima  (7).\n  2008_ar_fernandez:  abordar  (17),  capítulo  (12),  presupone  (5),  lesa  (8),  articular  (5).\n  2008_cl_bachelet:  desafío  (18),  mirada  (10),  aprobamos  (6),  adulto  (6),  diez  (11).\n  2008_co_uribe:  ecopetrol  (6),  revaluación  (4),  juegos  (4),  desatrasar  (3),  billones  (6).\n  2008_mx_calderon:  cártel  (5),  noches  (3),  mexicanas  (6),  controlaba  (3),  federales  (6).\n  2008_pe_garcia:  poblados  (11),  kilómetros  (52),  lima  (11),  carreteras  (21),  mineros  (4).\n  2009_ar_fernandez:  sosteniendo  (7),  dirigencia  (5),  coparticipación  (6),  catamarca  (7),  pbi  (9).\n  2009_cl_bachelet:  sello  (5),  fortalecidos  (5),  crisis  (48),  gente  (24),  aplauso  (4).\n  2009_co_uribe:  colombia  (20),  calzada  (6),  contributivo  (5),  desplazados  (6),  notificado  (3).\n  2009_mx_calderon:  federal  (27),  organizado  (10),  cambiar  (13),  propongo  (8),  policiacos  (4).\n  2009_pe_garcia:  lima  (11),  1,500  (6),  tingo  (4),  pampas  (4),  desorden  (6).\n\n\nPalabras en contexto\n\nEl proyecto con el que algunas historias dan por inauguradas las Humanidades Digitales es el Index Thomisticus, una concordancia de la obra de Tomás de Aquino liderada por el filólogo y religioso Roberto Busa (Hockey, 2004), en la que participaron decenas de mujeres en la codificación (Terras, 2013). Este proyecto que tomó años en completarse, es una función integrada en Voyant Tools: en la esquina inferior derecha, en la ventana de “Contextos” es posible hacer consultas de las concordancias izquierdas y derechas de términos específicos.\n\nLa tabla que vemos tiene las siguientes columnas predeterminadas:\n\n\n  Documento: aquí aparece el nombre del documento en el que ocurre(n) la(s) palabra(s) clave(s)  de la consulta\n  Izquierda: contexto izquierdo de la palabra clave (este puede ser modificado para abarcar más palabras o menos y si se da clic sobre la celda, ésta se expande para mostrar más contexto)\n  Términos: palabra(s) clave(s) de la consulta\n  Derecha: contexto derecho\n\n\nSe puede añadir la columna Posición que indica el lugar en el documento en el que se encuentra el término consultado:\n\n\n    \n\n    Agregar columna de posición\n\n\n\n\n\n  Consulta avanzada Voyant permite el uso de comodines para buscar variaciones de una palabra. Estas son algunas de las combinaciones\n  \n    famili&ast;: esta consulta arrojará todas las palabras que empiecen con el prefijo “famili” (familias, familiares, familiar, familia)\n    &ast;ción: términos que terminan con el sufijo “ción” (contaminación, militarización, fabricación)\n    pobreza, desigualdad: puedes buscar más de un término separándolos por comas\n    “contra la pobreza”: buscar la frase exacta\n    “pobreza extrema”~ 5:  buscar los términos dentro de las comillas, el orden no importa, y pueden haber hasta 5 palabras de por medio (esa condición regresaría frases cómo “la extrema desigualdad y la pobreza” donde se encuentra la palabra “pobreza” y “extrema”\n  \n\n\nActividad 9\n\n  Busca el uso de algún término que te parezca interesante, utiliza alguna de las estrategias de la consulta avanzada\n  Ordena las filas usando las diferentes columnas (Documento, Izquierda, Derecha y Posición): ¿qué conclusiones puedes derivar sobre tus términos utilizando la información de estas columnas?\n\n\n\n  Cuidado: el orden de las palabras en la columna “Izquierda” es inverso; es decir, de derecha a izquierda desde la palabra clave.\n\n\nExportando las tablas\nPara exportar los datos se da clic en el cuadro con flecha que aparece cuando pasas el cursor sobre la esquina derecha de “Contextos”. En seguida se selecciona la opción “Exportar datos actuales” y se da clic sobre la última opción Export all available data as tab separated values (text)grid.\n\nEso lleva a una página donde están separados los campos por un tabulador:\n\n\n    \n\n    Exportar contextos\n\n\n\n\nSelecciona todos los datos (Ctrl+A o Ctrl+E); copiálos (Ctrl+C) y pégalos en una hoja de cálculo (Ctrl+V). Si esto no funciona, guarda los datos como en un editor sencillo de texto como .txt (¡no olvides la codificación UTF-8!) y luego en tu hoja de cálculo importa los datos. En Excel esto se hace en la pestaña de “Datos” y después “Desde un archivo de texto”\n\n\n    \n\n    Importar datos desde un archivo de textos\n\n\n\n\nRespuestas a las actividades\n\nActividad 1\n\nEste corpus tiene 2 documentos con un total de palabras de 4 y 3 palabras únicas (tengo, hambre, sueño)\n\nActividad 2\n\n1) Podríamos observar, por ejemplo, que los textos más largos son de dos países: Chile y Argentina, y de tres presidentes distintos: Kirchner, Bachelet y Pinera. Sobre los más cortos podríamos ver que si bien el más corto es de Perú, en realidad los que más aparecen entre los breves son los de México y Colombia.\n\n2) Saber la extensión de nuestros textos nos permite entender la homogeneidad o disparidad de nuestro corpus, así como entender ciertas tendencias (por ejemplo, en qué años tendían a ser más cortos los discursos, en qué momento cambió la extensión, etc.)\n\nActividad 3\n\n1) La primera estrofa tiene 23 palabras y 20 son palabras únicas, por lo que 20/23 da igual a una densidad de vocabulario de 0.870; en realidad de 0.869 pero Voyant Tools redondea estos números: https://voyant-tools.org/?corpus=b6b17408eb605cb1477756ce412de78e. La segunda estrofa tiene 24 palabras y 20 son palabras únicas, por lo que 20/24 da igual a una densidad de vocabulario de 0.833: https://voyant-tools.org/?corpus=366630ce91f54ed3577a0873d601d714.\n\nComo podemos observar la diferencia entre un verso de Sor Juana Inés de la Cruz y otro compuesto por Érika Ender, Daddy Yankee y Luis Fonsi tienen una diferencia de densidad de 0.037, que no es muy alto. Debemos tener cuidado al interpretar estos números pues sólo son un indicador cuantitativo de la riqueza del vocabulario y no incluye parámetros como la complejidad de la rima o de los términos.\n\nParece haber una correspondencia entre los discursos más cortos y los más densos, esto es natural pues entre más breve es un texto menos “oportunidad” hay para repetirse. No obstante, esto también podría decirnos algo sobre los estilos de diferentes países o presidentes. Entre menos densidad es más probable que recurran a más recursos retóricos.\n\nActividad 4\n\nEstos resultados parecen indicar que la presidenta Kirchner, además de tener los discursos más largos es la que hace frases más largas; sin embargo tenemos que tener cuidado con las conclusiones de este tipo pues se trata de discursos orales en los que la puntuación depende de quien transcribe el texto.\n\nActividad 5\n\n  a (5943); más (1946); no (1694); mil (1045); millones (971)\n  La primera palabra es una preposición, la segunda un adverbio de comparición y la tercera un adverbio de negación. Estas palabras podrían ser significativas si lo que se busca comprender es el uso de este tipo de palabras funcionales. Sin embargo, si lo que se  busca son más bien sustantivos, habrá que hacer un filtrado (ver sección: “Palabras más frecuentes”)\n\n\nBibliografía\n\nHockey, Susan. 2004 “The History of Humanities Computing”. A Companion to Digital Humanities. Schreibman et al. (editores). Blackwell Publishing Ltd. doi:10.1002/9780470999875.ch1.\n\nPeña, Gilberto Anguiano, y Catalina Naumis Peña. 2015. «Extracción de candidatos a términos de un corpus de la lengua general». Investigación Bibliotecológica: Archivonomía, Bibliotecología e Información 29 (67): 19-45. https://doi.org/10.1016/j.ibbai.2016.02.035.\n\nSinclair, Stéfan and Geoffrey Rockwell, 2016.  Voyant Tools. Web. http://voyant-tools.org/.\n\nTerras, Melissa, 2013. “For Ada Lovelace Day – Father Busa’s Female Punch Card Operatives”. Melissa Terras’ Blog. Web. http://melissaterras.blogspot.com/2013/10/for-ada-lovelace-day-father-busas.html.\n\n\nEste tutorial fue escrito gracias al apoyo de la Academia Británica y preparado durante el Taller de escritura de The Programming Historian en la Universidad de los Andes en Bogotá, Colombia, el del 31 de julio al 3 de agosto de 2018.\n\n\nNotas al pie\n\n  \n    \n      Los textos de Perú fueron recopilados por a Pamela Sertzen &#8617;\n    \n    \n      Existen formas más complejas para cargar el corpus que puedes consultar en la documentación en inglés. &#8617;\n    \n    \n      Para más información, consulta la documentación en inglés. &#8617;\n    \n  \n\n\nEn este tutorial se aprenderá cómo organizar y analizar un conjunto de textos con Voyant-Tools.\n\n"
  },


  {
    "id": 4,
    "url": "http://localhost:4000/es/lecciones/contar-frecuencias",
    "title": "Contar frecuencias de palabras con Python",
    "body": "\nContar frecuencias de palabras con Python\n\nContenidos\n\n\n  Objetivo de la lección    \n      Archivos necesarios para esta lección\n    \n  \n  Frecuencias\n  Diccionarios de Python\n  Los pares palabra-frecuencia\n  Retirar palabras vacías\n  Ensamblar todo\n  Notas sobre las palabras en español\n  Lecturas sugeridas    \n      Sicronización de código\n    \n  \n\n\nObjetivo de la lección\n\nTu lista ahora está lo suficientemente limpia para comenzar a analizar su contenido de una manera útil. Contar la frecuencia de palabras específicas en la lista puede proveernos con datos ilustrativos. Python posee una manera fácil de contar frecuencias, pero requiere el uso de un nuevo tipo de variable: el diccionario. Antes de comenzar a trabajar en un diccionario, considera los procesos utilizados para calcular las frecuencias en una lista.\n\nArchivos necesarios para esta lección\n\n\n  obo.py\n\n\nSi no tienes este archivo puedes descargar un archivo zip que contiene el código de las lecciones previas de esta serie.\n\nFrecuencias\n\nAhora queremos contar la frecuencia de cada palabra en nuestra lista. Ya has visto que es fácil procesar una lista utilizando un bucle for. Intenta guardar y ejecutar el ejemplo siguiente. Recuerda que += le indica al programa que añada algo al final de una variable existente.\n\n# cuenta-elementos-de-lista-1.py\n\ncadenaPalabras = 'it was the best of times it was the worst of times '\ncadenaPalabras += 'it was the age of wisdom it was the age of foolishness'\n\nlistaPalabras = cadenaPalabras.split()\n\nfrecuenciaPalab = []\nfor w in listaPalabras:\n    frecuenciaPalab.append(listaPalabras.count(w))\n\nprint(\"Cadena\\n\" + cadenaPalabras +\"\\n\")\nprint(\"Lista\\n\" + str(listaPalabras) + \"\\n\")\nprint(\"Frecuencias\\n\" + str(frecuenciaPalab) + \"\\n\")\nprint(\"Pares\\n\" + str(list(zip(listaPalabras, frecuenciaPalab))))\n\n\nAquí, comenzamos con una cadena de texto y la dividimos en una lista tal como hicimos antes. Entonces, creamos una lista (inicialmente vacía) llamada frecuenciaPalab, fuimos por cada una de las palabras en listaPalabras y contamos el número de veces que cada palabra aparece en toda la lista. Añadimos entonces el conteo de palabras a nuestra lista frecuenciaPalab. Utilizando la operación zip, somos capaces de hacer coincidir la primera palabra de nuestra lista de palabras con el primer número en la lista de frecuencias, la segunda palabra con la segunda frecuencia, y así el resto. Terminamos con una lista de palabras y frecuencias pareadas. La función str convierte cualquier objeto en una cadena así que puede ser impresa.\n\nDebes obtener algo como esto:\n\n\nCadena\nit was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness\n\nLista\n['it', 'was', 'the', 'best', 'of', 'times', 'it', 'was',\n'the', 'worst', 'of', 'times', 'it', 'was', 'the', 'age',\n'of', 'wisdom', 'it', 'was', 'the', 'age', 'of',\n'foolishness']\n\nFrequencias\n[4, 4, 4, 1, 4, 2, 4, 4, 4, 1, 4, 2, 4, 4, 4, 2, 4, 1, 4,\n4, 4, 2, 4, 1]\n\nPares\n[('it', 4), ('was', 4), ('the', 4), ('best', 1), ('of', 4),\n('times', 2), ('it', 4), ('was', 4), ('the', 4),\n('worst', 1), ('of', 4), ('times', 2), ('it', 4),\n('was', 4), ('the', 4), ('age', 2), ('of', 4),\n('wisdom', 1), ('it', 4), ('was', 4), ('the', 4),\n('age', 2), ('of', 4), ('foolishness', 1)]\n\n\nTe retribuirá estudiar el código anterior hasta entenderlo antes de seguir adelante.\n\nPython incluye también una herramienta muy conveniente llamada lista por comprensión (list comprehension), que puede ser utilizada para hacer lo mismo que hace el bucle for, pero de manera más económica.\n\n# cuenta-elementos-de-lista-1.py\n\ncadenaPalabras = 'it was the best of times it was the worst of times '\ncadenaPalabras += 'it was the age of wisdom it was the age of foolishness'\nlistaPalabras = cadenaPalabras.split()\n\nfrecuenciaPalab = [listaPalabras.count(w) for w in listaPalabras] # a list comprehension\n\nprint(\"Cadena\\n\" + cadenaPalabras +\"\\n\")\nprint(\"Lista\\n\" + str(listaPalabras) + \"\\n\")\nprint(\"Frecuencias\\n\" + str(frecuenciaPalab) + \"\\n\")\nprint(\"Pares\\n\" + str(list(zip(listaPalabras, frecuenciaPalab))))\n\n\nSi estudias esta lista por comprensión cuidadosamente descubrirás que hace exactamente lo mismo que el bucle for en el ejemplo previo, pero de una manera condensada. Cualquiera de los dos métodos trabajará bien, así que utiliza la versión con la que te sientas más a gusto.\n\nPor regla general es más acertado que utilices un código que entiendas en vez de un código que se ejecute más rápidamente.\n\nEn este punto tenemos una lista de pares en la que cada par contiene una palabra y su frecuencia. Esta lista es algo redundante. Si el artículo ‘the’ se encuentra 500 veces, entonces esta lista contendrá quinientas copias del par (‘the’, 500). También la lista tiene el orden en el que aparecen las palabras en el texto original en vez de enlistar las palabras de la más a la menos frecuente. Podemos resolver ambos problemas convirtiendo la lista en un diccionario e imprimiendo entonces el diccionario en el orden en el que aparecen de más a menos los elementos.\n\nDiccionarios de Python\n\nLas cadenas y las listas están ordenadas secuencialmente, lo cual significa que puedes acceder a sus contenidos utilizando un índice, un número que comienza en 0. Si tienes una lista que contiene cadenas, puedes utilizar un par de índices para acceder primero a una cadena particular de la lista y luego a un carácter particular de esa cadena. Estudia los ejemplos siguientes.\n\n\ns = 'hola mundo'\nprint(s[0])\n-&gt; h\n\nprint(s[1])\n-&gt; o\n\nm = ['hola', 'mundo']\nprint(m[0])\n-&gt; hola\n\nprint(m[1])\n-&gt; mundo\n\nprint(m[0][1])\n-&gt; o\n\nprint(m[1][0])\n-&gt; m\n\n\nPara seguirle el rastro a las frecuencias, vamos a utilizar otro tipo de objeto de Python, un diccionario. El diccionario es una colección no-ordenada de objetos. Esto significa que no puedes usar un índice para recobrar elementos de ella. Sin embargo, puedes buscarlos mediante la utilización de una clave (de ahí el nombre de diccionario). Estudia el ejemplo siguiente:\n\n\nd = {'mundo': 1, 'hola': 0}\nprint(d['hola'])\n-&gt; 0\n\nprint(d['mundo'])\n-&gt; 1\n\nprint(d.keys())\n-&gt; ['mundo', 'hola']\n\n\nLos diccionarios pueden resultar algo confusos para un programador novato. Trata de pensarlos como un diccionario de palabras de cualquier lengua. Si no sabes (o recuerdas) exactamente en qué difiere “biyectiva” de “inyectiva” puedes buscar los dos términos en el Diccionario de la Lengua Española. El mismo principio se aplica cuando imprimes print(d['hola']); excepto que, en vez de imprimir una definición literaria imprime el valor asociado con la palabra clave ‘hola’ tal como lo definiste cuando creaste el diccionatio llamado d. En este caso, el valor es “0”.\n\nToma en cuenta que utilizas paréntesis para definir el diccionario y corchetes para acceder a las cosas dentro de él. La operación keys devuelve una lista de claves (keys) que se definen en el diccionario.\n\nLos pares palabra-frecuencia\n\nSobre la base de lo que tenemos hasta ahora queremos una función que pueda convertir una lista de palabras en un diccionario de pares de palabra-frecuencia. El único comando nuevo que vamos a necesitar es dict, que hace un diccionario a partir de una lista de pares. Copia lo siguiente y añádelo en el módulo obo-py.\n\n# Dada una lista de palabras, devuelve un diccionario de\n# pares de palabra-frecuencia.\n\ndef listaPalabrasDicFrec(listaPalabras):\n    frecuenciaPalab = [listaPalabras.count(p) for p in listaPalabras]\n    return dict(list(zip(listaPalabras,frecuenciaPalab)))\n\n\nTambién querremos una función que pueda ordenar un diccionario de pares de palabra-frecuencia, en orden de frecuencia descendente. Copia esto y añádelo también al módulo obo.py.\n\n# Ordena un diccionario de pares palabra-frecuencia en\n# orden de frecuencia descendente.\n\ndef ordenaDicFrec(dicfrec):\n    aux = [(dicfrec[key], key) for key in dicfrec]\n    aux.sort()\n    aux.reverse()\n    return aux\n\n\nAhora podemos escribir un programa que importe un URL y nos devuelva pares de palabra-frecuencia de la página Web puestos en orden descendente de frecuencia. Copia el siguiente programa en el Komodo Edit, guárdalo como html-a-frec.py y ejecútalo. Estudia el programa y los datos de salida con atención antes de continuar.\n\n#html-a-frec.py\n\nimport urllib.request, urllib.error, urllib.parse, obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nhtml = respuesta.read()\ntexto = obo.quitarEtiquetas(html).lower()\nlistaPalabras = obo.quitaNoAlfaNum(texto)\ndiccionario = obo.listaPalabrasDicFrec(listaPalabras)\ndiccOrdenado = obo.ordenaDicFrec(diccionario)\n\nfor s in diccOrdenado: print(str(s))\n\n\nRetirar palabras vacías\n\nCuando observamos los datos de salida del programa html-a-frec.py, vemos que las palabras más frecuentes en el texto son palabras funcionales como “the”, “of”, “to” y “and”.\n\n(192, 'the')\n(105, 'i')\n(74, 'to')\n(71, 'was')\n(67, 'of')\n(62, 'in')\n(53, 'a')\n(52, 'and')\n(50, 'you')\n(50, 'he')\n(40, 'that')\n(39, 'his')\n(36, 'it')\n\n\nPor lo general, estas palabras son las más comunes en cualquier texto en idioma inglés, por lo que no nos dicen mucho acerca de lo que es distintivo en el juicio de Bowsey. En general, estamos más interesados en encontrar las palabras que nos ayuden a diferenciar este texto de textos acerca de diferentes temas. Así que vamos a filtrar las palabras funcionales comunes. Las palabras que son ignoradas como éstas se conocen como palabras vacías = palabrasvac. Vamos a utilizar la siguiente lista depalabras en inglés adaptada de una que fue publicada en línea por los informáticos de Glasgow. Cópiala y ponla al principio de la biblioteca obo.py que estás construyendo.\n\npalabrasvac = ['a', 'about', 'above', 'across', 'after', 'afterwards']\npalabrasvac += ['again', 'against', 'all', 'almost', 'alone', 'along']\npalabrasvac += ['already', 'also', 'although', 'always', 'am', 'among']\npalabrasvac += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\npalabrasvac += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\npalabrasvac += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\npalabrasvac += ['because', 'become', 'becomes', 'becoming', 'been']\npalabrasvac += ['before', 'beforehand', 'behind', 'being', 'below']\npalabrasvac += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\npalabrasvac += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\npalabrasvac += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\npalabrasvac += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\npalabrasvac += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\npalabrasvac += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\npalabrasvac += ['every', 'everyone', 'everything', 'everywhere', 'except']\npalabrasvac += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\npalabrasvac += ['five', 'for', 'former', 'formerly', 'forty', 'found']\npalabrasvac += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\npalabrasvac += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\npalabrasvac += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\npalabrasvac += ['herself', 'him', 'himself', 'his', 'how', 'however']\npalabrasvac += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\npalabrasvac += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\npalabrasvac += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\npalabrasvac += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\npalabrasvac += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\npalabrasvac += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\npalabrasvac += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\npalabrasvac += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\npalabrasvac += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\npalabrasvac += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\npalabrasvac += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\npalabrasvac += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\npalabrasvac += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\npalabrasvac += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\npalabrasvac += ['some', 'somehow', 'someone', 'something', 'sometime']\npalabrasvac += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\npalabrasvac += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\npalabrasvac += ['then', 'thence', 'there', 'thereafter', 'thereby']\npalabrasvac += ['therefore', 'therein', 'thereupon', 'these', 'they']\npalabrasvac += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\npalabrasvac += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\npalabrasvac += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\npalabrasvac += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\npalabrasvac += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\npalabrasvac += ['whatever', 'when', 'whence', 'whenever', 'where']\npalabrasvac += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\npalabrasvac += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\npalabrasvac += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\npalabrasvac += ['within', 'without', 'would', 'yet', 'you', 'your']\npalabrasvac += ['yours', 'yourself', 'yourselves']\n\n\nAhora, deshacerse de las palabras funcionales de una lista es tan fácil como utilizar otra lista por comprensión. Añade también esta función al módulo obo.py.\n\n# Dada una lista de palabras, retira cualquiera que esté\n# en la lista de palabras funcionales.\n\ndef quitarPalabrasvac(listaPalabras, palabrasvac):\n    return [w for w in listaPalabras if w not in palabrasvac]\n\n\nEnsamblar todo\n\nAhora tenemos todo lo que necesitamos para determinar frecuencias de palabras en páginas Web. Copia lo siguiente en Komodo Edit, guárdalo como html-a-frec-2.py y ejecútalo.\n\n# html-a-frec-2.py\n\nimport urllib.request, urllib.error, urllib.parse\nimport obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nhtml = respuesta.read()\ntexto = obo.quitarEtiquetas(html).lower()\nlistaPalabrasCompleta = obo.quitaNoAlfaNum(texto)\nlistaPalabras = obo.quitarPalabrasvac(listaPalabrasCompleta, obo.palabrasvac)\ndiccionario = obo.listaPalabrasDicFrec(listaPalabras)\ndiccOrdenado = obo.ordenaDicFrec(diccionario)\n\nfor s in diccOrdenado: print(str(s))\n\n\nSi todo va bien, tus datos de salida se verán como esto:\n\n(25, 'house')\n(20, 'yes')\n(20, 'prisoner')\n(19, 'mr')\n(17, 'man')\n(15, 'akerman')\n(14, 'mob')\n(13, 'black')\n(12, 'night')\n(11, 'saw')\n(9, 'went')\n(9, 'sworn')\n(9, 'room')\n(9, 'pair')\n(9, 'know')\n(9, 'face')\n(8, 'time')\n(8, 'thing')\n(8, 'june')\n(8, 'believe')\n...\n\n\nNotas sobre las palabras en español\n\nHasta ahora hemos trabajado con un documento en inglés: la transcripción del juicio contra Bejamin Bowsey. Una vez que domines estas técnicas, seguramente querrás emplearlas en tu investigación y con documentos en español. Para ello, deberás hacer algunas modificaciones.\n\nLa primera es que, a diferencia del inglés, el idioma español contiene una serie de signos ortográficos (tildes) que modifican los caracteres. Los acentos (á, é, í, ó, ú), la diéresis (ü) y la virgulilla de la eñe (ñ). Para poder trabajar con estos signos es necesario indicarle al programa que se va a encontrar con ellos y que los debe considerar como caracteres. Para ello, basta con declarar que trabajaremos con una codificación de caracteres UTF-8. Por lo tanto, deberás incluir esta indicación en tus programas de la siguiente manera:\n\n# cuenta-elementos-de-lista-1.py\n# -*- coding: utf-8 -*-\n\ncadenaPalabras = 'Desocupado lector: sin juramento me podrás creer que quisiera este libro '\ncadenaPalabras += 'como hijo del entendimiento fuera el más hermoso, el más gallardo y más discreto que pudiera imaginarse'\nlistaPalabras = cadenaPalabras.split()\n\nfrecuenciaPalab = [listaPalabras.count(w) for w in listaPalabras]\n\nprint(\"Cadena\\n\" + cadenaPalabras +\"\\n\")\nprint(\"Lista\\n\" + str(listaPalabras) + \"\\n\")\nprint(\"Frequencias\\n\" + str(frecuenciaPalab) + \"\\n\")\nprint(\"Pares\\n\" + str(list(zip(listaPalabras, frecuenciaPalab))))\n\n\nComo te habrás dado cuenta, en la segunda línea del programa se hace la declaración de la codificación de caracteres.\n\nLa segunda modificación es en las palabras funcionales, o palabras vacías en español. A continuación te ofrecemos una lista de ellas preparada por Jairo Antonio Melo:\n\npalabrasvac = ['él', 'ésta', 'éstas', 'éste', 'éstos']\npalabrasvac += ['última', 'últimas', 'último', 'últimos']\npalabrasvac += ['a', 'añadió', 'aún', 'actualmente', 'adelante']\npalabrasvac += ['además', 'afirmó', 'agregó', 'ahí', 'ahora', 'al']\npalabrasvac += ['algún', 'algo', 'alguna', 'algunas', 'alguno', 'algunos']\npalabrasvac += ['alrededor', 'ambos', 'ante', 'anterior', 'antes',]\npalabrasvac += ['apenas', 'aproximadamente', 'aquí', 'así']\npalabrasvac += ['aseguró', 'aunque', 'ayer', 'bajo', 'bien', 'buen']\npalabrasvac += ['buena', 'buenas', 'bueno', 'buenos', 'cómo', 'cada']\npalabrasvac += ['casi', 'cerca', 'cierto', 'cinco', 'comentó', 'como']\npalabrasvac += ['con', 'conocer', 'consideró', 'considera', 'contra']\npalabrasvac += ['cosas', 'creo', 'cual', 'cuales', 'cualquier', 'cuando']\npalabrasvac += ['cuanto', 'cuatro', 'cuenta', 'da', 'dado', 'dan', 'dar']\npalabrasvac += ['de', 'debe', 'deben', 'debido', 'decir', 'dejó', 'del']\npalabrasvac += ['demás', 'dentro', 'desde', 'después', 'dice', 'dicen']\npalabrasvac += ['dicho', 'dieron', 'diferente', 'diferentes', 'dijeron']\npalabrasvac += ['dijo', 'dio', 'donde', 'dos', 'durante', 'e', 'ejemplo']\npalabrasvac += ['el', 'ella', 'ellas', 'ello', 'ellos', 'embargo', 'en']\npalabrasvac += ['encuentra', 'entonces', 'entre', 'era', 'eran', 'es']\npalabrasvac += ['esa', 'esas', 'ese', 'eso', 'esos', 'está', 'están', 'esta']\npalabrasvac += ['estaba', 'estaban', 'estamos', 'estar', 'estará', 'estas']\npalabrasvac += ['este', 'esto', 'estos', 'estoy', 'estuvo', 'ex', 'existe']\npalabrasvac += ['existen', 'explicó', 'expresó', 'fin', 'fue', 'fuera']\npalabrasvac += ['fueron', 'gran', 'grandes', 'ha', 'había', 'habían']\npalabrasvac += ['haber', 'habrá', 'hace', 'hacen', 'hacer', 'hacerlo']\npalabrasvac += ['hacia', 'haciendo', 'han', 'hasta', 'hay', 'haya']\npalabrasvac += ['he', 'hecho', 'hemos', 'hicieron', 'hizo', 'hoy']\npalabrasvac += ['hubo', 'igual', 'incluso', 'indicó', 'informó']\npalabrasvac += ['junto', 'la', 'lado', 'las', 'le', 'les', 'llegó']\npalabrasvac += ['lleva', 'llevar', 'lo', 'los', 'luego', 'lugar']\npalabrasvac += ['más', 'manera', 'manifestó', 'mayor', 'me', 'mediante']\npalabrasvac += ['mejor', 'mencionó', 'menos', 'mi', 'mientras', 'misma']\npalabrasvac += ['mismas', 'mismo', 'mismos', 'momento', 'mucha', 'muchas']\npalabrasvac += ['mucho', 'muchos', 'muy', 'nada', 'nadie', 'ni', 'ningún']\npalabrasvac += ['ninguna', 'ningunas', 'ninguno', 'ningunos', 'no', 'nos']\npalabrasvac += ['nosotras', 'nosotros', 'nuestra', 'nuestras', 'nuestro']\npalabrasvac += ['nuestros', 'nueva', 'nuevas', 'nuevo', 'nuevos', 'nunca']\npalabrasvac += ['o', 'ocho', 'otra', 'otras', 'otro', 'otros', 'para']\npalabrasvac += ['parece', 'parte', 'partir', 'pasada', 'pasado', 'pero']\npalabrasvac += ['pesar', 'poca', 'pocas', 'poco', 'pocos', 'podemos']\npalabrasvac += ['podrá', 'podrán', 'podría', 'podrían', 'poner', 'por']\npalabrasvac += ['porque', 'posible', 'próximo', 'próximos', 'primer']\npalabrasvac += ['primera', 'primero', 'primeros', 'principalmente', 'propia']\npalabrasvac += ['propias', 'propio', 'propios', 'pudo', 'pueda']\npalabrasvac += ['puede', 'pueden', 'pues', 'qué', 'que', 'quedó']\npalabrasvac += ['queremos', 'quién', 'quien', 'quienes', 'quiere']\npalabrasvac += ['realizó', 'realizado', 'realizar', 'respecto', 'sí']\npalabrasvac += ['sólo', 'se', 'señaló', 'sea', 'sean', 'según', 'segunda']\npalabrasvac += ['segundo', 'seis', 'ser', 'será', 'serán', 'sería', 'si']\npalabrasvac += ['sido', 'siempre', 'siendo', 'siete', 'sigue', 'siguiente']\npalabrasvac += ['sin', 'sino', 'sobre', 'sola', 'solamente', 'solas', 'solo']\npalabrasvac += ['solos', 'son', 'su', 'sus', 'tal', 'también', 'tampoco']\npalabrasvac += ['tan', 'tanto', 'tenía', 'tendrá', 'tendrán', 'tenemos']\npalabrasvac += ['tener', 'tenga', 'tengo', 'tenido', 'tercera', 'tiene']\npalabrasvac += ['tienen', 'toda', 'todas', 'todavía', 'todo', 'todos']\npalabrasvac += ['total', 'tras', 'trata', 'través', 'tres', 'tuvo']\npalabrasvac += ['un', 'una', 'unas', 'uno', 'unos', 'usted', 'va']\npalabrasvac += ['vamos', 'van', 'varias', 'varios', 'veces', 'ver']\npalabrasvac += ['vez', 'y', 'ya', 'yo']\n\n\nLecturas sugeridas\n\nLutz, Learning Python\n\n\n  Ch. 9: Tuples, Files, and Everything Else\n  Ch. 11: Assignment, Expressions, and print\n  Ch. 12: if Tests\n  Ch. 13: while and for Loops\n\n\nPilgrim, Diving into Python\n\n\n  Ch. 7: Regular Expressions\n\n\nSicronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones5.zip (zip sync)\n\n\n\nContar la frecuencia de palabras específicas en una lista puede proveer datos ilustrativos. Con esta lección aprenderás una forma fácil para contar dichas frecuencias usando Python.\n\n"
  },


  {
    "id": 5,
    "url": "http://localhost:4000/es/lecciones/corpus-paralelo-lfaligner",
    "title": "Creación de corpus paralelo con LF Aligner\n",
    "body": "\nCreación de corpus paralelo con LF Aligner\n\n\nContenidos\n\n\n  Introducción\n  Para este tutorial necesitarás los siguientes materiales y conocimientos:\n  Instalación y ejecución del programa\n  Carga de documentos en el programa    \n      Eligiendo el formato apropiado\n      Interfaz de carga\n      Especificando las lenguas de tus textos\n      Cargando los documentos\n    \n  \n  Resultados de la alineación\n  Edición del bitexto    \n      Interfaz de edición del bitexto (solo en Windows)\n    \n  \n  Cierre del programa: Windows\n  Ubicación del documento alineado\n  Visualización y búsquedas simples\n  Referencias bibliográficas\n\n\nUn corpus paralelo o bitexto consiste en la recopilación de varias versiones de un texto. En este tutorial aprenderás a alinear el texto original con sus traducciones para poder cotejarlos con facilidad.\n\nIntroducción\nLF Aligner es un programa gratuito, basado en un algoritmo de código abierto de alineación de oraciones, que pertenece al conjunto de herramientas digitales llamadas CATs (Computer Assisted Translation Tools, por sus siglas en inglés) o herramientas de traducción asistida. Principalmente, se usa para la creación de bitextos que facilitan la búsqueda de términos especializados y sus traducciones. Sitios como Linguee utilizan este tipo de herramientas para crear enormes corpus paralelos que el usuario puede consultar fácilmente. En ciencias sociales y humanidades podemos aprovechar este programa para crear textos que faciliten las tareas de lectura distante y análisis estilístico. La aplicación puede importar texto de documentos en múltiples formatos y de memorias de traducción generadas con programas de código libre o privativo. En este tutorial nos centraremos en la importación de texto de fuentes digitales usadas comunmente por los investigadores como páginas web o documentos de texto plano, ya que, además, agilizan el proceso de alineación del corpus.\n\nPara este tutorial necesitarás los siguientes materiales y conocimientos:\n\n\n  El programa LF Aligner, disponible para Windows (versión 4.2), Mac (versión 3.12) y Linux (versión 3.11). En este tutorial nos centraremos en la versión de Windows, que es la más reciente. Sin embargo, también se explicará cómo utilizarlo en Mac y en sistemas basados en el kernel de Linux. La interfaz del programa está en inglés y no cuenta con una versión en español, por lo que se proveen traducciones de algunos elementos que son indispensables para comprender el funcionamiento de LF Aligner.\n  Un texto de partida -digitalizado- y por lo menos una traducción de este. En este caso, alinearemos distintas traducciones de un documento que desde 1948 guía el quehacer y la convivencia humana en todos los ámbitos de la vida pública y privada, la Declaración Universal de Derechos Humanos: en español, inglés, francés y portugués\n  Conocimiento básico de las lenguas de traducción, ya que en algunos casos tendremos que modificar algunos de los segmentos alineados.\n\n\nAdicionalmente, podemos utilizar este programa para alinear distintas versiones de un texto en una misma lengua, lo que es útil para análisis relacional, pero hay otras iniciativas que cumplen mejor con esta tarea como Collatex o Juxta.\n\nEs importante ser sistemático con la clasificación de los documentos. El nombre de nuestros archivos txt debe acompañarse con el código que alude a la lengua del texto. Con ello aseguramos que la información con la que trabajamos siga convenciones oficiales que serán útiles a la hora de comunicar los resultados de nuestra investigación Para ello nos basaremos en el código ISO 639-1 que identifica a cada lengua con dos letras. Así, el español se identifica con es, el inglés con en, el francés con fr y el portugués con pt.\n\nSi trabajas con lenguas que no estén incluidas en ese código, puedes recurrir al código ISO 639-3 que utiliza descriptores de 3 letras y abarca la totalidad de las lenguas del mundo.\n\nComo resultado final del procesamiento de los textos con LF Aligner obtendrás algo así:\n\n\n    \n\n    Resultado del procesamiento de los textos\n\n\n\n\nInstalación y ejecución del programa\nPara comenzar a utilizar el programa, no es necesario instalar ningún software adicional; solo debes descargar el paquete que ofrece la web oficial, descomprimirlo en una carpeta de tu elección y ejecutar el archivo .exe (Windows), .sh (Linux) o .command (Mac), según corresponda, que se encuentra en el paquete.\n\nEl uso de las versiones para Linux y Mac es idéntico, salvo en la forma de ejecutar el programa.\n\nEn el caso de Mac, al ejecutar el archivo .command, se abrirá una ventana con la terminal que premite continuar con el proceso de alineación.\n\nEn el caso de Linux, necesitarás abrir, por separado, la terminal disponible en tu distribución de Linux para luego ejecutar el fichero.\n\nAdemás, si trabajas en un entorno Linux de 64 bits, necesitarás instalar algunos paquetes adicionales para que el programa funcione correctamente. Los comandos que debes introducir en la terminal son los siguientes:\n\n\n  sudo dpkg –add-architecture i386\n  sudo apt-get update\n  sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386\n\n\nPara abrir el programa, además de utilizar los comandos de navegación, una forma sencilla de ejecutar este tipo de archivos consiste en arrastrarlo hasta la ventana de la terminal, soltarlo ahí y luego presionar entrar.\n\n\n    \n\n    Ejecución del programa en Linux\n\n\n\n\nCarga de documentos en el programa\nEligiendo el formato apropiado\nAntes de comenzar a utilizar el programa, debemos extraer la información que nos interesa y almacenarla en un documento txt. Se recomienda hacer una revisión previa de cada texto, por separado, para identificar elementos que podrían interferir en el proceso de alineación de los textos. Es importante que cada texto tenga una puntuación, cuando menos, consistente, así como una tabulación regular. En lo posible, las palabras y oraciones deben estar separadas por un solo espacio y los párrafos por una cantidad de espacios y marcas de párrafo regular.\n\n\n    \n\n    Documentos de texto plano\n\n\n\n\nInterfaz de carga\nAl ejecutar el programa, nos mostrará inmediatamente la interfaz de carga de documentos con las opciones que se describen a continuación:\n\n\n    \n\n    Interfaz de carga: selección de tipo de documentos\n\n\n\n\n\n  txt (UTF-8), rtf, doc o docx: permite importar texto plano o guardado en formatos de procesadores de texto como Microsoft Word y Libreoffice Writter. Es la opción más común, puesto que, por lo general, modificaremos un poco los textos antes de trabajar con ellos.\n  pdf o pdf exportado a txt: algunos documentos con formato .pdf permiten exportar todo el texto que contienen a un archivo txt. Por lo general, podremos hacer esto desde el menú de archivo de nuestro lector de documentos pdf favorito, con la opción guardar como y eligiendo el formato txt para guardar.\n  Archivo HTML almacenado en nuestro equipo: permite cargar una página descargada y almacenada en nuestro equipo o unidad de almacenamiento portátil. Debemos asegurarnos que dicho sitio web solo contenga el texto que nos interesa, ya que el programa importará indiscriminadamente todo lo que ese sitio contenga, incluyendo el texto del menú del sitio y de otros enlaces ahí presentes.\n  webpage (página web):  permite insertar la dirección web en la que se encuentra el texto para cargarlo automáticamente. Al igual que con la opción anterior, debemos procurar que el sitio solo contenga el texto que nos interesa para asegurar una alineación satisfactoria.\n  EU legislation by CELEX number (legislación de la UE según número CELEX): esta opción permite ingresar el número identificador de un documento legislativo de la Unión Europea para que el programa descargue e importe automáticamente los documentos en las lenguas que nos interesan. La numeración CELEX clasifica los documentos según tipo, tema y otros rasgos característicos.\n  European Parliament reports (informes del Parlamento Europeo): permite descargar estos informes según año y número, en las lenguas que posteriormente especifiquemos.\n\n\nPara efectos de este tutorial, debemos seleccionar la primera opción, txt (UTF-8), rtf, doc o docx, y presionar el botón next (siguiente).\n\nParticularides de la interfaz en Linux y Mac\nEn los sistemas Mac y en los basados en Linux el funcionamiento es idéntico, pero la interfaz se despliega de otra forma. En lugar de abrirse una nueva ventana, el programa muestra sus opciones dentro de la terminal abierta. Para elegir la modalidad de trabajo, debemos introducir, con el teclado, el código asignado a cada función. Las opciones que ofrece esta versión son las siguientes:\n\nt. txt (UTF-8), rtf, doc o docx.\n\np. pdf o pdf exportado a txt.\n\nh. Archivo HTML almacenado en nuestro equipo.\n\nw. Página web.\n\nc. Legislación de la UE según número CELEX.\n\ncom. Propuestas de la Comisión Europea.\n\nepr. Informes del Parlamento Europeo.\n\nEn este caso, ya que trabajaremos con documentos txt, debemos ingresar t- y presionar entrar.\n\n\n    \n\n    Interfaz de carga en Linux: selección de tipo de documentos\n\n\n\n\nEspecificando las lenguas de tus textos\n\n\n    \n\n    Interfaz de selección de lenguas\n\n\n\n\nLas opciones que la interfaz de selección de lenguas ofrece por defecto son las siguientes:\n\n  Cantidad de lenguas\n  Lengua 1\n  Lengua 2\n\n\nLF Aligner puede alinear hasta 11 documentos de forma simultánea. Por defecto, ofrece la opción de comenzar con el par lingüístico inglés-húngaro, pero podemos cambiar la opción que presenta por defecto si editamos el archivo LF_aligner_setup.txt que se encuentra en la carpeta del software.\n\n\n    \n\n    Configuración por defecto: inglés y húngaro\n\n\n\n\n\n    \n\n    Aquí se ha modificado el par a español-inglés\n\n\n\n\nDe momento, regresemos a la interfaz por defecto. En nuestro caso, alinearemos cuatro textos, por lo que en la opción Number of languages (cantidad de lenguas) debemos cambiar la cantidad de 2 a 4.\n\nDel mismo modo, debemos especificar cuál será el texto principal o de partida que servirá como eje para el cotejo. Sin embargo, puedes cambiar el orden de las lenguas, si así lo deseas, luego de alinear los textos. Si trabajas con muchas lenguas y quieres cotejar traducciones respecto de una lengua en específico, colocar el texto fuente en una posición central (y no a la extrema izquierda) podría ser útil. De momento, posicionaremos el texto en español en la primera columna de nuestro bitexto. En la opción Language 1 (lengua 1) cambiaremos la lengua a español (Spanish). Debemos hacer lo mismo con las lenguas 2 (English), 3 (French) y 4 (Portuguese). Una vez lista esta configuración, presiona el botón next (siguiente).\n\n\n    \n\n    Interfaz de selección de lenguas con la configuración deseada\n\n\n\n\nCómo especificar las lenguas de los textos en las versiones de Linux y Mac\nComo vimos anteriormente, las opciones se despliegan como texto dentro de la terminal. Debemos introducir con el teclado el número de lenguas (mínimo: 2; máximo: 11) y la combinación que deseamos, según el código de dos letras que cada lengua tiene (en nuestro caso: es, en, fr y pt).\n\n\n    \n\n    Interfaz de selección de lenguas en Linux\n\n\n\n\nCargando los documentos\nLos documentos se cargan uno a uno. Presiona el botón Browse (explorar) junto a la etiqueta de cada lengua para buscar el documento correspondiente. Es importante separar los archivos en una carpeta fácil de localizar y que se use exclusivamente para almacenar los documentos que queremos integrar en nuestro corpus paralelo.\n\n\n    \n\n    Interfaz de carga de documentos\n\n\n\n\nPodemos observar que cada archivo está debidamente nombrado, con código de dos letras, según lengua. Al cargar todos los archivos, la interfaz se verá así:\n\n\n    \n\n    \n\n\n\n\nPresiona el botón next (siguiente) para que el software proceda con la alineación automática.\n\nCarga de documentos en las versiones de Linux y Mac\nConforme lo solicite el programa, arrastraremos cada archivo -uno a la vez, en el orden que establecimos al momento de ingresar las lenguas-, lo soltaremos dentro de la ventana de la terminal y presionaremos entrar. Luego de haber cargado el último documento, el programa comenzará automáticamente con la alineación.\n\n\n    \n\n    Interfaz de carga de documentos en Linux\n\n\n\n\nComo podemos ver en la imagen, nos pide cada documento según el orden que ingresamos anteriormente. Primero, debemos arrastrar el documento en inglés (en), después, el documento en español (es), en tercer lugar, el documento en francés (fr) y, por último, el documento en portugués (pt).\n\nResultados de la alineación\n\n\n    \n\n    Resultados del proceso de alineación\n\n\n\n\nAntes de exportar el nuevo documento, el programa nos informará sobre los resultados del proceso de alineación automática. El algoritmo reconoce segmentos que corresponden a oraciones y organiza todos los textos de ese modo para proceder con la alineación.\n\nEn la imagen mostrada arriba, podemos observar que el texto en español tenía originalmente 92 segmentos; el software ha aumentado esta cifra a 99. Este ligero aumento en la cantidad de oraciones corresponde a la descomposición de los párrafos de cada documento. Del mismo modo, las oraciones de los demás textos han sido reorganizadas gracias al algoritmo y, en lo posible, alineadas con los segmentos correspondientes de las traducciones. Este resultado es esperable y se requiere de la intervención del usuario para completar el proceso de alineación. La práctica de esa tarea aporta al análisis preliminar del corpus, ya que seremos capaces de notar algunas diferencias estructurales en la composición de los textos. Esta leve diferencia entre las distintas versiones puede ser producto de omisiones o adiciones en las traducciones de la obra, o de diferencias sustanciales en las pausas utilizadas en el discurso, es decir, la puntuación.\n\nPor esta razón, la interfaz de resultados ofrece dos opciones (Windows):\n\n\n  Al parecer, la segmentación fue exitosa, así que usaré los textos segmentados por oración: En nuestro caso, esta es la opción que debemos escoger. En comparación con nuestro texto de partida, las traducciones tienen solo 2 o 3 segmentos más. Como se menciona arriba, explorar los elementos que produjeron este resultado nos ayudan a tener un primer acercamiento a texto, como veremos a continuación.\n  Revertir a las versiones segmentadas por párrafo: Si las diferencias en la segmentación son muy grandes, tanto de cada texto por separado como entre ellos, podemos recurrir a esta opción. Revertir a las versiones segmentadas por párrafo también es útil cuando trabajamos con lenguas que son muy diferentes entre sí o que el algoritmo no soporta de manera oficial. Esto permite continuar con el proceso de alineación, aunque se pierda un poco del potencial de la visualización.\n\n\nLuego de haber tomado una decisión al respecto -lo que también obedecerá a las necesidades de nuestro proyecto de investigación- debemos presionar el botón next (siguiente) para continuar.\n\nImportante. Seleccionar la opción de Generate xls in background after review (crear documento en formato xls después de la revisión), para poder exportar nuestro documento perfectamente alineado de manera automática, una vez completada la revisión.\n\nResultados de la alineación en las versiones de Linux y Mac\nEl programa nos informará sobre los resultados del proceso de alineación, ofreciéndonos casi las mismas opciones que su contraparte de Windows. La diferencia radica en que aquí simplemente nos pregunta si queremos revertir a segmentación por párrafo o no. Para tomar esta decisión, debemos basarnos en el resultado final de la segmentación que se muestra en pantalla:\n\n\n    \n\n    Resultados del proceso de alineación en Linux\n\n\n\n\nEn este caso, la variación en el número de segmentos antes y después de la alineación es mínima; esto quiere decir que no necesitamos revertir a la separación por párrafo y podemos conservar la versión alineada a nivel de oración hecha por el programa.\n\nPara continuar, elegiremos la opción no, introduciendo una n y presionando entrar.\n\nEdición del bitexto\nAhora solo falta decidir cómo revisaremos y editaremos el texto antes de exportarlo. El editor gráfico de LF Aligner es una herramienta que facilita esta tarea, pero también podemos exportar el texto inmediatamente y modificarlo con nuestra suite de ofimática preferida.\n\nLas opciones que el software ofrece son las siguientes (Windows):\n\n\n    \n\n    \n\n\n\n\n\n  Usar el editor gráfico de LF Aligner\n  Generar un documento xls y abrirlo para revisar\n  No revisar: Escogeremos esta opción solo cuando los valores de la segmentación mostrados en la interfaz anterior calcen perfectamente.\n\n\nPara este proyecto utilizaremos la herramienta de LF Aligner, por lo que debemos escoger la primera opción y presionar next (siguiente).\n\nConsideraciones sobre la edición del bitexto en las versiones de Linux y Mac\nLas versiones de Linux (3.11) y Mac (3.12) no cuentan con una interfaz gráfica propia para la revisión del bitexto. Al no existir este elemento, debemos generar y exportar el documento de planilla de cálculo para revisarlo con un tercer programa. Por esta razón, estas versiones ofrecen solo las siguientes opciones:\n\n  No revisar (n).\n  Abrir el documento .txt con el texto alineado para revisarlo (t).\n  Crear y abrir un documento .xls con el texto alineado (x).\n\n\nLo más conveniente para nuestros fines es exportar un documento .xls para editarlo en una hoja de cálculo. Cada celda de la planilla corresponderá a uno de los segmentos alineados. Seleccionamos, entonces, la tercera opción, introduciendo x con el teclado y presionando entrar.\nEn el caso de que seas usuario de Mac o Linux, debes saltarte el siguiente apartado y continuar con las instrucciones para el cierre del programa en Linux y Mac.\n\nInterfaz de edición del bitexto (solo en Windows)\nSe abrirá una nueva ventana con la interfaz de la herramienta de edición de los textos alineados.\n\n\n    \n\n    Herramienta gráfica de edición\n\n\n\n\nLa primera columna marca el número de cada segmento y las subsiguientes contienen el texto en las lenguas que ingresamos. Respecto a los segmentos, podemos apreciar que la versión en español contiene uno inexistente en las demás traducciones y, por tanto, el software ha creado un segmento vacío, marcando que no hay correspondencia en las otras lenguas. Esta simple diferencia puede suscitar preguntas relacionadas con el ámbito de la retórica contrastiva: ¿Por qué las demás versiones omiten esta información? ¿Acaso en español se exige la presencia de los datos de adopción y proclamación de un documento jurídico?\n\nRetomemos la numeración de los segmentos:\n\n\n    \n\n    Segmentos numerados\n\n\n\n\nEl software ha hecho calzar el número de segmentos de las traducciones con el de nuestro texto guía y, por esa razón, es necesario revisar el documento de forma más acuciosa, no perdiendo de vista los resultados expuestos en la fase anterior. En este caso, la estructura del texto ha facilitado enormemente la labor, pero, aun así, es posible encontrar algunos errores como el siguiente:\n\n\n    \n\n    Error en uno de los segmentos\n\n\n\n\nEn la columna de la traducción portuguesa (a la derecha, resaltada), parte del texto que debería de estar en el segmento 11 ha quedado en el segmento 10, presumiblemente por diferencias en la puntuación. El algoritmo no ha reconocido los dos puntos como una marca de término de la oración y esto ha provocado un desfase en esta versión respecto de las otras.\n\nPara solucionar este problema, debemos recurrir a los comandos representados por los botones de la barra inferior:\n\n  Merge (fusionar): sirve para combinar el texto de dos segmentos distintos en uno solo.\n  Split (separar): sirve para trasladar una porción de texto a otro segmento.\n  Shift up (desplazar hacia arriba): sirve para desplazar todo el texto de un segmento a una celda anterior, desplazando consigo el resto de los segmentos.\n  Shift down (desplazar hacia abajo): sirve para desplazar todo el texto de un segmento a una celda posterior, desplazando consigo el resto de los segmentos.\n\n\nEn este caso, debemos usar el comando Split para desplazar la porción de texto que está fuera de lugar a su casilla correspondiente. Para ello, debemos colocar el cursor del teclado en donde inicia el fragmento que deseamos mover y presionar el botón correspondiente de la barra inferior.\n\n\n    \n\n    El cursor del teclado está al comienzo del fragmento que queremos desplazar\n\n\n\n\n\n    \n\n    Al presional split, obtendremos este resultado\n\n\n\n\nComo todavía hay una porción de texto que debe colocarse en la celda siguiente, repetimos el procedimiento.\n\n\n    \n\n    Presionamos nuevamente split al comienzo del fragmento que queremos desplazar\n\n\n\n\nGracias a nuestra edición, el texto de los segmentos 10, 11 y 12 ha quedado perfectamente alineado.\n\nCierre del programa: Windows\nCuando termines de revisar el documento, escoge la opción save &amp; exit (guardar y salir) en el menú file (archivo).\n\n\n    \n\n    \n\n\n\n\nTras hacer esto, la herramienta de edición se cerrará. Regresa a la ventana principal del programa para cerrarlo completamente.\n\n\n    \n\n    El programa nos da la opción de generar un archivo de memoria de traducción\n\n\n\n\nLF Aligner ofrece la opción de exportar nuestro documento con formato de memoria de traducción (en este caso tmx). Este tipo de archivos sirven exclusivamente para alimentar software de traducción asistida, ya sea para creación de bases terminológicas personalizadas o para apoyo en las tareas de traducción asistida como traducción automática de segmentos. Para efectos de este tutorial, no es necesario hacer esto. Escoge la opción no y presiona next (siguiente) para finalizar. Aparecerá una última ventana avisándonos que el programa se ha cerrado exitosamente.\n\nCierre del programa en Linux y Mac\nJusto después de crear el archivo xls, el cual se abrirá inmediatamente, el programa preguntará si deseamos crear un archivo de memoria de traducción. Seleccionamos “no”, introduciendo n y presionando entrar. El software mostrará un último mensaje, indicándonos que el proceso ha finalizado. Basta con presionar entrar una vez más para terminar el programa. Luego de esto podemos cerrar la terminal sin ningún problema.\n\nUbicación del documento alineado\nSi seguiste las indicaciones anteriores sobre el nombramiento y almacenamiento de los textos, te será muy fácil encontrar el documento. Abre la carpeta en cuestión. Ahí verás una nueva carpeta cuyo nombre comienza con la palabra align. Dentro de ella encontrarás los documentos individuales en formato txt que corresponden al texto segmentado por el software y un archivo de planilla de datos (formato xls) que contiene el texto alineado y editado por nosotros.\n\n\n    \n\n    El archivo exportado en formato xls aparecerá en la carpeta correspondiente\n\n\n\n\nTambién puedes descargar el documento alineado y explorarlo para aprender más sobre el funcionamiento de este software.\n\nVisualización y búsquedas simples\nSi deseamos editar el documento de formas que la herramienta gráfica de LF Aligner no cubre, recomendamos abrirlo con un paquete de ofimática potente como Libreoffice; su aplicación Calc es un excelente procesador de hojas de cálculo. No obstante, como ya nos dimos por satisfechos con nuestro trabajo de revisión anterior, exportaremos el archivo en formato html para poder hacer búsquedas de manera sencilla en el documento, desde nuestro navegador web. Escoge guardar como, en el menú archivo y elige html como formato de guardado. La herramienta de búsqueda de texto de un navegador como Google Chrome (ctrl+f) bastará para hacer consultas sencillas.\n\n\n    \n\n    Búsqueda simple con el navegador Google Chrome\n\n\n\n\nTambién puedes guardar, por separado, las versiones recién alineadas en documentos de texto plano (txt) y usar un visualizador sencillo de traducciones paralelas como AntPConc.\n\nSobre la base de la imagen anterior, podemos plantear algunas preguntas que podrían ser útiles para nuestra investigación; tanto en la fase preliminar de un proyecto, en la cual no se tiene claridad sobre lo que se quiere observar, como en una fase avanzada, en la que hacemos búsquedas motivadas por preguntas y criterios previamente establecidos. El tutorial sobre AntConc alojado en este sitio profundiza más en el concepto de lectura distante.\n\nComo vemos con el ejemplo de persona -búsqueda basada en una lectura exploratoria del texto- tanto las similitudes como las diferencias en las traducciones del término son reveladoras; por un lado, permiten conocer sus distintas traducciones y, por otro, permiten describir y comprender la naturaleza de las regularidades y variaciones de estas, lo que nos acerca más al estudio de las técnicas de traducción empleadas y las características de cada texto. En otras palabras, visualizar los textos de este modo nos permite observar, cuantificar y calificar los fenómenos discursivos y de traducción que pueden encontrarse en el texto.\n\nReferencias bibliográficas\n\n\n  \n    Froehlich, Heather, “Análisis de corpus con AntConc”, traducido por Carlos Manuel Varón Castañeda, The Programming Historian en español 3 (2018), Análisis de corpus con AntConc\n  \n  \n    Luna, R., “El corpus: herramienta de investigación traductológica”, Temas de traducción, Lima, Universidad Femenina del Sagrado Corazón (2002), pp. 57-72.\n  \n  \n    Tiedemann, Jörg, Bitext Alignment, San Rafael CA, Morgan &amp; Claypool (2011).\n  \n\n\n\nEste tutorial fue posible gracias al apoyo de la British Academy y fue escrito durante el taller de Programming Historian llevado a cabo en la Universidad de Los Andes en Bogotá, Colombia, 31 de julio - 3 de agosto, 2018.\n\n\nEsta lección enseña a crear corpus con traducciones a distintas lenguas, de forma que queden perfectamente alineados para una mejor visualización y consulta.\n\n"
  },


  {
    "id": 6,
    "url": "http://localhost:4000/es/lecciones/creando-diagramas-de-redes-desde-fuentes-historicas",
    "title": "De la hermenéutica a las redes de datos: Extracción de datos y visualización de redes en fuentes históricas",
    "body": "\nDe la hermenéutica a las redes de datos: Extracción de datos y visualización de redes en fuentes históricas\n\nContenidos\n\n\n  Introducción\n  Sobre el caso de estudio\n  Desarrollando un esquema de codificación\n  Visualiza datos en red utilizando Palladio\n  El valor agregado de las visualizaciones de redes\n  Otras herramientas de visualización para tener en cuenta\n\n\nIntroducción\n\nLa visualizaciones de redes pueden ayudar a los humanistas a revelar patrones complejos escondidos y estructuras en fuentes textuales. Este tutorial explica cómo extraer datos en red (personas, instituciones, lugares, etcétera.) de fuentes históricas a través del uso de métodos no especializados desarrollados en el marco del análisis de datos qualitativos (Qualitative Data Analysis, QDA) y el análisis de redes sociales (Social Network Analysis, SNA), y cómo visualizar estos datos con Palladio, una aplicación independiente de plataforma y que es particularmente fácil de usar.\n\n\n    \n\n    Figura 1: Una visualización de redes en Palladio y lo que vas a poder crear al final de este tutorial.\n\n\n\n\nLa gráfica anterior muestra un fragmento de la red de Ralph Neumann, en particular sus conexiones con personas que lo ayudaron a él y a su hermana durante su vida clandestina en Berlín entre 1943 y 1945.  La gráfica se puede modificar fácilmente y preguntar lo siguiente: ¿Quién ayudó en qué manera? ¿Quién los ayudó? ¿Quién está conectado a quién?\n\nEn general, el análisis de redes provee las herramientas para explorar constelaciones muy complejas de relaciones entre entidades. Piensa en tus amigos: sería fácil mapear quiénes son cercanos y quiénes no se llevan bien. Ahora, imagina que quieres explicar estas relaciones a alguien que no conoce a ninguno de tus amigos, o que quieres incluir las relaciones entre los amigos de tus amigos. En situaciones como esta el lenguaje y nuestra capacidad de comprender estructuras sociales llega a sus límites rápidamente. Las visualizaciones gráficas pueden ser medios para comunicar y explorar efectivamente estas complejas constelaciones. En general tu puedes pensar el análisis de redes sociales (ARS) como un medio para transformar la complejidad de un problema en un objeto de investigación. A menudo, los nodos en una red representan humanos conectados con otros humanos por todos los tipos de relaciones sociales imaginables. Pero casi que cualquier cosa puede ser entendida como un nodo: una película, un lugar, un título laboral, un punto en el tiempo, un lugar de reunión. En forma similar el concepto de vínculo (también llamado arista) entre nodos es igualmente flexible: dos teatros pueden estar conectados por una película mostrada en ambos, o por co-propiedad, proximidad geográfica, o haber empezado a funcionar el mismo año. Todo esto depende de tus intereses de investigación y cómo los expresas en forma de nodos y relaciones en una red.\n\nEsta lección no reemplaza ninguno de los muchos manuales genéricos de análisis de redes, como el libro de John Scott Social Network Analysis. Para una introducción general al campo y sus dificultades para los humanistas recomiendo  la serie de blog posts de Scott Weingart “Networks Demystified” así como también el artículo de Claire Lemercier “Formal network methods in history: why and how?”. También podrías querer explorar la bibliografía y calendario de eventos en Historical Network Research para darte una idea de cómo los historiadores han usado las redes en sus investigaciones.\n\nEste tutorial se enfoca en la extracción de datos de un texto desestrucurado y muestra una forma de visulizarlos utilizando Palladio. Está diseñado a propósito para ser lo más simple y robusto posible. Por el alcance limitado de este tutorial, es suficiente decir que un actor se refiere a las personas, instituciones, etcétera., que son el objeto de estudio y que están conectadas por relaciones. Dentro del contexto del Análisis de Redes Sociales (ARS) (también llamada gráfica o grafo de red), a los actores o puntos centrales en cuestión, les llamamos nodos, y a las conexiones que existen entre ellos, les llamamos lazos o vínculos. En todos los casos es importante recordar que los nodos y los lazos son modelos drásticamente simplificados utilizados para representar la complejidad de eventos pasados y en sí mismos muchas veces no son suficientes para generar conocimiento. Pero es posible que el gráfico resalte algunos aspectos interesantes, desafíe tu hipótesis, y/o te lleve a generar nuevas hipótesis. Los digramas de redes se vuelven más significativos cuando son parte de un diálogo con datos y otras fuentes de información.\n\nMuchos proyectos de análisis de redes en las ciencias sociales se basan en fuentes de datos preexistentes, o datos que fueron creados con el propósito de ser usados para análisis de redes. Algunos ejemplos incluyen registros de correo electrónico, cuestionarios, o relaciones comerciales los cuales hacen relativamente fácil identificar quién está conectado con quien y cómo. Es considerablemente más difícil extraer datos de redes de textos no estructurados. Esto nos fuerza a casar las complejidades de la hermenéutica con el rigor del análisis formal de datos. El término “amigo” puede servir como un ejemplo: dependiendo del contexto puede significar cualquier cosa desde un insulto a una expresión de amor. El contexto del conocimiento y el análisis del texto puede ayudar a identificar lo que significa en cualquier caso dado. Un sistema formal de categorías debería representar los diferentes signficados con tantos detalles como sean necesario para tus propósitos.\n\nEn otras palabras, el reto es sistematizar la interpretación textual. Las redes que se crean desde conjuntos de datos preexistentes necesitan considerarse dentro del contexto en el cual fueron creados (e.g. la terminología de las preguntas en un cuestionario y los grupos de destinatarios). Las redes creadas desde texto no estructurado presentan retos adicionales: las interpretaciones son sumamente individuales, y dependen de los puntos de vista y conocimiento del contexto).\n\nSobre el caso de estudio\n\nEl caso de estudio que utilizo para este tutorial es una narrativa en primera persona de Ralph Neumann, un judío que sobrevivió al Holocausto. Puedes encontrar en texto en internet. El esquema de codificación que presento abajo es una versión simplificada del que desarrollé durante mi proyecto doctoral sobre redes de apoyo encubierto durante la Segunda Guerra Mundial. Mi investigación estuvo guiada por tres preguntas: ¿En qué medida las relaciones sociales pueden ayudar a explicar por qué personas comunes tomaron los riesgos asociados a ayudar a otros? ¿Cómo dichas relaciones permitieron a la gente prestar ayuda dado que tenían a su disposición recursos muy limitados? ¿Cómo ayudaron las relaciones sociales a los refugiados judíos a sobrevivir clandestinamente?\n\nEn este proyecto las visualizaciones en red me ayudaron a descubrir intermediarios hasta el momento olvidados pero muy importantes, resaltar la importancia general de los refugiados judíos como intermediarios, y navegar los casi 5,000 actos de ayuda que conectaron alrededor de 1,400 personas entre 1942 y 1945.\n\nDesarrollando un esquema de codificación\n\nPara visualizar relaciones en red, una de las dificultades principales es decidir quién debe formar parte de la red y cuáles relaciones entre los actores seleccionados se van a codificar. Seguramente esto se tomará algún tiempo y será un proceso iterativo pues necesitarás balancear tus intereses de investigación e hipótesis con la disponibilidad de la información en tus textos, y representar ambos en un esquema rígido y necesariamente simplicado.\n\nLas preguntas principales durante este proceso son: ¿Qué aspectos de las relaciones entre dos actores son relevantes? ¿Quién forma parte de la red? ¿Quién no lo es? ¿Qué atributos importan? ¿Qué esperas encontrar?\n\nYo encontré las siguientes respuestas a estas preguntas:\n\n¿Qué define una relación entre dos actores?\n\nCualquier acción que contribuya directamente a la supervivencia de personas perseguidas y en la clandestinidad. Esto incluye por ejemplo comunistas no judíos pero excluye testigos que escogieron no denunciar a los refugiados o personas conocidas entre varios actores (esto, por la falta de suficiente cobertura en las fuentes). Los actores fueron codificados como proveedores o receptores de un acto de ayuda independientemente de su status como refugiados. Por el momento no hay manera simple o robusta de manejar las ambigüedades o las dudas. Por esta razón escogí recolectar datos verificables únicamente.\n\n¿Quién es parte de la red? ¿Quién no lo es?\n\nCualquier persona que sea mencionada como un ayudante, involucrado en actividades de ayuda, involucrado en actividades que pretendían reprimir la conducta prosocial. De hecho, algunas actividades de ayuda no tuvieron ninguna conexión con mis casos de estudio pero en otros casos este enfoque reveló inesperadas conexiones cruzadas entre redes.\n\n¿Qué tipos de relaciones puedes observar?\n\nCategorizaciones generales de: forma de ayuda, intensidad de las relaciones, duración de la ayuda, hora de la ayuda, hora de la primera reunión (ambas codificadas en pasos de 6 meses).\n\n¿Qué atributos son relevantes?\n\nPrincipalmente el estatus racial de acuerdo con la legislación del Nacional Socialismo.\n\n¿Qué esperas encontrar?\n\nUn entendimiento más profundo sobre quién ayuda a quién y cómo, y descubrir patrones en los datos que correspondan a la teoría de redes. Una interacción altamente productiva entre mis fuentes y la visualización de datos me llevaron a seguir con esto.\n\nTen en cuenta que los esquemas de codificación en general no pueden representar la complejidad total de las fuentes en tanto su ambivalencia y sus sutilezas. El propósito del esquema de codificación es desarrollar un modelo de relaciones en las cuales estés interesado. Como tal, los tipos de relaciones y los atributos son interpretaciones asbtraídas y categorizadas de las complejidades transmitidas en el texto(s). Esto también significa que en muchos casos los datos y visualizaciones en red solo tendrán sentido una vez se reunan con su contexto original, en mi caso, las fuentes primarias de donde los extraje.\n\nTraducir las interpretaciones textuales en recolección de datos tiene sus raíces en el análisis de datos cualitativos en sociología.  Es importante que tu tanto como otros, puedan volver sobre tus pasos y poder entender cómo has definido tus relaciones. Es muy útil definirlas de manera abstracta y dar ejemplos de tus fuentes para así ilustrar tus selecciones. Cualquier conjunto de datos que produzcas puede ser solo tan claro y coherente como tus prácticas de codificación. La claridad y la coherencia incrementan durante el proceso iterativo de crear esquemas de codificación y al probarlo en una variedad de fuentes diferentes hasta que encaje.\n\n\n    \n\n    Figura 2: Una primera aproximación al esquema de codificación\n\n\n\n\nLa figura 2 muestra una captura con una muestra de los datos del esquema de codificación que utilicé en mi proyecto. En este caso, Alice ayuda a Paul. Podemos expresar esto como una relación entre los actores “Alice” y “Paul” quienes comparten una relación en la categoría “Forma de ayuda”. Dentro de esta categoría encontramos la subcategoría “4. Alimentos, mercancías” que describe su relación con más detalle.\n\nLa mayoría de las herramientas de visualización en redes te permite especificar si una red es dirigida o, como en este caso, no dirigida. En redes dirigidas, las relaciones describen un intercambio entre uno y otro actor, en nuestro caso esto es “ayuda”. Por convención, los nodos activos son mencionados primero (en este caso Alice) en el conjunto de datos. En la visualización de una red dirigida verás flechas que van de un actor al otro. Las relaciones también pueden ser recíprocas, por ejemplo cuando Alice ayuda a Bob y Bob ayuda a Alice.\n\nSin embargo, muchas veces no tiene sentido trabajar con direccionalidad, por ejemplo cuando dos actores son simplemente parte de la misma organización. En este caso la red debe ser no dirigida y estaría representada con una línea simple entre dos actores.\n\nYo quería saber qué tan seguido los actores prestaban ayuda y qué tan seguido la recibían. En particular me interesaba el grado de los esfuerzos de autoayuda judía, por lo cual una aproximación desde una red dirigida y el rol de “Proveedor” y “Receptor” tenían sentido. La tercera columna en el esquema de codificación es opcional y provee información adicional sobre el tipo de relación entre Alice y Paul. Como categoría elegí “Forma de ayuda” la cual refleja las formas más comunes en que se dio el apoyo.\n\nLas categorías y subcategorías emergieron de un largo proceso de codificación de diferentes tipos de textos y diferentes tipos de redes de apoyo. Durante este proceso aprendí, por ejemplo, qué formas relevantes de ayuda son raramente descritas y en consecuencia no se pueden rastrear, como por ejemplo cuando se provee información como forma de apoyo. Anticipa tener que adaptar tu esquema de codificación frecuentemente al comienzo, y prepárate para recodificar tus datos algunas veces hasta que logres que haya una correspondencia consistente con tus fuentes e intereses.\n\nTal y como está, el esquema de codificación transmite la información según la cual Alice proveyó alimentos y otras mercancías a Paul, como lo indica el valor 4 que corresponde a la subcategoría “4. Alimentos, mercancías” en la categoría “Forma de ayuda”. Las relaciones humanas son sin embargo significativamente más complejas que esto y están caracterizadas por diferentes capas de relaciones siempre cambiantes. Hasta cierto punto podemos representar algo de esta complejidad al recolectar múltiples relaciones. Considera esta oración de muestra: “En septiembre de 1944 Paul se quedó donde su amiga Alice; se habían reunido alrededor de la Pascua del año anterior.”\n\n\n    \n\n    Figura 3: Una representación de la oración de muestra\n\n\n\n\nEl esquema de codificación en la Figura 3 describe la relación entre ayudantes y receptores de ayuda en mayor detalle. “Relación” por ejemplo da una caracterización general de qué tan bien se conocían dos actores, “Duración” captura la duración de un acto de ayuda, “Fecha de actividad” indica cuándo ocurrió un acto de ayuda y “Fecha de la primera reunión” debe explicarse por sí mismo. El valor “99” aquí especifica “desconocido” ya que la oración de muestra no describe la intensidad de la relación entre Alice y Paul con mayor detalle. Ten en cuenta que este esquema se enfoca exclusivamente en recolectar actos de ayuda, no en capturar el desarrollo de las relaciones entre las personas (que no están cubiertas por mis fuentes). Elecciones explícitas como esta definen el valor de los datos durante el análisis.\n\nTambién es posible recolectar información sobre los actores en la red; los llamados atributos de los datos utilizan más o menos el mismo formato. La Figura 4 contiene una muestra de datos para Alice y Paul.\n\n\n    \n\n    Figura 4: Muestra de atributos de datos\n\n\n\n\nSi leemos la información que está ahora almacenada en el esquema de codificación, aprendemos que Alice le proporció alojamiento a Paul (“Forma de ayuda”: 4), que no sabemos qué tan cercanos eran (“Relación”: 99) o cuánto tiempo se alojó Paul (“Duración”: 99). Sabemos, sin embargo, que esta relación tuvo lugar en algún momento durante la segunda mitad de 1944 (“Fecha de actividad”: 14) y que se habían reunido por primera vez en la primera mitad de 1943 (“Fecha de primera reunión”: 11). La fecha de la primera reunión puede inferirse de las palabras “alrededor de la Pascua de año anterior”. Si tengo alguna duda, siempre elijo “99” para representar “desconocido”.\n\nPero ¿qué tal si Alice también ayudó a Paul con apoyo emocional (otra subcategoría de “Forma de ayuda”) mientras que se quedó con ella? Para reconocer esto, codifiqué una fila que describe la provisión de alojamiento y una segunda fila abajo que describe la provisión de apoyo emocional. Ten en cuenta que no todas las herramientas de visualización de redes te permitirían representar lados paralelos e ignorarían el segundo acto de ayuda que ocurrió o intentarían unir las dos relaciones. Sin embargo tanto NodeXL como Palladio pueden manejar esto y se rumora que la próxima entrega de Gephi también tendrá está función. Si encuentras este problema y ninguna de estas herramientas son una buena opción para ti, yo recomendaría configurar una bases de datos relacional y trabajar con consultas específicas para cada visualización.\n\nEl proceso de diseñar dicho esquema de codificación te fuerza a ser explícito sobre tus supuestos, intereses y los materiales que tienes a tu disposición, algo que es valioso más allá del análisis de datos. Otro efecto secundario de extraer datos en red del texto es, que llegarás a conocer tus fuentes muy bien: oraciones que sigan el modelo de “La Persona A está conectada a la Persona B, C y D através de relaciones de tipo X en el momento X” serán probablemente muy inusuales. En cambio, se necesitará una lectura detallada, un conocimiento profundo del contexto y la interpretación para descubrir quién está conectado con quién y en qué forma. Esto significa que codificar datos de esta forma generará muchas preguntas y te llevará a estudiar tus fuentes con más profundidad y más rigurosamente que si hubieras trabajado con ellas de la manera “tradicional”.\n\nVisualiza datos en red utilizando Palladio\n\nUna vez hayas creado tu esquema de codificación y hayas codificado tus fuentes, estarás listo para visualizar tu red de relaciones. Primero asegúrate de que todas las celdas vacías estén llenas o con un número que represente un tipo de de enlace o con “99” para “desconocido”. Crea una nueva copia de tu archivo (Guarda como..) y elimina los códigos para las diferentes categorías para que tu hoja de cálculo se vea como la Figura 5.\n\n\n    \n\n    Figura 5: Muestra de atributos de los datos lista para ser exportada para visualización o computación.\n\n\n\n\nTodos los editores de hojas de cálculo permiten exportar tablas como .csv (valores separados por comas) o como archivos .txt . Estos archivos pueden ser importados a todas las herramientas de visualización de redes comunmente utilizados (ver lista al final del tutorial). Para tus primeros pasos yo sugiero que pruebes Palladio, una herramienta de fácil uso para visualización de datos que se encuentra en desarrollo activo por parte de la Universidad de Stanford. Palladio corre en navegadores y trabaja independiente de plataforma. Ten en cuenta que aunque Palladio es muy versátil, está diseñada más para visualizaciones rápidas que para análisis de redes sofisticado.\n\nLos siguientes pasos explican cómo visualizar datos en red en Palladio, pero también recomiendo que revises sus propios materiales de inducción y explores sus datos de muestra. Acá, sin embargo, utilizo un conjunto de datos ligeramente modificado con base en el esquema de codificación\ndatos 1 - Relaciones, datos 2 - attribute table, presentado antes (también lo puedes bajar y utilizarlo para explorar otras herramientas).\n\nPaso a paso:\n\n1. Palladio. Entra a http://palladio.designhumanities.org/.\n\n2. Comienza. En el sitio web haz clic en el botón “Start”.\n\n3. Carga los atributos de los datos. De tu hoja de cálculo, copia los atributos de los datos Atributos, pégalos en la sección blanca de la página, ahora haz clic en “Load”.\n\n\n    \n\n    Figura 6: Subiendo los atributos de los datos en Palladio.\n\n\n\n\n4. Edita los atributos. Cambia el título de la tabla por algo más significativo, como “Personas”. Ahora puedes ver la columna “Personas”, “Estatus racial” y “Sexo” los cuales corresponden a las columnas en los datos de muestra. Ahora necesitas asegurarte de que Palladio entienda que hay acciones asociadas con las personas que acaban de introducir en la base de datos.\n\n\n    \n\n    Figura 7: Vista de los atributos de los datos en Palladio.\n\n\n\n\n5. Carga los datos relaciones. Para hacer esto, haz clic en “Persona” y “Add a new table” (Añade una nueva tabla). Ahora pega todos los datos relacionales, en el campo apropiado. Palladio espera identificadores únicos para enlazar la información relacional a la información de atributo por actor. Asegúrate de que esto se alinee bien y evita caracteres irritantes como “/”. Palladio te avisará con mensajes de error si esto ocurre. Haz clic en “Load data” (Cargar datos), cierra la ventana superpuesta y regresa a la vista de los datos principales. Deberías ver algo como:\n\n\n    \n\n    Figura 8: Cargando los datos relacionales.\n\n\n\n\n6. Enlaza atributos y relaciones. Ahora necesitamos enlazar explícitamente las dos tablas que hemos creado. En nuestro caso, los nombres y apellidos de las personas funcionan como identificadores (ID) así que necesitamos conectarlos. Para hacer esto haz clic en la ocurrencias correspondientes en la nueva tabla. Es los archivos de muestra estas son “Proveedor” y “Receptor”. Haz clic en “Extension” (abajo al lado izquierdo) y selecciona “Personas”, la tabla que contiene toda la información de los atributos de las personas. Haz lo mismo para “Receptor”.\n\n\n    \n\n    Figura 9: Enlanzando personas y relaciones.\n\n\n\n\n7. Identifica datos temporales. Palladio tiene una característica especial para visualizar tiempo. La puedes usar si sabes cuándo empieza y cuando termmina cada relación. La muestra de datos contiene dos columnas con los datos necesarios para la categoría de tiempo. Haz clic en “Tiempo en que paso comienza” y selecciona el tipo de datos “Date” (Fecha). Haz lo mismo para “Tiempo en que paso termina” (Figura 10). El equipo de Palladio recomienda que tus datos estén en el formato de YYYY-MM-DD (AAAA-MM-DD), pero mi tiempo en formato más abstracto funciona bien. Si quisieras cargar coordenadas geográficas (no cubiertas en este tutorial pero disponible acá: Palladio Simple Map Scenario) tendrías que seleccionar el tipo de datos “Coordinates”.\n\n\n    \n\n    Figura 10: Cambiando el tipo de datos a ‘Date’ (Fecha)\n\n\n\n\n8. Carga la herramienta gráfica. Ya terminaste de cargar tus datos. Haz clic en “Graph” (Gráfica) para cargar la visualización de la interface (Figura 11).\n\n\n    \n\n    Figura 11: Carga la herramienta gráfica\n\n\n\n\n9. Especifica la fuente y el destino de los nodos. Primero que todo Palladio te pide especificar la “Source” (Fuente) y “Target” (Destino) de los nodos en la red (Figura 12). Empecemos con “Proveedores” y “Receptores”. Ahora verás el gráfico y podrás comenzar a estudiarlo con más detalle.\n\n\n    \n\n    Figura 12: Selecciones ‘Proveedor’ como ‘Source’ (‘Fuente’) y ‘Receptor’ como ‘Target’ (‘Destino’).\n\n\n\n\n10. Resalta los nodos. Continúa seleccionando las opciones de “Highlight” (“Resaltar”). Esto te dará una idea inmediata sobre quién actuó como proveedor de ayuda, quién únicamente recibió ayuda y qué actores fueron tanto proveedores como receptores de ayuda.\n\n11. Filtro de facetas. Ahora prueba el filtro de facetas, (Figura 13). Reconocerás las columnas que describen los diferentes actos de ayuda. Comienza seleccionando “3” en la columna de “Forma de ayuda”. Esto reducirá la gráfica a mostrar solamente provisiones de alojamiento. Después selecciona valores de la columna “Fecha de actividad” para continuar acortando tu consulta. Esto mostrará quién proveyó alojamiento y cómo cambia esto a través del tiempo. Vuelve a seleccionar todos los valores en una columna haciendo clic en la caja que se encuentra al lado del nombre de la columna. Toma el tiempo necesario para explorar el conjunto de datos – ¿cómo cambia a través del tiempo? Cuando acabes asegúrate de eliminar el filtro de facetas utilizando el ícono del basurero rojo.\n\nLas visualizaciones en red son increíblemente sugestivas. Recuerda que lo que sea que veas es una representación diferente de tu codificación de datos (y de las elecciones que hiciste en el camino) y que habrá errores que necesitarás arreglar. Cualquiera de las gráficas con las que trabajé hubieran podido ser diferentes de haber elegido tiempos diferentes para los pasos o incluído personas que apenas se conocían entre sí, pero que no se involucraron en ningún comportamiento de ayuda.\n\n\n    \n\n    Figura 13: El filtro de facetas en Palladio.\n\n\n\n\n12. Visualización de redes bipartitas. Esto es muy bueno, pero hay algo más que hace de Palladio una gran herramienta para iniciarse con las visualizaciones en red: hace que sea muy fácil producir redes bipartitas, o redes de 2 modos. Lo que has visto hasta ahora es la llamada red unipartita o red de 1 modo: representa las relaciones entre los nodos de fuente y de destino (por ejemplo, personas) a través de uno o más tipos de relaciones. Las figuras 13 y 14 son ejemplos de este tipo de gráficas.\n\nEl análisis de redes sin embargo te da mucha libertad para repensar lo que son la fuente (Source) y el destino (Target). Las redes bipartitas tienen dos tipos diferentes de nodos, un ejemplo puede ser seleccionar “personas” como el primer tipo de nodo y “punto en el tiempo” como el segundo. La Figura 15 muestra una red bipartita y revela qué receptores de ayuda estuvieron presentes en la red al mismo tiempo. Compara esta gráfica con la Figura 16 que muestra qué proveedores de ayuda estuvieron presentes al mismo tiempo. Esto señala un alto grado de fluctuación entre los proveedores, una observación que resulta válida para todas las redes que estudié. Mientras los humanos somos muy hábiles procesando redes entre personas, procesar estas redes más abstractas se nos dificulta. Intenta experimentar con diferentes redes bipartitas: Haz clic en “Target” (Destino) pero esta vez selecciona “Forma de ayuda” o “Género” o cualquier otra categoría.\n\nTen en cuenta que si quisieras ver “Proveedor” y “Receptor” como un tipo de nodo y “Fecha de actividad” como el segundo, deberás crear en tu editor de hojas de cálculo una columna con todas las personas y una segunda columna con los puntos en el tiempo durante los cuales las personas estuvieron presentes e importar estos datos a Palladio. También en este momento Palladio todavía no te deja representar los atributos de los datos coloreando los nodos, pero todas las demás herramientas tienen esta funcionalidad.\n\n\n    \n\n    Figura 14: Visualización de una red unipartita: Proveedores y Receptores de ayuda.\n\n\n\n\n\n    \n\n    Figura 15: Visualización de una red bipartita: Receptores y Fecha de Actividad.\n\n\n\n\n\n    \n\n    Figura 16: Visualización de una red bipartita: Proveedores y Fecha de actividad\n\n\n\n\n13. Línea del tiempo. La opción “Timeline” (Línea del tiempo) proporciona una forma relativamente fácil de visualizar cambios en tu red. La Figura 17 muestra la distribución de hombres y mujeres en la red a lo largo de un periodo. La primera columna en el eje y corresponde al campo “Fechas” y representa los diferentes pasos en el tiempo. Las barras representan el atributo de “Sexo”: desconocido, número de hombres y mujeres está representados por la altura de los segmentos en una barra (estas van desde el color gris claro hasta el negro). Coloca el cursor sobre las barras para ver qué representa cada segmento. La barra de abajo corresponde al campo “Height shows” y acá representa el número total de personas que cambian entre los pasos en el tiempo 13 y 14.\n\n\n    \n\n    Figura 17: Distribución de género en la red a lo largo del tiempo.\n\n\n\n\n14. Periodo. Aun más interesante es la vista de “Time Span” (Periodo de tiempo) que actualiza la visualización de red dinámicamente. Haz clic en “Time Span”. La Figura 18 ilustra lo que deberías ver ahora. Utiliza el ratón para resaltar la sección entre los pasos en el tiempo que estáran resaltados gris. Ahora puedes arrastrar la sección resaltada através de la línea del tiempo y ver cómo cambia la gráfica entre paso y paso en el tiempo.\n\n\n    \n\n    Figure 18: Vizualización de pasos en el tiempo en línea del tiempo.\n\n\n\n\n15. Tamaño del nodo. Palladio te deja cambiar el tamaño de tus nodos con base en los atributos de los actores. Ten en cuenta que esto no tiene sentido para los datos de la muestra dado que los valores numéricos representan categorías. Sin embargo, los tamaños de los nodos puedes ser útiles si fueras a representar las suma de los actos de ayuda de una persona, lo que en este caso correspondería a su Grado de salida, el número de relaciones salientes para un nodo.\n\n16. Exporta tu visualización. Palladio te deja exportar tus redes como archivos .svg, un formato de imagen hecho con vectores. Utiliza tu navegador preferido para abrirlas.\n\n17. Listas, mapas y galerías. Te habrás dado cuenta que Palladio tiene una variedad adicional de formatos de visualización: listas, mapas y galerías. Al igual que la sección de gráfico, estas son intuitivas y están bien diseñadas. La opción  “Galleries”  te deja especificar ciertos atributos de tus actores y presentarlos como tarjetas. Al añadir valores de latitud y longitud a tus actores podrás tener una idea instantánea de dónde ocurre tu red. Dale una mirada a los archivos de prueba de Palladio para explorar esto.\n\nEl valor agregado de las visualizaciones de redes\n\nLa extracción cuidadosa de datos de redes desde texto tarda mucho tiempo y es agotadora pues require de mucha concentración en cada paso del camino. Regularmente me pregunté si valía la pena y si al final habría podido hacer las mismas observaciones sin el apoyo de las visualizaciones de redes. La respuesta es sí, podría haber llegado a las mismas conclusiones sin la codificación de todos estos datos y sí, valió la pena. Anotar los datos relacionales se vuelve muy rápido y sin dolor en el proceso de hacer la lectura detallada.\n\nEn mi experiencia, la lectura detallada guiada por preguntas y la interpretación por un lado y por el otro la codificación y visualización de datos no son procesos separados del todo sino que están entrelazados y se pueden complementar uno al otro de manera  efectiva. El juego no es considerado generalmente como algo muy académico, pero especialmente con este tipo de datos es una valiosa inversión de tu tiempo: no solamente juegas con tus datos, los reorganizas y por ende repiensas constantemente lo que sabes de tu tema y que puedes saber sobre tu tema de investigación.\n\nCada lazo que codifiqué representa la historia de cómo alguien ayudó a alguien más. Las visualizaciones de redes me ayudaron a entender cómo estas cerca de 5,000 historias y 1,400 individuos se relacionaban unos con otros. Muchas veces confirmaron lo que ya sabía pero regularmente también me sorprendieron y generaron preguntas interesantes. Por ejemplo, me ayudaron a identificar a Walter Heymann como la persona cuya mediación entre contactos comenzó dos redes de apoyo importantes que posteriormente le permitieron salvar a cientos de personas. Descripciones de su contacto con actores destacados en ambas redes estaban dispersas en diferentes documentos con los cuales yo había trabajado en diferentes fases del proyecto. La visualización agregó todas estas relaciones y reveló estas conexiones. Más investigación después mostró que de hecho fue él quien los reunió a todos.\n\n\n    \n\n    Figura 19: Walter Heymann medió entre contactos lo que llevó al surgimiento de dos redes de apoyo importantes.\n\n\n\n\nEn otras ocasiones las visualizaciones revelaron la existencia de cadenas de contactos de largo alcance entre diferentes clases sociales lo cual ayudó a los refugiados crear lazos de confianza con extraños, también mostraron brechas inesperadas entre actores que yo esperaba que estuvieran conectados, me llevaron a identificar grupos en listas de nombres que se traslapaban, observar fases de actividad e inactividad, me ayudaron identificar personas que tendieron puentes entre diferentes grupos y en general, me llevaron a enfatizar la mediación entre contactos de víctimas judías como un factor importante y hasta ahora ignorado en el surgimiento de redes encubiertas.\n\nLas visualizaciones por supuesto no son “prueba” de nada sino herramientas para ayudar a entender relaciones complejas; su interpretación está basada en un buen entendimiento de los datos subyacentes y como fue visualizadas. Una selección de visualizaciones de redes pueden además acompañar el texto y ayudar a tu audiencia a entender mejor las complejas relaciones que discutes, así como los mapas que a veces encuentras en la contraportada de libros viejos.\n\nAlgunos aspectos prácticos:\n\n\n  Recolecta y almacena tus datos en una hoja de cálculo y utiliza una copia para las visualizaciones\n  Asegúrate de entender el razonamiento detrás de cualquier algoritmo de centralidad o de diseño que elijas pues esto afectará la forma en la ves tus datos. Wikipedia es usualmente una buena fuente sobre información comprensiva acerca de estos.\n  No dudes en revisar y empezar de nuevo si sientes que tu esquema de codificación no funciona como lo esperabas. Sin duda esto valdrá la pena.\n\n\nFinalmente, cualquiera de las visualizaciones que puedes crear con el conjunto de datos de muestra en esta lección requiere conocimiento del contexto para ser verdaderamente significativo. La única forma para descubras si este método tiene sentido para tu investigación, es empezar a codificar tus propios datos y utilizar tu propio conocimiento del contexto para darle sentido a las visualizaciones.\n\n¡Buena suerte!\n\nOtras herramientas de visualización para tener en cuenta\n\nNodegoat – similar a Palladio en cuanto que hace fácil la recolección de datos, el mapeo y la visualización en gráficas. Permite confirgurar fácilmente bases de datos relacionales y deja a los usuarios almacenar sus datos en servidores. El tutorial está disponible acá.\n\nNodeXL – capaz de hacer varias tareas comunes en el análisis de redes sociales, fácil de usar, de código abierto pero requiere Windows y MS Office 2007 o más nuevo para correr. Tutorial 1, Tutorial 2.\n\nGephi – programa de código abierto para cualquier plataforma. Es la más versátil y mejor conocida herramienta de visualización excepto por una curva de aprendizaje muy alta. Los desarrolladores anuncian soporte para lados paralelos en la versión 1.0. Tutoriales: por Clement Levallois y Sebastien Heymann.\n\nVennMaker – es independiente de plataforma y puede probarse de manera gratuita. VennMaker invierte el proceso de recolección de datos: los usuarios comienzan con un lienzo personalizable y dibujan los nodos auto-definidos en él. La herramienta recolecta los datos correspondientes tras bastidores.\n\nLas herramientas más comunmente utilizadas para análisis más matemáticos son UCINET (tiene licencia y turoriales disponibles en su página web) y Pajek (gratuito) por el cual existe un muy buen libro de guía. Ambos fueron desarrollados por Windows pero corren bien en otros sistemas utilizando Wine.\n\nPara usuarios de Python el muy bien documentado paquete Networkx es un gran punto de partida; existen otros paquetes para otros lenguajes de programación.\n\n\nLa visualizaciones de redes pueden ayudar a los humanistas a revelar patrones complejos escondidos y estructuras en fuentes textuales. Este tutorial explica cómo extraer datos en red (personas, instituciones, lugares, etcétera.) de fuentes históricas a través del uso de métodos no especializados desarrollados en el marco del análisis de datos qualitativos (Qualitative Data Analysis, QDA) y el análisis de redes sociales (Social Network Analysis, SNA), y cómo visualizar estos datos con Palladio, una aplicación independiente de plataforma y que es particularmente fácil de usar.\n\n"
  },


  {
    "id": 7,
    "url": "http://localhost:4000/es/lecciones/crear-exposicion-con-omeka",
    "title": "Crear una exposición con Omeka",
    "body": "\nCrear una exposición con Omeka\n\nContenidos\n\n\n  Antes de empezar: mapea tu exposición\n  Agrega tu exposición\n  Agrega una página\n  Agrega un bloque de contenido a tu página\n  Agrega contenido a tu bloque de contenido\n  ¡Tienes una página en Omeka!\n\n\nAntes de empezar: mapea tu exposición\n\nEs necesario pensar la exposición antes de empezar a crearla. Crearás secciones y páginas y, para esto, necesitarás pensar qué argumento plasmar y cómo piensas hacerlo. En la siguiente lección uso el simple ejemplo de mis perros. Pero ¿qué pasaría si trabajara, digamos, el cine mudo? Mis secciones podrían ser temáticas (comedias, romances, dramas), cronológicas (primeras películas de cine mudo, periodo de transición, era clásica) o de estilo (moderno, impresionista, narrativo.) Todo depende del mensaje que quiera transmitir a los visitantes del sitio. Podrías dibujar un mapa de la exposición, mostrando dónde quieres ubicar cada recurso digital.\n\nAgrega tu exposición\n\n\n    \n\n    Crea una página de exposición\n\n\n\n\nUna colección es una simple lista de objetos. Una exposición es un recorrido guiado por tus artículos, complementado con textos descriptivos y diseños personalizados. Para crear una exposición, presiona el botón que dice Exhibit (exposición) y Add an exhibit(añadir exposición). Llena los campos de la parte superior de la página. Un slug es un nombre de tu exposición legible para una máquina y se convertirá en parte de tu URL.\n\nAgrega una página\n\nLas páginas son donde vas a pegar los artículos de tu exposición. Una exposición puede tener múltiples páginas y puedes arrastrarlas y soltarlas para reorganizar su orden e incluso hacer que ciertas páginas sean subsecciones de otras páginas.\n\nPresiona el botón verde Add Page (añadir página). En la siguiente página ingresarás cierta información y escogerás un diseño para la exposición de tu página.\n\nAgrega un bloque de contenido a tu página\n\n\n    \n\n    Campos en ‘añadir una página’\n\n\n\n\nEn la página siguiente verás la opción Page Title (título de página) y Slug. Llena dichos campos.\n\nVerás la opción New Block (nuevo bloque). Las páginas están compuestas de bloques, los cuales pueden ser archivos y texto, sólo archivos o sólo texto.\n\nHaz click en la opción File with Text (archivo con texto) y después en Add new content block (añadir un contenido de bloque nuevo).\n\nAgrega contenido a tu bloque de contenido\n\n\n    \n\n    Añade un objeto y un archivo a tu bloque de contenido\n\n\n\n\nEn Block 1 (File with Text) (Bloque 1 (Archivo con texto)) presiona el botón Add Item (añadir objeto).\n\nEn la ventana que se va a abrir, haz click en tu artículo y luego presiona Select Item (seleccionar objeto). Puedes agregar un pie de foto si quieres. Presiona el botón verde Apply (aplicar). También he agregado un texto de relleno en el campo Text (texto).\n\nCuando hayas acabado presiona el botón View Public Page para ver cómo quedó tu sitio en Omeka.\n\n¡Tienes una página en Omeka!\n\n\n    \n\n    El perro Bertie es un objeto en la exposición\n\n\n\n\nAhora tu sitio tiene artículos, colecciones y una exposición – ¡todos los elementos básicos de un sitio Omeka!\n\nAhora que has agregado los artículos a tu sitio Omeka y los agrupaste por colecciones, estás listo para el paso siguiente: llevar a tus usuarios a un tour guiado por los artículos coleccionados.\n\n"
  },


  {
    "id": 8,
    "url": "http://localhost:4000/es/lecciones/crear-y-ver-archivos-html-con-python",
    "title": "Crear y ver archivos HTML con Python",
    "body": "\nCrear y ver archivos HTML con Python\n\nContenidos\n\n\n  Objetivo de la lección\n  Archivos necesarios para esta lección\n  Crear HTML con Python\n  ‘Hola Mundo’ en HTML usando Python\n  Utilizar Python para controlar Firefox    \n      Instrucciones para usuarios de Mac\n      Instrucciones para Windows\n    \n  \n  Lecturas sugeridas    \n      Sincronización de código\n    \n  \n\n\nObjetivo de la lección\n\nEsta lección utiliza Python para crear y ver un archivo HTML. Si escribes programas que tengan salida en HTML puedes utilizar cualquier navegador para ver tus resultados. Esto es especialmente conveniente si tu programa crea automáticamente hipervínculos o entidades gráficas y diagramas.\n\nAquí aprenderás cómo crear archivos HTML con scripts de Python, y cómo utilizar Python para abrir un archivo HTML en Firefox.\n\nArchivos necesarios para esta lección\n\n\n  obo.py\n\n\nSi no tienes estos archivos de las lecciones anteriores, puedes descargar python-es-lecciones5, un archivo zip de las lecciones anteriores.\n\nCrear HTML con Python\n\nEn este punto hemos comenzado a aprender cómo utilizar Python para descargar fuentes documentales en línea y extraer información de ellas automáticamente. Recuerda que nuestro objetivo final es incorporar fácilmente la programación a nuestra práctica de investigación. Acorde con este objetivo, en esta lección y la siguiente vamos a aprender cómo recuperar nuestros datos como HTML. Esto tiene algunas ventajas. Primero, al almacenar nuestra información en nuestro disco duro como HTML podemos abrirla con Firefox y utilizar Zotero para indexarla y anotarla después. Segundo, hay una amplia gama de visualizaciones para HTML que podemos aprovechar más adelante.\n\nSi no has hecho todavía el tutorial de HTML de W3 Schools, invierte tiempo en ello antes de continuar. Buscamos crear un documento HTML con Python así que necesitas saber qué es un documento HTML.\n\n‘Hola Mundo’ en HTML usando Python\n\nUna de las ideas más poderosas en la informática es que un archivo que parece contener código desde una perspectiva puede ser visto como conjunto de datos desde otra. Es posible, en otras palabras, escribir programas que manipulen otros programas. Lo que vamos a hacer es crear un archivo HTML que diga “Hola Mundo” utilizando Python. Lo haremos almacenando etiquetas HTML en una cadena multilineal de Python y guardando el contenido en un nuevo archivo. Este archivo se guardará con una extensión .html en vez de .txt.\n\nNormalmente un archivo HTML comienza con una declaración doctype. Viste esto cuando escribiste un programa “Hola Mundo” en HTML en una lección anterior. Para hacer que la lectura de nuestro código sea más fácil, omitiremos el doctype en este ejemplo. Recuerda que una cadena multilineal se crea encerrando el texto en tres juegos de comillas (ver abajo).\n\n# escribe-html.py\n\nf = open('holamundo.html','wb')\n\nmensaje = \"\"\"&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;&lt;p&gt;Hola Mundo!&lt;/p&gt;&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n\nf.write(mensaje)\nf.close()\n\n\nGuarda el programa anterior como escribe-html.py y ejecútalo. Utiliza File -&gt; Open en tu editor seleccionado para abrir holamundo.html para verificar que tu programa en realidad creó el archivo. El contenido debe verse como esto:\n\n\n    \n\n    Fuente HTML generada con Python\n\n\n\n\nAhora ve a tu navegador Firefox y elige Archivo-&gt; Nueva pestaña; ve a la pestaña y elige Archivo-&gt; Abrir archivo Selecciona holamundo.html. Ahora deberías ver el mensaje en el navegador. Detente un momento para pensar en esto: ahora tienes la habilidad de escribir un programa que crea automáticamente una página Web. No hay ninguna razón por la que no podrías escribir un programa para crear automáticamente un sitio Web completo si lo quisieras.\n\nUtilizar Python para controlar Firefox\n\nCreamos automáticamente un archivo HTML, pero entonces tuvimos que dejar nuestro editor e ir a Firefox para abrir ese archivo en una nueva pestaña. ¿No sería genial que nuestro programa de Python incluya este paso final? Escribe o copia el código de abajo y guárdalo como escribe-html-2.py. Cuando lo ejecutas debe crear y abrir automáticamente tu archivo HTML en una nueva pestaña de Firefox. ¡Genial!\n\nInstrucciones para usuarios de Mac\n\nLos usuarios de Mac deben especificar la localización precisa del archivo .html en su computadora. Para hacerlo, localiza la carpeta programming-historianque creaste para hacer estos tutoriales, haz clic con el botón derecho y selecciona “Obtener información”.\n\nPuedes entonces copiar y pegar la localización del archivo enlistado después de “Ubicación:” y asegúrate de incluir una diagonal (/) para permitirle a la computadora saber que quieres algo dentro del directorio (en vez del directorio en sí mismo).\n\n# escribe-html-2-mac.py\nimport webbrowser\n\nf = open('holamundo.html','wb')\n\nmensaje = \"\"\"&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;&lt;p&gt;Hola Mundo!&lt;/p&gt;&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n\nf.write(mensaje)\nf.close()\n\n#Cambia la ruta para indicar la localización del archivo\nnombreArchivo = 'file:///Users/username/Desktop/programming-historian/' + 'holamundo.html'\nwebbrowser.open_new_tab(nombreArchivo)\n\n\nSi recibes un error de “File not found” no has cambiado la ruta de nombre de archivo correctamente.\n\nInstrucciones para Windows\n\n# escribe-html-2-windows.py\n\nimport webbrowser\n\nf = open('holamundo.html','wb')\n\nmensaje = \"\"\"&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;&lt;p&gt;Hola Mundo!&lt;/p&gt;&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n\nf.write(mensaje)\nf.close()\n\nwebbrowser.open_new_tab('holamundo.html')\n\n\n***\n\nNo solamente has escrito un programa en Python que puede escribir HTML simple, sino que también has logrado controlar tu navegador de Firefox utilizando Python. En la siguiente lección regresaremos a la salida de datos que hemos recolectado como un archivo HTML.\n\nLecturas sugeridas\n\n\n  Lutz, Learning Python\n    \n      Re-read and review Chs. 1-17\n    \n  \n\n\nSincronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto. Si estás trabajando con la versión Mac o Linux de las lecciones deberás abrir el archivo obo.py y cambiar “file:///Users/username/Desktop/programming-historian/” a la ruta del directorio de tu propia computadora.\n\n\n  python-es-lecciones6.zip zip sync\n\n\n\nAquí aprenderás cómo crear archivos HTML con scripts de Python, y cómo utilizar Python para abrir un archivo HTML en Firefox.\n\n"
  },


  {
    "id": 9,
    "url": "http://localhost:4000/es/lecciones/datos-de-investigacion-con-unix",
    "title": "Contabilizar y minar datos de investigación con Unix",
    "body": "\nContabilizar y minar datos de investigación con Unix\n\nContenidos\n\n\n  Contabilizar y minar datos de investigación con Unix    \n      Introducción\n      Software y configuración\n      Contando archivos\n      Extracción de información o minería de archivos        \n          Conclusión\n        \n      \n    \n  \n\n\nContabilizar y minar datos de investigación con Unix\n\nIntroducción\n\nCuando tus datos de investigación están organizados de manera clara y predecible, pueden ser contabilizados y puedes extraer información utilizando el intérprete de comandos (shell) de Unix. Esta lección se apoya en las lecciones “Preservar tus datos de investigación” e “Introducción a la línea de comandos de Bash”. Dependiendo de la seguridad que hayas adquirido en el uso del intérprete de Unix, también puede ser útil como lección o actualización independiente.\n\nCuando se acumulan datos de investigación para un proyecto, un historiador puede hacerse preguntas diferentes al volver a revisar los datos en un proyecto posterior. Si los datos se distribuyen en diversos archivos, como una serie de datos tabulados, un conjunto de textos transcritos o una colección de imágenes, se pueden manipular utilizando sencillos comandos de Unix.\n\nEl intérprete de Unix te brinda acceso a un abanico de potentes comandos que pueden transformar la manera en que contabilizas y extraes información de tus datos. Esta lección te introduce a una serie de comandos para el recuento y la extracción de datos tabulados, aunque de manera superficial respecto de lo que puede hacer el intérprete de Unix. Al aprender algunos comandos podrás realizar tareas que son imposibles en LibreOffice Calc, Microsoft Excel u otros programas de hoja de cálculo similares. Estas órdenes se pueden aplicar fácilmente a datos no tabulados.\n\nTus posibilidades para manipular, contar y extraer datos dependerán, generalmente, de la cantidad de metadatos -o texto descriptivo- contenidos en los nombres de los archivos que estás utilizando, así como del rango de comandos de Unix que hayas aprendido a usar. Por lo tanto, incluso si no te parece necesario trabajar con el intérprete de Unix, será bueno que dediques un tiempo en estructurar mejor tus archivos de datos y tus convenciones para nombrarlos, de manera consistente y predecible. Será un paso significativo para obtener el máximo rendimiento de los comandos de Unix y poder contabilizar y extraer información de tus datos. Dada la importancia de que tus datos sean consistentes y predecibles, más allá del tema de su preservación, consulta: “Preservar tus datos de investigación”\n\n\n\nSoftware y configuración\n\nLos usuarios de Windows deben instalar Git Bash. Lo pueden hacer descargando el más reciente instalador de la página web de Git para Windos. Las instrucciones para su instalación están disponibles en Open Hatch (en inglés).\n\nLos usuarios de OS X y Linux necesitarán utilizar la Terminal, o intérprete de línea de comandos, como se explica en la “Introducción a la línea de comandos de Bash.”\n\nEsta lección se escribió utilizando Git Bash 1.9.0 en sistema operativo Windows 7. Se han incluido, cuando ha sido posible, rutas de archivo equivalentes para OS X/Linux. Sin embargo, como los comandos y variables pueden cambiar ligeramente entre sistemas operativos, los usuarios de OS X/Linux pueden consultar Deborah S. Ray y Eric J. Ray, Unix and Linux: Visual Quickstart Guide, 4a ed. (2009), que cubre la interoperabilidad con gran detalle. (N. del T.: en español se puede consultar Unix y linux : Guía práctica\n\nLos archivos utilizados en esta lección están disponibles en “Figshare”. Estos contienen metadatos de artículos académicos catalogados en el rubro ‘Historia’ en la base de datos ESTAR de la Biblioteca Británica. Los datos son distribuidos bajo una renuncia de derechos de autor CC0.\n\nDescarga los datos requeridos en tu ordenador y descomprime el archivo zip. Si no cuentas con un software adecuado para descomprimir archivos .zip, te recomendamos 7-zip. En Windows, te aconsejamos descomprimir la carpeta en tu disco C: para que los archivos queden en tu directorio c:\\proghist\\. No obstante, cualquier locación trabajará bien, pero entonces es posible que tengas que ajustar tus comandos conforme vayas siguiendo la lección. En OS X o Linux, también te aconsejamos descomprimir en tu directorio de usuario para que aparezcan en /user/NOMBREDEUSUARIO/proghist/. En ambos casos, esto significa que cuando abras una nueva ventana de tu terminal, con solamente teclear cd proghist te podrás mover al directorio correcto.\n\n\n\nContando archivos\n\nComenzaremos esta lección contando el contenido de los archivos utilizando el intérprete de Unix. Éste puede ser utilizado para realizar conteos rápidos en varios archivos, algo que difícilmente lograrás a través de la interfaz gráfica de usuario (GUI por sus siglas en inglés) de las suites ofimáticas comunes.\n\nEn Unix, el comando wc se utiliza para contabilizar los contenidos de un archivo o una serie de ellos.\n\nAbre el intérprete de Unix y entra al directorio que contiene nuestros datos, el subdirectorio data del directorio proghist. Recuerda que, si en algún momento no sabes en qué lugar estás dentro de la estructura de tu directorio, escribe pwd y usa el comando cd para moverte a donde lo necesites. La estructura de directorios es ligeramente diferente entre OS X/Linux y Windows: en el primero, el directorio tiene el siguiente formato ~/users/NOMBREDEUSUARIO/proghist/data mientras que en Windows su formato es c:\\proghist\\data.\n\nEscribe ls y oprime Enter. Esto imprime o muestra una lista que incluye dos archivos y un subdirectorio.\n\nLos archivos en este directorio son: el conjunto de datos 2014-01_JA.csv que contiene los metadatos de los artículos académicos y un archivo con documentación acerca de 2014-01_JA.csv, llamado 2014-01_JA.txt.\n\nEl subdirectorio se llama derived_data. Contiene cuatro archivos .tsv derivados del archivo 2014-01_JA.csv. Cada uno de estos incluye los datos en los que aparece una palabra clave como africa o america en el campo ‘Title’ de 2014-01_JA.csv. El directorio derived_data también incluye un subdirectorio llamado results.\n\nNota: Los archivos CSV son aquellos en los que las unidades de datos, o celdas de una tabla, están separados por comas (valores separados por comas) y los archivos TSV son aquellos en los que están separados por tabuladores. Ambos se pueden leer en cualquier editor de texto o en programas de hoja de cálculo como Libre Office Calc o Microsoft Excel.\n\nAntes de que comiences a trabajar con estos archivos debes moverte al directorio en el que están almacenados. Navega a c:\\proghist\\data\\derived_data en Windows o a ~/users/NOMBREDEUSUARIO/proghist/data/derived_data en OS X.\n\nYa que estés ahí puedes contabilizar el contenido de los archivos.\n\nEl comando Unix para conteo es wc. Escribe wc -w 2014-01-31_JA_africa.tsv y presiona Enter. La variable -w combinada con la orden wc instruye a tu computadora para imprimir en la ventana del intérprete un conteo de palabras y mostrar el nombre del archivo que ha sido contabilizado.\n\nComo vimos en “Introducción a la línea de comandos de Bash”, las variables como -w son importantes para obtener el máximo rendimiento del intérprete de Unix ya que nos permiten un mejor control de los comandos.\n\nSi tu investigación está más enfocada al número de entradas (o líneas) que al número de palabras, puedes usar la variable de conteo de líneas. Escribe wc -l 2014-01-31_JA_africa.tsv y presiona Enter. La variable -l combinada con la orden wc imprime el conteo de líneas y el nombre del archivo que ha sido contabilizado.\n\nAhora escribe: wc -c 2014-01-31_JA_africa.tsv y oprime Enter. Aquí utilizamos la variable -c en combinación con la orden wc para imprimir el conteo de caracteres del archivo 2014-01-31_JA_africa.tsv.\n\nNota: los usuarios de OS X y Linux pueden utilizar también -m en vez de -c.\n\nCon estas tres variables, lo más obvio que pueden hacer los historiadores es una comparación rápida del perfil de sus fuentes en formato digital. Por ejemplo, un conteo de palabras por página de un libro, la distribución de caracteres por página a través de una colección de periódicos, el promedio de longitud de líneas utilizadas por los poetas. Puedes utilizar wc en combinación con comodines y variables para construir consultas más complejas. Escribe wc -l 2014-01-31_JA_a*.tsv y presiona Enter. Verás el conteo de líneas de los archivos 2014-01-31_JA_africa.tsv y 2014-01-31_JA_america.tsv, lo que ofrece una manera simple de comparar los dos conjuntos de datos. Por supuesto, puede ser más rápido comparar la cantidad de líneas en los dos documentos con Libre Office Calc, Microsoft Excel o algún programa de hoja de cálculo similar. Pero cuando quieres comparar la cantidad de líneas para decenas, cientos o miles de documentos, el intérprete de Unix tiene una clara ventaja en cuanto a velocidad.\n\nAdemás, a medida que nuestros conjuntos de datos aumentan en tamaño, puedes usar el intérprete de Unix para hacer cosas más interesantes que copiar tus recuentos de líneas manualmente mediante la impresión en pantalla o copiar y pegar. Con el operador de redireccionamiento &gt; puedes exportar los resultados de la consulta a un nuevo archivo. Escribe wc -l 2014-01-31_JA_a*.tsv&gt; results / 2014-01-31_JA_a_wc.txt y presiona Enter. Lo anterior ejecuta la misma consulta pero, en lugar de imprimir los resultados en la ventan del intérprete de Unix, guarda los resultados como 2014-01-31_JA_a_wc.txt. Al indicar results /, se genera el archivo .txt en el subdirectorio results. Para comprobar esto, navega al subdirectorio results, presiona Enter, escribe ls, y presiona Enter nuevamente para ver que este archivo está enlistado dentro c:\\proghist\\data\\derived_data\\results en Windows, o /users/USERNAME/proghist/data/derived_data/results en OS X / Linux.\n\nExtracción de información o minería de archivos\n\nEl intérprete de Unix puede hacer mucho más que contar palaras, caracteres y líneas dentro de un archivo. La orden grep (que significa ‘impresión de una expresión regular global’) se utiliza para buscar cadenas de caracteres específicas a lo largo de diversos archivos. Es capaz de hacerlo mucho más rápido que la interfaz de búsqueda gráfica ofrecida por la mayoría de los sistemas operativos o las suites de ofimática. Combinado con el operador &gt;, el comando grep se convierte en una poderosa herramienta de búsqueda. Puedes utilizarla para minar o extraer información acerca de las características o agrupaciones de palabras que aparecen en varios de los archivos y luego exportar los resultados a un nuevo archivo. Las únicas limitaciones aquí son: tu imaginación, la forma en la que están organizados tus datos y, cuando trabajas con miles o millones de archivos, el poder de procesamiento del que dispongas.\n\nPara comenzar a utilizar el comando grep, navega primero al directorio derived_data (cd ..). Ahí, escribe grep 1999 *.tsv y oprime Enter. Esta búsqueda rastrea todos los archivos .tsv en el directorio que concuerden con el criterio dado: que contengan la cadena de caracteres ‘1999’ e imprime las cadenas resultantes en la ventana del intérprete.\n\nNota: es una gran cantidad de datos para imprimir, así que, si te aburre esperar, oprime ctrl+c para cancelar la ación. Ctrl+c se utiliza para abortar cualquier proceso en el intérprete de Unix.\n\nPresiona la flecha hacia arriba una vez para volver a la orden más reciente. Modifica grep 1999 *.tsv por grep -c 1999 *.tsv y presiona Enter. El intérprete imprime ahora el número de veces que aparece la secuencia 1999 en cada archivo .tsv. Regresa otra vez a la línea anterior y modifica esto así: grep -c 1999 2014-01-31_JA_*.Tsv &gt; results/2014-01-31_JA_1999.txt y presiona enter. Esta consulta busca la cadena ‘1999’ en todos los documentos y guarda los resultados en el archivo 2014-01-31_JA_1999.txt dentro del subdirectorio results.\n\nLa cadena de caracteres puede contener letras: grep -c revolution 2014-01-31_JA_america.tsv 2014-02-02_JA_britain.tsv, por ejemplo, contabiliza las veces que aparece la cadena ‘revolution’ en los archivos definidos e imprime los resultados en el intérprete. Ejecuta esto y luego modifícalo a grep -ci revolution 2014-01-31_JA_america.tsv 2014-02-02_JA_britain.tsv. Lo anterior repite la búsqueda y la imprime pero sin diferenciar mayúsculas y minúsculas, así que incluye revolution y Revolution. Observa que el conteo se ha incrementado casi 30 veces por los títulos de artículos de revistas que contienen la palabra clave ‘revolution’. De nuevo, si vuelves a la orden anterior y añades &gt; results/, seguido del nombre de un archivo -idealmente en formato .txt, se guardarán los resultados en un archivo.\n\nTambién puedes utilizar grep para crear subconjuntos de datos tabulados. Escribe grep -i revolution 2014-01-31_JA_america.tsv 2014-02-02_JA_britain.tsv &gt; AÑO-MES-DIA_JA_america_britain_i_revolution.tsv (donde AÑO-MES-DIA será la fecha en la que estés completando esta lección) y oprime Enter. Este comando busca en ambos archivos definidos y exporta cualquier línea que contenga revolution (sin importar mayúsculas) al archivo .tsv especificado.\n\nLos datos no se guardaron en el directorio results porque nos son estrictamente resultados sino datos derivados. Dependiendo de tu proyecto de investigación será preferible guardar estos en otro subdirectorio. Por ahora mira dentro de este archivo para verificar su contenido y, una vez hecho,  bórralo utilizando el comando rm. Nota: el comando rm es muy potente y debe ser usado con cautela. Consulta, por favor, “Introducción a la línea de comandos de Bash” para mayor información de cómo utilizarlo correctamente.\n\nFinalmente, puedes insertar otra variable, -v, para excluir elementos de los datos cuando uses el comando grep. Escribe grep -iv revolution 2014*_JA_a*.tsv &gt; 2014_JA_iv_revolution.csv y oprime Enter. Esta búsqueda rastrea todas las líneas que no contienen revolution o Revolution en los tres archivos definidos y las exporta al archivo c:\\proghist\\data\\derived_data\\2014_JA_iv_revolution.csv.\n\nFíjate que has transformado los datos de un formato de archivo a otro, de .tsv a .csv. A menudo se produce una pérdida en la estructura de datos cuando realizas estas transformaciones. Confírmalo por tu cuenta ejecutando grep -iv revolution 2014*_JA_a*.tsv &gt; 2014_JA_iv_revolution.tsv y abre ambos archivos, .csv y .tsv, en Libre Office Calc, Microsoft Excel, o cualquier programa de hoja de cálculo similar. Observa las diferencias en la delimitación de columnas entre los dos archivos.\n\nResumen\n\nCon el intérprete de Unix ahora puedes:\n\n\n  usar el comando wc con las variables -w y -l para contar palabras y líneas en un archivo o en una serie de ellos.\n  usar la redirección y la estructura de archivos &gt; subdirectorio/nombredearchivo para guardar el archivo resultante en un subdirectorio.\n  usar el comando grep para buscar ocurrencias en una cadena de caracteres.\n  usar la variable -c con greppara contar las ocasiones en las que aparece una cadena de caracteres. La variable -i arrojará una búsqueda de cadenas sin diferenciar mayúsculas, la variable -v excluirá la cadena de los resultados.\n  combina estos comandos y variables para construir búsquedas más complejas de una manera que se adapte a la posibilidad de contar y extraer información de tus datos en tu proyecto de investigación.\n\n\n\n\nConclusión\n\nEn esta lección has aprtendido a realizar recuentos básicos en archivos, buscar entre tus datos cadenas de caracteres comunes y guardar resultados y datos derivados. Aunque esta lección se restringe a contar y extraer información de datos tabulados, el procedimiento se puede extender fácilmente a archivos de texto plano. Para ello te recomandamos dos guías escritas por William Turkel:\n\n\n  William Turkel, ‘Basic Text Analysis with Command Line Tools in Linux’ (15 de junio, 2013)\n  William Turkel, ‘Pattern Matching and Permuted Term Indexing with Command Line Tools in Linux’ (20 de junio, 2013)\n\n\nComo sugieren estas recomendaciones, en esta lección solo revisamos superficialmente lo que es capaz de hacer el intérprete de Unix. Sin embargo, esperamos haberte proporcionado una prueba suficiente para impulsar una mayor investigación de su uso.\n\nPara muchos historiadores, el verdadero potencial de estas herramientas solo es visible al aplicarlas en un proyecto de investigación real. Una vez que tu investigación crezca y, con ella, los datos de investigación, será extremadamente útil poder manipular, contar y extraer información de miles de archivos. Si decides continuar con el tema de esta lección e investigar más sobre el intérprete de Unix, descubrirás que incluso una gran colección de archivos cuyos datos no contienen elementos alfanuméricos, como archivos de imágenes, pueden también clasificarse, seleccionarse y consultarse fácilmente.\n\nEn esta lección aprenderás cómo los datos de tu investigación pueden ser contados y extraídos mediante el shell Unix, cuando están organizados de manera clara y predecible.\n\n"
  },


  {
    "id": 10,
    "url": "http://localhost:4000/es/lecciones/datos-tabulares-en-r",
    "title": "Datos tabulares en R",
    "body": "\nDatos tabulares en R\nObjetivos\n\nA medida que se digitalizan más y más datos históricos, contar con una forma rápida de analizar grandes cantidades de datos en forma de tabla hace la investigación más rápida y efectiva.\n\nR es un lenguaje de programación para el análisis estadístico. Como tal, puede ser usado para completar análisis cuantitativos en recursos históricos que incluyen test estadísticos, entre otros. Puesto que puedes ejecutar el mismo código repetidas veces sobre las mismas fuentes, R permite analizar datos de forma rápida y produce resultados reproducibles. Al poder guardar tu código, R te permite reusar o revisar funciones para futuros proyectos, haciéndose una parte flexible de tus herramientas.\n\nEste tutorial no presupone conocimiento previo de R. Te guiará por algunas de las funciones básicas de R, sirviendo como una introducción al lenguaje. Te guiará en el proceso de instalación, te explicará algunas de las herramientas que puedes utilizar en R, y te explicará cómo trabajar con grupos de datos mientras investigas. El tutorial hará esto a través de mini-lecciones que te enseñarán el tipo de recursos con los que R trabaja bien y ejemplos de cómo hacer cálculos para encontrar información que pueda ser relevante a la investigación histórica. La lección también cubrirá diferentes métodos de entrada en R, como las matrices y el uso de archivos CSV (valores separados por comas).\n\n¿Para quién es útil?\n\nR es ideal para analizar grandes cantidades de datos que llevarían demasiado tiempo de computación manual. Una vez que entiendas cómo escribir algunas de las funciones básicas y a importar tus propios archivos de datos, podrás analizar y visualizar los datos de forma rápida y eficiente.\n\nMientras que R es una gran herramienta para datos tabulares, puede que encuentres más útiles otros acercamientos al análisis de fuentes no tabulares (como transcripciones de periódicos). Si te interesa estudiar este tipo de recursos, echa un vistazo al resto de lecciones en The Programming Historian en español.\n\nInstalar R\n\nR es un lenguaje de programación y un entorno para trabajar con datos. Se puede usar en la consola de R en la línea de comandos o en el Interfaz de R, ambos disponibles solamente en inglés. Este tutorial se centrará en el uso de la consola de R. Para empezar con R, descarga el programa desde The Comprehensive R Archive Network. R es compatible con Linux, Mac y Windows.\n\nCuando inicies la consola de R por primera vez, se abrirá una ventana parecida a esta:\n\n\n    \n\n    La consola de R en Mac.\n\n\n\n\nUsar la consola de R\n\nLa consola de R es un buen lugar para empezar si eres nuevo con R porque está específicamente diseñada para este lenguaje y tiene funciones que son específicas a él.\n\nLa consola es donde escribirás los comandos. Para limpiar la pantalla inicial, ve a ‘Edit’ (editar) en la barra de menús y selecciona ‘Clear Console’ (limpiar consola). Esto te proporcionará una página limpia. También puedes cambiar la apariencia de la consola clicando en la rueda de colores en la parte superior de la consola en un Mac, o seleccionando ‘GUI Preferences’ (preferencias de la Interfaz Gráfica de Usuario) en el menú ‘Edit’ en un PC. Puedes ajustar el color del fondo de pantalla y también el color de la fuente para tus funciones.\n\nUsar grupos de datos\n\nAntes de trabajar con tus propios datos, ayuda que te hagas una idea del funcionamiento de R usando los grupos de datos que éste incluye. Puedes buscar en los grupos de datos ejecutando data() en la consola. Esto mostrará una lista de todos los grupos de datos disponibles en una ventana aparte; la lista incluye los títulos de todos los grupos de datos además de una pequeña descripción de la información de cada uno.\n\nEcha un vistazo al grupo de datos de AirPassengers en la consola1. Esto cargará el grupo de datos en la consola. Para ver los datos, escribe AirPassengers en la siguiente línea y pulsa ‘Intro’. Esto cargará una tabla mostrando el número de pasajeros que volaron en aerolíneas internacionales entre enero de 1949 y diciembre de 1960, en unidades de mil. Escribe data(AirPassengers) en la consola y pulsa ‘Intro’. En la siguiente línea, escribe AirPassengers y pulsa ‘Intro’ de nuevo. Deberías poder ver:\n\n&gt; data(AirPassengers)\n&gt; AirPassengers\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\nAhora puedes usar R para responder a un número de preguntas basadas en estos datos. Por ejemplo, ¿cuáles fueron los meses más populares para volar? ¿Hubo un incremento en viajes internacionales con el tiempo? Probablemente puedas encontrar la respuesta a estas preguntas simplemente escaneando esta tabla pero no tan rápido como lo hace el ordenador. ¿Y qué ocurre si tenemos muchos más datos?\n\nFunciones básicas\n\nSe puede usar R para calcular un número de valores que pueden ser útiles mientras investigas un grupo de datos. Por ejemplo, puedes encontrar la media, la mediana y los valores mínimos y máximos en el conjunto de datos. Para obtener la media y la mediana en el conjunto de datos, puedes ejecutar mean(AirPassengers) y median(AirPassengers) en la consola respectivamente. ¿Qué ocurre si quieres calcular más de un único valor al mismo tiempo? Para producir un resumen de los datos, ejecuta summary(AirPassengers) (resumen) en la consola. Esto te dará los puntos mínimo y máximo del conjunto, así como la media, la mediana y los valores cuartiles primero y tercero.  \n\n&gt; summary(AirPassengers)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.\n  104.0   180.0   265.5   280.3   360.5   622.0\n\nAl crear un resumen podemos ver que el número mínimo de pasajeros entre enero de 1949 y diciembre de 1960 fue de 104.000, y que el  número máximo de pasajeros fue de 622.000. La media muestra que aproximadamente 280.300 personas viajaron por cada mes que se recogieron estos datos. Estos valores pueden ser útiles para ver el grado de variación en número de pasajeros en el tiempo.\n\nUsar la función summary() es una forma de obtener una vista general del conjunto de datos pero ¿qué ocurre si te interesa un subconjunto de datos como un año particular o algunos meses? En R puedes seleccionar diferentes puntos de datos (como un mes concreto) y un rango (como un año concreto) para calcular diferentes valores. Por ejemplo, puedes sumar el número de pasajeros de dos meses para determinar el total de pasajeros durante ese periodo de tiempo.\n\nIntenta sumar los dos primeros valores del conjunto AirPassengers en la consola y luego pulsa ‘Intro’. Deberías ver dos líneas que apuntan:\n\n&gt; 112+118\n[1] 230\n\n\nEsto te da el número total de pasajeros (en cientos de miles) que volaron en enero y febrero de 1949.\n\nR puede hacer más que simple aritmética. Puedes crear objetos o variables para representar números y expresiones. Por ejemplo, puedes dar el nombre Ene1949 a la variable para el valor de enero de 1949. Escribe Ene1949 &lt;- 112 en la consola y luego Ene1949. La anotación &lt;- asigna el valor 112 a la variable Ene1949. Deberías ver:\n\n&gt; Ene1949 &lt;- 112\n&gt; Ene1949\n[1] 112\n\n\nR es sensible a minúsculas y mayúsculas, por tanto, has de tener cuidado al usar las mismas anotaciones cuando usas las variables que has asignado (o nombrado) en otras acciones. Sin embargo, el nombre de las variables puede ir en inglés o español, o cualquier otro idioma. Puedes leer el artículo de Rasmus Bååth, The State of Naming Conventions in R (en inglés), para tener más información sobre la mejor forma de llamar a las variables.\n\nPara eliminar una variable de la consola, escribe rm() (remove o borrar) con la variable de la que te quieras deshacer dentro de los paréntesis y pulsa ‘Intro’. Para ver todas las variables que has designado escribe ls() (list objects) en la consola y pulsa ‘Intro’; esto te ayudará a evitar la repetición de nombres en múltiples variables. Esto también es importante porque R guarda en su memoria todos los objetos que creas y aunque tú no puedas ver la variable llamada x en la consola, puede que la hayas creado antes y accidentalmente podrías sobreescribirla asignando el mismo nombre a otra variable.\n\nAquí está la lista de variables que hemos creado de momento:\n\n&gt; ls()\n[1] \"AirPassengers\" \"Ene1949\"   \n\n\nTenemos la variable AirPassengers y la variable Ene1949. Si borramos la variable Ene1949 y reescribimos ls(), veremos:\n\n&gt; rm(Ene1949)\n&gt; ls()\n[1] \"AirPassengers\"\n\n\nSi en algún momento te atascas con una función o no puedes arreglar un error, escribe help() en la consola para abrir la página de ayuda. También puedes encontrar ayuda general usando el menú ‘Help’ en la parte de arriba de la consola. Si quieres cambiar algo en el código que ya has escrito, puedes reescribir el código en una nueva línea. Para ahorrar tiempo, también puedes usar los cursores en el teclado para desplazarte arriba y abajo en la consola y así encontrar la línea de código que quieres cambiar.\n\nPuedes usar letras como variables pero cuando empieces a trabajar con tus propios datos es más fácil que asignes nombres que representen mejor los datos. Incluso con los datos de AirPassengers(), asignar variables que corresponden a meses o años específicos hace más fácil saber con qué puntos estás trabajando.\n\nPractica\n\nA. Asigna variables para los puntos de datos de AirPassengers() de enero de 1950 y enero de 1960. Suma ambas variables en la siguiente línea.\n\nB. Utiliza las variables que acabas de crear para encontrar diferencias entre los viajeros de 1950 y 1960.\n\nSoluciones\n\nA. Asigna variables para los puntos de datos de AirPassengers() de enero de 1950 y enero de 1960. Suma ambas variables en la siguiente línea.\n\n&gt; Ene1950 &lt;- 115\n&gt; Ene1960 &lt;- 417\n&gt; Ene1950+Ene1960\n[1] 532\n\n\nEsto significa que 532.000 personas viajaron en vuelos internacionales en enero de 1950 y de 1960.\n\nB. Utiliza las variables que acabas de crear para encontrar diferencias entre los viajeros de 1950 y 1960.\n\n&gt; Ene1960-Ene1950\n[1] 302\n\n\nEsto significa que hubo 302.000 pasajeros más en los vuelos internaciones en enero de 1960 respecto a enero de 1950.\n\nEstablecer variables para puntos de datos puede ser tedioso, especialmente si los nombres que das son largos. Sin embargo, el proceso para asignar un rango de valores a una variable que contenga todos los datos de un año es similar. Hacemos esto creando listas llamadas ‘vectores’ usando el comando c. c aquí quiere decir ‘combinar’ y permite unir números en una variable común. Por ejemplo, puedes crear un vector para los datos de AirPassengers de 1949 y llamarlo Air49:\n\n&gt; Air49&lt;- c(112,118,132,129,121,135,148,148,136,119,104,118)\n\n\nCada punto es accesible usando el nombre de la variable y su posición de indexado (empezando en 1). En este caso, Air49[2] contiene el valor que corresponde a febrero de 1949 - 118.\n\n&gt; Air49[2]\n[1] 118\n\n\nPuedes crear una lista de valores consecutivos usando dos puntos. Por ejemplo:\n\n&gt; y &lt;- 1:10\n&gt; y\n[1] 1 2 3 4 5 6 7 8 9 10\n\n\nCon esto, puedes usar la siguiente expresión para definir una variable para los datos de AirPassengers de 1949.\n\n&gt; Air49 &lt;- AirPassengers[1:12]\n&gt; Air49\n [1] 112 118 132 129 121 135 148 148 136 119 104 118\n\n\nAir49[2] ha seleccionado los doce primeros objetos en el conjunto de datos de AirPassengers. Esto te ofrece los mismos resultados que los de arriba, pero toma menos tiempo y además reduces la posibilidad de que un valor sea transcrito incorrectamente.\n\nPara obtener el número total de pasajeros de 1949, puedes sumar todos los objetos del vector usando la función sum() (sumar).\n\n&gt;  sum(Air49)\n[1] 1520\n\n\nPor tanto, el número total de pasajeros de 1949 fue de aproximadamente 1.520.000.\n\nFinalmente, la función length() (longitud o tamaño) hace posible saber el número de objectos en un vector:\n\n&gt; length(Air49)\n[1] 12\n\n\nPractica\n\n\n  Crea una variable para los datos de 1950 AirPassengers.\n  Imprime el segundo objecto en la serie de 1950.\n  ¿Cuál es el tamaño (length) de la secuencia en la pregunta 2?\n  ¿Cuántos pasajeros volaron en total en 1950?\n\n\nSoluciones\n\n1.\n&gt; Air50 &lt;- AirPassengers[13:24]\nAir50\n[1] 115 126 141 135 125 149 170 170 158 133 114 140\n\n\n2.\n&gt; Air50[2]\n[1] 126\n\n\n3.\n&gt; length(Air50)\n[1] 12\n\n\n4.\n&gt;sum(Air50)\n[1] 1676\n\n\nSi quieres crear variables para todos los años en este conjunto de datos, puedes utilizar algunas de las herramientas que hemos estudiado para determinar el número de pasajeros de avión a lo largo del tiempo. Aquí tienes una lista de variables de 1949 a 1960, seguido del número total de pasajeros por año:\n\n&gt; Air49 &lt;- AirPassengers[1:12]\nAir50 &lt;- AirPassengers[13:24]\nAir51 &lt;- AirPassengers[25:36]\nAir52 &lt;- AirPassengers[37:48]\nAir53 &lt;- AirPassengers[49:60]\nAir54 &lt;- AirPassengers[61:72]\nAir55 &lt;- AirPassengers[73:84]\nAir56 &lt;- AirPassengers[85:96]\nAir57 &lt;- AirPassengers[97:108]\nAir58 &lt;- AirPassengers[109:120]\nAir59 &lt;- AirPassengers[121:132]\nAir60 &lt;- AirPassengers[133:144]\n\n\n&gt; sum(Air49)\n[1] 1520\nsum(Air50)\n[1] 1676\nsum(Air51)\n[1] 2042\nsum(Air52)\n[1] 2364\nsum(Air53)\n[1] 2700\nsum(Air54)\n[1] 2867\nsum(Air55)\n[1] 3408\nsum(Air56)\n[1] 3939\nsum(Air57)\n[1] 4421\nsum(Air58)\n[1] 4572\nsum(Air59)\n[1] 5140\nsum(Air60)\n[1] 5714\n\n\nSegún esta información, puedes ver que el número de pasajeros aumentó cada año. Con estos datos podrías ir más allá y determinar si hubo un incremento en el interés de vacacionar en ciertas épocas del año, o incluso el porcentaje de aumento de pasajeros a lo largo del tiempo.\n\nTrabajar con bases de datos más grandes\n\nTen en cuenta que el ejemplo de más arriba no se adapta bien para bases de datos más grandes: contar los puntos de datos para encontrar los correctos sería muy tedioso. Piensa qué ocurriría si estuvieras buscando la información del año 96 en un conjunto de datos con 150 años de datos recogidos.\n\nEn realidad puedes seleccionar filas y columnas de datos específicos si el conjunto de datos está en un formato concreto. Carga los datos de mtcars en tu consola:\n\n&gt; data(mtcars)\n&gt; mtcars\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nEste conjunto de datos ofrece una perspectiva general del Motor Trend Car Road Tests de la revista Motor Trend de 19742. Contiene información sobre cuántas millas por galón o kilómetros por litro podía viajar un coche3, el número de cilindros de motor de cada coche, los caballos, la relación del eje trasero, el peso y otras características de cada modelo. Los datos podrían ser utilizados para descubrir cuáles de estas características hicieron que cada tipo de coche fuera más o menos seguro para los pasajeros a lo largo del tiempo.\n\nPuedes seleccionar las columnas introduciendo el nombre del conjunto de datos seguido de corchetes y el número de la fila o la columna de datos que te interese. Para ordenar las filas y las columnas, piensa en dataset[x,y], siendo el dataset el conjunto con el que estás trabajando, la x la fila y la y la columna.\n\nSi te interesara la primera fila de infomación del conjunto mtcars, ejecutarías lo siguiente en tu consola:\n\n&gt; mtcars[1,]\n          mpg cyl disp  hp drat   wt  qsec vs am gear carb\nMazda RX4  21   6  160 110  3.9 2.62 16.46  0  1    4    4\n\n\nPara ver una columna de los datos, puedes ejecutar:\n\n&gt; mtcars[,2]\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nEsto también mostraría todos los valores bajo la categoría cyl (cilindrada). La mayoría de los modelos de coche tienen un cilindrada de 4, 6 u 8. También puedes seleccionar puntos de datos individuales ejecutando valores para x (fila) e y (columna):\n\n &gt; mtcars[1,2]\n[1] 6\n\n\nEsto ofrece el valor de la primera fila en la segunda columna. Desde aquí, puedes crear un resumen de una fila o de una columna de datos sin tener que contar el número de objetos en cada conjunto de datos. Por ejemplo, escribiendo summary(mtcars[,1]) en la consola y pulsando ‘Intro’ obtienes el resumen de la capacidad de millas por galón de los diferentes coches en el conjunto de datos mtcars:\n\n&gt; summary(mtcars[,1])\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.\n  10.40   15.42   19.20   20.09   22.80   33.90\n\n\nEl resumen indica que el máximo de eficiencia de combustible era de 33.9 millas por galón o 54.5 kilómetros por 3.78 litros, del Toyota Corolla, y el coche menos eficiente era el Lincoln Continental, que solo conseguía hacer 10.4 millas por galón, es decir, 16.7 kilómetros por 3.78 litros. Podemos encontrar los coches que coinciden con los puntos de datos mirando de nuevo a la tabla. Es mucho más fácil encontrar un valor específico que tratar de realizar el cálculo en tu cabeza o buscar en la hoja de cálculo.\n\nMatrices\n\nAhora que entiendes mejor cómo funcionan algunas de las funciones básicas de R, podemos ver formas de usar esas funciones con nuestros propios datos. Esto incluye la creación de matrices usando conjunto de datos pequeños. El beneficio de saber cómo construir matrices en R es que si solo tienes unos pocos puntos de datos para trabajar puedes crear una matriz en vez de un CSV (archivo de valores separados por comas) que luego tendrías que importar. Una de las formas más sencillas de crear una matriz es crear al menos dos variables o vectores y después unirlas. Por ejemplo, mira estos datos del Old Bailey (o Tribunal Penal Central de Inglaterra y Gales) en línea:\n\n\n    \n\n    Conjunto de datos del Old Bailey para casos criminales en cada década entre 1670 y 1800.\n\n\n\n\nEl Old Bailey contiene estadísticas e información sobre los casos criminales celebrados en el Tribunal Penal Central de Londres entre 1674 y 1913. Si quisiéramos ver el número total de robos y robos con violencia para las décadas de entre 1670 y 1710, pondríamos esos números en una matriz.\n\nPara hacer esto, creamos las variables Robos y RobosViolentos usando el total de cada década como puntos de datos:\n\n&gt; Robos &lt;- c(2,30,38,13)\nRobosViolentos &lt;- c(7,20,36,3)\n\n\nPara crear una matriz podemos usar la función cbind() (column bind o unión de columnas). Esto une Robos y RobosViolentos en columnas, representadas como Crimen aquí:\n\n&gt; Robos &lt;- c(2,30,38,13)\nRobosViolentos &lt;- c(7,20,36,3)\nCrimen &lt;- cbind(Robos,RobosViolentos)\nCrimen\n     Robos RobosViolentos\n[1,]     2              7\n[2,]    30             20\n[3,]    38             36\n[4,]    13              3\n\n\nTambién puedes establecer una matriz usando rbind(). rbind() une los datos en filas (row bind o unión de filas). Observa la diferencia entre Crimen y Crimen2:\n\n&gt; Crimen2 &lt;- rbind(Robos,RobosViolentos)\n&gt; Crimen2\n               [,1] [,2] [,3] [,4]\nRobos             2   30   38   13\nRobosViolentos    7   20   36    3\n\n\nLa segunda matriz también puede ser creada usando la expresión t(Crimen) (transposición de matriz), que genera lo inverso a Crimen.\n\nTambién puedes contruir una matriz usando matrix(). Esto te permite transformar una secuencia de números, como el número de robos y robos violentos cometidos, en una matriz si no has creado variables separadas para estos puntos de datos:\n\n&gt; matrix(c(2,30,3,4,7,20,36,3),nrow=2)\n     [,1] [,2] [,3] [,4]\n[1,]    2    3    7   36\n[2,]   30    4   20    3\n\n\n[2,]   30    4   20    3\n&gt; matrix(c(2,30,3,4,7,20,36,3),ncol=2)\n     [,1] [,2]\n[1,]    2    7\n[2,]   30   20\n[3,]    3   36\n[4,]    4    3\n\n\nLa primera parte de la función es la lista de números. Después, puedes determinar cuántas filas (nrow=) (número de filas) o columnas (ncol=) (número de columnas) tendrá la matriz.\n\nLa función apply() (aplicar) te permite realizar la misma función en cada fila o columna de una matriz. Hay tres partes en la función apply, en la que tienes que seleccionar: la matriz que estás utilizando, los términos que quieres usar y la función que quieres realizar sobre la matriz:\n\n&gt; Crimen\n     Robos RobosViolentos\n[1,]     2              7\n[2,]    30             20\n[3,]    38             36\n[4,]    13              3\n&gt; apply(Crimen,1,mean)\n[1]  4.5 25.0 37.0  8.0\n\n\nEste ejemplo muestra la función apply usada en la matriz Crimen para calcular la media (mean) de cada fila y, por tanto, el número promedio de robos y de robos con violencia combinados que fueron cometidos en cada década. Si quieres saber la media de cada columna, usa un 2 en lugar de un 1 dentro de la función:\n\n&gt; apply(Crimen,2,mean)\n         Robos RobosViolentos\n         20.75          16.50\n\n\nEsto muestra el número promedio de robos y de robos con violencia entre las décadas.\n\nPractica\n\n\n  \n    Crea una matriz con dos columnas usando los siguientes datos de Quebrantamiento de la Paz y Asesinatos de entre 1710 y 1730 de la tabla de más arriba del Old Bailey: c(2,3,3,44,51,17)\n  \n  \n    Utiliza la función cbind() para unir QuebrantamientoPaz &lt;- c(2,3,3) y Asesinatos &lt;- c(44,51,17).\n  \n  \n    Calcula la media de cada columna de la matriz usando la función apply().\n  \n\n\nSoluciones\n\n1.\n&gt; matrix(c(2,3,3,44,51,17),ncol=2)\n     [,1] [,2]\n[1,]    2   44\n[2,]    3   51\n[3,]    3   17\n\n\n2.\n&gt; QuebrantamientoPaz &lt;- c(2,3,3)\n&gt; Asesinatos &lt;- c(44,51,17)\n&gt; PazAsesinatos &lt;- cbind(QuebrantamientoPaz,Asesinatos)\n&gt; PazAsesinatos\n     QuebrantamientoPaz Asesinatos\n[1,]                  2         44\n[2,]                  3         51\n[3,]                  3         17\n\n\n3.\n&gt; apply(PazAsesinatos,2,mean)\n&gt; QuebrantamientoPaz         Asesinatos\n&gt;          2.666667          37.333333\n\n\nUsar las matrices puede ser útil si estás trabajando con una cantidad pequeña de datos. Sin embargo, no siempre es la mejor opción porque las matrices pueden ser difíciles de leer. A veces es más fácil crear tu propio archivo usando un programa de hojas de cálculo como Excel u Open Office. De esta manera te puedes asegurar de que toda la información que quieres estudiar está organizada. Además, puedes importar dicho archivo a R.\n\nCargar tu propio conjunto de datos en R\n\nAhora que has practicado con datos simples, estás preparado/a para trabajar con tus propios datos. Estos posiblemente están en una hoja de cálculo. ¿Cómo puedes trabajar con estos datos en R? Hay varias formas de hacer esto. La primera es cargar la hoja de cálculo directamente en R. Otra forma es importar un archivo CSV (valores separados por comas) o TXT (de texto) a R.\n\nPara cargar un archivo de Excel directamente a la consola de R, primero tienes que instalar el paquete readxl (leer archivo excel). Para hacer esto, escribe install.packages(\"readxl\") en la consola y pulsa Intro. Puede que tengas que comprobar que el paquete se ha instalado en la consola clicando la pestaña ‘Packages&amp;Data’ (paquetes y datos) en el menú, seleccionando ‘Package Manager’(gerente de paquetes) y después clicando en la caja junto al paquete readxl. Desde aquí, puedes seleccionar un archivo y cargarlo en R. Abajo tienes un ejemplo de lo que puede parecer cargar un archivo simple de Excel:\n\n&gt;  x &lt;- read_excel(\"Workbook2.xlsx\")\n&gt; x\n a b\n1 1 5\n2 2 6\n3 3 7\n4 4 8\n\n\nDespués del comando read_excel está el nombre del archivo que has seleccionado. Los números de abajo corresponden a los datos en la hoja de cálculo que he usado de ejemplo. Ten en cuenta que las filas están numeradas y mis columnas están etiquetadas como lo están en la hoja de cálculo original.\n\nCuando cargas datos en R asegúrate de que el archivo al que estás accediendo esté en el directorio en que estás trabajando en tu ordenador. Para comprobar esto, puedes escribir dir() (directorio) o getwd() (mostrar ruta del directorio de trabajo) en la consola. Puedes cambiar el directorio si lo necesitas clicando en la pestaña de ‘Miscellaneous’ (miscelánea) en el menú de tu pantalla y seleccionando el directorio que desees para R. Si no haces esto R no podrá encontrar el archivo correctamente.\n\nOtra forma de cargar datos en R es usar un archivo CSV. Un archivo CSV (valores separados por comas) muestra los valores en filas y columnas, separando éstas con comas. Puedes guardar cualquier documento creado en Excel como un archivo .csv y después cargarlo a R. Para usar un archivo CSV en R, asigna un nombre al archivo usando el comando &lt;- seguido de read.csv(file=\"nombre-del-archivo.csv\",header=TRUE,sep=\",\") en la consola. nombre-del-archivo le indica a R qué archivo seleccionar mediante el comando file= (el archivo equivale a), mientras que la configuración del encabezado o header= como TRUE (verdadero) indica que la primera fila se trata del encabezado y no de variables. Con sep indicamos que hay una coma entre cada número y línea.\n\nNormalmente, un CSV puede contener bastante información. Sin embargo, para comenzar, trata de crear un archivo CSV en Excel usando los datos del Old Bailey que hemos usado para las matrices. Establece las columnas para las fechas entre 1710 y 1730 además del número de crímenes de quebrantamientos de paz y de asesinatos para esas décadas. Guarda el archivo como “OldBailey.csv” e intenta cargarlo en R usando los pasos anteriores. Vas a ver:\n\n&gt; read.csv (file=\"OldBailey.csv\", header=TRUE, sep=\",\")\nFecha QuebrantamientoPaz Asesinatos\n1 1710              2      44\n2 1720              3      51\n3 1730              4      17\n\n\nAhora puedes acceder a los datos en R y realizar cálculos que te ayuden a estudiarlos. Los archivos CSV pueden ser más complejos que este ejemplo, así que también puedes abrir en R cualquier conjunto de datos en que estés trabajando.\n\nPuedes importar archivos de texto (TXT) de una manera similar. Usa el comando read.table() para cargar archivos de texto en R, siguiendo la misma sintaxis que en el ejemplo de más arriba.\n\nGuardar datos en R\n\nAhora que has cargado datos en R y conoces algunas formas de trabajar con los datos, ¿qué ocurre si quieres guardarlos en otro formato? La función write.xlsx te permite hacer precisamente eso: tomar datos de R y guardarlos en un archivo de Excel. Intenta guardar el archivo Old Bailey como un archivo de Excel. Primero tienes que cargar el paquete. Después, crea una variable para los datos de Old Bailey y crea el archivo:\n\n&gt; library(xlsx)\n&gt; write.xlsx(x= OldBailey, file= \"OldBailey.xlsx\", sheetName= \"OldBailey\", row.names= TRUE)\n\nEn este caso, y dentro del paréntesis de esta la función write.xlsx, estamos llamando a procesar la variable “OldBailey” con el argumento x= ; a la vez, indicamos que el archivo guardado debe llamarse “OldBailey” con la extensión “.xlsx” mediante el argumento file=; además, damos el nombre “OldBailey” a la hoja de cálculo en que estarán los datos mediante sheetName=   y, finalmente, establecemos que sí queremos (TRUE o verdadero) que los nombres de la fila en nuestra variable se guarden en el nuevo archivo. [N. de la T.]\n\nResumen y siguientes pasos\n\nEste tutorial ha explorado lo básico de R para trabajar con datos tabulares de tu investigación. R puede ser una herramienta útil para la investigación en las Humanidades y las Ciencias Sociales porque el análisis de los datos es reproducible y te permite analizar datos de forma rápida sin tener que crear un sistema complicado. Ahora que conoces algunas funciones básicas de R puedes explorar algunas de las otras funciones del programa, incluyendo la computación estadística, la producción de gráficos y la creación de tus propias funciones.\n\nPara más información sobre R, visita el Manual de  R.\n\nTambién hay numerosos tutoriales de R online, incluyendo:\n\n\n  R: A self-learn tutorial (en inglés) - este tutorial cubre varias funciones y provee ejercicios para practicar.\n  DataCamp Introducción a R (en español) - este es un curso online gratuito que te ofrece comentarios sobre tu código para ayudarte a identificar errores y aprender a escribir código más eficientemente.\n\n\nFinalmente, un buen recurso para los historiadores digitales es el libro Digital History Methods in R de Lincoln Mullen.\n\nNotas\n\n\n  \n    \n      Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976), Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G. &#8617;\n    \n    \n      Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391Ð411. &#8617;\n    \n    \n      Nota de la traductora: un galón equivale a 3,78 litros y una milla a 1,6 kilómetros. &#8617;\n    \n  \n\n\nEsta lección te enseña una forma rápida de analizar grandes cantidades de datos en forma de tabla, haciendo la investigación más rápida y efectiva.\n\n"
  },


  {
    "id": 11,
    "url": "http://localhost:4000/es/lecciones/de-html-a-lista-de-palabras-1",
    "title": "De HTML a lista de palabras (parte 1)",
    "body": "\nDe HTML a lista de palabras (parte 1)\n\nContenidos\n\n\n  Objetivos de la lección\n  El reto\n  Archivos necesarios para esta lección\n  Idear un algoritmo\n  Aislar el contenido deseado\n  Lecturas sugeridas\n  Sincronización de código\n\n\nObjetivos de la lección\n\nEn esta lección en dos partes partiremos de lo que has aprendido en Descargar páginas web con Python, para aprender cómo remover las etiquetas HTML de la página web de la transcripción del juicio criminal contra Benjamin Bowsey de 1780. Lograremos esto utilizando una variedad de operadores de cadenas, métodos de cadenas y habilidades de lectura cercana. Vamos a presentar bucles (looping) y condicionales (branching), de manera que los programas puedan repetir tareas y pruebas para ciertas condiciones, haciendo posible separar el contenido de las etiquetas HTML. Por último, convertimos el contenido de una cadena larga a una lista de palabras que posteriormente podrán ser ordenadas, indexadas y contadas.\n\nEl reto\n\nPara tener una idea más clara de la tarea que tenemos por delante, abre el archivo obo-t17800628-33.html que creaste en la lección Descargar páginas web con Python (o descarga y guarda el juicio, si aún no tienes una copia). Entonces observa el código HTML en tu navegador de Fierfox usando Herramientas -&gt; Desarrollador web -&gt; Código fuente de esta página. A medida que te desplazas a través del código fuente te darás cuenta que hay etiquetas HTML mezcladas con el texto. Si eres nuevo en HTML te recomendamos tomar el tutorial de W3Schools HTML para familiarizarte con el marcado. Si tu trabajo requiere a menudo que tengas que retirar etiquetas sin duda te va a servir para entenderlo en cuanto lo veas.\n\nArchivos necesarios para esta lección\n\n\n  obo-t17800628-33.html\n\n\nIdear un algoritmo\n\nDado que el objetivo es deshacerse del HTML, el primer paso es crear un algoritmo que devuelva solamente el texto (menos las etiquetas HTML) del artículo. Un algoritmo es un procedimiento que se ha especificado con suficiente detalle de tal forma que puede ser implementado en una computadora. Es muy útil escribir primero tus algoritmos en español llano; es una idea excelente delinear exactamente qué es lo que quieres que haga antes de sumergirte en el código. Para construir este algoritmo te vas a servir de tus habilidades de lectura cercana para encontrar la manera de capturar solamente el contenido textual de la biografía.\n\nAl examinar el código fuente de obo-t17800628-33.html notarás que la transcripción real no se inicia de forma inmediata. Por el contrario, hay un número de etiquetas HTML y algo de información para citar. En este caso el contenido no comienza ¡sino hasta la línea 81!\n\n&lt;p&gt;324.                                  &lt;a class=\"invisible\" name=\"t17800628-33-defend448\"&gt; &lt;/a&gt;                     BENJAMIN                      BOWSEY                                                                                                          (a blackmoor                  ) was indicted for                                                          that he together with five hundred other persons and more, did, unlawfully, riotously, and tumultuously assemble on the 6th of June\n\n\nSolamente nos interesa la transcripción del juicio, no los metadatos extra contenidos en las etiquetas. No obstante, te darás cuenta que el final de los metadatos coincide con el principio de la transcripción. Esto hace que la ubicación de los metadatos sea un marcador potencialmente útil para aislar texto transcrito.\n\nA primera vista, podemos ver que la transcripción del juicio inicia con una etiqueta HTML: &lt;p&gt; que significa “párrafo”. Ésta es la primera etiqueta de párrafo en el documento. Debemos ser capaces de usar esto para encontrar el punto de inicio de nuestro documento transcrito. Tenemos suerte en este caso porque resulta que esta etiqueta es una manera confiable para determinar el principio de la transcripción del texto del juicio (si quieres, échale un vistazo a otros juicios para comprobarlo).\n\nEl texto del juicio termina en la línea 82 con otra etiqueta HTML: &lt;br/&gt;, que significa un salto de línea. Resulta que es el último salto de línea del documento. Estas dos etiquetas (la del primer párrafo y la del último salto de línea) nos proveen el recurso para aislar el texto transcrito. Los sitios web bien estructurados siempre tienen una única manera de señalar el final del contenido. Solmamente necesitas observar con atención.\n\nLo siguiente que querrás hacer es retirar todas las marcas de HTML que permanecen mezcladas con el contenido. Como sabes, las etiquetas HTML se encuentras siempre entre un par de corchetes angulares que se corresponden, por lo que probablemente una apuesta segura es que al quitar todo lo que esté dentro de dos corchetes angulares quitarás el código HTML y dejarás solamente la transcripción. Ten en cuenta que estamos asumiendo que la transcricpión no contiene símbolos matemáticos como “menor que” y “mayor que”. Si Bowsey hubiese sido un matemático, nuestro supuesto no sería tan seguro.\n\nLo que sigue describe nuestro algoritmo en palabras.\n\nPara aislar el contenido:\n\n\n  Descarga el texto transcrito\n  Busca el HTML y guarda la localización de la primera etiqueta &lt;p&gt;\n  Busca el HTML y guarda la localización de la útlima etiqueta &lt;p&gt;\n  Guarda todo lo que aparezca después de la primera etiqueta &lt;p&gt; y antes de la etiqueta &lt;br/&gt; en una cadena de texto: contenidoPagina\n\n\nEn este punto tenemos la trascripción del texto del juicio más el marcado de HTML. Después:\n\n\n  Mira con atención cada carácter en la cadena de texto contenido-de-pagina, carácter por carácter\n  Si el carácter es un corchete angular izquierdo (&lt;) nos encontramos dentro de una etiqueta así que ignora cada uno de los caracteres siguientes\n  Si el carácter es un corchete angular derecho (&gt;) estamos saliendo de una etiqueta; ignora el carácter actual, pero mira cada uno de los caracteres siguientes\n  Si no estamos dentro de una etiqueta, adjunta el carácter actual a una nueva variable: texto\n\n\nFinalmente:\n\n\n  Divide la cadena de texto en una lista de palabras individuales que después puedan manipularse más\n\n\nAislar el contenido deseado\n\nEl siguiente paso utiliza los comandos de Python aprendidos en la lección Manipular cadenas de caracteres en Python para implementar la primera mitad del algoritmo: retirar todo el contenido antes de la etiqueta &lt;p&gt; y después de la etiqueta &lt;br/&gt;. En resumen, el algoritmo fue el siguiente:\n\n\n  Descarga el texto transcrito\n  Busca el HTML y guarda la localización de la primera etiqueta &lt;p&gt;\n  Busca el HTML y guarda la localización de la útlima etiqueta &lt;p&gt;\n  Guarda todo lo que aparezca después de la primera etiqueta &lt;p&gt; y antes de la etiqueta &lt;br/&gt; a una cadena de texto: contenidoPagina\n\n\nPara lograr esto, utilizarás el método de cadena de caracteres “find” y el método .rfind() (que permite encontrar la última coincidencia de algo) y crearás una nueva subcadena conteniendo solamente el contenido deseado entre esas posiciones indexadas.\n\nA medida que trabajas, vas a construir archivos separados para contener tu código. Uno de estos archivos se llamará obo.py (a partir de “Old Bailey Online”). Este archivo va a contener todo el código que tú quieres reutilizar; en otras palabras, obo.py es un módulo. Discutimos la idea de módulos en la lección Reutilizacion de código y modularidad cuando guardamos nuestras funciones en saludo.py.\n\nCrea un nuevo archivo llamado obo.py y guárdalo en tu carpeta programming-historian. Vamos a utilizar este archivo para mantener copias de las funciones necesarias para procesar The Old Bailey Online. Teclea o copia el siguiente código en tu archivo.\n\n# obo.py\n\ndef quitarEtiquetas(contenidoPagina):\n    lugarInicio = contenidoPagina.find(\"&lt;p&gt;\")\n    lugarFin = contenidoPagina.rfind(\"&lt;br/&gt;\")\n\n    contenidoPagina = contenidoPagina[lugarInicio:lugarFin]\n    return contenidoPagina\n\n\nAhora crea un segundo archivo llamado contenido-juicio.py y guarda el programa que se muestra a continuación:\n\n# contenido-juicio.py\n\nimport urllib.request, urllib.error, urllib.parse, obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nHTML = respuesta.read()\n\nprint((obo.quitarEtiquetas(HTML)))\n\n\nCuando ejecutes contenido-juicio.py éste obtendrá la página Web de la transcripción del juicio de Bowsey, entonces mira en el módulo obo.py la función quitarEtiquetas. El programa utilizará esa función para extraer todo lo que esté después de la primera etiqueta &lt;p&gt; y antes de la última &lt;br/&gt;. Con algo de suerte esto debe ser el contenido textual de la transcripción de Bowsey acompañada con algo de marcado en HTML. No te preocupes si tu pantalla de salida de comandos termina en una línea gruesa negra. La pantalla de salida de Komodo Edit tiene un número máximo de caracteres a desplegar, después de lo cual los caracteres empiezan a escribirse unos sobre otros en la pantalla, literalmente, dando la apriencia de una mancha negra. No te preocupes: el texto está ahí aún cuando tú no puedas leerlo; así que puedes copiar y pegarlo en un archivo de texto para confirmarlo.\n\nTomemos un momento para estar seguros de que entendemos de qué manera contenido-juico.py es capaz de utilizar las funciones almacenadas en obo.py. La función quitarEtiquetas que guardamos en obo.py requiere un argumento. En otras palabras, para ejecutarse con propiedad requiere que se le suministre una unidad de información. Recordemos el ejemplo del perro entrenado de lecciones previas. Para que ladre, el perro necesita dos cosas: aire y una deliciosa recompensa. La función quitarEtiquetas en obo.py requiere una cosa: una cadena de texto llamada contenidoPagina. Pero te darás cuenta que cuando llamamos a quitarEtiquetas en el último programa (contenido-juicio.py), no hay ninguna mención a “contenidoPagina”. En cambio, se le ha dado a la función HTML como argumento. Esto puede ser confuso para las personas que están empezando a programar. Una vez que una función ha sido declarada, no necesitamos utilizar el mismo nombre de la variable cuando llamamos a la función. Mientras que proporcionemos el tipo de argumento adecuado, todo debe funcionar correctamente sin importar cómo lo llamamos. En este caso, queremos que contenidoPagina utilice el contenido de nuestra variable HTML. Podría pasar por cualquier cadena de texto, incluida alguna que se ingrese directamente en el paréntesis. Intenta volver a ejecutar contenido-juicio.py cambiando el argumento quitarEtiquetas a “Soy aficionado a los perros”, y mira lo que sucede. Toma en cuenta que dependiendo de cómo definas tu función (y lo que hace), tu argumento necesitará posiblemente ser algo distinto que una cadena: un entero por ejemplo.\n\nLecturas sugeridas\n\n\n  Lutz, Learning Python\n    \n      Ch. 7: Strings\n      Ch. 8: Lists and Dictionaries\n      Ch. 10: Introducing Python Statements\n      Ch. 15: Function Basics\n    \n  \n\n\nSincronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones2.zip (zip)\n\n\n\nEn esta lección en dos partes partiremos de lo que has aprendido sobre Descargar páginas web con Python, para aprender cómo remover las etiquetas HTML de la página web de la transcripción del juicio criminal contra Benjamin Bowsey de 1780. Lograremos esto utilizando una variedad de operadores de cadenas, métodos de cadenas y habilidades de lectura cercana. Vamos a presentar bucles (looping) y condicionales (branching), de manera que los programas puedan repetir tareas y pruebas para ciertas condiciones, haciendo posible separar el contenido de las etiquetas HTML. Por último, convertimos el contenido de una cadena larga a una lista de palabras que posteriormente podrán ser ordenadas, indexadas y contadas.\n\n"
  },


  {
    "id": 12,
    "url": "http://localhost:4000/es/lecciones/de-html-a-lista-de-palabras-2",
    "title": "De HTML a lista de palabras (parte 2)",
    "body": "\nDe HTML a lista de palabras (parte 2)\n\nContenidos\n\n\n  Objetivos de la lección    \n      Archivos requeridos para esta lección\n    \n  \n  Repetir y probar en Python    \n      Bucles (Looping)\n      Salto (Branching)\n    \n  \n  Utiliza el algoritmo para retirar el marcado en HTML    \n      La rutina de quitarEtiquetas\n    \n  \n  Listas en Python\n  Lecturas sugeridas    \n      Sincronización de código\n    \n  \n\n\nObjetivos de la lección\n\nEn esa lección aprenderás los comandos de Python que son necesarios para implementar la segunda parte del algoritmo que comenzamos en De HTML a lista de palabras (parte 1). La primera parte del algoritmo obtiene el contenido de una página HTML y guarda solamente el contenido que se encuentra entre la primera etiqueta &lt;p&gt; y la última etiqueta &lt;br/&gt;. La segunda mitad del algoritmo hace lo siguiente:\n\n\n  Revisar cada carácter de la cadena de texto contenidoPagina, uno por uno.\n  Si el carácter es un corchete angular izquierdo (&lt;) entonces estamos dentro de una etiqueta así que ignora cada uno de los caracteres siguientes.\n  Si el carácter es un corchete angular derecho (&gt;) entonces estamos saliendo de una etiqueta; ignora el carácter actual, pero mira cada uno de los caracteres siguientes.\n  Si no estamos dentro de una etiqueta, añade añade el carácter actual a una nueva variable: texto.\n  Secciona la cadena de caracteres texto en una lista de palabras individuales que puedan ser manipuladas después.\n\n\nArchivos requeridos para esta lección\n\n\n  obo.py\n  contenido-juicio.py\n\n\nSi no tienes estos archivos puedes descargar el archivo comprimido python-es-lecciones2.zip (zip) de la lección anterior.\n\nRepetir y probar en Python\n\nEl siguiente escalón es implementar el algoritmo que busca cada uno de los caracteres en la cadema contenidoPagina, uno a la vez, y decide si el carácter pertenece a una marca de HTML o al contenido de la transcripción del juicio. Antes de que puedas hacer esto tienes que aprender algunas cuantas técnicas para la repetición de tareas y condiciones de prueba.\n\nBucles (Looping)\n\nComo muchos lenguajes de programación Python incluye un número de mecanismos de bucle. El que necesitarás usar en este caso es un bucle for. La versión debajo le dice al intérprete que haga algo en cada carácter de una cadena llamada contenidoPagina. La variable caract contendrá cada carácter de contenidoPagina en sucesión. La nombramos caract porque no tiene un significado especial y podríamos haberla llamado tintineo o k si nos hubiéramos sentido tentados. Puedes utilizar la codificación a colores en Komodo Edit como una guía para decidir si una palabra es una variable con un nombre dado por el usuario (como caract) o se trata de un nombre definido para Python que sirve para un propósito específico (como ‘for’). Generalmente es buena idea darle a las variables nombres que provean información acerca de lo que contienen. Esto hará mucho más fácil entender un programa que no has revisado desde hace tiempo. Con esto en mente, tintineo no es seguramente una buena elección para el nombre de la variable en este caso.\n\nfor caract in contenidoPagina:\n\t# haz algo con caract\n\n\nSalto (Branching)\n\nEnseguida necesitarás una manera de comprobar los contenidos de una cadena y escoger la acción a seguir basada en esa prueba. De nuevo, como muchos lenguajes de programación, Python incluye un número de mecanismos de salto (o estructuras de control). La que vamos a utilizar aquí es la sentencia condicional if. La versión debajo hace una prueba para ver si la cadena llamada caract consiste en un corchete angular izquierdo. Como mencionamos anteriormente, la sangría o indentación en Python es importante. Si el código está indentado, Python lo ejecutará cuando la condición sea verdadera.\n\nToma en cuanta que Python utiliza el signo de igual (=) para asignación, es decir, para ajustar que una cosa sea equivalente a otra. Con el fin de comprobar la igualdad, utiliza dos signos de igual (==) en lugar de uno. Los programadores principiantes suelen confundir ambos.\n\nif caract == '&lt;':\n    # haz algo\n\n\nUna forma más general de la sentencia condicional if te permite especificar qué hacer ante un evento en el que la condición de prueba es falsa.\n\nif caract == '&lt;':\n    # haz algo\nelse:\n    # haz algo distinto\n\n\nEn Python tienes la opción de hacer pruebas adicionales después de la primera mediante la utilización de la sentencia condicional elif (abreviatura de else if).\n\nif caract == '&lt;':\n    # haz algo\nelif caract == '&gt;':\n    # haz otra cosa\nelse:\n    # haz algo completamente diferente\n\n\nUtiliza el algoritmo para retirar el marcado en HTML\n\nAhora sabes lo suficiente para implementar la segunda parte del algoritmo: retirar todas las etiquetas HTML. En esta parte del algoritmo queremos:\n\n\n  Buscar en cada carácter de la cadena contenidoPagina, un carácter a la vez\n  Si el carácter es un corchete angular izquierdo (&lt;) estamos dentro de una etiqueta así que ignora el carácter\n  Si el carácter es un corchete angular derecho (&gt;) estamos saliendo de una etiqueta, ignora el carácter\n  Si no estamos al interior de una etiqueta, anexa el carácter actual a una nueva variable: texto\n\n\nPara hacer esto, usarás un bucle para buscar cada carácter sucesivo en la cadena. Usarás entonces una sentencia condicional if / elif para determinar si el carácter es parte de una marca de HTML o parte del contenido, después anexar los caracteres de contenido a la cadena texto. ¿Cómo haremos el seguimiento de si nos encontramos dentro o fuera de una etiqueta? Podemos utilizar una variable entera que podrá ser 1 (verdadero) si el carácter correspondiente está dentro de una etiqueta y 0 (falso) si  no lo está (en el siguiente ejemplo hemos llamado a la variable “adentro”).\n\nLa rutina de quitarEtiquetas\n\nPoniendo todo junto, la versión final de la rutina se muestra a continuación. Observa que hemos expandido la función quitarEtiquetas que creamos anteriormente. Asegúrate de mantener la sangría o indentación como se muestra cuando remplaces la anterior rutina quitarEtiquetas de obo.py con esta nueva.\n\nTu rutina debe verse ligeramente diferente y, mientras que funcione, todo está bien. Si estás inclinado a experimentar, probablemente es mejor que pruebes nuestra versión para asegurarte que tu programa hace lo que hace el nuestro.\n\n# obo.py\ndef quitarEtiquetas(contenidoPagina):\n    lugarInicio = contenidoPagina.find(\"&lt;p&gt;\")\n    lugarFin = contenidoPagina.rfind(\"&lt;br/&gt;\")\n\n    contenidoPagina = contenidoPagina[lugarInicio:lugarFin]\n\n    adentro = 0\n    texto = ''\n\n    for caract in contenidoPagina:\n        if caract == '&lt;':\n            adentro = 1\n        elif (adentro == 1 and caract == '&gt;'):\n            adentro = 0\n        elif adentro == 1:\n            continue\n        else:\n            texto += caract\n\n    return texto\n\n\nHay dos nuevos conceptos de Python en este nuevo código: continue y return.\n\nLa declaración de Python continue le ordena al intérprete regresar al principio del bucle. Así que si estamos procesando caracteres dentro de un par de corchetes angulares, queremos ir al siguiente carácter en la cadena de texto contenidoPagina sin añadir nada a nuestra variable texto.\n\nEn los ejemplos anteriores hemos utilizado print extensamente. Éste da salida al resultado de nuestro programa en la pantalla para que lo lea el usuario. Sin embargo, a menudo queremos que una parte del programa envíe información a otra parte. Cuando termina de ejecutarse una función, puede regresar un valor al código que la ha invocado.  Si vamos a llamar a quitarEtiquetas utilizando otro programa, deberemos hacerlo de esta manera:\n\n#entender la declaración Return\n\nimport obo\n\nmiTexto = \"Éste es mi &lt;h1&gt;HTML&lt;/h1&gt; mensaje\"\n\nelResultado = obo.quitarEtiquetas(miTexto)\n\n\nAl utilizar return, hemos sido capaces de guardar la salida de datos de la función quitarEtiquetas directamente en una variable que hemos denominado ‘elResultado’, cuyo proceso podemos reanudar según sea necesario mediante código adicional.\n\nFíjate que en el ejemplo quitarEtiquetas desde el inicio de esta subsección, el valor que queremos recuperar no es contenidoPagina sino el contenido que ha sido despojado de las etiquetas HTML.\n\nPara comprobar nuestra nueva rutina de quitarEtiquetas puedes ejecutar el programa contenido-juicio.py de nuevo. Dado que hemos redefinido quitarEtiquetas, el programa contenido-juicio.py ahora hace algo diferente (y más cercano a lo que nosotros queremos). Antes de que continúes, asegúrate de comprender por qué cambia el comportamiento de contenido-juicio.py si solamente hemos editado obo.py.\n\nListas en Python\n\nAhora que tienes la habilidad para extraer texto en crudo de páginas Web, querrás tener ese texto en una forma que sea fácil de procesar. Hasta ahora, cuando has necesitado guardar información en tus programas de Python lo has hecho utilizando cadenas de texto. Sin embargo, hay un par de excepciones. En la rutina de quitarEtiquetas también hiciste uso de un entero llamado adentro para guardar un 1 cuando estabas procesando una etiqueta y un 0 cuando no. Puedes hacer operaciones matemáticas con los enteros pero no puedes guardar fracciones o números decimales en una variable de entero.\n\nadentro = 1\n\n\nY cada vez que has necesitado leer o escribir a un archivo, has utilizado un controlador de archivo especial como f en el ejemplo siguiente:\n\nf = open('holamundo.txt','wb')\nf.write('hola mundo')\nf.close()\n\n\nSin embargo, uno de los tipos de objetos que provee Python es list (o lista), una colección ordenada de otros objetos (incluyendo, potencialmente, otras listas). Convertir una cadena de texto a una lista de caracteres o palabras es muy sencillo. Escribe o copia el siguiente programa en tu editor de texto para ver dos maneras de lograrlo. Guarda el archivo como cadena-a-lista.py y ejecútalo. Compara las dos listas que se imprimen en el panel de comandos de salida y ve si puedes imaginarte cómo funciona este código.\n\n# cadena-a-lista.py\n\n# algunas cadenas\ns1 = 'hola mundo'\ns2 = 'qué tal mundo'\n\n# lista de caracteres\ncaracList = []\nfor caract in s1:\n    caracList.append(caract)\nprint(caracList)\n\n# lista de 'palabras'\nlistPalabras = s2.split()\nprint(listPalabras)\n\n\nLa primera rutina utiliza un bucle “for” para pasar por cada carácter en la cadena de texto s1, y añade el carácter al final de caracList. La segunda rutina utiliza la operación dividir para romper la cadena s2 en fragmentos cada vez que encuentre espacios en blanco (espacios, tabulaciones, retornos de carro y caracteres similares). En realidad, es simplificar un poco las cosas referirse a los objetos de la segunda lista como palabras. Prueba a cambiar el contenido de s2 del programa anterior por “qué tal mundo!” y ejecútalo de nuevo. ¿Qué sucedió con el signo de exclamación? Recuerda que deberás guardar los cambios antes de utilizar Ejecutar Python de nuevo.\n\nConsiderando lo que has aprendido hasta ahora, ya puedes abrir un URL, descargar la página Web en una cadena de texto, despojarla de las etiquetas HTML y luego cortar el texto en una lista de palabras. Intenta ejecutar el siguiente programa:\n\n# html-a-lista-1.py\nimport urllib.request, urllib.error, urllib.parse, obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nhtml = respuesta.read()\ntexto = obo.quitarEtiquetas(html)\nlistaPalabras = texto.split()\n\nprint((listaPalabras[0:120]))\n\n\nDebes obtener algo como lo siguiente:\n\n['324.', '\\xc2\\xa0', 'BENJAMIN', 'BOWSEY', '(a', 'blackmoor', ')', 'was',\n'indicted', 'for', 'that', 'he', 'together', 'with', 'five', 'hundred',\n'other', 'persons', 'and', 'more,', 'did,', 'unlawfully,', 'riotously,',\n'and', 'tumultuously', 'assemble', 'on', 'the', '6th', 'of', 'June', 'to',\n'the', 'disturbance', 'of', 'the', 'public', 'peace', 'and', 'did', 'begin',\n'to', 'demolish', 'and', 'pull', 'down', 'the', 'dwelling', 'house', 'of',\n'\\xc2\\xa0', 'Richard', 'Akerman', ',', 'against', 'the', 'form', 'of',\n'the', 'statute,', '&amp;amp;c.', '\\xc2\\xa0', 'ROSE', 'JENNINGS', ',', 'Esq.',\n'sworn.', 'Had', 'you', 'any', 'occasion', 'to', 'be', 'in', 'this', 'part',\n'of', 'the', 'town,', 'on', 'the', '6th', 'of', 'June', 'in', 'the',\n'evening?', '-', 'I', 'dined', 'with', 'my', 'brother', 'who', 'lives',\n'opposite', 'Mr.', \"Akerman's\", 'house.', 'They', 'attacked', 'Mr.',\n\"Akerman's\", 'house', 'precisely', 'at', 'seven', \"o'clock;\", 'they',\n'were', 'preceded', 'by', 'a', 'man', 'better', 'dressed', 'than', 'the',\n'rest,', 'who']\n\n\nTener simplemente una lista de palabras no es realmente significativo. Como seres humanos tenemos la habilidad de leer; sin embargo, te estás acercando a tener una idea de lo que tus programas pueden procesar.\n\nLecturas sugeridas\n\n\n  Lutz, Learning Python\n    \n      Ch. 7: Strings\n      Ch. 8: Lists and Dictionaries\n      Ch. 10: Introducing Python Statements\n      Ch. 15: Function Basics\n    \n  \n\n\nSincronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones3.zip (zip sync)\n\n\n\nEn esa lección aprenderás los comandos de Python que son necesarios para implementar la segunda parte del algoritmo que comenzamos en la lección ‘De HTML a lista de palabras (parte 1)’.\n\n"
  },


  {
    "id": 13,
    "url": "http://localhost:4000/es/lecciones/descarga-automatizada-con-wget",
    "title": "Descarga automatizada con Wget",
    "body": "\nDescarga automatizada con Wget\n\nContenidos\n\n\n  Nota del editor\n  Objetivos de la lección\n  Primer paso: la instalación    \n      Instrucciones para Linux\n      Instrucciones para OS X        \n          Opción uno en OS X: el método preferido\n          Opción dos para OS X\n        \n      \n      Instrucciones para Windows\n    \n  \n  Segundo paso: Aprender acerca de la estructura de Wget - Descargar un conjunto específico de archivos    \n      Tercer paso: copia (mirror) de un sitio completo\n    \n  \n  Una herramienta flexible para descargar fuentes de Internet    \n      Otras lecturas        \n          Notas\n        \n      \n    \n  \n\n\nNota del editor\n\nEsta lección requiere que uses la línea de comandos. Si no tienes experiencia previa en el uso de la línea de comandos, será útil estudiar la lección  Introducción a la línea de comandos en Bash, en The Programming Historian en español.\n\nObjetivos de la lección\n\nEsta lección está diseñada para usuarias/os intermedias/os, aunque pueden seguirla principiantes.\n\nWget es un programa útil, que se ejecuta a través de la línea de comandos de tu computadora y  sirve para recuperar material en línea.\n\n\n    \n\n    Intérprete de línea de comandos, Terminal, en Mac\n\n\n\n\nPuede ser de utilidad en las siguientes situaciones:\n\n\n  Recuperar o duplicar (crear una copia exacta) de un sitio web completo. Este sitio web puede contener documentos históricos, o simplemente puede ser tu propio sitio web personal del que deseas hacer una copia de seguridad. Un comando u orden puede descargar todo el sitio en tu computadora.\n  Descargar archivos específicos de la jerarquía de un sitio web (cierta parte del sitio web como, por ejemplo, cada página que se encuentre dentro del directorio /papeles/ del sitio).\n\n\nEn esta lección trabajaremos con tres ejemplos rápidos de cómo puedes usar wget en tu trabajo. Al final de la lección podrás descargar rápidamente grandes cantidades de información de Internet de manera automatizada. Si encuentras un repositorio de información histórica en línea, en lugar de hacer clic con el botón derecho en cada archivo y guardarlo para construir tu conjunto de datos, tendrás las habilidades para elaborar un solo comando que descargue todo.\n\nPrimero, algunas precauciones. Debes tener cuidado de cómo usas wget. Si consultas el manual en caso de duda y repasas la lección aquí, está bien. Siempre debes generar un retraso en tus comandos para no sobrecargar los servidores y también debes poner un límite a la velocidad de descarga. Todo esto es parte del ser un buen ciudadano de Internet. Podemos pensar en la analogía de utilizar una toma de agua con prudencia en vez de abrir todas las llaves al mismo tiempo (no es bueno para ti ni para la compañía de agua).\n\nTrata de específicar de la mejor manera posible la formulación de tu descarga. Hay por ahí un chiste que sugiere que puedes descargar accidentalmente ¡todo Internet con wget! Es un poco exagerado, ¡pero no está demasiado lejos!\n\nComencemos.\n\nPrimer paso: la instalación\n\nInstrucciones para Linux\n\nSi usas Linux ya debes tener instalado wget. Compruébalo abriendo tu línea de comandos. Escribe wget y presiona enter. Si tienes instalado wget el sistema responderá:\n\n-&gt; Missing URL.\n\n\nsi no está instalado verás:\n\n-&gt; command not found.\n\n\nSi usas OS X o Windows tienes que descargar el programa. Usuarias/os de Linux sin wget deben seguir las instrucciones para OS X a continuación.\n\nInstrucciones para OS X\n\nOpción uno en OS X: el método preferido\n\nEn OS X hay dos formas de obtener wget e instalarlo. Lo más fácil es instalar un administrador de paquetes y usarlo para instalar wget automáticamente. Hay un segundo método, que se discute más adelante, que involucra compilarlo.\n\nSin embargo, para un correcto funcionamiento de ambos métodos se requiere que instales las ‘Herramientas para línea de comandos’ de Apple. Esto implica descargar XCode. Si tienes el ‘App Store’, puedes descargar XCode a través de este enlace. Si no, las siguientes instrucciones funcionarán.\n\nPara descargar XCode, ve al sitio web de desarrolladores de Apple, regístrate como desarrollador y luego en la sección descargas para desarrolladores de Apple necesitarás encontrar la versión correcta. Si estás en la versión más reciente, Lion a partir de julio de 2012,1 puedes utilizar el enlace principal. De lo contrario, deberás hacer clic en el enlace: “¿Está buscando herramientas de desarrollador adicionales? Ver descargas”.\n\nDespués de iniciar sesión con tus credenciales de desarrollador gratuitas verás una larga lista. Escribe “xcode” en la barra de búsqueda y encuentra la versión que sea compatible con la versión de tu sistema operativo. Encontrar la versión correcta para ti puede tomar algunos clics. Por ejemplo, Xcode 3.2 es la versión para OS X 10.6 Snow Leopard, 3.0 es la versión para OS X 10.5 Leopard, etc.\n\nEs una descarga muy grande y tomará algún tiempo en completarse. Una vez que tengas el archivo, instálalo.\n\nDeberás instalar el kit ‘Command Line Tools’ de XCode. Abre la pestaña ‘Preferencias’, haz clic en ‘Descargas’ y luego en ‘Instalar’ junto a ‘Herramientas de línea de comandos’. Ahora estamos listos para instalar un gestor de paquetes.\n\nEl gestor de paquetes más fácil de instalar es Homebrew. Ve a https://brew.sh/index_es y revisa las instrucciones. Hay muchos comandos importantes, como wget, que no están incluidos de forma predeterminada en OS X. Este programa facilita la descarga y la instalación de todos los archivos necesarios.\n\nPara instalar Homebrew, abre la ventana de Terminal y escribe:\n\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n\n\nEsta instalación de Hombrew utiliza el lenguaje de programación Ruby, integrado en OS X. Para ver si la instalación fue correcta, escribe la siguiente orden en la ventana de tu Terminal:\n\nbrew\n\n\nSi se ha instalado bien, debe aparecer una lista de opciones de documentación. Pero aún tenemos que ejecutar otro comando para asegurarnos de que todo funcione:\n\nbrew doctor\n\n\nCon Homebrew listo podemos instalar wget, que ahora será un paso fácil.\n\nbrew install wget\n\n\nSe procederá a descargar la versión más reciente de wget, que es wget 1.14.2 Después de que la secuencia de comandos deje de ejecutarse y vuelva a la ventana principal, escribe el siguiente comando en la terminal:\n\nwget\n\n\nSi se instaló verás:\n\n-&gt; Missing URL.\n\n\nSi no, verás:\n\n-&gt; command not found.\n\n\nEn este punto, deberías haber instalado wget correctamente. ¡Ahora todo está listo para seguir!\n\nOpción dos para OS X\n\nSi por alguna razón no deseas instalar un administrador de paquetes, puedes descargar solo wget. Esto será apropiado si estás utilizando un administrador de paquetes diferente (como Mac Ports) o si deseas mantener tu infraestructura al mínimo. Sigue las mismas instrucciones para instalar Xcode y el conjunto de herramientas de línea de comandos.\n\nLuego puedes descargar una versión no compilada de wget desde el sitio web de GNU. Yo elegí descargar el archivo wget-1.13.tar.gz, que puedes encontrar siguiendo el enlace a cualquier página de descarga, ya sea HTTP o FTP). Descomprime haciendo doble clic en el archivo en tu directorio de inicio. En una Mac, este será su directorio: /user/; por ejemplo, mi nombre de usuario es ianmilligan y aparece junto a un icono de casa en mi Finder. Luego abre Terminal. Para este tutorial, hemos descargado wget-1.13.\n\nTenemos que navegar primero al directorio en el que se encuentran los archivos wget. En la terminal, escribe:\n\ncd wget-1.13\n\n\nTen en cuenta que si has descargado una versión diferente de wget, los siguientes pasos funcionarán pero tendrás que reemplazar el número de la versión (aquí 1.13) por el tuyo.\n\nAhora necesitamos generar las instrucciones, o makefile, para el archivo. Esto es una especie de boceto del aspecto que tendrá el archivo final. Escribe:\n\n./configure –with-ssl=openssl\n\n\nAhora que tenemos el proyecto abocetado, ordenemos a la computadora que lo siga. Escribe:\n\nmake\n\n\nAhora necesitas crear el archivo final. Al escribir antes el comando sudo, estás ejecutando los comandos siguientes con los privilegios de seguridad más altos. Esto le permite a la computadora instalar el archivo en tu sistema.\n\nsudo make install\n\n\nEn este punto del proceso tendrás que introducir la contraseña de tu computadora en el prompt que aparezca. Escríbela.\n\nDeberás haber instalado wget.\n\nInstrucciones para Windows\n\nLa forma más fácil es descargar una versión funcional. Para hacerlo, visita este sitio web y descarga wget.exe. Al momento de escribir este tutorial es la versión 1.17.1, y debe descargar el archivo binario de 32 bits. El archivo es el segundo enlace en la columna binaria de 32 bits, titulada simplemente wget.exe.\n\nSi colocas wget.exe en tu directorio C:\\Windows, puedes usar wget desde cualquier lugar de tu computadora. Esto hará tu vida más fácil ya que no tendrás que preocuparte por ejecutar siempre wget desde un solo lugar en tu sistema. Si está en este directorio, Windows sabrá que el comando se puede usar en cualquier parte en el que se encuentra la ventana de tu terminal.\n\nSegundo paso: Aprender acerca de la estructura de Wget - Descargar un conjunto específico de archivos\n\nEn este punto, las personas usuarias de las tres plataformas deben estar en la misma página. Usamos wget a través de la interfaz de línea de comandos de nuestro sistema operativo (introducido anteriormente como Terminal para usuarios de Mac y Linux, donde ha estado jugando con algunos comandos de Python). Debes usar su línea de comandos en lugar de Komodo Edit que puedes haber usado en otras lecciones.\n\nLa documentación completa para wget se puede encontrar en la página del Manual de wget de GNU.\n\nTomemos un ejemplo de conjunto de datos. Digamos que deseas descargar todos los documentos alojados en el sitio web ActiveHistory.ca. Todos están ubicados en: http://activehistory.ca/papers/; en el sentido de que están todos contenidos en el directorio /papers/. Por ejemplo, el noveno documento publicado en el sitio web es http://activehistory.ca/papers/historypaper-9/. Piensa en esta estructura de la misma forma que los directorios en tu propia computadora. Si tienes una carpeta con la etiqueta /Historia/, es probable que contenga varios archivos dentro de ella. La misma estructura es válida para los sitios web y estamos usando esta lógica para decirle a nuestra computadora qué archivos queremos descargar.\n\nSi deseas descargarlos todos manualmente deberás escribir un programa personalizado o hacer clic derecho en cada papel para hacerlo. Si los archivos están organizados de una manera que se ajuste a tus necesidades de investigación, wget es el abordaje más rápido.\n\nPara asegurarte que wget está trabajando, prueba lo siguiente.\n\nEn tu directorio de trabajo, crea un nuevo directorio. Llamémoslo wget-activehistory. Puedes hacer esto utilizando tu Finder / Windows, o si estás en una ventana de Terminal en esa ruta, puedes escribir:\n\nmkdir wget-activehistory\n\n\nAhora tienes un directorio en el que trabajaremos. Abre la interfaz de la línea de comandos y navega al directorio wget-activehistory. Como recordatorio, recuerda que puedes escribir:\n\ncd [directory]\n\n\n… para navegar a un directorio determinado. Si has creado este directorio en tu directorio de inicio, al escribir cd wget-activehistory podrás moverte a tu nuevo directorio.\n\nEscribe la orden siguiente:\n\nwget http://activehistory.ca/papers/\n\n\nDespués de algunos mensajes iniciales, verás algo parecido a lo siguiente (por supuesto que las cifras, las fechas y algunos detalles serán diferentes):\n\nSaving to: `index.html.1'\n\n[] 37,668 --.-K/s in 0.1s\n\n2012-05-15 15:50:26 (374 KB/s) - `index.html.1' saved [37668]\n\n\nWget descargó la primera página de http://activehistory.ca/papers/, que contiene el índice de los documentos, a tu nuevo directorio. Si lo abres, verás el texto principal en la página de inicio de ActiveHistory.ca. Así que de un golpe ya hemos descargado algo rápidamente.\n\nPero lo que queremos hacer ahora es descargar cada uno de los papeles. Así que necesitamos agregar algunos comandos a wget.\n\nWget opera sobre las siguientes bases generales:\n\nwget [options] [URL]\n\n\nAcabamos de aprender cosas sobre el componente [URL] en el ejemplo anterior, ya que le indica al programa a dónde ir. Sin embargo, las opciones le dan al programa un poco más de información sobre lo que queremos hacer. El programa sabe que una opción es una opción por la presencia de un guión antes de la variable. Esto le permite saber la diferencia entre la URL y las opciones. Así que vamos a aprender algunos comandos ahora:\n\n-r\n\n\nLa recuperación recursiva es la parte más importante de wget. Lo que esto significa es que el programa comienza siguiendo los enlaces del sitio web y también los descarga. Entonces, por ejemplo, http://activehistory.ca/papers/ tiene un enlace a http://activehistory.ca/papers/historypaper-9/, por lo que también se descargará si utilizamos la recuperación recursiva. Sin embargo, también seguirá a cualquier otro enlace: si hubiera un enlace a http://uwo.ca en algún lugar de esa página, seguiría eso y lo descargaría también. De forma predeterminada, -r envía wget a una profundidad de cinco sitios después del primero. Esto es siguiendo los enlaces, hasta un límite de cinco clics después del primer sitio web. En este punto, será bastante indiscriminado. Así que necesitamos más comandos:\n\n--no-parent\n\n\n(El doble guión indica el texto completo de un comando. Todos los comandos también tienen una versión corta, éste podría iniciarse usando -np).\n\nEsto es muy importante. Quiere decir que wget debe seguir los enlaces pero no más allá del último directorio principal. En nuestro caso, eso significa que no irá a ninguna sitio que no sea parte de la jerarquía de http://activehistory.ca/papers/. Si se tratara de una ruta larga como http://niche-canada.org/projects/events/new-events/not-yet-happened-events/, solo encontraría archivos en la carpeta /not-yet-happened-events/. Es un comando crítico para delimitar tu búsqueda.\n\nAquí una representación gráfica:\n\n\n    \n\n    Representación gráfica de cómo trabaja el comando ‘no-parent’ en wget\n\n\n\n\nFinalmente, si deseas navegar fuera de una jerarquía, es mejor delimitar qué tan lejos quieres ir. El valor predeterminado es seguir cada enlace y mantener un límite de cinco páginas desde la primera página. Sin embargo, tal vez solo quieras seguir un enlace y detenerte allí. En ese caso, podría escribir -l 2, lo cual nos lleva a una profundidad de dos páginas web. Ten en cuenta que esto es una ‘L’ minúscula, no un número 1.\n\n-l 2\n\n\nSi estos comandos ayudan a dirigir wget, también debemos agregar algunos más para ser amables con los servidores y para evitar que las contramedidas automáticas del sitio detecten que el servidor está siendo atacado. Para ello, hay dos comandos esenciales adicionales:\n\n-w 10\n\n\nNo es correcto solicitar demasiadas peticiones a la vez a un servidor web. También hay otras personas que esperan información, por lo que es importante compartir la carga. El comando -w 10 marca una espera de diez segundos entre las solicitudes que hacemos al servidor. Puedes acortar esto, ya que diez segundos es bastante largo. En mis propias búsquedas, a menudo uso una espera de 2 segundos. En raras ocasiones, puede encontrarse con un sitio que bloquee la descarga automática por completo. Los términos de servicio del sitio web, que debes consultar, pueden no mencionar una política de descarga automatizada. Pero los pasos para prohibirlo pueden incorporarse en la arquitectura de su sitio web. En casos tan raros, puede usar el comando ––random-wait que variará la espera entre 0,5 y 1,5 veces el valor que proporciones aquí.\n\nOtro aspecto crítico es limitar el ancho de banda que utilizarás en la descarga:\n\n--limit-rate=20k\n\n\nEste es otro comando importante y “educado”. No deseas utilizar demasiado ancho de banda de los servidores. Por lo tanto, este comando limitará la velocidad máxima de descarga a 20kb por segundo. La opinión varía acerca de cuál es una tasa límite adecuada. Probablemente podríamos llegar hasta unos 200 kb por segundo para archivos pequeños. Sin embargo, para no cargar demasiado al servidor, vamos a mantentenerlo en 20k. ¡Esto también nos mantendrá felices en ActiveHistory.ca!\n\nTercer paso: copia (mirror) de un sitio completo\n\nConsiderando todo esto descarguemos todos los documentos de ActiveHistory.ca. Ten en cuenta que la barra diagonal final en la URL es crítica. Si la omites, wget pensará que los documentos son un archivo en lugar de un directorio. Los directorios terminan en barras. Los archivos no lo hacen. El comando descargará la página completa de ActiveHistory.ca. El orden de las opciones no importa.\n\nwget -r --no-parent -w 2 --limit-rate=20k http://activehistory.ca/papers/\n\n\nVa a ser más lento que antes, pero tu terminal comenzará a descargar todos los documentos de ActiveHistory.ca. Cuando haya terminado, debes tener un directorio etiquetado como ActiveHistory.ca que contendrá el subdirectorio /papers/ perfectamente reflejado en tu sistema. Este directorio aparecerá en la ubicación desde la que ejecutaste el comando en tu línea de comandos, por lo que es probable que esté en tu directorio USER. Los enlaces serán reemplazados por enlaces internos a las otras páginas que ha descargado, por lo que realmente puedes tener un sitio ActiveHistory.ca completamente operativo en tu computadora. Esto te permite comenzar a jugar con él sin preocuparte por tu velocidad de internet.\n\nPara saber si la descarga fue un éxito, también tendrás un registro en la pantalla de comandos. Echa un vistazo para asegurarte de que todos los archivos se descargaron correctamente. Si no se han descargado, te avisará que has fallado.\n\nSi quieres descargar un sitio web completo, hay un comando incorporado para wget que te lo permite.\n\n-m\n\n\nEste comando significa “espejo” (mirror) y es muy útil para hacer copias de seguridad de un sitio web completo. Introduce el siguiente conjunto de comandos: marcado de tiempo(time stamping), que analiza la fecha del sitio y no lo reemplaza si ya tienes esa versión en tu sistema (que es muy útil para descargas repetidas), así como una recursión infinita (irá por tantas capas en el sitio como sea necesario). El comando para copiar completo el sitio ActiveHistory.ca sería:\n\nwget -m -w 2 --limit-rate=20k http://activehistory.ca\n\n\nUna herramienta flexible para descargar fuentes de Internet\n\nA medida que tengas más comodidad usando la línea de comandos, verás que wget es un agregado útil a tu conjunto de herramientas digitales. Si hay un corpus completo de documentos de archivo que deseas descargar para minería de texto, si están organizados en un directorio y están todos juntos (lo que no es tan común como podría pensarse), con un comando wget rápido esto será más eficaz que hacer scraping en los enlaces con Python. Asimismo, puedes comenzar a descargar cosas directamente desde tu línea de comandos: programas, archivos, copias de seguridad, etc.\n\nOtras lecturas\n\nAquí solo he dado una instantánea de algunas de las funcionalidades de wget. Para más información, consulta el manual de wget.\n\nNotas\n\n\n  \n    \n      Al momento de la traducción el más reciente es Mojave (OS-X 10.14), desde el 25 de septiembre de 2018. &#8617;\n    \n    \n      La versión más reciente es wget 1.19, desde el 3 de febrero de 2017. &#8617;\n    \n  \n\n\nWget es un programa útil que se ejecuta a través de la línea de comandos de tu computadora. Sirve para recuperar material en línea.\n\n"
  },


  {
    "id": 14,
    "url": "http://localhost:4000/es/lecciones/editar-audio-con-audacity",
    "title": "Editar audio con Audacity",
    "body": "\nEditar audio con Audacity\n\nContenidos\n\n\n  Objetivos del módulo\n  Trabajar con Audacity\n  Grabar audio\n  Editar audio\n  Exportar\n\n\nObjetivos del módulo\n\nPara aquellos interesados en audio, las habilidades básicas de edición de sonido les serán de mucha ayuda. Ser capaz de manipular los materiales puede ayudarte a dominar tu objeto de estudio: puedes ampliar y extraer momentos específicos para analizar, procesar el audio, y subir los materiales a un servidor para complementar la entrada de un blog en la materia. En un nivel más práctico, estas habilidades te permitirán grabar y comprimir grabaciones, tuyas o de otros, para su distribución.  ¿Esa conferencia de un profesor invitado a tu facultad? ¡Grábala y edítala tú mismo! Hacerlo así es una forma sencilla de distribuir recursos entre varias instituciones, y también ayuda a hacer los materiales más accesibles pera lectores y escuchas con una amplia variedad de necesidades de aprendizaje.\n\nEn esta lección aprenderás a utilizar Audacity para cargar, grabar, editar, mezclar y exportar archivos de audio. Con frecuencia, las plataformas de edición de audio son costosas y ofrecen numerosas funciones que pueden ser abrumadoras para el usuario que no tiene experiencia previa, al contrario, Audacity es una alternativa gratuita y de código abierto que ofrece gran funcionalidad y fácil acceso para editar archivos de audio.\n\nPara esta lección vamos a trabajar con dos archivos de audio: una grabación de las Variaciones Goldberg de Bach, y otra grabación de tu propia voz que se hará en el transcurso de la lección.\n\nÉste tutorial utiliza Audacity 2.1.2, lanzado en enero de 2016.\n\nTrabajar con Audacity\n\nPrimero, descarga los archivos necesarios.\n\nVas a necesitar el archivo en .mp3 de las Variaciones Goldberg de Bach. Para descargarlo, haz click con el botón derecho aquí y selecciona “guardar como” para guardar el archivo en tu computadora como un MP3.\n\nA continuación, descarga e instala Audacity, que está disponible en el sitio del proyecto. Audacity puede utilizarse en Mac OSX, Windows o Linux.\n\nDescarga el programa y haz doble clic para instalar.\n\nPara empezar, abre la grabación de Bach que recién descargaste usando el menú de archivo de Audacity.\n\nLa interfaz cargará y mostrará los archivos cargados:\n\n\n\nAudacity convierte el sonido en un diagrama de onda, una forma frecuentemente utilizada para representar sonido. El eje horizontal representa el tiempo en forma de segundos (o minutos y segundos, dependiendo de la extensión del clip). El inicio del sonido se visualiza del lado izquierdo de la interfaz y Audacity coloca marcadores a lo largo de la onda hacia la derecha. Si damos clic en el botón de reproducir Audacity se moverá sobre el sonido de izquierda a derecha, entre tanto una línea vertical representará nuestra posición en el clip de audio.\n\nEl eje vertical representa la amplitud, que experimentamos como intensidad sonora o volumen. De manera predeterminada, el eje vertical mide el volumen en una regla vertical de -1 a 1: los extremos de -1 y 1 representan la intensidad sonora posible de la grabación sin distorsión, mientras que 0 representa silencio. Así, el silencio comienza como una línea plana desde la cual el sonido será más alto y más profundo a medida que aumente su intensidad. Para mayor información acerca del porqué algunos de los números son negativos, revisa la introducción a la acústica de Jeffrey Hass (en inglés).\n\nLa representación de tiempo y amplitud de Audacity es tu primer y más fácil punto de referencia para la edición de sonido, y la herramienta facilita la navegación por el mismo. Sigo llamándole a esto una onda, pero aún no se parece mucho a una. Vamos a echar un vistazo más de cerca al seleccionar una parte de la pieza de audio.\n\n\n  Haz clic en algún lugar de la onda para seleccionarla.\n  Arrastra para resaltar una parte de la onda (funciona en cualquier parte con sonido). Si no estás satisfecho con la selección, puedes arrastrar las orillas de tu selección para ajustar los límites.\n  Una vez que estés conforme con la pieza de audio, selecciona “Ampliar” en el menú “Ver”.\n\n\nSi amplías seis o siete veces, verás algo que puede parecerse más a una onda:\n\n\n\nObserva que el incremento de tiempo en Audacity se ajusta conforme amplas la selección. Las frecuencias de tono se miden en ondas por segundo, y el programa tiene que fusionar las partes para lograr que el clip de sonido encaje en una ventana. El resultado es una forma de onda que nosotros vemos cuando reducimos la selección, al seleccionar “Normal”, desde el menú Ver. Cada vista –la micro y la macro- tiene sus usos particulares. Volveremos a ellas más adelante.\n\n\n\nAntes de proceder, vale la pena observar las diversas paletas que proporciona Audacity para sus funciones más comunes. La paleta de reproducción ofrece símbolos que seguramente son familiares: los botones que te permiten pausar, reproducir, detener, avanzar al principio o al final de un clip, y grabar.\n\n\n\nPor otro lado, la paleta de herramientas probablemente parece nueva. No discutiremos todas las funciones que ofrece Audacity, así que no usaremos algunos de estos botones. Pero toma nota: las herramientas de “selección” superior izquierda y el “cambio de tiempo”, inferior medio, serán las dos que usaremos en esta lección. De forma predeterminada, cuando abres Audacity, tu estarás utilizando la herramienta de selección.\n\nGrabar audio\n\nHemos cargado la introducción musical para nuestro podcast. Continuemos grabando nuestra propia voz.\n\n\n  \n    De forma predeterminada, Audacity reproducirá y volverá a grabar tu pista original cuando intentes grabar una nueva. Para evitar esto, puedes silenciar temporalmente la pista de Bach cuando grabes tu voz. Para silenciar la pista, da clic en el botón “Silencio”, a la izquierda de la forma de onda de Bach. La pista de Bach se volverá gris para mostrar que no se está reproduciendo.\n  \n  \n    Para empezar a grabar en Audacity, presiona el círculo rojo en la parte superior izquierda de la venta de Audacity. No te preocupes demasiado en conseguir la calidad adecuada; a continuación, trabajaremos en la edición del archivo sonoro.\n  \n  \n    Haz tu mejor voz de radio-locutor en dirección de tu computadora, y cuando estés listo, da clic en el rectángulo para detener la grabación.\n  \n\n\nSe mostrará algo parecido a esto:\n\n\n\nNuestra grabación original de “Bach” se mantiene en la parte superior de la interface, mientras que nuestra nueva grabación está por debajo de ella. De forma predeterminada, Audacity no sobreescribirá una grabación anterior. Por el contrario, aísla ambos sonidos o pistas, permitiéndonos manipular componentes separados antes de mezclarlos en una grabación final. Podemos hacer cambios a uno sin afectar al otro. Observa cómo, con respecto al tiempo, la nueva pista se grabó de manera predeterminada al principio del proyecto de Audacity. Por ahora, las pistas de “Bach” y la vocal comienzan al mismo tiempo. Existen otras imperfecciones potenciales en tu grabación única, algunas de las cuales podemos corregir.\n\nFinalmente, observa cómo en mi ejemplo existen dos formas de onda para la grabación de Bach, pero solo una para la grabación de mi voz. La grabación de Bach fue hecha en estéreo, lo que significa que había dos canales de entrada, mientras que la grabación de mi voz fue hecha en monoauraL. Audacity permite grabar en ambos, y cualquiera de las dos funcionará para esta lección, así que no te preocupes si tu grabación aparece en estéreo. Puedes cambiar de mono a estéreo y viceversa desde “Editar”, disponible en la sección “Barra de herramientas” del menú “ver”. Para más información sobre mono contra estéreo, revista esta lectura (en inglés).\n\nAparte: a menudo puede ser de utilidad convertir la salida de sonido de tu laptop en entrada, para que puedas grabar los sonidos que se reproducen en tu computadora sin preocuparte del ruido externo o volver a grabar audio digital. Para obtener información sobre cómo llevar a cabo éste proceso, consulta Soundflower.\n\nEditar audio\n\nEl tema de la ingeniería de audio es amplio y puede ser parte de una larga y fructífera carrera –no esperamos agotar todos los tópicos potenciales en este tutorial–, pero podemos ofrecer sólo algunas técnicas básicas útiles para trabajar con audio digital. Sus experiencias pueden variar en función del carácter único de su propia grabación.\n\nPara utilizar la pista grabada, vamos a necesitar limpiarla un poco, aislar y refinar las piezas que queremos. Nuestro primer paso consistirá en remover el silencio no deseado creado durante el retraso entre el comienzo de la grabación y cuando comencé a hablar.\n\n\n  Ampliar el comienzo de la pista nos dará una vista del silencio, y al hacer clic y arrastrar las secciones del diagrama de ondas, podemos eliminarlos al pulsar la tecla suprimir (en la mayoría de los teclados).\n\n\n\n\n\n\nEsas pequeñas pausas pueden pasar prácticamente inadvertidas, pero son elementos importantes dentro de cualquier pista de audio,además, queremos que los límites de la nueva pista vocal no contengan datos extraños. Después de eliminar, debes de tener un clip de audio agradable y compacto, con tan solo una pequeña fracción de silencio en cada extremo.\n\nPara asegurar transiciones suaves entre las pistas, debemos introducir efectos de fundido o transiciones graduales en amplitud. Es  buena idea incluir un pequeño fundido de entrada (fade in) al comienzo de la pista y un fundido de salida (fade out) al final que lleve al silencio. Hacerlo puede prevenir fallos y ruidos al evitar que el sonido aparezca y desaparezca súbitamente.\n\n\n  Amplifica el principio de la pista, resalta el inicio de la onda, incluyendo sólo una fracción del sonido de destino, y selecciona “Aparecer progresivamente” del menú “Efecto”.\n\n\nSi sólo seleccionaste una pequeña porción de audio, es posible que no puedas ver los cambios que causaron los desvanecimientos. Estas capturas de gran aumento ayudarán:\n\n\n\n\n\nEl fundido de entrada disminuyó dramáticamente la amplitud inicial e introdujo cambios graduales de amplitud a lo largo de las secciones destacadas de la pista, suavizando y creando la percepción de un incremento en el volumen.\n\n\n  Repite esto al final de la pista, pero ahora con “desvanecer progresivamente”\n\n\nTu pista estará configurada para ser insertada suavemente en cualquier parte del archivo.\n\nLa eliminación del silencio y del sonido no deseado preparó el clip, pero aún tenemos que moverlo hacia la marca de tiempo que queremos. Queremos ubicarlo en la parte apropiada del podcast, después de que la música introductoria se haya reproducido un poco. Para mover una pista horizontalmente en el eje de las X del diagrama de onda y re-asignarle una nueva posición en el tiempo, usa la herramienta de cambio de tiempo. Con esta herramienta seleccionada, al hacer clic en una pista de sonido te permite moverla horizontalmente en el tiempo, en relación con las otras pistas.\n\n\n  Mueve nuestro clip vocal hacia la derecha, para que comience después de que la música introductoria se haya reproducido durante algunos segundos.\n\n\n\n\nSi el volumen de tu voz, en relación con la música introductoria, te parece desequilibrado, puedes reorganizarlos para que estén más equilibrados. El volumen de una pista en particular se puede ajustar utilizando el control deslizante de volumen de la pista, ubicado a la izquierda del panel de la pista. Éste parece una pequeña escala -/+:\n\n\n\nPero eventualmente vamos a querer cambiar el enfoque de la pista por completo de la música de introducción y dar nuevo énfasis a la grabación de nuestra voz. Un “crossfade” como este, es fácil de realizar en Audacity.\n\n\n  \n    Primero, elimina los cinco segundos iniciales de la introducción de Bach. Sitúa el cursor en el lugar de la pista donde deseas comenzar a borrar y después presione “Control +Shift+ K” o selecciona en el menú “Editar”, “Seleccionar/Desde el cursor hasta el final”. Esto seleccionará todo desde la ubicación del cursor hasta el final de la pista.\n  \n  \n    Alinea lo que queda con tu pista de voz usando la barra de desplazamiento de control de tiempo, para que las dos pistas se sobrepongan ligeramente.\n  \n  \n    Después usa la herramienta de selección para hacer clic y arrastrar la sección en la que se sobrepondrán, comenzando con la pista superior y terminando con la inferior. Ambas pistas deben de estar destacadas.\n  \n\n\n\n\n\n  Seleccionar “Crossfade Tracks”, del menú Efecto, esto le indicará a Audacity que realice el desvanecimiento de salida de la pista superior mientras hace el desvanecimiento de entrada de la pista inferior; en este caso, el posicionamiento de las pistas es importante.\n\n\nAudacity te ofrecerá opciones para el crossfade de la pista, pero por ahora está bien mantener la configuración preestablecida en “Fade type:constant gain”. Ésta configuración garantiza que ambas pistas se desvanecerán o alinearán (para mayor información, revisa la documentación de “crossfades” de Audacity\n\n\n\nCuando el producto final está mezclado, el resultado será una transición fluida entre los dos elementos.\n\nExportar\n\nDe forma predeterminada, todo lo que hagas en Audacity es guardado en el formato de archivo propio de la herramienta, “.aup” . Para completar este pequeño proyecto, necesitamos exportarlo a un formato que pueda ser reproducido por la mayoría de los programas de audio.\n\n\n  Selecciona “Exportar audio” del menú archivo.\n\n\nAl hacer esto, mezclarás las múltiples pistas en un solo archivo de audio, y te dará la oportunidad de proporcionar metadatos a tu trabajo.\n\nExiste un rango de diferentes opciones para refinar el proceso de exportación, pero el más importante es “tipo de archivo”. MP3 y Ogg son buenas opciones para el audio destinado a ser mostrado en la web, ya que ambos comprimen los archivos para que sean rápidos de cargar. Para mejores resultados, puedes incluir ambos formatos y sólo mostrar uno como una alternativa cuando alguno no sea compatible con el navegador web del usuario.  Para mayor información, NCH Software ofrece un buen desglose técnico para sus diferentes opciones, mientras que Jonathan Sterne ha hecho un trabajo fascinante sobre las implicaciones culturales de tales decisiones de formato. Y la W3Schools ofrece una buena comparación de estos formatos usados en el desarrollo web.\n\n¡Felicidades! Has producido exitosamente un pequeño podcast. Puede que no parezca mucho, pero con frecuencia yo uso estas mismas recomendaciones para presentaciones, sitios web y cuestiones académicas. De ninguna manera esta lección pretende agotar los múltiples temas al respecto, pero debe haberte proporcionado algunas herramientas básicas para trabajar con sonido en proyectos de humanidades digitales.\n\nCon esta lección aprenderás a utilizar Audacity para cargar, editar, mezclar y exportar archivos de audio.\n\n"
  },


  {
    "id": 15,
    "url": "http://localhost:4000/es/lecciones/escritura-sostenible-usando-pandoc-y-markdown",
    "title": "Escritura sostenible en texto plano usando Pandoc y Markdown",
    "body": "\nEscritura sostenible en texto plano usando Pandoc y Markdown\n\nContenidos\n\n\n  Objetivos\n  Filosofía\n  Principios\n  Requisitos de software\n  Bases de Markdown\n  Estar en contacto con la terminal de la máquina\n  Usar Pandoc para convertir Markdown a un documento de MS Word\n  Trabajar con bibliografías\n  Cambiar los estilos de citación\n  Resumen\n  Recursos útiles\n\n\n\n    \n\n    \n\n\n\n\nObjetivos\n\nEn este tutorial aprenderás lo básico de Markdown -una sintaxis de marcado para texto plano que es fácil de leer y de escribir-, así como Pandoc, una herramienta de línea de comandos que convierte el texto plano en varios tipos de archivos bellamente formateados: PDF, .docx, HTML, LaTeX, presentaciones de diapositivas y más.1 Con Pandoc como tu herramienta digital de composición tipográfica, puedes usar la sintaxis de Markdown para añadir figuras, una bibliografía, formato, y cambiar fácilmente estilos de citación de Chicago a MLA (por ejemplo), todo ello utilizando texto plano.\n\nEl tutorial asume que no tienes conocimientos técnicos previos, pero escala con la experiencia ya que a menudo sugerimos técnicas más avanzadas hacia el final de cada sección. Éstas están claramente marcadas y pueden ser revisitadas después de alguna práctica y experimentación.\n\nEn vez de seguir este tutorial de una manera mecánica, te recomendamos esforzarte por entender las soluciones ofrecidas aquí como una metodología que necesitarías adaptar posteriormente para ajustarla a tu entorno y flujo de trabajo. La instalación de las herramientas necesarias presenta tal vez el mayor obstáculo para la participación. Destina suficiente tiempo y paciencia para instalar todo correctamente o házlo con un colega que tenga una configuración similar para ayudarse mutuamente. Consulta la sección Recursos útiles más adelante si te quedas atascado.2\n\nFilosofía\n\nEscribir, almacenar y recuperar documentos son actividades centrales en el flujo de trabajo de la investigación en humanidades. Sin embargo, muchos autores basan su práctica en herramientas y formatos propietarios que a veces no cubren ni siquiera los requerimientos básicos de la escritura académica. Habrás experimentado cierta frustación por la fragilidad de las notas a pie de página, las bibliografías, figuras y borradores de libros escritos en Microsoft Word o Google Docs. Sin embargo, la mayoría de las revistas aún insisten en recibir textos en formato .docx.\n\nPero más que causar una frustación personal, esta dependencia a las herramientas y formatos propietarios tiene implicaciones negativas a largo plazo para la comunidad académica. En este entorno, las revistas deben subcontratar la composición tipográfica, alienan a los autores de los contextos materiales de la publicación añadiendo otros obstáculos innecesarios a la libre circulación del conocimiento.3\n\nCuando utilizas MS Word, Google Docs u Open Office para escribir documentos, lo que ves no es lo que obtienes. Debajo de la capa visible de palabras, oraciones y párrafos se encuentra una complicada capa de código comprensible solamente para las máquinas. Debido a esta capa oculta, tus archivos .docx y .pdf dependen de herramientas propietarias para mostrarse correctamente. Dichos documentos son difíciles de buscar, de imprimir y de convertir a archivos con otros formatos.\n\nMás aún, el tiempo utilizado en formar el documento en MS Word u Open Office se desperdicia, porque el editor de la revista donde lo envías retira todo ese formato. Tanto los autores como los editores se beneficiarían si intercambiaran archivos con un formato mínimo, dejando la composición tipográfica a la etapa de composición final del proceso de publicación.\n\nAquí es donde brilla Markdown. Markdown es una sitaxis para el marcado semántico de elementos dentro de un documento de forma explícita, no en alguna capa oculta. La idea es identificar las unidades que tienen significado para los seres humanos como títulos, secciones, subsecciones, notas a pie de página y las ilustraciones. Por lo menos, los archivos seguirán siendo comprensibles para ti, incluso si el editor de textos que estás utilizando deja de funcionar o si queda fuera del mercado.\n\nEscribir en esta forma libera al autor de la herramienta. Markdown se puede escribir en cualquier editor de texto y ofrece un rico ecosistema de software que puede representar ese texto en documentos con aspecto atractivo. Por esta razón, Markdown está experimentando un periodo de crecimiento, no solamente como un medio para la escritura de documentos académicos sino como una convención para la edición en línea en general.\n\nLos editores de texto para todo prósito más populares incluyen Atom (para todas las plataformas) y Notepad++ (para Windows).\n\nEs importante entender que Markdown no es más que una convención. Los archivos Markdown se almacenan como texto plano, además de añadir la flexibilidad del formato. Los archivos de texto plano han existido desde los tiempos de las máquinas de escribir eléctrónicas. La longevidad de este estándar hace, de manera inherente, que sean más sostenibles y más estables que los formatos propietarios. Mientras que los archivos producidos hace diez años en Microsfot Word o en Pages de Apple pueden causar serios problemas cuando se abren con la última versión del programa, aún es posible abrir un archivo de texto plano escrito en alguno de los editores de texto “muertos”, del pasado, muchas décadas después: AlphaPlus, Perfect Writer, Text Wizard, Spellbinder, WordStar o SCRIPSIT2.0, el favorito de Isaac Asimov producido por Radio Shack. Escribir en texto plano te garantiza que tus archivos permanecerán legibles diez, quince o veinte años a partir de ahora. En esta lección se describe un flujo de trabajo que libera al investigador de programas de procesamiento de texto propietarios y archivos de formatos frágiles.\n\nAhora es posible escribir una amplia gama de documentos en un formato -artículos, entradas de blogs, wikis, programas de estudio y cartas de recomendación-, utilizando el mismo conjunto de herramientas y técnicas para buscar, descubrir, hacer copias de seguridad y distribuir nuestros materiales. Tus notas, entradas de blog, documentación de código y wikis pueden ser creados en Markdown. Cada vez más, muchas plataformas como WorPress, Reddit y GitHub soportan nativamente la escritura en Markdown. A largo plazo, tu investigación se beneficiará de este tipo de flujos de trabajo unificados, lo que hace que sea más fácil guardar, buscar, compartir y organizar tus materiales.\n\nPrincipios\n\nInspirados en las buenas prácticas de una variedad de disciplinas nos hemos guiado por los siguientes principios:\n\n\n  \n    Sostenibilidad. El texto plano a la vez garantiza transparencia y responde a las normas de conservación a largo plazo. MS Word puede seguir el camino de Word Perfect en el futuro, pero el texto plano seguirá siendo siempre fácil de leer, catalogar, minar y transformar. Por otra parte, el control de versiones de texto plano permite efectuar cambios de manera fácil y potente, lo cual es muy útil en la creación colaborativa y organización de borradores. Tus archivos de texto plano serán accesibles en teléfonos celulares, tabletas, o tal vez en una terminal de baja potencia de alguna biblioteca lejana. El texto plano es compatible con versiones anteriores y tiene garantía de futuro. Cualquier software o hardware que se presente más adelante será capaz de entender tus archivos de texto plano.\n  \n  \n    Preferencia por formatos legibles por humanos. Al escribir en Word o en Google Docs, lo que se ve no es lo que se obtiene. El archivo .docx tiene caracteres escondidos, generados automáticamente, que crean una capa de composición tipográfica eclipsada que hace que al usuario le sea difícil solucionar problemas. Algo tan sencillo como pegar una imagen o un texto desde el navegador puede tener efectos impredecibles en el formato del documento.\n  \n  \n    Separación de forma y contenido. Escribir y formar al mismo tiempo distrae. La idea es escribir primero y dar formato más tarde, lo más cerca posible al momento de la publicación. Una tarea como cambiar el estilo de citación de Chicago a MLA debe ser posible sin esfuerzo. Los editores de revistas que quieran ahorrar tiempo ante formatos innecesarios y corrección de textos, deben ser capaces de proporcionar a sus autores una plantilla de formato que se encargue de las minucias de la composición tipográfica.\n  \n  \n    Soporte del aparato crítico. El flujo de trabajo tiene que manejar con gracia notas a pie de página, cifras, caracteres internacionales y bibliografía.\n  \n  \n    Independencia de plataforma. Como las plataformas de publicación se multiplican, tenemos que ser capaces de generar una multiplicidad de formatos, incluyendo presentaciones de diapositivas, impresión, web y dispositivos móviles. Idealmente, nos gustaría ser capaces de generar los formatos más comunes sin romper las referencias bibliográficas. Nuestro flujo de trabajo debe ser portátil al grado que sería bueno poder copiar una carpeta a un pendrive y saber que contiene todo lo necesario para su publicación. Escribir en texto plano significa que puedes compartir fácilmente, editar y archivar tus documentos en prácticamente cualquier entorno. Por ejemplo, un temario de clase escrito en Markdown puede ser guardado como PDF, impreso como hoja de mano, convertido a HTML para la Web, todo desde el mismo archivo. Los archivos impresos y subidos a la web pueden ser publicados de la misma fuente y tener un aspecto similar, preservando la distribución lógica del material.\n  \n\n\nMarkdown y LaTeX responden a todas estas exigencias. Elegimos Markdown (y no LaTeX) porque ofrece la sintaxis más ligera y libre de desorden (de ahí “mark down”), y porque cuando se combina con Pandoc permite una mayor flexibilidad de salidas (incluyendo archivos .docx y .tex).4\n\nRequisitos de software\n\nExpresamente omitiremos algunos detalles menudos relacionados con la instalación del software listado abajo para cada plataforma o sistema. Por ejemplo, no tiene sentido proporcionar las instrucciones de instalación para LaTeX cuando las instrucciones en línea para tu sistema operativo siempre serán más completas y actualizadas. De la misma manera la mecánica de la instalación de Pandoc se obtiene de manera más completa si buscas en Google “installing Pandoc”, con lo que probablemente el primer resultado sea la página principal de Pandoc.\n\n\n  \n    Editor de Texto Plano. Entrar al mundo de la edición en texto plano amplía tu capacidad de seleccionar herramientas innovadoras de manera espectacular. Busca en línea “markdown text editor” y experimenta con las opciones. No importa lo que utilices siempre que sea explícitamente un editor de texto plano como Atom o Notepad++. Recuerda: ya no estamos atados a la herramienta, se puede cambiar de editor en cualquier momento.\n  \n  \n    Terminal de línea de comandos. Trabajar en la “línea de comandos” es lo mismo que escribir comandos en la terminal. En Mac sólo tienes que utilizar tu Finder para acceder a “Terminal”. En Windows utiliza PowerShell. Es probable que los usuarios de Linux ya estén familiarizados con sus terminales. A continuación, vamos a cubrir los conceptos más basicos de cómo encontrar y utilizar la línea de comandos.\n  \n  \n    Pandoc. Las instrucciones detalladas de instalación específica para cada plataforma están disponibles en el sitio web de Pandoc. Para este tutorial es crucial que instales Pandoc en tu ordenador, así que asegúrate de invertir tiempo navegando por las instrucciones. Pandoc fue creado y es mantenido por John MacFarlane, profesor de Filosofía en la Universidad de California en Berkeley. Esto es humanidades digitales en su mejor expresión y servirá como el motor de nuestro flujo de trabajo. Con Pandoc serás capaz de compilar el texto y la bibliografía de tu trabajo en documentos con un formato flexible y atractivo. Una vez que hayas seguido las instrucciones de instalación, verifica su instalación escribiendo en la línea de comandos de tu máquina “pandoc –version”. Asumimos que por lo menos tienes la versión 1.12.3 publicada en enero de 2014.\n  \n\n\nRecomendamos que instales los dos siguientes programas de aplicación, aunque no son un requisito indispensable para completar este tutorial.\n\n\n  \n    Zotero o Endnote. El software para referencias bibliográficas como Zotero y Endnote son herramientas indispensables para organizar y formar citaciones en un trabajo de investigación. Estos programas pueden exportar tus biliotecas como un archivo BibTeX (sobre el que aprenderás inmediatamente en el caso 2, más abajo). Este archivo, que es en sí mismo un documento de texto con el formato de todas tus referencias bibliográficas, te permitirá citar publicaciones rápida y fácilmente utilizando @tags. Cabe señalar que también es posible escribir todas tus referencias bibliograficas a mano usando nuestra bibliografía como plantilla.\n  \n  \n    LaTeX. Las instrucciones detalladas para la instalación específica en cada plataforma están disponibles en el sitio web de Pandoc. A pesar de que este tutorial no cubre LaTeX, éste es utilizado por Pandoc para la creación de PDF. Los usuarios suelen convertir en LaTeX directamente para tener un control más minucioso de la composición tipográfica de los .pdf. Los principiantes pueden considerar saltarse este paso. De lo contrario, escribe en tu terminal latex -vpara ver si LaTeX se ha instalado correctamente (obtendrás un error si así no fuera y algo de información sobre la versión si fue exitosa).\n  \n\n\nBases de Markdown\n\nMarkdown es una convención para estructurar tus documentos en texto plano de una manera semántica. La idea es identificar estructuras lógicas en tu documento (un título, una sección, subsecciones, notas al pie, etc.), marcarlas con algunos caracteres distintivos y luego “compilar” el texto resultante con un intérprete de composición tipográfica que dará forma al documento en consonancia con el estilo especificado.\n\nLas convenciones para Markdown están disponibles en varios tipos o “flavors”, diseñados para su uso en contextos particulares como blogs, wikis o repositorios de código. El flavor de Markdown utilizado por Pandoc está orientado para un uso académico. Sus convenciones están descritas en la página de Pandoc’s Markdown. Estas convenciones incluyen el “YAML” block, que contiene una serie de metadatos muy útiles. 5\n\nVamos a crear ahora un documento simple en Markdown. Abre tu editor de texto plano seleccionado y escribe algo que debe tener un aspecto como el siguiente:\n\n---\ntitle: Flujo de trabajo en texto plano\nauthor: Gabriel García\ndate: 20 de enero de 2014\nfontfamily: times\n---\n\n\nEl Markdown “Pandoc-flavored” almacena cada uno de los valores anteriores y los “imprime” en la ubicación apropiada de tu documento de salida una vez que está listo para la composición tipográfica. Más adelante aprenderemos a incluir campos más potentes en YAML. Por ahora, vamos a suponer que estamos escribiendo un documento compuesto por tres secciones, cada una subdividida en dos. Hay que dejar una línea en blanco después de los tres últimos guiones del bloque YAML para que puedas pegar lo que sigue:\n\n# Sección 1\n\n## Subsección 1.1\n\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\nEl siguiente párrafo debe empezar como éste, sin sangría:\n\n## Subsección 1.2\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque  ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.\n\n# Sección 2\n\n## Subsección 2.1\n\n\n\nSigue adelante e introduce cualquier texto de relleno. Los espacios vacíos tienen significado en Markdown por lo que no debes poner sangría en los párrafos pero sí es importante que separes los párrafos con una línea en blanco. Las líneas en blanco también deben preceder a los encabezados de sección.\n\nPuedes añadir asteriscos para dar énfasis a las palabras con negritas o cursivas de esta manera: *cursivas*y **negritas**. También hay que añadir a nuestro texto un enlace y una nota a pie de página para cubrir los requisitos de un texto promedio. Escribe:\n\nUna oración que requiere una cita.[^1]\n\n[^1]: ¡Ésta es mi primer nota a pie de página! Y un [enlace](https://www.eff.org/).\n\n\nCuando el texto del enlace y la dirección del mismo son iguales es más rápido escribir: &lt;https://www.eff.org/&gt;, en vez de [https://www.eff.org/](https://www.eff.org/).\n\nVamos a guardar nuestro archivo antes de ir más lejos. Haz una carpeta para albergar este proyecto. Es probable que tengas un sistema de organización de tus documentos, proyectos, ilustraciones y bibliografías, pero a menudo tu documento, tus proyectos, tus ilustraciones y bibliografías se encuentran en diferentes carpetas, lo que los hace difíciles de encontrar. Nuestro objetivo es crear una carpeta única para cada proyecto con todos los materiales relevantes incluidos en ella. La regla general es “un proyecto, un texto, una carpeta”. Denomina a tu archivo algo así como “principal.md”, donde “md” significa que es un archivo Markdown.\n\nUna vez que has guardado el archivo, vamos a añadir una imagen. Copia una imagen pequeña a la carpeta y añade lo siguiente en alguna parte del cuerpo de texto: ![una imagen](tu_imagen.jpg).\n\nEn este punto tu archivo principal.md debe verse como sigue\n\n---\ntitle: Flujo de trabajo en texto plano\nauthor: Gabriel García\ndate: 20 de enero de 2014\n---\n\n# Sección 1\n\n## Subsección 1.1\n\nLorem *ipsum* dolor sit amet, **consectetur** adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\nEl siguiente párrafo debe empezar como este, sin sangría:\n\n## Subsección 1.2\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque  ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.\n\n# Sección 2\n\n## Subsección 2.1\n![una imagen](tu_imagen.jpg)\n\n## Subsección 2.2.\n\nUna oración que requiere una cita.[^1]\n\n[^1]: ¡Ésta es mi primer nota a pie de página! Y un [enlace](https://www.eff.org/).\n\n\nY como veremos en breve, este archivo de texto plano se puede representar como un muy buen PDF.\n\n\n    \n\n    Captura de pantalla de un PDF interpretado por Pandoc\n\n\n\n\nSi quieres tener una idea de cómo serán interpretado en un fomato HTML este tipo de marcado, prueba este sitio de prueba en línea y juega con varios tipos de sintaxis. Recuerda que ciertos elementos del Pandoc-flavored markdown (como el bloque de título o las notas al pie) no funcionan en esta versión web ya que solamente acepta lo básico.\n\nEn este punto, deberás ocupar algún tiempo explorando algunas de las características de Markdown como las citas de texto (referidas con el símbolo &gt;), los listados que empiezan con * o -, los saltos de línea literales que empiezan con | (útiles para poesía), las tablas y algunas otras funciones señaladas en la página sobre Markdown de Pandoc.\n\nPresta particular atención a los espacios en blanco y al flujo de los párrafos. La documentación lo explica sucintamente cuando define un párrafo como “una o más líneas de texto seguidas por una o más líneas en blanco.” Consiedra que “las nuevas líneas son tratadas como espacios” y que “si necesitas un salto de línea elocuente, utiliza dos o más espacios en blanco al final de la línea.” La mejor manera de entender lo que significa es experimentar libremente. Utiliza el modo de vista previa de tu editor o solamente ejecuta Pandoc para ver los resultados de tus experimentos.\n\nPero sobre todo, evita la necesidad de formatear. Recuerda que estás identificando unidades semánticas: secciones, subsecciones, énfasis, notas al pie y figuras. Incluso *cursivas*y **negritas** en Markdown no son en realidad marcas de formato, sino que indican un nivel diferente de énfasis. La aplicación del formato sucederá después, una vez que conozcas el momento del proceso en el que hay que hacerlo y los requerimientos de la publicación.\n\nExisten programas que te permiten obtener una vista previa en vivo de la salida de markdown al tiempo que editas tu archivo de texto plano y que detallaremos más adelante en la sección de Recursos útiles. Algunos de ellos soportan notas a pie, figuras, incluso bibliografías. Sin embargo, para sacar provecho al máximo de Pandoc, te recomendamos que te quedes con lo más sencillo: archivos de texto plano almacenados localmente en tu computadora.\n\nEstar en contacto con la terminal de la máquina\n\nAntes de que podamos publicar nuestro archivo principal.md en otros formatos, necesitamos un poco de orientación para trabajar en la interfaz de línea de comandos utilizando la aplicación de la terminal de nuestro ordenador, que es la única manera (y la mejor) de utilizar Pandoc.\n\nLa interfaz de línea de comandos es un sitio amigable una vez que te acostumbras a ella. Si ya te es familiar la utilización de línea de comandos, puedes saltarte esta sección. Para el resto de lectores, es importante entender que al usar la terminal directamente podrán acceder a una amplia gama de herramientas de investigación poderosas que de otra manera es imposible, y será la base para trabajos más avanzados. Para el propósito de este tutorial necesitas aprender solamente unos cuantos comandos muy sencillos.\n\nPrimero, abre una nueva ventana de línea de comandos. Si utilizas una macOS, abre Terminal en el directorio Aplicaciones/Utilidades. En Windows utilizarás PowerShell. En Windows 7 o posterior, recomendamos que utilices el “poweshell” o, para una solución más robusta, instala el subsistema de Windows para Linux y utiliza la terminal que viene con tu distribución Linux favorita. Para una excelente introducción a la línea de comando, consulta “Introduction to the Bash Command\nLine” por Ian Milligan y James Baker.\n\nEn el terminal debe ver una ventana de texto y un puntero (prompt) que puede verse más o menos como esto: nombre-del-ordenador:~nombre-de-usuario$. La tilde indica que estás en el directorio de usuario, y de hecho puedes escribir $ cd ~en cualquier punto para regresar a tu directorio de usuario. No escribas el símbolo de moneda pues solamente indica el puntero de tu terminal, solicitándote que escribas algo en la terminal (como opuesto a que escribas algo en un documento); recuerda introducir Enter después de escribir cada comando.\n\nEs muy común que tu carpeta “Documents” esté localizada en este directorio. Escribe $ pwd (= “print working directory”) y oprime Enter para mostrar el nombre del directorio actual. Utiliza $ pwd cada vez que sientas que te has extraviado.\n\nEl comando $ ls (= list), simplemente enlista los archivos en el directorio actual. Finalmente, puedes usar $ cd&gt; (= change directory) como $ cd NOMBRE_DE_LA_CARPETA (en donde NOMBRE_DE_LA_CARPETA indica la carpeta en la que quieres navegar). Puedes utilizar $ cd ..para moverte automáticamente un nivel arriba en la estructura del directorio (el directorio principal de la carpeta en la que te encuentras actualmente). Una vez que has empezado a escribir el nombre de la carpeta, utiliza la tecla de tabulador para autocompletar el nombre -lo cual es particularmente útil para carpetas con nombre muy largos o nombres de carpetas que contienen espacios en blanco.6\n\nEstos tres comandos de terminal: pwd, ls y cd es todo lo que necesitas en este tutorial. Practica con ellos la navegación por las carpetas de tus documentos por unos minutos y mientras piensa en la manera en la que has organizado tus archivos. Si lo deseas, sigue lo que haces ayudándote de tu organizador de archivos de la interfaz gráfica de usuario (Finder) para poder orientarte.\n\nUsar Pandoc para convertir Markdown a un documento de MS Word\n\n¡Ya estamos listos para la composición tipográfica! Abre la ventana de tu terminal, utiliza $ pwdy $ cd NOMBRE_DE_LA_CARPETA para navegar hasta la carpeta en la que se encuentra tu proyecto. Una vez que estés ahí escribe $ ls en la terminal para enlistar los archivos. Si ves tu archivo .md y tus imágenes te encuentras en el lugar correcto. Para convertir .md a .docx escribe:\n\n$ pandoc principal.md -o principal.docx\n\n\nAbre el arhivo con MS Word para contejar tus resultados. Si utilizas Open- o Libre Office puedes ejecutar:\n\n$ pandoc principal.md -o principal.odt\n\n\nSi la linea de comandos es una novedad para ti, imagina que lees los comandos anteriores y que dicen algo como: “Pandoc: crea un archivo MS Word a partir de mi archivo Markdown.” La partícula -o es una “bandera” que en este caso dice algo como “en vez de que explícitamente tenga yo que indicarte la fuente y el objeto de los formatos de archivos, adivina con sólo ver la extensión de los archivos.” Hay muchas opciones disponibles en Pandoc a través de estas “banderas”. Puedes ver la lista completa en el sitio web de Pandoc, o escribiendo en la terminal:\n\n$ man pandoc\n\n\nIntenta ejecutar el comando:\n\n$ pandoc principal.md -o proyecto.html\n\n\nAhora navega de nuevo por el directorio de tu proyecto. ¿Puedes decir qué sucedió?\n\nLos usuarios más avanzados que tienen instalado LaTeX querrán experimentar con la conversión de markdown a un archivo .txt o a un archivo .pdf formateado especialmente. Una vez que se ha instalado LaTeX se pueden crear archivos PDF bellamente formados utilizando la misma estructura de comandos:\n\n$ pandoc -o principal.pdf principal.md\n\n\nAsegúrate que tu editor de texto soporte el formato de codificación UTF-8. Cuando utilices LaTeX para convertir al formato .pdf, en vez del atributo fontfamily en YAML para cambiar la fuente, especifica el atributo mainfont para producir algo como esto:\n\n\n\ntitle: Flujo de trabajo en texto plano\nauthor: Dennis Tenen, Grant Wythoff\ndate: 20 de enero de 2014\nmainfont: times    ---\n\n\nTrabajar con bibliografías\n\nEn esta sección agregaremos una bibliografía a nuestro documento y después la convertiremos de un formato estilo Chicago a un formato estilo MLA.\n\nSi no estás usando un gestor de referencias bibliográficas como Endnote o Zotero, deberías comenzar a hacerlo inmediatamente. Nosotros preferimos Zotero porque, al igual que Pandoc, fue creado por la comunidad académica y, al igual que otros proyectos de código abierto, es distribuido con una Licencia Pública General de GNU. Mucho más importante para nosotros es que tu gestor de referencias tenga la habilidad de generar bibliografías en formato de texto plano para estar en consonancia con nuestro principio de “todo en texto plano”. Prosigue y abre el gestor de referencias de tu elección y añade algunas entradas de ejemplo. Cuando hayas terminado, encuentra la opción para exportar tu bibliografía en formato BibTeX (.bib). Guarda tu archivo .bib en el directorio de tu proyecto y dale un nombre razonable como proyecto.bib.\n\nLa idea general es mantener tus fuentes organizadas en una base de datos bibliográfica centralizada mientras vas generando archivos .bib específicos y más pequeños que serán almacenados en el mismo diretorio de tu proyecto. Prosigue y abre tu archivo .bib con el editor de texto plano que hayas elegido.7\n\nTu archivo .bib deberá contener múltiples entradas que se ven más o menos así:\n\n   @article{fyfe_digital_2011,\n        title = {Digital Pedagogy Unplugged},\n        volume = {5},\n        url = {http://digitalhumanities.org/dhq/vol/5/3/000106/000106.html},\n        number = {3},\n        urldate = {2013-09-28},\n        author = {Fyfe, Paul},\n        year = {2011},\n        file = {fyfe_digital_pedagogy_unplugged_2011.pdf}\n    }\n\n\nRara vez tendrás que editar esto a mano (aunque puedes hacerlo). En la mayoría de los casos, simplemente exportas el archivo .bib de Zotero o de un gestor de referencias similar. Tomate un tiempo para orientarte en esto. Cada entrada consiste en un tipo de documento, “artículo” (article) en nuestro caso, un identificador único (fyfe_digital_2011) y los metadatos relevantes de título (title), autor (author), etc. Lo que más nos interesa es el identificador (ID) único que sigue inmediatamente al símbolo de llave ( { ) en la primera línea de cada entrada. El ID único es lo que nos permite conectar la bibliografía con el documento principal. Deja este archivo abierto por ahora y regresa a tu archivo principal.md.\n\nEdita la nota a pie de página en la primera línea de tu archivo principal.md para que se vea de una forma parecida a los siguientes ejemplos en los cuales @nombre_título_fecha puede ser reemplazado por uno de los ID únicos de tu archivo proyecto.bib.\n\n\n  Una referencia bibliográfica formateada como ésta se traducirá apropiadamente tanto en un estilo de citación en texto -como en nota a pie- [@nombre_título_fecha, 67].8\n  \"Para citas entrecomilladas, pon la coma afuera de los signos de las comillas\" [@nombre_título_fecha, 67].\n\n\nUna vez que ejecutes el markdown a través de Pandoc, “@fyfe_digital_2011” se ampliará a una citación completa en el estilo que hayas seleccionado. Puedes usar la sintaxis @citacion de cualquier manera que veas que encaja: dentro de las líneas de tu texto o en las notas a pie. Para generar una bibliografía simplemente incluye una sección llamada # Bibliografía al final del documento.\n\nAhora, vayamos de nuevo a nuestro bloque de metadatos en el encabezado de tu documento .md, y especifica el archivo de bibliografía que deberá utilizarse, algo como:\n\n---\ntitle: Flujo de trabajo en texto plano\nauthor: Gabriel García\ndate: 20 de enero de 2014\nbibliography: proyecto.bib\n---\n\n\nEsto le dice a Pandoc que busque tu bibliografía en el archivo proyecto.bib dentro del mismo directorio de tu archivo principal.md. Veamos si esto trabaja. Guarda tu archivo, ve a la ventana de terminal y ejecuta:\n\n$ pandoc principal.docx --filter pandoc-citeproc -o principal.md\n\n\nEl filtro “pandoc-citeproc” compila todas tus etiquetas de citas. El resultado debe ser un archivo de MS Word formateado decentemente. Si tienes instalado LaTeX, conviértelo a .pdf utilizando la misma sintaxis para mejores resultados. No te preocupes si las cosas no aparecen exactamente de la manera que tú quisieras -recuerda que vas a afinar el formato de todo una vez y más tarde, lo más cerca posible del momento de la publicación. Por ahora solamente estamos creando borradores basados en valores por defecto.\n\nCambiar los estilos de citación\n\nEl estilo de citación por defecto en Pandoc es el de Chicago Autor-fecha. Podemos especificar un estilo diferente utilizando una hoja de estilo escrita en “lenguaje de estilo de citación” (CSL por citation style language, otra convención en texto plano utilizada para describir estilos de citas) y que es designado por la extensión de archivo .csl. Afortunadamente, el proyecto CSL mantiene un repositorio de estilos de citaciones comunes, algunas incluso ajustadas a ciertas revistas en específico. Visita http://editor.citationstyles.org/about/ para encontrar el archivo .csl para el estilo Modern Language Association (MLA), descarga el archivo modern-language-association.csl y guárdalo en la carpeta de tu proyecto como mla.csl. Ahora, necesitamos indicarle a Pandoc que utilice la hoja de estilo de MLA en vez de la de Chicago que tiene por defecto. Haremos esto actualizando el encabezado o bloque YAML:\n\n---\ntitle: Flujo de trabajo en texto plano\nauthor: Gabriel García\ndate: 20 de enero de 2014\nbibliography: proyecto.bib\ncsl: mla.csl\n---\n\n\nDespués simplemente utiliza la funcionalidad de Pandoc para transformar tu archivo de markdown a tu formato objetivo (.pdf o .docx):\n\n$ pandoc principal.md --filter pandoc-citeproc -o principal.pdf\n\n\nResumen\n\nAhora debes ser capaz de escribir artículos en Markdown, crear borradores en varios formatos, añadir bibliografías y cambiar estilos de citación de manera sencilla. Un vistazo final al directorio de tu proyecto te mostrará un número de archivos de origen de datos: tu archivo principal.md, el archivo proyecto.bib, el archivo mla.csl, y algunas imágenes. Además de los archivos de origen, deberías ver algunos archivos de salida que creamos durante el tutorial: principal.docx o principal.pdf. Tu carpeta debe verse más o menos de esta manera.\n\n\ttutorial-Pandoc/\n\t\tprincipal.md\n\t\tproyecto.bib\n\t\tmla.csl\n\t\timage.jpg\n\t\tprincipal.docx\n\n\nTrata tus archivos de origen como versiones autorizadas de tu texto y los archivos de salida como impresiones desechables que puedes  generar fácilmente y sobre la marcha con Pandoc. Todas las revisiones deben ir dentro del archivo principal.md. El archivo principal.docx está ahí para la última etapa de limpieza y formato. Por ejemplo, si la revista requiere manuscritos a doble espacio, puedes darle el doble espacio rápidamente en Open Office o Microsoft Word. Pero no gastes demasiado tiempo formando. Recuerda que el manuscrito debe ir despojado de todo cuando va a imprenta. El tiempo dedicado a formar cosas innecesarias puede aprovecharse mejor en pulir la prosa de tu borrador.\n\nRecursos útiles\n\nEn caso de meterte en problemas no hay un mejor lugar para empezar a buscar soluciones que el sitio web de Pandoc de John MacFarlane y la lista de correos afiliada (en inglés). Al menos en dos sitios de tipo “Pregunta y respuesta” puedes encontrar respuestas a preguntas sobre Pandoc: Stack Overflow y Digital Humanities Q&amp;A. Puedes hacer preguntas en vivo en Freenode IRC, #Pandoc channel, frecuentado por un amistoso grupo de asiduos. A medida que aprendas más acerca de Pandoc, puedes explorar una de sus particularidades más poderosa: filtros.\n\nAunque te sugerimos comenzar con un simple editor de texto plano, hay muchas más alternativas (más de 70, de acuerdo con esta entrada de blog a MS Word para trabajar específicamente con Markdown, disponibles en línea y a menudo sin costo. Para las autónomas nos gustan Mou, Write Monkey, y Sublime Text. Varias plataformas web que han surgido recientemente proporcionan interfaces gráficas adecuadas para desarrollar una escritura colaborativa con seguimiento de cambios en las versiones utilizando Markdown. Éstas incluyen: prose.io, Authorea, Penflip, Draft, y StackEdit.\n\nPero el ecosistema no está limitado sólo a editores. Gitit e Ikiwiki soportan escritura en Markdown utilizando Pandoc como compilador. A esta lista se puede agregar una serie de herramientas que generan páginas web estáticas de manera rápida: Yst, Jekyll, Hakyll y bash shell script por el historiador Caleb McDaniel.\n\nFinalmente, se están creando plataformas de publicación enteras basadas en el uso de Markdown. La plataforma de mercado Leanpub puede ser una alternativa interesante al modelo tradicional de publicación y nosotros mismos estamos experimentando con el diseño de una revista académica en GitHub y readthedocs.org (herramientas que suelen utilizarse para técnicas de documentación).\n\n\n  \n    \n      ¡No te preocupes si no entiendes aún esta terminología! &#8617;\n    \n    \n      GitHub. Utiliza la opción “raw” cuando lo veas en GitHub para observar la fuente de Markdown. Los autores queremos agradecer a Alex Gil y sus colegas del Columbia’s Digital Humanities Center, y a los participantes de openLab en el Studio de la Bilioteca Butler por probar el código de este tutorial en diversas plataformas. &#8617;\n    \n    \n      Véase la excelente discusión sobre este tema, por Charlie Stross, en Why Microsoft Word Must Die. &#8617;\n    \n    \n      Considera que la extensión .bib debe estar “vinculada” a Zotero en tu sistema operativo. Esto significa que si haces doble click en un archivo .bib, es probable que Zotero intente abrir el archivo mientras que nosotros queremos abrirlo con un editor de texto. Es posible que en el futuro quieras asociar la extensión .bib a tu editor de texto. &#8617;\n    \n    \n      Ten en cuenta que a menudo el YAML replica algo, aunque no todo, de la funcionalidad (bandera) de la línea de comando. Por ejemplo, los estilos de fuentes pueden pasarse a Pandoc en la forma de pandoc principal.md --mainfont=times -o target.pdf. Sin embargo, preferimos utilizar las opciones de, encabezado YAML siempre cuando sea posible, pues hace la funcionalidad de nuestra línea de comandos más fácil de escribir y recordar. Utilizando una herramienta de control de cambios como Git preservará tus cambios al YAML, mientras lo que escribes en la terminal es más efímero. Consulta la sección de plantillas en el manual de Pandoc (man pandoc) para ver la lista de variables YAML disponibles. &#8617;\n    \n    \n      No hay buenas soluciones para traducir a MS Word desde LaTeX. &#8617;\n    \n    \n      Es una buena idea crearse el hábito de no usar espacios en el nombre de una carpeta o un archivo. Los guiones y guiones bajos en vez espacios en los nombres de archivo aseguran una compatibilidad perdurable entre plataformas cruzadas. &#8617;\n    \n    \n      Gracias a @njbart por la corrección. En respuesta a nuestra sugerencia original: Alguna frase que necesita citación.^[@fyfe_digital_2011 argues that too.] él escribe: “This is not recommended since it keeps you from switching easily between footnote and author-date styles. Better use the [corrected] (no circumflex, no final period inside the square braces, and the final punctuation of the text sentence after the square braces; with footnote styles, pandoc automatically adjusts the position of the final punctuation).” &#8617;\n    \n  \n\n\nEn este tutorial aprenderás lo básico de Markdown—una sintaxis de marcado para texto plano que es fácil de leer y de escribir así como Pandoc, una herramienta de línea de comandos que convierte el texto plano en varios tipos de archivos bellamente formateados: PDF, .docx, HTML, LaTeX, presentaciones de diapositivas y más.\n\n"
  },


  {
    "id": 16,
    "url": "http://localhost:4000/es/lecciones/instalacion-linux",
    "title": "Creación de un entorno de desarrollo integrado para Python (Linux)",
    "body": "\nCreación de un entorno de desarrollo integrado para Python (Linux)\n\nContenidos\n\n\n  Respalda tu computadora\n  Instalar Python v.3\n  Crea un directorio\n  Instala Komodo Edit\n  Haz un comando de ejecución de Python en Komodo Edit\n  Paso 2 – “Hola Mundo” en Python\n  Interactuar con el intérprete de comandos (shell) de Python\n\n\nGracias a John Fink por proveer las bases de esta sección. Estas instrucciones son para Ubuntu 18.04 LTS, pero deben funcionar para cualquier distribución y APT como Debian Linux Mint, siempre y cuando tengas instalado sudo.\n\nRespalda tu computadora\n\nSiempre es importante asegurarse de tener copias de seguridad hechas de modo regular y, sobre todo, recientes. Este es un buen consejo de por vida y no se limita a los momentos en los que estés dedicado a programar.\n\nInstalar Python v.3\n\n\n  Abre terminal (Dash Home, entonces teclea Terminal, luego haz clic en el icono de Terminal).\n  En Terminal teclea: sudo apt-get install python3\n  Escribe tu contraseña de administrador del sistema y entonces teclea Y  para finalizar la instalación. Ten en cuenta que probablemente Python 3 esté instalado previamente en el sistema, así que no entres en pánico si Ubuntu te lo dice.\n\n\nCrea un directorio\n\nGuardarás tus programas de Python en un directorio. Puede ser donde quiera que te guste, pero probablemente lo mejor es colocarlo en el directorio de Home. Algo como esto en la ventana abierta de tu terminal hará el truco:\n\ncd ~\nmkdir programming-historian\n\n\nInstala Komodo Edit\n\nKomodo Edit es un editor de texto libre y de código abierto, pero tienes muchas opciones de editores de texto si lo prefieres. Puedes descargar desde el sitio web de Komodo Edit. Una vez que lo has descargado, ábrelo con el package manager de Ubuntu, extraerlo en el directorio de Home y seguir las instrucciones de instalación. Si estás siguiendo estas instrucciones e instalado Komodo Edit, abre la carpeta de Home, ve al directorio Komodo-Edit-11/bin  y haz clic en Komodo. Puedes también hacer clic con el botón derecho del mouse sobre el icono de Komodo en el lanzador (launcher) , y hacer clic en “Lock to Launcher” para tenerlo de manera permanente en la barra del lanzador.\n\nHaz un comando de ejecución de Python en Komodo Edit\n\n\n  En Komodo Edit, haz clic en el icono de engranaje bajo Toolbox y selecciona New Command\n  En el campo superior escribe Run Python File\n  En el campo ‘Command’ escribe %(python3) %f, Haz clic en OK al pie de la ventana de insertar comando.\n\n\nPaso 2 – “Hola Mundo” en Python\n\nEs tradicional que para comenzar a programar en un nuevo lenguaje tratemos de crear un programa que despliegue la frase “Hola Mundo” y termine. Vamos a mostrar cómo hacer esto en Python y en HTML.\n\nPython es un buen lenguaje de programación para principiantes gracias a que es un lenguaje de programación de muy alto nivel. Es posible, en otras palabras escribir programas cortos que realizan una gran cantidad de procesos. Entre más corto es el programa, lo más probable es que todo quepa en una pantalla y que sea más fácil hacer un seguimiento de todo en tu mente.\n\nPython es un lenguaje de programación “interpretado”. Esto significa que hay un programa de cómputo especial (conocido como intérprete) que sabe cómo seguir las instrucciones escritas en este lenguaje. Una manera de usar el intérprete es guardar todas tus instrucciones en un archivo y luego ejecutar el intérprete sobre ese archivo. El archivo que contiene instrucciones de lenguaje de programación es conocido como programa. El intérprete ejecutará cada una de las instrucciones que le hayas dado en tu programa y luego se detendrá. Vamos a intentar esto.\n\nEn tu editor de texto crea un nuevo archivo y escribe el siguiente programa de dos líneas y guárdalo en tu carpeta programming-historian con el nombre hola-mundo.py.\n\n# hola-mundo.py\nprint('hola mundo')\n\n\nEl editor de texto que seleccionaste utilizar debe tener un botón Run que te permitirá ejecutar tu programa. Si todo funciona bien, deberás ver algo como sigue (El ejemplo es como se ve en Komodo Edit.):\n\n% include figure.html caption=”hello world en Komodo Edit en Linux” filename=”komodo-edit-output-linux.png” %}\n\nInteractuar con el intérprete de comandos (shell) de Python\n\nOtra manera de interactuar con un intérprete es usando lo que se conoce como shell o intérprete de comandos. Se puede escribir en una declaración y oprimir la tecla Enter, y el shell responderá a tus comandos. Utilizar un shell es una excelente forma de comprobar que la construcción de tus declaraciones es adecuada al asegurarte que hace lo que tu piensas que debería hacer.\n\nPuedes ejecutar un shell de Python abriendo Terminal. Para Linux ve a  Aplicaciones -&gt; Accesorios -&gt; Terminal y haz lo mismo. Frente al prompt del intérprete de comandos escribe:\n\npython\n\n\nOprime entonces la tecla Enter. Con ello aparecerá el prompt de Python lo que significa que puedes usar ahora comandos de Python en el shell. Ahora escribe:\n\nprint('Hola Mundo')\n\nOprime la tecla Enter. La computadora responderá con:\n\nHola Mundo\n\n\nCuando queramos representar la interacción con el intérprete de comandos usaremos -&gt; para indicar la respuesta del shell a tus comandos, como se muestra inmediatamente:\n\nprint('Hola Mundo')\n-&gt; Hola Mundo\n\n\nEn la pantalla de tu computadora aparecerá de esta manera:\n\n\n    \n\n    hello world in Terminal on Linux\n\n\n\n\nAhora que tú y tu computadora están en marcha y funcionando, podemos movernos hacia unas tareas algo más interesantes. Si estás trabajando de manera ordenada las lecciones de Python, te sugerimos que pases ahora a la lección Para entender páginas web y HTML.\n\n\nEste tutorial te ayudará a configurar un entorno de desarrollo integrado para Python en un computador con el sistema operativo de Linux.\n\n"
  },


  {
    "id": 17,
    "url": "http://localhost:4000/es/lecciones/instalacion-mac",
    "title": "Creación de un entorno de desarrollo integrado para Python (Mac)",
    "body": "\nCreación de un entorno de desarrollo integrado para Python (Mac)\n\nContenidos\n\n\n  Haz respaldo (copia de seguridad) de toda tu computadora\n  Instalar Python v.3\n  Creación de un directorio\n  Beautiful Soup\n  Instalar Komodo Edit    \n      Inicia Komodo Edit\n      Configuración de Komodo Edit\n    \n  \n  Paso 2 – “Hola Mundo” en Python    \n      Interactuar con el intérprete de comandos (shell) de Python\n    \n  \n\n\nHaz respaldo (copia de seguridad) de toda tu computadora\n\nLos usuarios de Mac pueden aprovechar Time Machine para esta labor.\n\nInstalar Python v.3\n\nA partir de enero 2020, Python versión 2 dejará de recibir actualizaciones y la versión 3 será la única desarrollada activamente. Ya que Mac OS X tiene preinstalado Python v.2., podrás continuar utilizando los programas que todavía dependen de esa versión pero necesitarás descargar la versión 3 para seguir las lecciones que encontrarás en The Programming Historian. Puedes corroborar si tu Mac cuenta con Python versión 3 instalado abriendo Terminal en el directorio ´'/Aplicaciones/Utilidades'´. En la ventana de Terminal escribe ´which Python3´ seguido de Enter. Al oprimir la tecla Enter se envía el comando a la computadora cuando se utiliza Terminal. Si ves que en Terminal aparece: ´'/usr/bin/python3'´ o algo por el estilo que contiene la palabra ´python3 y un manojo de barras oblicuas, puedes tener la seguridad de que tu equipo y sistema lo tienen. Si no fuese así, cierra Terminal y descarga la última versión estable del lenguaje de programación Python (v.3.8 es la más actualizada hasta noviembre de 2019), e instálalo siguiendo las instrucciones del sitio web de Python.\n\nCreación de un directorio\n\nPara mantener organizados los datos en tu equipo, lo mejor es crear un directorio o carpeta en tu computadora dedicado exclusivamente a almacenar todos los programas que escribas con Python (por ejemplo: programming-historian y manténlo en el lugar de tu disco duro que mejor te acomode).\n\nBeautiful Soup\n\nDescarga la más reciente versión de Beautiful Soup y cópiala en el directorio o carpeta donde vas a alojar tus propios programas. Beautiful Soup es una librería (una colección de código previamente escrito) que permite que los programas escritos con Python puedan seccionar más fácilmente páginas web en partes significativas que pueden seguir procesándose después.\n\nInstalar Komodo Edit\n\nKomodo Edit es un editor de texto que sirve para programación, es software libre y de código fuente abierto. Pero como se indicó en la introducción, se pueden utilizar otras opciones de editores de texto. Algunos colegas prefieren un programa llamado TextWrangler. El que decidas utilizar queda a gusto tuyo, pero en aras de conservar la coherencia en estas lecciones se utilizará aquí como ejemplo Komodo Edit. Puedes descargar una copia libre del editor desde el sitio web de Komodo Edit. Se puede descargar desde el sitio web de Komodo e instalar fácilmente desde el archivo .DMG.\n\nInicia Komodo Edit\n\nDeberá verse algo por el estilo:\n\n\n    \n\n    Komodo Edit en una Mac\n\n\n\n\nSi no está visible el panel de Caja de Herramientas (Toolbox) a la derecha de la pantalla, es necesario activarlo en el menú correspondiente: View-&gt;Tabs &amp; Sidebars -&gt;Toolbox. No importa si el panel de proyecto está abierto o no. Conviene, como siempre con nuevo software, dedicar un tiempo a familiarizarse con los diversos menús y barras de herramientas. El archivo de ayuda es bastante bueno.\n\nConfiguración de Komodo Edit\n\nAhora bien, una vez descargado e instalado el editor es necesario configurarlo para que puedas correr los programas de Python. En la ventana de la derecha (caja de herramientas o Toolbox) hay que hacer clic en el icono de engranaje y seleccionar “New Command…” Esta acción abre una nueva ventana de diálogo. Ahí se deberá renombrar como “Ejecutar Python”. En el campo activo “Command” deberás escribir:\n\n%(python) %f\n\n\nY en el campo activo “Start in” debes escribir:\n\n%D\n\nUna vez configurado haz clic en OK, con lo cual habrá un nuevo botón para ejecutar Python en el panel de la caja de herramientas (Toolbox).\n\nPaso 2 – “Hola Mundo” en Python\n\nComo la mayoría sabe, es tradicional que para comenzar a programar en un nuevo lenguaje tratemos de crear un programa que despliegue la frase “Hola Mundo” y termine. Vamos a mostrar cómo hacer esto en Python y en HTML.\n\nPython es un buen lenguaje de programación para principiantes gracias a que es un lenguaje de programación de muy alto nivel, es decir, expresa el algoritmo de una manera muy parecida a la capacidad cognitiva humana en vez de la capacidad ejecutora de las computadoras (lenguaje de bajo nivel). En otras palabras (y entre otras cosas), en él es posible escribir programas cortos que realizan una gran cantidad de procesos. Entre más corto es el programa, lo más probable es que todo quepa en una pantalla y que sea más fácil hacer un seguimiento comprehensivo de todo en tu mente.\n\nTodos los lenguajes que estaremos utilizando son capaces de ser interpretados en términos informáticos. Es decir, que existe un programa especial en la computadora (conocido como intérprete) que sabe exactamente cómo seguir las instrucciones escritas en dicho lenguaje. Una manera de utilizar un intérprete es guardando todas las instrucciones en un archivo para luego ejecutar el intérprete sobre él. El intérprete ejecutará cada una de las instrucciones que le hayas dado en tu programa y luego se detendrá. Vamos a intentarlo con un ejemplo.\n\nEn tu editor de texto crea un nuevo archivo y escribe el siguiente programa de dos líneas y guárdalo en tu carpeta ‘programming-historian con el nombre hola-mundo.py\n\n# hola-mundo.py\nprint('hola mundo')\n\nEl editor de texto que seleccionaste debe tener un botón “run” que te permitirá ejecutar tu programa. Por ejemplo, si estás utilizando TextWrangler, haz clic en el botón “#!” para ejecutarlo. Si todo funciona bien (es posible que no, con lo cual habrá que revisar las diversas instalaciones y configuraciones), deberás ver algo como sigue:\n\n\n    \n\n    ‘Hello World’ en Python en una Mac\n\n\n\n\nInteractuar con el intérprete de comandos (shell) de Python\n\nOtra manera de interactuar con un intérprete es usando lo que se conoce como shell o intérprete de comandos. Se puede escribir en una declaración y oprimir la tecla Enter, y el shell responderá a tus comandos. Utilizar un shell es una excelente forma de comprobar que la construcción de tus declaraciones es adecuada al asegurarte que hace lo que tu piensas que debería hacer. Esto se puede hacer de maneras un tanto distintas en las diversas plataformas (Mac, Windows o Linux).\n\nPuedes ejecutar un shell de Python iniciando Terminal. En la Mac, abre el Finder, haz doble click en  Aplicaciones -&gt; Utilidades -&gt; Terminal. Escribe “python” en la ventana que se abre en tu pantalla y oprime la tecla Enter. Ante el shell prompt de Python escribe:\n\nprint('Hola Mundo')\n\n\nOprime la tecla Enter. La computadora responderá con:\n\nHola Mundo\n\n\nCuando queramos representar gráficamente la interacción con el intérprete de comandos usaremos -&gt; para indicar la respuesta del shell a tus comandos, como se muestra inmediatamente:\n\nprint('Hola Mundo')\n-&gt; Hola Mundo\n\n\nEn la pantalla de tu computadora aparecerá de esta manera:\n\n\n    \n\n    Intérprete de comandos de Python en Terminal de Mac\n\n\n\n\nPara salir del shell de Python en Terminal debes escribir en el prompt shell:\n\nexit()\n\n\nAhora que tú y tu computadora están en marcha y funcionando, podemos movernos hacia unas tareas algo más interesantes. Si estás trabajando de manera ordenada las lecciones de Python, te sugerimos que pases ahora a la lección Para entender páginas web y HTML.\n\n\nEste tutorial te ayudará a configurar un entorno de desarrollo integrado para Python en un computador con el sistema operativo de Apple.\n\n"
  },


  {
    "id": 18,
    "url": "http://localhost:4000/es/lecciones/instalacion-windows",
    "title": "Creación de un entorno de desarrollo integrado para Python (Windows)",
    "body": "\nCreación de un entorno de desarrollo integrado para Python (Windows)\n\nContenidos\n\n\n  Respalda toda tu computadora.\n  Instalar Python v.3\n  Creación de un directorio\n  Instalar Komodo Edit\n  Inicia Komodo Edit    \n      Configuración de Komodo Edit\n    \n  \n  Paso 2 – “Hola Mundo” en Python\n  Interactuar con el intérprete de comandos (shell) de Python\n\n\nRespalda toda tu computadora.\n\nSiempre es importante asegurarse de tener copias de seguridad hechas de modo regular y, sobre todo, recientes. Este es un buen consejo de por vida y no se limita a los momentos en los que estés dedicado a programar.\n\nInstalar Python v.3\n\nDirígete al sitio web de Python, descarga la última versión estable del lenguaje de programación Python (3.8 es la correspondiente a noviembre de 2019), e instálalo siguiendo las instrucciones del sitio web de Python.\n\nCreación de un directorio\n\nPara mantener organizados los datos en tu equipo, lo mejor es crear un directorio o carpeta en tu computadora dedicado exclusivamente a almacenar todos tus programas que escribas con Python (i.e, programming-historian) y mantenlo en el lugar de tu disco duro que mejor te acomode.\n\nInstalar Komodo Edit\n\nKomodo Edit es un editor de texto libre y de código abierto, pero puedes utilizar varias opciones de editores de texto si quieres utilizar otros programas. Puedes descargar una copia desde el sitio web de Komodo Edit.\n\nInicia Komodo Edit\n\nSe deberá ver algo parecido a la siguiente ventana:\n\n\n    \n\n    Komodo Edit en Windows\n\n\n\n\nSi no está visible el panel de Caja de Herramientas (Toolbox) de la derecha, es necesario activarlo en el menú correspondiente. Selecciona View -&gt; Tabs -&gt; Toolbox. No importa si el panel del proyecto está abierto o no. Tómate un tiempo para familiarizarte con el diseño del Komodo Editor. El archivo de ayuda es bastante bueno.\n\nConfiguración de Komodo Edit\n\nAhora es necesario configurarlo para que puedas correr los programas de Python.\n\n1 .  Selecciona Edit -&gt; Preferences. Esto abrirá una nueva ventana de diálogo. En “Languages” y “Python 3” selecciona “Browse” y navega hasta C:\\Users\\tunombredeusuario\\AppData\\Local\\Programs\\Python\\Python38-32)\nSi se ve más o menos así, oprime OK:\n\n\n    \n\n    Seleccionar Python como intérprete por defecto.\n\n\n\n\n2 .  Enseguida en la sección  “Preferences” selecciona Internacionalization. Selecciona Python del menú despegable que se llama Language-specific Default Encoding y asegúrate que UTF-8 esté seleccionado como el método de codificación por defecto.\n\n\n    \n\n    Configurar lenguaje a UFT-8.\n\n\n\n\nEnseguida selecciona Toolbox -&gt; Add -&gt; New Command . Esto abrirá una nueva ventana de diálogo en la que deberás renombrar tu comando como Run Python. Debajo de Command teclea:\n\n%(python3) %f\n\nSi olvidas este comando, Python se quedará colgado porque no estará recibiendo las órdenes (input).\n\nEl campo activo ‘Start in’ debes escribir:\n\n%D\n\n\nSi se ve así, oprime OK:\n\n\n    \n\n    Configuración del comando ‘Run Python’.\n\n\n\n\n\n    \n\n    Configuración del comando ‘Run Python Start’.\n\n\n\n\nTu nuevo comando debe aparecer en el panel de la caja de herramientas (Toolbox). Probablemente deberás reiniciar tu computadora para completar el paso antes de que Python trabaje con Komodo Edit.\n\nPaso 2 – “Hola Mundo” en Python\n\nEs tradicional que para comenzar a programar en un nuevo lenguaje tratemos de crear un programa que despliegue la frase “Hola Mundo” y termine. Vamos a mostrar cómo hacer esto en Python y en HTML.\n\nPython es un buen lenguaje de programación para principiantes gracias a que es un lenguaje de programación de muy alto nivel. Es posible, en otras palabras, escribir programas cortos que realizan una gran cantidad de procesos. Entre más corto es el programa, lo más probable es que todo quepa en una pantalla y que sea más fácil hacer un seguimiento de todo en tu mente.\n\nPython es un lenguaje de programación “interpretado”. Esto significa que hay un programa de cómputo especial (conocido como intérprete) que sabe cómo seguir las instrucciones escritas en este lenguaje. Una manera de usar el intérprete es guardar todas tus instrucciones en un archivo y luego ejecutar el intérprete sobre ese archivo. El archivo que contiene instrucciones de lenguaje de programación es conocido como programa.  El intérprete ejecutará cada una de las instrucciones que le hayas dado en tu programa y luego se detendrá. Vamos a intentar esto.\n\nEn tu editor de texto crea un nuevo archivo y escribe el siguiente programa de dos líneas y guárdalo en tu carpeta programming-historian con el nombre hola-mundo.py.\n\n# hola-mundo.py\nprint('hola mundo')\n\n\nEl editor de texto que seleccionaste debe tener un botón Run  que te permitirá ejecutar tu programa. Si todo funciona bien, deberás ver algo como sigue (El ejemplo es como se ve en Komodo Edit. Da un clic en la imagen para ver una copia en tamaño completo):\n\n\n    \n\n    Hola Mundo en Komodo Edit\n\n\n\n\nInteractuar con el intérprete de comandos (shell) de Python\n\nOtra manera de interactuar con un intérprete es usando lo que se conoce como shell o intérprete de comandos. Se puede escribir en una declaración y oprimir la tecla Enter, y el shell responderá a tus comandos. Utilizar un shell es una excelente forma de comprobar que la construcción de tus declaraciones es adecuada al asegurarte que hace lo que tu piensas que debería hacer. Esto se puede hacer de maneras un tanto distintas en las diversas plataformas (Mac, Windows o Linux).\n\nPuedes ejecutar un shell de Python haciendo doble clic en el archivo ejecutable python.exe. Si instalaste la más reciente versión de Python 3.8 (la más reciente para noviembre de 2019), probablemente el archivo .exe  esté localizado en el directorio C:\\Users\\tunombredeusuario\\AppData\\Local\\Programs\\Python\\Python38-32. En la ventana del intérprete de comandos (“Símbolo de Sistema”), escribe:\n\nprint('Hola Mundo')\n\n\nOprime la tecla Enter. La computadora responderá con:\n\nHola Mundo\n\nCuando queramos representar la interacción con el intérprete de comandos usaremos -&gt; para indicar la respuesta del shell a tus comandos, como se muestra inmediatamente:\n\nPrint('Hola Mundo')\n-&gt; Hola Mundo\n\n\nEn la pantalla de tu computadora aparecerá de esta manera:\n\n\n    \n\n    Python Shell en Windows\n\n\n\n\nAhora que tú y tu computadora están en marcha y funcionando, podemos movernos hacia unas tareas algo más interesantes. Si estás trabajando de manera ordenada las lecciones de Python, te sugerimos que pases ahora a la lección Para entender páginas web y HTML.\n\n\nEste tutorial te ayudará a configurar un entorno de desarrollo integrado para Python en un computador con el sistema operativo de Windows.\n\n"
  },


  {
    "id": 19,
    "url": "http://localhost:4000/es/lecciones/instalar-modulos-python-pip",
    "title": "Instalar módulos de Python con pip",
    "body": "\nInstalar módulos de Python con pip\n\nContenidos\n\n\n  Objetivos de la lección\n  Introducir módulos    \n      Instrucciones para Mac y Linux\n      Instrucciones para Windows\n    \n  \n  Instalar módulos de Python\n\n\nObjetivos de la lección\n\nEsta lección muestra cómo descargar e instalar módulos de Python. Hay muchas maneras de instalar módulos externos, pero para esta lección vamos a utilizar un programa llamado pip. El programa pip viene instalado por defecto en Python 2.7.9 y versiones más nuevas. Este tutorial es muy útil para cualquiera que utilice versiones antiguas de Python (lo que todavía es común).\n\nIntroducir módulos\n\nUna de las principales ventajas de utilizar Python es el número de librerías o bibliotecas de código excelentes que están amplia y fácilmente disponibles y que te pueden ahorrar escribir mucho código, o simplemente realizar una tarea particular de la manera más sencilla (como crear un archivo CSV o recopilar información de una página web de forma automática -webscraping). Cuando buscas en Google soluciones a problemas, encuentras ejemplos de código que utilizan librerías de las cuales no habías escuchado hablar antes. ¡No tengas miedo! Una vez que estas bibliotecas están instaladas en tu computadora, puedes utilizarlas importándolas al principio de tu código. Puedes importar tantas librerías como quieras, por ejemplo:\n\nimport csv\nimport requests\nimport kmlwriter\nimport pprint\n\n\nPara los nuevos usuarios de Python puede resultar un tanto intimidante descargar e instalar por primera vez módulos externos. Hay muchas maneras de hacerlo (aumentando así la confusión); esta lección explica una de las formas más sencillas y la más común de instalar módulos de Python.\n\nEl objetivo aquí es instalar software en tu computadora que puede descargar e instalar automáticamente los módulos de Python. Utilizaremos el programa llamado pip.\n\n\n  Nota: En Python 3.4, pip está incluido en la instalación por defecto. Hay muchas razones por las que no debes tener todavía esta versión; en caso de que no la tengas, estas instrucciones deben ayudar.\n\n\nInstrucciones para Mac y Linux\n\nSegún la documentación de pip, podemos descargar una secuencia de comandos (script) Python para instalarlo. En una Mac o Linux debemos instalar pip con línea de comandos usando curl, que es una orden que descarga el script de Perl y que permite la instalación de pip.\n\ncurl -O https://bootstrap.pypa.io/get-pip.py\n\n\nUna vez que descargaste el archivo get-pip.py, necesitas ejecutarlo con el intérprete de Python. Sin embargo, si intentas ejecutar el script con Python de esta manera:\n\npython get-pip.py\n\n\nLa secuencia de comandos del script seguramante falle. Esto se debe a que no tiene permisos para actualizar ciertos directorios en tu sistema de archivos para evitar que scripts aleatorios puedan cambiar archivos importantes e instalarte virus. En este caso, y en todos los casos en que necesites dar permiso a un script seguro para escribir en las carpetas del sistema, puedes utilizar el comando sudo (abreviatura de “Super User DO”) delante del comando Python, como:\n\nsudo python get-pip.py\n\n\nInstrucciones para Windows\n\nComo en los sistemas operativos anteriores, la manera más fácil de instalar pip es utilizando el programa de Python llamado get-pip.py, que puedes descargar aquí. Cuando abres este enlace te puede asustar el revoltijo horrible que te espera. Por favor, no te espantes. Solamente usa tu navegador para guardar esta página con su nombre por defecto, que es get-pip.py. Guarda el archivo en tu directorio de Python para que sepas dónde encontrarlo.\n\nUna vez guardes el archivo, necesitas ejecutarlo, lo cual puedes hacer de dos maneras. Si prefieres utilizar tu intérprete de Python, solamente haz click con el botón derecho sobre el archivo get-pip.py y selecciona “abrir con” y luego selecciona el intérprete de Python que suelas utilizar.\n\nSi prefieres instalar pip utilizando la terminal de línea de comandos, navega al directorio en el que pusiste Python y obtén get-pip.py. Para este ejemplo asumimos el directorio python27, así que usa el comando C:\\&gt;cd python27. Una vez que estés en este directorio, ejecuta el comando:\n\npython get-pip.py to install pip\n\n\nSi buscas más información consulta la página de StackOverflow que parece estar actualizada de manera regular.\n\nInstalar módulos de Python\n\nAhora que ya tienes pip, resultará fácil instalar los módulos de Python dado que el programa hace todo el trabajo por ti. Cuando encuentres un módulo que quieras utilizar, generalmente tendrá documentación o instrucciones de instalación que incluyan el comando pip necesario, como:\n\npip install requests\npip install beautifulsoup4\npip install simplekml\n\n\nComo ya se dijo, recuerda que probablemente necesitarás ejecutar pip con sudo en Mac y Linux (no en Windows).\n\nsudo pip install requests\n\n\n¡Listo para trabajar!\n\n\nHay muchas maneras de instalar módulos externos; este tutorial explica uno de los métodos más comunes utilizando un programa llamado pip.\n\n"
  },


  {
    "id": 20,
    "url": "http://localhost:4000/es/lecciones/intro-a-google-maps-y-google-earth",
    "title": "Introducción a Google Maps y Google Earth\n",
    "body": "\nIntroducción a Google Maps y Google Earth\n\n\nContenidos\n\n\n  Google Maps    \n      Comenzar\n      Crear capas de vectores\n      Compartir tu mapa personalizado\n    \n  \n  Google Earth\n  KML: archivos de Keyhole Markup Language\n  Agregar mapas históricos escaneados\n\n\nGoogle Maps\n\nGoogle My Maps y Google Earth son una buena manera de comenzar\na crear mapas digitales. Con una cuenta de Google puedes crear y editar\nmapas personales haciendo clic en Mis Sitios.\n\nMy Maps te permite elegir entre diferentes mapas de base (incluyendo los\nhabituales satelital, físico y estándar) y agregar puntos, líneas y polígonos.\nTambién es posible importar datos de una hoja de cálculos si tienes columnas\ncon información geográfica (esto es, longitudes y latitudes o nombres de\nlugares). Esto automatiza una tarea que solía ser tediosa conocida como\ngeocodificación. Esta no es sólo una de las formas más sencillas de comenzar a\ntrazar tu información histórica en un mapa, sino que también ofrece el poder\ndel motor de búsqueda de Google. A medida que vayas leyendo acerca de lugares\ndesconocidos en documentos históricos, artículos de revistas o libros, puedes\nbuscarlos con Google Maps, marcando múltiples ubicaciones y de este modo\nexplorar cómo se relacionan geográficamente entre sí. Tus mapas personales son\nalmacenados por Google (en su nube), lo cual quiere decir que podrás acceder a\nellos desde cualquier computadora con una conexión a internet. Puedes mantenerlos\nprivados o incluirlos en tu sitio web o blog. Por último, tienes la opción de\nexportar tus puntos, líneas y polígonos como archivos KML y abrirlos en Google\nEarth o Quantum GIS.\n\nComenzar\n\n\n  Abre tu navegador favorito.\n  Ingresa a Google My Maps.\n  Identifícate con tu cuenta de Google si no estás conectado ya (si es\nnecesario, sigue las sencillas instrucciones para crear una cuenta).\n\n\n\n    \n\n    Figura 1\n\n\n\n\n\n  Haz clic en el signo de interrogación en la esquina inferior derecha y luego\nen “Visita guiada” para una introducción de cómo funciona My Maps.\n\n\n\n    \n\n    Figura 2\n\n\n\n\n\n  \n    En la esquina superior izquierda aparece un menú con el título “Mapa sin\nnombre”. Haciendo clic en el título puedes renombrarlo como “Mi mapa de\npruebas” o lo que prefieras.\n  \n  \n    Luego está la barra de búsqueda.\nIntenta buscar una ubicación de tu proyecto de investigación actual. Luego,\nhaz clic en la ubicación y agrégala a tu mapa eligiendo “Agregar al\nmapa”. Éste es el método más sencillo para agregar puntos a tu nuevo mapa.\nPrueba a buscar algunos nombres de lugares históricos que ya no existen\n(como Berlin o Constantinople en Ontario). Obtendrás resultados mezclados,\nen los cuales Google a menudo identifica correctamente la ubicación pero\ntambién ofrece alternativas incorrectas. Esto es algo importante a tener\nen cuenta al crear una hoja de cálculos. Normalmente es preferible utilizar\nlos nombres modernos de los lugares para evitar el riesgo de que Google elija\nla Constantinopla equivocada.\n  \n\n\n\n    \n\n    Figura 3\n\n\n\n\n\n    \n\n    Figura 4\n\n\n\n\n\n  Luego, puedes importar un set de datos. Haz clic en “Importar” debajo de\n“Capa sin título”.\n\n\n\n    \n\n    Figura 5\n\n\n\n\n\n  Se abrirá una nueva ventana que te dará la opción de importar un archivo\nCSV (valores separados por coma), un XLSX (Microsoft Excel), un KML\n(formato de archivo para datos geográficos de Google) o GPX (un formato de\narchivo común para GPS). Los primeros dos son formatos comunes de hojas de\ncálculo. CSV es simple y universal y XLSX es el formato de MS Excel.\nTambién puedes utilizar una hoja de cálculo de Google a través de tu cuenta\nde Drive.\n\n\n\n    \n\n    Figura 6\n\n\n\n\n\n  A continuación, descarga el\nArchivo CSV del Suministro global de grasa de Reino Unido\ny guárdalo en tu computadora. Si abres el archivo en Excel u otro programa\nde hojas de cálculo, encontrarás un set de datos sencillo de dos columnas\ncon una lista de diferentes tipos de grasas con los lugares asociados. Estos\ndatos fueron construidos utilizando tablas de importaciones británicas\nde 1896.\n\n\n\n    \n\n    Figura 7\n\n\n\n\n\n  Arrastra el archivo al recuadro provisto por Google Maps.\n  Te pedirá que indiques qué columna debe utilizar Google para colocar\nlas marcas de posición. Elige “Lugar”.\n\n\n\n    \n\n    Figura 8\n\n\n\n\n\n  Luego, te solicitará que que elijas qué columna utilizar para\nlos marcadores. Elige “Producto”.\n  Ahora deberías tener un mapa global de los mayores exportadores de grasa a\nGran Bretaña a mediados de la década de 1890.\n\n\n\n    \n\n    Figura 9: Clic para ver imagen en tamaño completo\n\n\n\n\n\n  A continuación puedes explorar los datos en mayor detalle y modificar el\nEstilo para distinguir entre tipos diferentes de grasas.\n  Haz clic en “Estilo uniforme”, debajo de la etiqueta “Suministro global de\ngrasas de Reino Unido” y elige la opción “Estilo por columna de datos:\nProducto”. A la izquierda, la leyenda mostrará la cantidad de ocurrencias de\ncada estilo entre paréntesis, por ejemplo: “Semillas de lino (4)”.\n\n\n\n    \n\n    Figura 10\n\n\n\n\n\n    \n\n    Figura 11\n\n\n\n\n\n  Sigue jugando con las opciones.\n  Esta funcionalidad es una herramienta poderosa para mostrar sets de datos\nhistóricos. Sin embargo, tiene limitaciones, porque Google Maps sólo importa\nlas primeras 100 líneas de una hoja de cálculo. Por el momento sólo permite\nincluir hasta tres sets de datos en un mapa, es decir, un máximo de 300\nitems.\n\n\n\n    \n\n    Figura 12\n\n\n\n\nCrear capas de vectores\n\nTambién puedes crear nuevas capas del mapa (conocidas formalmente como capas\nde vectores). Las capas de vectores son uno de los componentes principales del\nmapeo digital (incluido SIG). Sencillamente, son puntos, líneas o polígonos\nutilizados para representar características geográficas. Los puntos permiten\nidentificar y etiquetar ubicaciones clave, las líneas se usan\na menudo para calles o vías ferroviaras, y los polígonos te permiten representar\náreas (campos, edificios, distritos, etc.). En Google Maps funcionan del mismo\nmodo en que lo hacen en SIG. La mayor restricción es que sólo se puede agregar\nuna cantidad limitada de información a las tablas de la base de datos asociadas\ncon puntos, líneas o polígonos. Esto se convierte en una dificultad a medida que\ncrece tu investigación con mapas digitales, pero no es un problema cuando estás\ncomenzando. En Google Maps puedes agregar un marcador, un texto de descripción\ny enlaces a un sitio web o una foto. Encontrarás más información acerca\nde cómo crear vectores históricos en un SIG completo en\nCreating New Vector Layers in QGIS 2.0.\n\n\n  Para agregar una capa puedes utilizar la que ya ha sido creada con el\nnombre “Capa sin título”, haciendo clic en ella y renombrándola a “Capa 1”.\nO bien, puedes crear otra nueva: haz clic en el botón de “Agregar capa” y\nse creará una nueva “Capa sin título” que podrás renombrar como “Capa 2”.\nDebería verse así:\n\n\n\n    \n\n    Figura 13\n\n\n\n\n\n  Fíjete que a la izquierda de la capa hay una casilla de verificación:\nal desmarcarla se desactiva una capa (es decir, deja de verse en el mapa) y\nsu información. Desmarca la capa de “Suministro global del grasa de Reino\nUnido” y haz clic en Capa 1.\n  \n    Antes de agregar capas de vectores debemos considerar qué mapa base\nutilizar. Al final de la ventana del menú hay una línea que dice “Mapa\nbase”. Un mapa base es uno que muestra información de fondo como rutas,\nfronteras, accidentes geográficos, etc., sobre el cual se pueden ubicar\ncapas con distintos tipos de información espacial. Google Maps te permite\nelegir entre una variedad de mapas base, dependiendo del tipo de mapa que\ndesées crear. Las imágenes de satélite se están convirtiendo en un formato\nestándar para el mapa base, pero tienen mucha información y pueden restarle\nvalor a otros aspectos del mapa que uno quiera destacar. Hay algunas\nalternativas sencillas como “Físico claro” o incluso “Político claro”, si\nnecesitas las divisiones políticas.\n  \n  \n    Haz clic en la flecha a la izquierda de “Mapa base” en el menu. Se abrirá\nun submenú para elegir entre diferentes tipos de mapas base. Elige\n“Satélite”.\n  \n  Comienza agregando algunos marcadores (el equivalente de Google de un punto).\nHaz clic en el botón de agregar marcadores debajo de la barra de búsqueda en\nla parte superior de la ventana y, a continuación, haz clic en el lugar del\nmapa donde quieres que aparezca el marcador.\n\n\n\n    \n\n    Figura 14\n\n\n\n\n\n  Aparecerá un recuadro para etiquetar el marcador y agregar una descripción\nen un campo de texto. Agregamos Charlottetown y anotamos en la descripción\nque fue fundada en 1765.\n\n\n\n    \n\n    Figura 15\n\n\n\n\n\n  Agrega algunos puntos más, incluyendo etiquetas y descripciones.\n\n\n\n  Verás que tu marcador ahora aparece bajo “Capa 1” a la izquierda de tu\npantalla en la ventana del menú. Allí hay una opción para modificar la forma\ny el color del ícono haciendo clic en el símbolo ubicado a la derecha del\nnombre del marcador. Además, abajo del título “Capa 1” hay un link con el\ntexto “Estilos individuales” que abre un menú para controlar distintos\naspectos de la apariencia de la capa.\n\n\n\n    \n\n    Figura 16\n\n\n\n\n\n  \n    Ahora agregaremos algunas líneas y formas (llamadas polígonos en el programa\nde SIG). Agregar líneas y polígonos es un proceso bastante similar.\nDibujaremos algunas líneas en una nueva capa (los diferentes tipos de puntos,\nlíneas y formas deberían estar en capas separadas).\n  \n  Selecciona la “Capa 2” en el menú (sabrás qué capa has seleccionado por el\nborde azul a la izquierda del item).\n  Haz clic en el ícono de “Trazar una línea” a la derecha del símbolo de\nmarcador y luego en “Agregar línea o forma”:\n\n\n\n    \n\n    Figura 17\n\n\n\n\n\n  \n    Elige una calle y haz clic con el mouse a lo largo de ella, calcando un\npoco la ruta. Aprieta “Enter” cuando quieras terminar la línea.\n  \n  Nuevamente, aquí puedes agregar una etiqueta (por ejemplo, ponerle nombre a\nuna calle) e información descriptiva.\n  También puedes cambiar el color y el grosor de la línea. Para hacer esto,\nbusca la calle que acabas de dibujar en la Capa 2 en el menú y haz clic\na la derecha de su nombre.\n\n\n\n    \n\n    Figura 18\n\n\n\n\n\n  Para crear un polígono (una forma) puedes conectar los puntos de la línea\nhasta alcanzar una forma cerrada. Para hacer esto, comienza a dibujar y\nfinaliza haciendo clic en el primer punto de tu línea. Puedes crear formas\nsimples, como el campo de un granjero, u otras mucho más complejas, como\nlos límites de una ciudad (ver ejemplos abajo). Te recomendamos\nexperimentar por tu cuenta creando líneas y polígonos.\n\n\n\n    \n\n    Figura 19\n\n\n\n\n\n    \n\n    Figura 20\n\n\n\n\n\n  \n    Al igual que con los marcadores y líneas, puedes cambiar el nombre y la\ndescripción de un polígono. También puedes cambiar el color y el ancho de la\nlínea haciendo clic en el ícono a la derecha del nombre de tu polígono en el\nmenú, así como también cambiar la transparencia, que será abordada a\ncontinuación.\n  \n  \n    Verás que el área comprendida por un polígono está sombreada con el mismo\ncolor que el borde. Puedes cambiar la opacidad de esta sombra modificando la\n“transparencia”, lo cual altera el punto hasta el cual se puede ver\nclaramente la imagen de fondo (su mapa base).\n  \n\n\nCompartir tu mapa personalizado\n\n\n  \n    La mejor manera de compartir el mapa en línea es utilizando el botón de\n“Compartir” en el menú. Al hacer click, obtendrás un enlace para enviar por\ncorreo electrónico o mediante redes sociales como G+, Facebook o Twitter.\n  \n  \n    Otra forma de compartir una versión dinámica de tu mapa es insertarlo en\nun blog o sitio web utilizando la opción “Insertar en mi sitio” del menú\ndesplegable que se encuentra a la derecha del nombre del mapa.\nAl seleccionar esta opción se obtiene una etiqueta de marco incorporado o\n&lt;iframe&gt; para incluir en un sitio HTML. Puedes modificar la altura y\nel ancho del marco cambiando los números entre comillas.\n  \n\n\n\n  Nota: actualmente no hay forma de configurar la escala por defecto o las\n  opciones de las leyendas de un mapa insertado, pero si necesitas eliminar la\n  leyenda del mapa que aparece en su sitio HTML puedes hacerlo reduciendo el\n  ancho del &lt;iframe&gt; a 580 o menos.\n\n\n\n  \n    Otra alternativa es exportar los datos a un archivo KML utilizando el mismo\nmenú desplegable, luego del cual te dará la opción de exportar el mapa\ncompleto  o seleccionar una capa en particular. Prueba exportando la capa\n“Suministro  global de grasa de Reino Unido”. Estos datos podrás importarlos\nluego en otros programas como Google Earth y Quantum GIS. Es una\nfuncionalidad importante, pues significa que si empiezas a trabajar con\nmapas digitales en Google Maps, luego podrás exportar lo que hayas hecho a\nuna base de datos SIG.\n  \n  \n    Si crees que el servicio gratuito de Google Maps te ofrece todas las\nherramientas que necesitas para tu tema de investigación, puedes finalizar\nla lección aquí. Si no, a continuación, aprenderás acerca de Google Earth y,\nen la lección 2, sobre Quantum GIS.\n  \n\n\n\n    \n\n    Figura 21\n\n\n\n\n\n    \n\n    Figura 22\n\n\n\n\nGoogle Earth\n\nGoogle Earth funciona en buena medida del mismo modo que Google Maps Engine Lite,\npero tiene funcionalidades adicionales. Por ejemplo, ofrece mapas 3D y acceso a\ndatos de numerosas fuentes de terceros, incluyendo colecciones de mapas\nhistóricos. Google Maps no te solicita que instale ningún programa y sus mapas son\nguardados en la nube. Google Earth, en cambio, debe ser instalado y no funciona\nen la nube, aunque los mapas que crees pueden ser exportados.\n\n\n  \n    Instala Google Earth: http://www.google.com/earth/index.html\n  \n  \n    Abre el programa y familiarízate con el globo terráqueo digital.\nUtiliza el menú para agregar y quitar capas de información. Esto es muy\nsimilar al modo en que funcionan programas más avanzados de SIG. Puedes\nagregar y quitar distintos tipos de informaciones geográficas incluyendo\nfronteras políticas (polígonos), rutas (líneas) y lugares (puntos). Mira las\nflechas rojas en la siguiente imagen para ver la ubicación de estas capas.\n  \n\n\n\n    \n\n    Figura 23: Clic para ver la imagen en tamaño completo\n\n\n\n\n\n  Fíjate que bajo el título “Capas” en el costado inferior izquierdo del margen\nde la ventana, Google ofrece una serie de capas listas para usar que se\nactivan seleccionando la casilla correspondiente.\n\n\n\n    \n\n    Figura 24\n\n\n\n\n\n  Google Earth también incluye algunos mapas históricos escaneados y\nfotografías aéreas (en SIG este tipo de mapas, que están hechos de píxeles,\nse conocen como datos ráster). Dentro de “Galería” puedes encontrar y\nseleccionar los mapas históricos de la colección Rumsey. Esto agregará\níconos alrededor de todo el globo (con una mayor concentración en los\nEstados Unidos) de mapas escaneados que han sido georeferenciados (estirados\ny fijados para coincidir con una ubicación) sobre el globo terráqueo digital.\nEsto anticipa una metodología clave en los SIG históricos. (También\nencontrarás capas de mapas históricos y otras capas SIG en la Galería de\nGoogle Earth). Tómate un tiempo para explorar algunos mapas históricos.\nVerifica si hay algún mapa incluido en la colección Rumsey que pueda ser útil\npara tu investigación o tus clases. (Para obtener más mapas digitalizados\npero no georeferenciados, visita www.davidrumsey.com.)\n\n\n\n    \n\n    Figura 25\n\n\n\n\n\n  Posiblemente necesites hacer zoom para ver todos los íconos de mapas.\n¿Puedes encontrar el globo terráqueo de 1812?\n\n\n\n    \n\n    Figura 26\n\n\n\n\n\n  Al hacer clic en un ícono se abre un panel de información. Haz clic en\nla miniatura del mapa para verlo adherido al globo terráqueo digital.\nAprenderás a georeferenciar mapas correctamente en Georeferencing in QGIS 2.0.\n\n\n\n    \n\n    Figura 27\n\n\n\n\n\n    \n\n    Figura 28: Clic para ver imagen en tamaño completo\n\n\n\n\nKML: archivos de Keyhole Markup Language\n\n\n  \n    Google desarrolló un formato de archivo para guardar y compartir datos de\nmapas: KML. Este acrónimo deriva de Keyhole Markup Language y es un tipo de\narchivo fácilmente portable (es decir que un KML puede ser utilizado en\ndistintos tipos de programas SIG) que puede almacenar muchos tipos diferentes\nde datos SIG, incluyendo vectores.\n  \n  \n    Los mapas e imágenes que crees en Google Maps y Google Earth pueden ser\nguardados como archivos KML. Esto quiere decir que puedes guardar el trabajo\nhecho en ambos programas y que los archivos KML sirven para transferir datos\nentre las dos plataformas y llevar sus datos de mapa a Quantum GIS o ArcGIS.\n  \n  \n    Por ejemplo, puedes importar los datos de Google Maps Engine Lite.\nSi creaste un mapa en el ejercicio anterior, lo encontrarás haciendo clic\nen “Mi mapa de prueba” en la página de inicio de Maps Engine Lite. Haz\nclic en el ícono con tres puntos a la derecha del título del mapa y luego\nselecciona “Exportar a KML”. (También puedes descargar y explorar el\nmapa de la vía marítima de Dan Macfarlane para esta parte del ejercicio).\n  \n\n\nImportar tu archivo KML en Google Earth\n\n\n  Descarga el archivo KML de Google Maps Engine Lite (como fue descripto\narriba).\n  Haz doble clic en el archivo KML en tu carpeta de Descargas.\n  Busca los datos en la carpeta de “Lugares Temporales” de Google Earth.\n\n\n\n    \n\n    Figura 29: Clic para ver imagen en tamaño completo\n\n\n\n\n\n  Ahora puedes explorar estos recursos cartográficos en 3D o agregar\nnuevas líneas, puntos y polígonos utilizando los distintos íconos ubicados\nen la parte superior izquierda de la ventana de Google Earth (ver imagen más\nabajo). Esto funciona esencialmente de la misma manera que en Google Maps,\naunque hay mayores funcionalidades y opciones. En el mapa de la vía marítima\nde Dan, los viejos canales y la actual vía marítima fueron trazados con\ndistintos colores y anchos de línea utilizando la herramienta de línea\n(superponiendo mapas históricos, lo cual se explica más abajo),\nmientras que varios recursos fueron señalados con los marcadores\ncorrespondientes. Para quienes les interese, también está la opción de\ngrabar un viaje que podría ser útil para presentaciones o con fines didácticos\n(cuando se selecciona el ícono de “Guarda un viaje” las opciones de grabación\naparecen en la sección inferior izquierda de la ventana).\n\n\n\n    \n\n    Figura 30\n\n\n\n\n\n  Prueba agregar un nuevo recurso a los datos de la vía marítima de Dan. Hemos\ncreado un polígono (en la terminología de SIG, un polígono es una forma\ncerrada de cualquier tipo: un círculo, un hexágono o un cuadrado son todos\nejemplos de polígonos) del lago St. Clair, que puede verse en la siguiente\nimagen. Busca el lago St. Clair (al este de Detroit) e intenta agregar un\npolígono.\n\n\n\n    \n\n    Figura 31: Clic para ver la imagen en tamaño completo\n\n\n\n\n\n    \n\n    Figura 32\n\n\n\n\n\n  Etiqueta el nuevo recurso como Lago St Claire. Luego, arrástralo\nencima de los datos de la vía marítima de Dan y agregalo a la colección.\nPuedes guardar esta versión extendida del mapa de la vía marítima como un KML\npara compartir por correo electrónico, subirlo a Google Maps, o exportar\nestos datos a QGIS. Utiliza la opción de buscar haciendo clic derecho en la\ncolección de la vía marítima y elige “Guardar lugar como”.\n\n\n\n    \n\n    Figura 33\n\n\n\n\n\n    \n\n    Figura 34\n\n\n\n\n\n    \n\n    Figura 35\n\n\n\n\nAgregar mapas históricos escaneados\n\nGoogle Earth permite utilizar una copia digital de un mapa histórico.\nÉste puede ser un mapa que ha sido escaneado o una imagen que ya está en formato\ndigital (para consejos sobre cómo encontrar mapas históricos en línea vea:\nMobile Mapping and Historical GIS in the Field). El principal objetivo de\nutilizar un mapa digital, desde un punto de vista histórico, es ubicarlo encima\nde una imagen de Google Earth en el navegador, lo cual se conoce como superposición\n(overlay). Realizar superposiciones nos permite realizar comparaciones útiles\nde cambios a través del tiempo.\n\n\n  \n    Comienza identificando las imágenes que quieres utilizar: la imagen en Google\nEarth y el mapa que quieres superponer. Para esto último, el\narchivo puede ser en formato JPEG o TIFF, pero no PDF.\n  \n  \n    En Google Earth, identifica el área del mapa donde quieres aplicar la\nsuperposición. Ten en cuenta que puedes ir atrás en el tiempo (es decir, ver\nfotos satelitales más antiguas) haciendo clic en el ícono de “Mostrar\nimágenes históricas” en la barra superior y luego ajustando el control\ndeslizable de la escala temporal que aparecerá.\n  \n\n\n\n    \n\n    Figura 36\n\n\n\n\n\n    \n\n    Figura 37\n\n\n\n\n\n  Una vez que hayas identificado las imágenes que quieres utilizar, haz clic\nen el ícono de “Añadir superposición de imagen” en la barra superior.\n\n\n\n    \n\n    Figura 38\n\n\n\n\n\n  Aparecerá una nueva ventana. Comienza poniéndole un título diferente si lo\ndeseas (por defecto es “Superposición de imágenes sin título”).\n\n\n\n    \n\n    Figura 39: Clic en la imagen para ver en tamaño completo\n\n\n\n\n\n  \n    Haz clic en el botón “Examinar”, a la derecha del campo “Vínculo”, para\nseleccionar de tus archivos el mapa que desees que sea la imagen a superponer.\n  \n  \n    Corre la ventana de “Nueva Superposición de Imágenes” (no la cierres ni\nhagas clic en “Cancelar” o “Aceptar”) para poder ver el navegador de Google\nEarth. El mapa que cargaste aparecerá sobre la imagen satelital de Google Earth\nen el navegador.\n  \n  \n    Hay marcadores en verde fosforescente en el medio y en los bordes del mapa\nsubido, que pueden ser utilizados para estirar, achicar y mover el mapa\npara que se alinee correctamente con la imagen del satélite. Éste es un modo\nsencillo de georeferenciar (mira Georeferencing in QGIS 2.0). La imagen\nde abajo muestra los pasos anteriores utilizando un viejo mapa de la ciudad\nde Aultsville superpuesto a imágenes satelitales de Google de 2008 en el\ncual se ven los restos de las calles y los cimientos de los edificios\nen el río St. Lawrence (Aultsville fue uno de los “pueblos perdidos” que\nfueron inundados por el proyecto de Vía Marítima y Energía de St. Lawrence).\n  \n\n\n\n    \n\n    Figura 40: Clic en la imagen para ver en tamaño completo\n\n\n\n\n\n  \n    Volviendo a la ventana de “Nueva Superposición de Imágenes”, fíjate que hay\nuna serie de opciones para seleccionar (“Descripción”, “Ver”, “Altitud”,\n“Actualizar”, “Ubicación”). En esta instancia probablemente no necesites\npreocuparte por ellas, pero quizás quieras agregar información bajo la\npestaña de Descripción.\n  \n  \n    Cuando estés satisfecho con tu superposición, haz clic en “Aceptar” en\nla esquina inferior derecha de la ventana de “Nueva Superposición de\nImágenes”.\n  \n  \n    Es importante que guardes tu trabajo. En “Archivo”, en la barra del menú hay\ndos opciones. Puedes guardar una copia de la imagen (Archivo -&gt; Guardar -&gt;\nGuardar imagen…) que creaste en tu computadora en formato JPG o  guardar\nla superposición de Google Earth para poder acceder a ella en\nel futuro (Archivo -&gt; Guardar -&gt; Guardar en Mis Sitios). Esta segunda opción\ngenera un archivo KML.\n  \n  \n    Para compartir archivos KML simplemente ubica el archivo que guardaste en tu\ncomputadora y súbelo a tu sitio web, tu perfil de redes sociales o envíalo\ncomo adjunto en un correo electrónico.\n  \n\n\nYa aprendiste a utilizar Google Maps y Google Earth. ¡Asegúrate de guardar tu\ntrabajo!\n\nEsta lección es parte de Geospatial Historian\n\n\nGoogle My Maps y Google Earth son una buena manera de comenzar a crear mapas digitales. Con una cuenta de Google puedes crear y editar mapas personales haciendo clic en Mis Sitios\n\n"
  },


  {
    "id": 21,
    "url": "http://localhost:4000/es/lecciones/introduccion-a-bash",
    "title": "Introducción a la línea de comandos en Bash",
    "body": "\nIntroducción a la línea de comandos en Bash\n\nContenidos\n\n\n  Introducción a línea de comandos en Bash    \n      Introducción\n      Sólo para usuarios de Windows: instalar Git Bash\n      Abrir el intérprete de línea de comandos\n      Navegando por el sistema de archivos de tu computadora\n      Interactuar con archivos\n      Editar archivos de texto directamente en línea de comandos\n      Mover, copiar y borrar archivos\n      Conclusiones\n      Guía de referencia\n    \n  \n\n\nIntroducción a línea de comandos en Bash\n\nIntroducción\n\nMuchas de las lecciones en The Programming Historian en español requieren que introduzcas órdenes a través de una Interfaz de línea de comandos. La manera habitual en la que los usuarios de computadoras interactúan actualmente con sus sistemas es a través de la Interfaz Gráfica de Usuario, o GUI (siglas de Graphical User Inteface). Esto significa que cuando entras en una carpeta, haces clic en una imagen de una carpeta de archivos; cuando ejecutas un programa, haces clic en él; y cuando navegas por la Web, utilizas el ratón para interactuar con los diferentes elementos de una página Web. Sin embargo, antes de la aparición de las GUI a finales de la década de 1980, la principal forma de interactuar con una computadora era a través de una interfaz de línea de comandos.\n\n\n    \n\n    GUI de la computadora de Ian Milligan\n\n\n\n\nLas interfaces de línea de comandos ofrecen ventajas para los usuarios de computadoras que necesitan mayor precisión en su trabajo -como los historiadores digitales. Permiten un uso más detallado a la hora de ejecutar algunos programas, ya que puedes agregar parámetros para especificar exactamente cómo deseas ejecutar tu programa. Además, se pueden automatizar procesos fácilmente mediante scripts, que son esencialmente recetas de órdenes escritas en un archivo de texto.\n\nHay dos interfaces de línea de comandos principales, o shells, que utilizan muchos historiadores digitales. En OS X, así como en muchas de las distribuciones de Linux, el shell se conoce como bash (Bourne-again shell). Para los usuarios de sistemas Windows, la interfaz de línea de comandos está basada en MS-DOS por defecto, y aunque utiliza diferentes comandos y sintaxis, puede realizar tareas similares. Este tutorial proporciona una introducción básica a la terminal bash. Los usuarios de Windows pueden seguir instalando algún shell popular como Cygwin o Git Bash (ver más adelante).\n\nEsta lección utiliza un shell de Unix, es decir, un intérprete de línea de comandos que proporciona una interfaz de usuario para el sistema operativo Unix y similares. Esta lección cubre un pequeño número de órdenes básicas. Cuando termines este tutorial, podrás navegar a través de tu sistema de archivos y encontrar archivos, abrirlos, realizar tareas básicas de manipulación de datos como combinar y copiar archivos, así como leerlos y realizar ediciones relativamente sencillas. Estos comandos constituyen los cimientos sobre los que se pueden construir órdenes más complejas que se ajusten a tus datos de investigación y proyectos. A los lectores que deseen una guía de referencia que vaya más allá de esta lección les recomendamos leer Deborah S. Ray and Eric J. Ray, Unix and Linux: Visual Quickstart Guide, 4th edition (2009).\n\nSólo para usuarios de Windows: instalar Git Bash\n\nLos usuarios de OS X y la mayoría de las distribuciones de Linux tienen suerte pues ya cuentan con un Bash shell instalado por defecto. Para los usuarios de Windows, es necesario cubrir un paso extra e instalar Git Bash descargando la versión más reciente en esta página. Las instrucciones de instalación están disponibles en Open Hatch.\n\nAbrir el intérprete de línea de comandos\n\nVamos a iniciar el intérprete de línea de comandos (shell). En Windows, ejecuta Git Bash desde el directorio en el que lo instalaste. Lo tendrás que ejecutar como administrador. Para hacerlo, haz clic con el botón derecho sobre el programa y selecciona “ejecutar como administrador” (Run as Administrator). En OS X, el shell se encuentra localizado por defecto en:\n\nAplicaciones -&gt; Utilidades -&gt; Terminal\n\n\n    \n\n    El programa Terminal.app en OS X\n\n\n\n\nCuando lo ejecutes verás esto en la ventana:\n\n\n    \n\n    Pantalla de Terminal en blanco en nuestra estación de trabajo de OS X\n\n\n\n\nQuizá quieras cambiar la apariencia que por defecto tiene la terminal para no esforzarte de más al mirar continuamente texto negro sobre fondo blanco. En la aplicación por defecto de OS X puedes abrir el menú ‘Perfiles’ en ‘Preferencias’, bajo ‘Terminal’. Haz clic en la pestaña ‘Perfiles’ y cámbialo por un nuevo esquema de color. Personalmente preferimos algo con menor contraste entre el fondo y el primer plano, pues lo estarás viendo durante mucho tiempo. ‘Novel’ es uno muy relajante ya que es la paleta de colores de la popular suite Solarized. Los usuarios de Windows pueden obtener un efecto similar utilizando la pestaña ‘Properties’ de Git bash. Para llegar a ella, haz click con el botón derecho en cualquier lugar de la barra superior y seleciona ‘Properties’.\n\n\n    \n\n    Pantalla de configutación en Terminal de OS X\n\n\n\n\nUna vez satisfecho con la apariencia de la interfaz, ya estás listo para comenzar.\n\nNavegando por el sistema de archivos de tu computadora\n\nSi cuando abres la ventana del intérprete no estás seguro del sitio en que estás en el sistema de archivos de tu computadora, el primer paso es descubrirlo. A diferencia de un sistema gráfico, cuando estás en un shell no puedes ubicarte en distintos directorios a la vez. Cuando abres el explorador de archivos en tu escritorio estás mostrando los archivos que están dentro de un directorio. Puedes saber en qué directorio estás a través del comando pwd, que significa “imprime el directorio de trabajo” (print working directory). Así, pues, introduce:\n\npwd\n\ny pulsa Intro. Si usas OS X o Linux, tu computadora probablemente mostrará /usuarios/nombre-de-usuario con tu propio nombre de usuario. Por ejemplo, la ruta de Ian en OS X es /users/ianmilligan1/. Aquí es donde te darás cuenta que aquellos que usan OS X/Linux y los que usan Windows tendrán experiencias ligeramente distintas. En Windows, James se localiza en:\n\nC:\\users\\jbaker\n\nHay pequeñas diferencias, pero no te preocupes: una vez que aprendas a moverte y a manipular archivos estas divergencias entre plataformas pasarán a un segundo plano.\n\nPara orientarnos, obtengamos una lista de los archivos que están en ese directorio. Escribe:\n\nls\n\ny verás un listado de cada archivo y directorio que se encuentre en tu ubicación actual. Tu directorio puede estar desordenado o puede verse prístino, pero al menos observarás algunas ubicaciones conocidas. En OS X, por ejemplo, verás Applications, Desktop, Documents, Downloads, Library, Pictures, etc.\n\nPosiblemente quieras ver más información que únicamente la lista de archivos. Puedes obtenerla utilizando varios parámetros (flags) para completar las órdenes básicas. Se trata de adiciones a un comando que proporcionan a la computadora un poco más de orientación de qué tipo de salida o manipulación deseas. Para obtener una lista de éstos, los usuarios de OS X/Linux pueden recurrir al programa de ayuda integrado. Los usuarios de OS X/Linux pueden escribir:\n\nman ls\n\n\n    \n\n    Página del manual para el comando LS\n\n\n\n\nAquí verás una lista del nombre del comando, la forma en la que puedes manipularlo y lo que hace. Muchos de estos comandos no tendrán sentido en esta etapa, pero no te preocupes: con el tiempo te familiarizarás con ellos. Puedes explorar esta página de varias maneras: la barra espaciadora te permite moverte hacia abajo de la página, o puedes utilizar la flecha hacia abajo y la flecha hacia arriba por todo el documento.\n\nPara abandonar la página del manual, escribe: q y esto te llevará de regreso a la línea de comandos en la que estabas antes de entrar a la página del manual.\n\nTrata de jugar un poco con la página man para ver qué puedes hacer con otra orden que ya aprendiste: pwd.\n\nLos usuarios de Windows pueden utilizar el comando help, aunque esta orden tiene menos funciones que man de OS X/Linux. Escribe help para ver la ayuda disponible, y help pwd para ejemplos de la salida del comando.\n\nAhora intentaremos utilizar algunas de las opciones que viste en la página man de ls. A lo mejor lo único que quieres ver son los archivos TXT que están en tu directorio principal. Escribe:\n\nls *.txt\n\nEsto te mostrará una lista de los archivos de texto, si es que tienes alguno en tu directorio principal (posiblemente no, y eso está bien). El comando * es un comodín que se traduce como ‘todo’ o ‘cualquier cosa’. Así que en este caso le estás indicando a la máquina que te muestre todo lo que encaje con el patrón\n\n[todo.txt]\n\nEnsaya diferentes combinaciones. Si, por ejemplo, tienes varios archivos en el formato 1-español.txt, 2-español.txt, etcétera, el comando ls *-español.txt te mostrará todos ellos pero excluirá los que no se ajusten al patrón.\n\nDigamos que quieres más información. En esa larga página de man verás una ocpión que podría resultar útil:\n\n\n  -l      (The lowercase letter ''ell''.)  List in long format.  (See\n        below.)  If the output is to a terminal, a total sum for all the\n        file sizes is output on a line before the long listing.\n  \n\n\nAsí que, si escribes\n\nls -l\n\nla computadora te mostrará una larga lista de archivos que contiene información similar a la que encontrarías en tu Finder o explorador de archivos: el tamaño de los archivos en bites, la fecha de creación o de última modificación, y el nombre del archivo. No obstante, esto puede ser un poco confuso pues verás que, por ejemplo, el archivo prueba.html tiene ‘6020’ bits. En lenguaje cotidiano estamos más acostumbrados a utilizar unidades de medida como bytes, kilobytes, megabytes y gigabytes.\n\nAfortunadamente hay otra bandera:\n\n\n  -h      When used with the -l option, use unit suffixes: Byte, Kilobyte,\n        Megabyte, Gigabyte, Terabyte and Petabyte in order to reduce the\n        number of digits to three or less using base 2 for sizes.\n  \n\n\nCuando quieres utilizar dos banderas puedes simplemente ejecutarlas juntas. Así, al escribir\n\nls -lh\n\nobtendrás una salida en un formato legible para seres humanos; aprenderás que 6020 bits son también 5.9KB, que otro archivo tiene 1 megabite y así sucesivamente.\n\nEstas opciones son muy importantes. Lo verás en otras lecciones de The Programming Historian en español. Wget, MALLET y Pandoc utilizan la misma sintaxis. Afortunadamente no necesitas memorizar la sintaxis; en lugar de ello, mantén estas lecciones a mano para que puedas echar un vistazo rápido si es necesario ajustar algo. Estas lecciones se pueden hacer en cualquier orden.\n\nYa has estado mucho tiempo en tu directorio personal. Vamos a otro lugar; puedes hacerlo a través del comando cd que significa ‘Cambiar de directorio’.\n\nSi escribes:\n\ncd desktop\n\nal pulsar Intro estarás en tu escritorio. Esto es similar a cuando haces doble click en el folder de ‘Escritorio’ en el explorador de archivos. Para confirmarlo, escribe pwd y debes ver entonces algo como esto:\n\n/Users/ianmilligan1/desktop\n\nJuega un poco con estos primeros comandos: explora tu directorio actual utilizando el comando ls. Si quieres regresar al directorio anterior, puedes escribir:\n\ncd ..\n\nEsto mueve hacia “arriba” un directorio llevándonos de regreso a /Users/ianmilligan1/. Si en algún momento te sientes completamente perdido, el comando\n\ncd --\n\nte llevará de regreso al directorio principal, exactamente donde empezaste.\n\nIntenta explorar: visita tus directorios de documentos, imágenes, carpetas que posiblemente tengas en el escritorio. Acostúmbrate a moverte adentro y afuera de los directorios. Imagina que estás navegando por una estructura de árbol. Si estás en el escritorio no podrás hacer cd documents para cambiar a la carpeta documentos ya que es dependiente de tu directorio principal, mientras que la carpeta de escritorio y de la documentos son ‘hermanas’. Para llegar a una carpeta hermana debes regresar al directorio matriz de ambas. Para hacerlo, tienes que volver al directorio principal (cd ..) y luego seguir adelante de nuevo a cd documents.\n\nEs muy importante que seas capaz de navegar por el sistema de archivos utilizando la línea de comandos (shell) para muchas de las lecciones en The Programming Historian en español. A medida que te sientas más cómodo pronto te encontrarás saltando al directorio que deseas. En nuestro caso, desde cualquier lugar de nuestro sistema, se puede escribir:\n\ncd /users/ianmilligan1/mallet-2.0.7\n\nO en Windows algo como:\n\ncd c:\\mallet-2.0.7\\\n\ne ir a nuestro directorio MALLET para modelado de tópicos.\n\nFinalmente, prueba:\n\nopen .\n\nen OS X o\n\nexplorer .\n\nen Windows. Este comando abrirá tu GUI en el directorio actual. Asegúrate de dejar un espacio entre open o explorer y el punto.\n\nInteractuar con archivos\n\nAdemás de navegar por directorios, puedes interactuar con archivos a través de la línea de comandos: puedes leerlos, abrirlos, ejecutarlos e incluso editarlos sin tener que salir de la interfaz. Hay cierto debate sobre por qué alguien querría hacer todo esto; la razón principal es la extrema comodidad de trabajar con la línea de comandos: nunca tienes que tocar el ratón o el track pad de la computadora y, aunque tiene una curva de aprendizaje pronunciada, eventualmente puede convertirse en el único entorno de escritura. Además, muchos programas requieren la utilización de la línea de comandos para operar con ellos. Puesto que vas a utilizar programas a través de la línea de comandos, a menudo puede ser más rápido crear pequeñas ediciones sin necesidad de cambiar a un programa separado. Para algunos de estos argumentos véase el texto de Jon Beltran de Heredia, “Why, oh WHY, do those #?@! nutheads use vi?”.\n\nA continuación, presentaremos unas formas básicas de interactuar con archivos.\n\nPrimero, puedes crear un nuevo directorio para que puedas interactuar con archivos de texto. Lo crearemos en tu escritorio, por conveniencia. Siempre se podrá mover más tarde. Navega hasta tu escritorio con el shell y escribe:\n\nmkdir ProgHist-Textos\n\nEsto crea un directorio llamado (¡adivinaste!) ProgHist-Textos. En general, es bueno evitar poner espacios en tus nombres de archivos y directorios cuando se utiliza la línea de comandos (hay soluciones alternativas, pero este método es más simple); del mismo modo es recomendable evira la ‘ñ’ y el resto de caracteres especiales del castellano, tildes, etc. Aunque los sistemas actuales son capaces de utilizarlos, podemos encontrar problemas si tenemos que utilizar estos ficheros en sistemas antiguos. Puedes mirar en tu escritorio para verificar que funcionó. Ahora, muévete dentro de ese directorio (recuerda que será cd ProgHist-Textos).\n\nPero ¡espera! Hay un truco para hacer las cosas un poco más rápido. Ve arriba un directorio (cd .., lo cual te llevará de regreso al escritorio). Para navegar al directorio ProgHist-Textos puedes escribir cd ProgHist-Textos. Alternativamente puedes escribir cd Prog y luego pulsar la tecla de tabulador. Te darás cuenta de que la interfaz completa la línea como cd ProgHist-Textos. Si pulsas el tabulador en cualquier momento dentro del shell le pedirás que intente completar automáticamente la línea en función de los archivos o subdirectorios que estén en el directorio actual. Sin embargo, la función es sensible a mayúsculas (así, en el ejemplo anterior, cd prog no podrá autocompletarse como cd ProgHist-Textos). En donde haya dos archivos con los mismos caracteres, autocompletar solamente llenará la línea hasta el primer punto de diferencia. Sugerimos utilizar este método a lo largo de la lección para ver cómo se comporta.\n\nAhora necesitas encontrar un archivo de texto básico para que nos ayude con el ejemplo. ¿Por qué no utilizar un libro que sabes que es largo, como la épica “Guerra y Paz” de Leon Tolstói? El archivo de texto está disponible en Project Gutenberg. Si ya instalaste wget, puedes escribir:\n\nwget  http://www.gutenberg.org/files/2600/2600-0.txt\n\nSi no lo has instalado, descarga el texto utilizando tu navegador. Ve al enlace anterior y, desde tu navegador, usa el comando ‘Guardar como’ del menú ‘Archivo’. Guárdalo en tu nuevo directorio ProgHist-Textos. Ahora, cuando escribas\n\nls -lh\n\nverás algo así como:\n\n\n  \n    -rw-r–r–+ 1 ianmilligan1  staff   3.1M  1 May 10:03 2600-0.txt\n  \n\n\nPuedes leer el texto de este archivo de diferentes maneras. Primero, puedes decirle a la computadora que quieres leerlo utilizando el programa estándar que usas para abrir los archivos de texto. Por defecto, este debe ser TextEdit en OS X o Notepad en Windows. Para abrir un archivo solamente escribe:\n\nopen 2600-0.txt\n\nen OS X, o\n\nexplorer 2600-0.txt\n\nen Windows. Lo anterior selecciona el programa por defecto para abrir ese tipo de archivos y lo abre.\n\nSin embargo, a veces querrás trabajar sin dejar la línea de comandos. También puedes leer archivos en este entorno. Para probar esto, escribe:\n\ncat 2600-0.txt\n\nLa ventana de Terminal entra en erupción y Guerra y Paz se despliega en cascada. Esto es magnífico, en teoría, pero realmente no puedes obtener sentido de esta cantidad de texto. En lugar de ello, puede ser que sólo quieras ver el primer o el último fragmento del archivo.\n\nhead 2600-0.txt\n\nproporciona una visión de las primeras diez líneas, mientras que\n\ntail 2600-0.txt\n\nofrece una perspectiva de las últimas diez líneas. Ésta es una buena manera de determinar rápidamente el contenido del archivo. Puedes añadir un comando para cambiar la cantidad de líneas que se muestran: head -20 2600-0.txt, por ejemplo, mostrará las primeras veinte líneas.\n\nTambién puedes cambiar el nombre del archivo a algo más descriptivo. Puedes asignarle un nuevo nombre escribiendo:\n\nmv 2600-0.txt tolstoi.txt\n\nDespués, cuando ejecutes el comando ls, verás que ahora se llama tolstoi.txt. Si hubieras querido duplicarlo podrías haber ejecutado el comando ‘copiar’ escribiendo:\n\ncp 2600-0.txt tolstoi.txt\n\nVolveremos sobre este comando en breve.\n\nAhora que has utilizado varios comandos nuevos, es hora de aprender otro truco. Pulsa la flecha hacia arriba en tu teclado. Observa que cp pg2600.txt tolstoi.txt aparece delante del cursor. Puedes continuar pulsando la flecha hacia arriba para recorrer los comandos anteriores. La flecha hacia abajo retrocede hacia el comando más reciente.\n\nDespués de haber leído y renombrado varios archivos, es posible que quieras reunir tu texto en uno solo. Para combinar o concatenar dos a más archivos, puedes utilizar el comando cat. Primero, vamos a duplicar el archivo Tolstoi (cp tolstoi.txt tolstoi2.txt). Ahora que tienes dos copias de Guerra y Paz, vamos a ponerlas juntas para hacer un libro aún más largo.\n\nPara combinar o concatenar dos o más archivos usa el comando cat. Escribe:\n\ncat tolstoi.txt tolstoi2.txt\n\ny pulsa Intro. Esto imprime o muestra los archivos combinados en el shell. Sin embargo, es demasiado largo para leer en esta ventana. Afortunadamente, utilizando el comando &gt; puedes enviar la salida a un nuevo archivo en vez de a la ventana de la terminal. Escribe:\n\ncat tolstoi.txt tolstoi2.txt &gt; tolstoi-repetido.txt\n\nAhora, cuando escribas ls verás que tolstoi-repetido.txt aparece en tu directorio.\n\nCuando combinas más de dos archivos, la utilización de un comodín evita escribir cada uno de los nombres de archivo de manera individual. Como has visto antes, * es un marcador de posición que te permite incluir de cero a más caracteres o números. Así que, si escribes:\n\ncat *.txt &gt; todo-junto.txt\n\ny pulsas Intro, todos los archivos .txt que estén en el directorio de trabajo son combinados en orden alfabético dentro de todo-junto.txt. Esto puede ser muy útil cuando necesitas combinar una gran cantidad de pequeños archivos dentro de un directorio para poder trabajar con ellos en un programa de análisis de textos. Otro comodín que vale la pena recordar es ? que reemplaza un único carácter o número.\n\nEditar archivos de texto directamente en línea de comandos\n\nSi quieres leer un archivo completo sin salir de línea de comandos, puedes abrir Vim. Vim es un editor de texto adecuado para utilizarse con programas como Pandoc para el procesamiento de textos, o editar tu código sin tener que cambiar a otro programa. Lo mejor de todo es que viene incluido con bash tanto en OS X como en Windows. Vim tiene una curva de aprendizaje bastante grande, por lo que vamos a tocar algunos puntos menores.\n\nEscribe:\n\nvim tolstoi.txt\n\nVerás aparecer Vim frente a ti, un editor de texto en línea de comandos.\n\n\n    \n\n    Vim\n\n\n\n\nSi quieres aprender más de Vim, aquí tienes una buena guía disponible.\n\nEl uso de Vim para leer archivos es relativamente simple. Puedes usar las teclas de flechas para navegar alrededor y teóricamente leer Guerra y Paz a través de línea de comandos (lo cual sería todo un logro, por cierto). A continuación hay algunos comandos de navegación básica:\n\nCtrl+F (esto es, mantén oprimida la tecla ‘Control’ y presiona a la vez la tecla ‘F’), te moverá una página adelante (en Windows: Shift+FlechaArriba).\n\nCtrl+B te moverá una página arriba. (Shift+FlechaAbajo para usuarios de Windows).\n\nSi te quieres desplazar rápidamente al final de una línea, puedes oprimir $ y para moverte al inicio: 0. También puedes moverte entre frases escribiendo ) (hacia adelante) o ( (atrás). Para párrafos, utiliza } y {. Dado que estás haciendo todo con el teclado, en vez de tener que mantener pulsada la tecla de flecha para moverte por el documento, esto te permite pasar volando hacia atrás y adelante.\n\nVamos a desplazarnos a la parte superior para hacer un pequeño cambio, como añadir un campo de ‘lector’ en el encabezado. Sitúa el cursor entre Author: y Translator:, como esto:\n\n\n    \n\n    A punto de añadir un campo\n\n\n\n\nSi sólo comienzas a escribir obtendrás un mensaje de error o el cursor comenzará a saltar. Esto se debe a que tienes que especificar que deseas hacer una edición. Presiona la letra\n\na\n\nAl final de la pantalla verás:\n\n-- INSERT --\n\nEsto significa que estás en el modo ‘insertar’. Ahora puedes escribir y editar como si estuvieras en un editor de texto estándar. Pulsa Intro dos veces, luego flecha arriba, y escribe:\n\nReader: un historiador programador\n\nCuando termines, presiona ESC para abandonar el modo de inserción de texto.\n\nPara abandonar Vim o guardar cambios, tienes que introducir una serie de comandos. Presiona : y te moverás a la linea de entrada de comandos de Vim. Aquí puedes introducir una variedad de comandos. Si deseas guardar el archivo, escribe w y pulsa Intro para ‘escribir’ el archivo. Si ejecutas este comando verás:\n\n\n  \n    “tolstoi.txt” [dos] 65009L, 3291681C written\n  \n\n\n\n    \n\n    Después de escribir el archivo con nuestro pequeño cambio\n\n\n\n\nSi deseas salir del programa, escribe de nuevo : y luego q. Esto te regresará a la línea de comandos. Al igual que con el resto de bash, también podrías haber combinado los dos comandos. Presionando : y luego poniendo wq habríamos guardado el archivo y luego habríamos salido del programa. O, si querías salir sin guardar, q!, habrías salido de Vim y cancelado la preferencia de sobreescribir, por defecto, para guardar tus cambios.\n\nVim es diferente a los procesadores de texto a los que estás acostumbrado y requerirá más trabajo y práctica para llegar a tener fluidez en su uso. Pero si estás ajustando cosas menores en archivos, es una buena manera de empezar. A medida que te sientas más cómodo podrías incluso escribir documentos con él, aprovechando el potencial de formar y poner notas a pie de Pandoc y Markdown.\n\nMover, copiar y borrar archivos\n\nSupongamos que has terminado de trabajar con este directorio y que ahora quieres mover el archivo tolstoy.txt a otro sitio. En primer lugar debes crear una copia de seguridad. El shell es bastante implacable con los errores y hacer copias de seguridad es aún más importante que con las GUI. Si borras algo aquí, no hay papelera de reciclaje para recobrarlo. Para crear una copia de seguridad puedes escribir:\n\ncp tolstoi.txt tolstoi-backup.txt\n\nAhora, cuando ejecutes el comando ls verás cinco archivos, dos de los cuales son el mismo: tolstoi.txt y tolstoi-backup.txt.\n\nVamos a mover el primero de ellos a algún otro sitio. Por ejemplo, vamos a crear un segundo directorio en tu escritorio. Muévete al escritorio (cd ..) y crea (mkdir) otra carpeta. Vamos a llamarla proghist-dest.\n\nPara copiar tolstoy.txt tienes algunas cuantas opciones. Puedes ejecutar estos comandos desde cualquier sitio en el shell, o puedes hacerlo tanto desde el directorio de origen como el de destino. Para este ejemplo, vamos a ejecutarlos desde aquí. El formato básico del comando de copiado es cp [origen] [destino]. Esto es, escribes cp primero y luego incluyes el archivo o archivos que quieres copiar seguido de el lugar donde deben irse.\n\nEn este caso el comando:\n\ncp /users/ianmilligan1/desktop/ProgHist-Textos/tolstoy.txt /users/ianmilligan1/desktop/proghist-dest/\n\ncopiará tolstoy.txt del primer directorio al segundo directorio. Tienes que insertar tu propio nombre de usuario en lugar de ‘ianmilligan1’. Con esto ahora tendremos tres copias de la novela en nuestra computadora. La original, la copia de seguridad y la nueva copia en el segundo directorio. Si querías mover el archivo, es decir, sin dejar una copia detrás, podrías ejecutar el comando de nuevo cambiando cp por mv; pero no lo hagamos todavía.\n\nPodrías también copiar múltiples archivos con un sólo comando. Si querías copiar ambos, el original y la copia de seguridad, debes utilizar el comando comodín.\n\ncp /users/ianmilligan1/desktop/ProgHist-Textos/*.txt /users/ianmilligan1/desktop/proghist-dest/\n\nEste comando copia todos los archivos de texto desde la carpeta original a la carpeta de destino.\n\n\n  Nota: si estás en alguno de los directorios desde donde quieres copiar o a donde quieres llevar los archivos, no tienes que escribir toda la estructura de directorios. Vamos a hacerlo con ejemplos rápidos. Trasládate al directorio ProgHist-Textos. Desde esta ubicación, si quieres copiar estos dos archivos a proghist-dest, este comando funcionará:\n\n\ncp *.txt /users/ianmilligan1/desktop/proghist-dest/ (en OS X. Para Windows substituye el directorio)\n\nAlternativamente, si estuvieras en el directorio proghist-dest, este comando debe funcionar:\n\ncp /users/ianmilligan1/desktop/ProgHist-Textos/*.txt ./\n\nEl comando ./ hace referencia al directorio actual, en el que estás. Ciertamente, éste es un comando valioso.\n\nFinalmente, si quieres borrar un archivo, por cualquier razón, el comando es rm, o ‘retira’ (remove). Ten cuidado con el comando rm, dado que no querrás borrar archivos sin querer. Al contrario de borrar desde la GUI, NO hay papelera de reciclaje ni opciones de deshacer. Por esta razón, si tienes una duda, deberás ser cauteloso o hacer copias de seguridad de tus datos regularmente.\n\nVe a ProgHist-Textos y borra el archivo original escribiendo:\n\nrm tolstoy.txt\n\nConfirma que el archivo desapareció ejecutando el comando ls.\n\nSi quieres borrar un directorio completo, tienes dos opciones. Puedes utilizar rmdir, el opuesto a mkdir, para borrar un diretorio vacío. Para borrar un directorio con archivos, puedes usar desde el escritorio:\n\nrm -r ProgHist-Textos\n\nConclusiones\n\nLlegados hasta aquí, seguramente quieras descansar de la terminal. Para ello, escribe exit y eso cerrará tu sesión.\n\nHay más comandos para probar a medida que te sientas más cómodo con la línea de comandos. Algunos de nuestros favoritos son du, que es una forma de averiguar cuánto espacio del disco se está utilizando (du -h lo hace legible a humanos, como con otros comandos). Para aquellos usuarios de OS X, top proporciona una visión general de los procesos que se están ejecutando (mem en Windows), y touch NOMBREDEARCHIVO puede crear un archivo de texto básico en ambos sistemas.\n\nEn este punto esperamos que tengas una buena comprensión básica de cómo desplazarte usando la línea de comandos, mover archivos y realizar ediciones menores aquí y allá. Esta lección para principiantes está diseñada para darte cierta fluidez y confianza básicas. En el futuro, es posible que quieras atreverte con los scripts.\n\n¡Que te diviertas! Antes de que te des cuenta, te encontrarás a gusto con la conveniencia y la precisión del uso de la línea de comandos -para ciertas aplicaciones, por lo menos-, mucho más que con la voluminosa GUI que viene con tu sistema. Tu caja de herramientas acaba de hacerse más grande.\n\nGuía de referencia\n\nPara tu comodidad, aquí están los comandos que acabas de aprender en esta lección:\n\n\n  \n    \n      Comando\n      Qué hace\n    \n  \n  \n    \n      pwd\n      Imprime el ‘directorio actual de trabajo’, permitiéndote saber dónde estás.\n    \n    \n      ls\n      Enlista los archivos en el directorio actual.\n    \n    \n      man *\n      Enlista el manual del comando, sustituyendo el * por el nombre del comando.\n    \n    \n      cd *\n      Cambia el directorio actual a *.\n    \n    \n      mkdir *\n      Crea un directorio llamado *.\n    \n    \n      open or explorer\n      En OS X, open seguido del nombre del archivo lo abre; en Windows, el comando explorer seguido por el nombre del archivo hace lo mismo.\n    \n    \n      cat *\n      cat es un comando versátil. Leerá un archivo poniendo el nombre en vez de *, pero también se utiliza para combinar archivos.\n    \n    \n      head *\n      Muestra las primeras diez líneas de *.\n    \n    \n      tail *\n      Muestra las últimas diez líneas de *.\n    \n    \n      mv\n      Mueve un archivo.\n    \n    \n      cp\n      Copia un archivo.\n    \n    \n      rm\n      Borra un archivo.\n    \n    \n      vim\n      Abre el editor de documentos vim.\n    \n  \n\n\nCon esta lección aprenderás introducir órdenes a través de una Interfaz de Línea de comandos, en lugar de hacerlo en una Interfaz Gráfica de Usuario. La Interfaz de Línea de comandos es útil cuando el usuario necesita un mayor grado de precisión para llevar a cabo su investigación. Por ejemplo, permite añadir modificadores de tal modo que se puede ejecutar un programa de una manera determinada. Asimismo, te será útil para automatizar programas mediante scripts, es decir, recetas o paquetes que contienen una serie de instrucciones.\n\n"
  },


  {
    "id": 22,
    "url": "http://localhost:4000/es/lecciones/introduccion-a-markdown",
    "title": "Introducción a Markdown\n",
    "body": "\nIntroducción a Markdown\n\nIntroducción a Markdown\n\nObjetivos de la lección\n\nEn esta lección se ofrece una introducción a Markdown, un lenguaje de marcado con sintaxis en texto plano para generar textos con formato. Descubrirás el porqué se utiliza, cómo dar formato a los archivos de Markdown y cómo obtener una vista previa en la web de los documentos formados con Markdown.\n\nDado que las lecciones de The Programming Historian en español deben ser enviadas como archivos Markdown, hemos incluido ejemplos específicos de PH en la medida de lo posible. Espero que esta guía sea útil si estás considerando contribuir con una lección en este sitio.\n\n¿Qué es Markdown?\n\nMarkdown fue desarrollado en 2004 por John Gruber, y se refiere tanto a (1) una manera de formar archivos de texto, como a (2) una utilidad del lenguaje de programación Perl para convertir archivos Markdown en HTML. En esta lección nos centraremos en la primera acepción y aprenderemos a escribir archivos utilizando la sintaxis de Markdown.\n\nLos archivos de texto plano tienen muchas ventajas sobre otro tipo de formato. Por un lado, se pueden leer prácticamente en todos los dispositivos. También han resistido la prueba del paso del tiempo mejor que otro tipo de archivos -si alguna vez has intentado abrir un documento guardado en un formato de procesador de textos heredado, estarás familiarizado con los problemas de compatibilidad que implican-.\n\nAl utilizar la sintaxis de Markdown, serás capaz de producir archivos que pueden ser legibles como texto plano y que a la vez están listos para ser formados en otras plataformas. Muchos generadores de bitácoras y de sitios estáticos, así como sitios como GitHub, también aceptan Markdown y traducen estos archivos a HTML para su visualización en la web. Además, herramientas como Pandoc pueden convertir archivos en o desde Markdown. Para más información sobre Pandoc puedes consultar la lección sobre Escritura sostenible utilizando Pandoc y Markdown de Dennise Tenen y Grant Wythoff.\n\nSintaxis en Markdown\n\nLos archivos en Markdown se guardan con la extensión .md y se pueden abrir en un editor de texto como TextEdit, Notepad, Sublime Text o Vim. Muchos sitios web o plataformas de publicación también ofrecen editores basados en la web y/o extensiones para introducir texto utilizando la sintaxis de Markdown.\n\nEn este tutorial vamos a practicar la sintaxis de Markdown en el navegador usando StackEdit. Podrás introducir texto formado en Markdown a la izquierda e inmediatamente ver la versión traducida junto a él a la derecha.\n\nDado que todas las lecciones de The Programming Historian están escritas en Markdown, también podemos examinar sus archivos en StackEdit. Desde el editor de StackEdit, haz click en el icono de almohadilla # en la esquina superior izquierda del menú. Selecciona Import from URL y entonces pega la siguiente URL para ver la lección “Introducción a Bash” en el editor:\n\nhttps://github.com/programminghistorian/jekyll/tree/gh-pages/es/lecciones/intro-a-bash.md\n\n\nVerás que mientras que el panel de la derecha cuenta con una presentación más elegante del texto, el archivo de Markdown a la izquierda es aún bastante legible.\n\nVamos a sumergirnos ahora en la lección escribiendo nuestra propia sintaxis de Markdown. Crea un nuevo documento en StackEdit haciendo click en el ícono de la carpeta en la esquina superior derecha seleccionando “New document”. Debes ponerle nombre al documento en la caja de texto en la parte superior de la página.\n\nEncabezados\nMarkdown dispone de cuatro niveles de encabezados definidos por el número de # antes del texto del encabezado. Pega los siguientes ejemplos en la caja de texto de la izquierda:\n\n# Primer nivel de encabezado\n## Segundo nivel de encabezado\n### Tercer nivel de encabezado\n#### Cuarto nivel de encabezado\n\n\nEl primer y segundo nivel de encabezado también se pueden escribir como sigue:\n\nPrimer nivel de encabezado\n==========================\n\nSegundo nivel de encabeado\n--------------------------\n\n\nEstos se representarán como:\n\nPrimer nivel de encabezado\n\nSegundo nivel de encabezado\n\nTercer nivel de encabezado\n\nCuarto nivel de encabezado\n\nPrimer nivel de encabezado\n\nSegundo nivel de encabeado\n\nObserva que la sintaxis de Markdown sigue siendo comprensible aún en la versión de texto plano.\n\nPárrafos y saltos de línea\n\nEscribe la siguiente frase en la caja de texto:\n\n¡Bienvenidos a *The Programming Historian en español*!\n\nHoy aprenderemos la sintaxis de Mardown.\nEsta frase está separada de la anterior por un solo salto de línea.\n\n\nEsto queda representado como:\n\n¡Bienvenidos a The Programming Historian en español!\n\nHoy aprenderemos la sintaxis de Markdown.\nÉsta frase esta separada de la anterior por un solo salto de línea.\n\nLos párrafos deben estar separados por una línea vacía. Deja una línea entre la que contiene Markdown. y Ésta para que veas cómo trabaja. Los saltos de línea sencillos deben indicarse con dos espacios en blanco en algunas implementaciones de Markdown. Esto no es necesario en la variente de GitHub Flavored Markdown, que es la que utiliza por defecto StackEdit.\n\nAñadir énfasis\n\nEl texto se puede poner en cursivas encerrándolo entre los símbolos * o -. De la misma forma, el texto en negritas se escribe encerrando la palabra entre **o __.\n\nAñade énfasis a una frase utilizando estos métodos:\n\n¡Estoy **muy** entusiasmado con los tutoriales de _The Programming Historian en español_!\n\n\nLo cual queda representado así:\n\n¡Estoy muy entusiasmado con los tutoriales de The Programming Historian en español!\n\nListados\n\nMarkdown soporta la creación de listas ordenadas y sin ordenar. Escribe la siguiente lista dentro de la caja de texto:\n\nLista de compras\n---------------\n* Frutas\n  * Manzanas\n  * Naranjas\n  * Uvas\n* Lácteos\n  * Leche\n  * Queso\n\n\nPoner sangría al * te permite crear listas anidadas.\n\nEsto se depliega así:\n\nLista de compras\n\n  Frutas\n    \n      Manzanas\n      Naranjas\n      Uvas\n    \n  \n  Lácteos\n    \n      Leche\n      Queso\n    \n  \n\n\nLas listas ordenadas se escriben numerando cada línea. Una vez más, el objetivo de Markdown es producir documentos que sean legibles como texto plano y que a la vez puedan traducirse a otros formatos.\n\nLista de pendientes\n------------------\n1. Terminar el tutorial de Markdown\n2. Ir a la tienda de abarrotes\n3. Preparar el almuerzo\n\n\nLo cual se visualiza de la siguiente manera:\n\nLista de pendientes\n\n  Terminar el tutorial de Markdown\n  Ir a la tienda de abarrotes\n  Preparar el almuerzo\n\n\nFragmentos de código (snippets)\n\nRepresentar fragmentos de código en forma distinta al resto del documento es una buena práctica que lo hace más legible. La escritura de código se representa generalmente a espacio sencillo. Dado que Markdown no distingue las tipografías involucradas, representamos los fragmentos de código encerrados entre dos signos de acento grave `. Por ejemplo: `&lt;br/&gt;`. Cuando queremos representar un bloque completo de código lo debemos encerrar entre dos líneas de tres acentos graves. En la ventana de vista previa de StackEdit esto se representará como una caja de texto sombreada y escrita a espacio seguido.\n\nEscribe lo siguiente en la caja de texto:\n\n```html\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Título del sitio Web&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n```\n\n\nY se representará así:\n\n    &lt;html&gt;\n        &lt;head&gt;\n            &lt;title&gt;Título del sitio Web&lt;/title&gt;\n        &lt;/head&gt;\n        &lt;body&gt;\n        &lt;/body&gt;\n    &lt;/html&gt;\n\n\nObserva cómo el bloque de código se representa a renglón seguido.\n\nBloque de citas\n\nEscribe el siguiente texto en la caja de texto:\n\n&gt; Hola. Éste es un párrafo de texto incluido en un bloque de cita. Fíjate que tengo una sangría con respecto al margen izquierdo.\n\nLo cual se representará:\n\n\n  Hola. Éste es un párrafo de texto incluido como un bloque de cita textual. Fíjate que tengo una sangría con respecto al margen izquierdo.\n\n\nEnlaces de Internet\n\nLos enlaces de Internet se pueden escribir de dos maneras.\n\nEl título del enlace se encierra primero entre corchetes y después se incluye la dirección completa del URL entre paréntesis.\n\nPara más tutoriales visita la página [The Programming Historian en español](/es).\n\nLo cual se representa así:\n\nPara más tutoriales visita la página The Programming Historian en español.\n\nLos enlaces también se utilizan para crear notas a pie de página y son útiles porque, además, ayudan a mantener más ordenado tu documento en texto plano. Las notas a pie se escriben con un par adicional de corchetes con el número de referencia para establecer el vínculo que identifique la etiqueta.\n\nUn ejemplo es el sitio *[The Programming Historian en español][1]*\n\nEntonces puedes incluir el URL en otra parte del documento:\n\n[1]: http://programminghistorian.org/\n\nLo cual se despliega de la siguiente manera:\n\nUn ejemplo es el sitio The Programming Historian en español\n\nImágenes\n\nSe pueden referir las imágenes mediante el uso de !, seguido de un texto alternativo entre corchetes, seguido a su vez por el URL de la imagen y un título opcional entre comillas. Esto no se representará como texto en tu documento pero te permitirá incluir la imagen en la visualización de una página en HTML.\n\n![Logo de Wikipedia](https://upload.wikimedia.org/wikipedia/en/8/80/Wikipedia-logo-v2.svg \"Wikipedia logo\")\n\nEsto aparece como:\n\n\n\nReglas y líneas horizontales\n\nPuedes incluir líneas horizontales si escribes en una misma línea cualquiera de los siguientes tres signos: -. * o _, sin importar los espacios que dejes entre ellos. Cualquiera de estas combinaciones generarán una línea horizontal:\n\n___\n* * *\n- - - - - -\n\n\nEs decir:\n\n\n\n\n\n\n\nTablas\n\nLa versión básica de Markdown no incluye tablas; sin embargo, algunos sitios web y aplicaciones usan variantes de Markdown que pueden incluir tablas y otras características especiales. GitHub Flavored Markdown es una de estas variantes y es utilizado para visualizar archivos .md en el navegador del sitio de GitHub.\n\nPara crear una tabla en GitHub, usa barras verticales |para separar columnas y guiones entre los encabezados y el resto del contenido de la tabla. Dado que las barras verticales son sólo estrictamente necesarias entre columnas, puedes usarlas en los extremos de la tabla para darle una vista más acabada. Las celdas pueden tener contenido de cualquier extensión, y no es necesario que las barras verticales estén alineadas verticalmente entre sí.\n\n| Encabezado 1 | Encabezado 2 | Encabezado 3 |\n| --------- | --------- | --------- |\n| renglón 1, columna 1 | renglón 1, columna 2 | renglón 1, columna 3|\n| renglón 2, columna 1 | renglón 2, columna 2 | renglón 2, columna 3|\n| renglón 3, columna 1 | renglón 3, columna 2 | renglón 3, columna 3|\n\n\nEsto se visualiza así:\n\n\n  \n    \n      Encabezado 1\n      Encabezado 2\n      Encabezado 3\n    \n  \n  \n    \n      renglón 1, columna 1\n      renglón 1, columna 2\n      renglón 1, columna 3\n    \n    \n      renglón 2, columna 1\n      renglón 2, columna 2\n      renglón 2, columna 3\n    \n    \n      renglón 3, columna 1\n      renglón 3, columna 2\n      renglón 3, columna 3\n    \n  \n\n\nPara especificar la alineación del contenido de cada columna se pueden agregar dos puntos :al renglón de los encabezados como sigue:\n\n| Alineado-izquierda | Centrado | Alineado-derecha |\n| :-------- | :-------: | --------: |\n| Manzanas | rojo | 5000 |\n| Plátanos | amarillo | 75 |\n\n\nLo cual se representa de este modo:\n\n\n  \n    \n      Alineado-izquierda\n      Centrado\n      Alineado-derecha\n    \n  \n  \n    \n      Manzanas\n      rojo\n      5000\n    \n    \n      Plátanos\n      amarillo\n      75\n    \n  \n\n\nLimitaciones de Markdown\n\nAunque Markdown se está haciendo cada vez más popular, particularmente para los documentos con formato que se pueden ver en la web, muchas persones y editores siguen solicitando archivos tradicionales en Word, PDF y otros formatos. Esto puede arreglarse en parte utilizando herramientas de conversión en línea como Pandoc. No obstante, algunas características de los procesadores de texto, como la de control de cambios, no tienen soporte aún. Por favor, visita la lección de Programming Historian en español sobre Escritura sostenible en texto plano usando Pandoc y Markdown para mayor información sobre Pandoc.\n\nConclusiones\n\nMarkdown es un término medio muy útil entre los archivos de texto plano sin estilo y los documentos de procesadores de texto heredados. Su sintaxis simple se aprende rápidamente y es altamente legible en el mismo documento y cuando se transforma en HTML u otro tipo de documentos. En conclusión, escribir tus documentos en Markdown significa que serán capaces de ser utilizados y leídos a largo plazo.\n\n\nEn esta lección se ofrece una introducción a Markdown, un lenguaje de marcado con sintaxis en texto plano para generar textos con formato. Descubrirás el porqué se utiliza, cómo dar formato a los archivos de Markdown y cómo obtener una vista previa en la web de los documentos formados con Markdown.\n\n"
  },


  {
    "id": 23,
    "url": "http://localhost:4000/es/lecciones/introduccion-a-powershell",
    "title": "Introducción a la línea de comandos de Windows con PowerShell",
    "body": "\nIntroducción a la línea de comandos de Windows con PowerShell\n\nContenidos\n\n\n  Introducción\n  ¿Qué es PowerShell y por qué es útil?\n  Para empezar\n  Abrir PowerShell    \n      Navegación        \n          Ver contenido del directorio con Get-ChildItem (gci, ls)\n          Navegar entre directorios con Set-Location ( sl, cd)\n          Creación de nuevos directorios con mkdir\n          Uso de Explorerpara ver directorios en la GUI\n          Eliminación con Remove-Item (rm)\n          Entender la estructura de árbol del sistema de archivos de tu computadora\n          Moverse rápido con Push-Location(pushd) y Pop-Location (popd)\n        \n      \n      Trabajar con archivos        \n          Crear archivos con New-Item (ni)\n          Copiar y mover archivos con Copy-Item(cp) y Move-Item (mv)\n        \n      \n    \n  \n  Haciendo más    \n      Escribir en archivos con Write-Output (write, echo) y redirección\n      Leer archivos con Get-Content (gc, cat)\n      Trabajar con varios archivos a la vez usando caracteres comodín (*)\n      Búsquedas con Select-String (sls)\n      Bucles infinitos y abortar procesos con control-c\n      Especificación de cmdlets con parámetros\n      Más información sobre Get-Help\n      Solución del problema de bucle infinito con el parámetro -exclude\n      Obtener más provecho de los cmdlets con Piping\n      Utilización de herramientas de línea de comandos y ejecución de secuencias de comandos en Python\n    \n  \n  Conclusión\n  Referencia rápida\n\n\nIntroducción\n\nEn este tutorial aprenderás las bases de PowerShell de Windows, la interfaz de línea de comandos estándar de computadoras con Windows. Si eres usuario de Mac o Linux deberías consultar la Introducción a la línea de comandos en Bash. Si ya estás familiarizado con el uso de Bash, es posible que puedas comenzar con PowerShell solamente con ver la tabla al final de esta lección.\n\nEl tutorial está dividido en dos secciones principales. En la primera sección, “Para empezar”, aprenderás a realizar tareas básicas de escritorio como crear y abrir archivos y carpetas con PowerShell. En la segunda sección, “Haciendo más”, obtendrás un vistazo de algunas de las características que hacen que el trabajo en línea de comandos sea particularmente eficiente y aprendas lo básico para poder explorar más por tu cuenta. También te prepararás para ejecutar scripts de Python desde la línea de comandos.\n\nEste tutorial fue escrito para PowerShell 5.0. Si estás usando una versión anterior, encontrarás algunas pequeñas diferencias de sintaxis que debes ser capaz de superar con la pequeña ayuda de un buscador.\n\n¿Qué es PowerShell y por qué es útil?\n\nWindows PowerShell es una interfaz de línea de comandos para computadoras Windows. Una interfaz de línea de comandos (CLI, por sus siglas en inglés) es un programa que te permite hacer que tu computadora ejecute tareas utilizando órdenes escritas en vez de hacer clic sobre las imágenes en el escritorio como en una interfaz gráfica de usuario (GUI, por sus siglas en inglés). Técnicamente, PowerShell es más que sólo una CLI; puedes obtener una visión general de sus características en Wikipedia. El uso de la línea de comandos tiene muchas ventajas. Hace posible automatizar tareas y hacer muchas cosas con una orden. Lo que es más importante, una serie de herramientas de valor para los humanistas sólo se pueden ejecutar desde la línea de comandos, incluyendo muchas de las que puedes aprender en The Historian en español, como Mallet (en inglés), Pandoc, o Wget (en inglés). La línea de comandos es también el mejor lugar para trabajar con los programas que has construido y personalizado para tu propia investigación utilizando lenguajes de programación como Python.\n\nPara empezar\n\nEn primer lugar aprenderás a navegar a través de tus archivos y a realizar algunas tareas básicas que haces todos los días en la computadora.\n\nAbrir PowerShell\n\nBusca PowerShell en tu computadora. Probablemente tengas varias opciones, como “PowerShell”, “PowerShell ISE” y “PowerShell (x86)”. El ISE (entorno integrado de secuencias de órdenes -integrated scripting environment) es una herramienta útil que te permite escribir scripts al vuelo y también cuenta con una búsqueda de todos los comandos de PowerShell. En este momento es más de lo que necesitamos. El “X86” es compatible con versiones anteriores del sistema operativo (si has estado en el mundo de las computadoras por algún tiempo, recordarás los viejos procesadores de Intel de los años 80 y 90 llamados “286”, 2386”, “486”, y así sucesivamente. Eso es lo que permite el “X86”, pues es una versión de 32 bits). Pero queremos 64-bits y lo más simple, así que vamos a utilizar el llamado solamente “Windows PowerShell”. Posiblemente quieras agregarlo a tu barra de tareas: haz clic con el botón derecho para obtener la opción. Al abrirlo, se verá así:\n\n\n    \n\n    Puesta en marcha de PowerShell\n\n\n\n\nSi no quieres blanco sobre azul, haz clic con el botón derecho en la barra superior, selecciona “propiedades” y ve a “colores” para cambiar las cosas. Deberás cerrar y volver a abrir PowerShell para que se vea correctamente.\n\nNavegación\n\nAlgo bueno de PowerShell es que siempre sabrás dónde estás porque te lo dice en el prompt. En mi caso, yo veo:\n\nC:\\Users\\Ted&gt;\n\nDebes ver algo similar pero con tu nombre de usuario. En caso de que no sea así, escribe:\n\nsl ~\n\nAsegúrate de incluir el espacio. Esto te llevará a tu directorio personal: C:\\Users\\TUNOMBREDEUSUARIO donde “TUNOMBREDEUSUARIO” se reemplaza con el nombre de tu cuenta en la máquina. “Directorio” es sólo otra palabra para “carpeta”, y PowerShell considera tu carpeta de usuario como inicio -no el escritorio. El escritorio es realmente otra carpeta dentro de tu carpeta de usuario, es decir, un subdirectorio del directorio usuario. Introducir sl ~ es como abrir la carpeta llamada “usuarios” y desde ahí TUNOMBREDEUSUARIO utilizando la GUI. Comencemos aprendiendo como moverte entre los directorios y ver su contenido.\n\nVer contenido del directorio con Get-ChildItem (gci, ls)\n\nNuestra primera orden es Get-ChildItem. Escríbela y oprime Enter. Verás una lista de todo lo que hay en tu directorio actual. En mi caso se verá así:\n\n\n    \n\n    Listado del contenido del directorio con Get-ChildItem\n\n\n\n\nToma en cuenta que en realdad no escribí GetChildItem. Solamente gci. Los comandos que aprenderemos son todos de la forma “Verbo-Sustantivo” (Verb-Noun). Son llamados “cmdlets” (pronunciado “commandlets”) y se supone que su forma hace más fácil recordar lo que hacen y predecir otros cmdlets similares. Debido a que los cmdlets son bastante largos, la mayoría de ellos tienen alias más elegantes que puedes utilizar en su lugar. Primero presentaré los cmdlets con sus nombres, pero siempre usaré los alias estándar, porque son mucho más rápidos para trabajar. Es importante tener en cuenta que muchos cmdlets tienen varios alias. Por ejemplo, Get-ChildItem, gci, dir y ls hacen exactamente lo mismo. Aunque no sorprende que gci sea la abreviatura de Get-ChildItem, es posible que te preguntes de dónde provienen dir y ls.\n\nPowerShell es relativamente nuevo (se lanzó por primera vez en 2006), y sus diseñadores esperaban que muchas personas que lo utilizarían ya tendrían experiencia con algunas CLI existentes (interfaces de línea de comandos), específicamente con el CLI más antiguo de Microsoft llamado Símbolo de sistema (command prompt) o con Linux CLIs como Bash, que ahora también es estándar en OS X. Por lo tanto, muchos cmdlets tienen un alias que es el comando estándar en uno de estos dos sistemas (y a menudo para ambos). En el ejemplo presente, dir viene de Símbolo de sistema, y ls proviene de Bash. Utilizaré los alias de estilo “PowerShell” en este tutorial, ya que hace más fácil recordar los nombres reales de cmdlet. Sin embargo, intentaré también mencionar otros alias comunes, particularmente aquellos familiares para los usuarios de Bash. Si trabajas con mucha gente que usa OS X o Linux, puede ser bueno conocer estos nombres. La tabla en la parte inferior proporciona los cmdlets junto con sus alias estándar de PowerShell y el equivalente de Bash más cercano.\n\nSigue adelante e intenta usar gci, dir y ls. Obtendrás exactamente la misma lista de cosas. La mayoría de estas cosas serán directorios. Uno de ellos debe ser tu escritorio. Vamos a entrar en ese directorio.\n\nNavegar entre directorios con Set-Location ( sl, cd)\n\nPara desplazarte a tu escritorio, usaremos el cmdlet Set-Location. Escribe en PowerShell:\n\nsl desktop\n\nEsto le indica a PowerShell que se mueva al escritorio. Observa que puedes escribir “desktop” usando todas las letras minúsculas, aunque cuando viste el contenido del directorio TUNOMBREDEUSUARIO, “Desktop” se escribió con una “D” mayúscula. PowerShell no distingue entre mayúsculas y minúsculas. Ahora que has cambiado tu ubicación, puedes usar gci para ver una lista de todo lo que hay en tu escritorio, es decir, todo el directorio llamado Desktop. Si estás tan desorganizado como yo, esta será una larga lista. Podemos volver al directorio TUNOMBREDEUSUARIO escribiendo:\n\nsl ..\n\n¡No olvides el espacio! Ahora escribe de nuevo:\n\nsl ..\n\nDebes estar en el directorio Users.\n\nAhora trata de volver al escritorio y luego de nuevo a Users. Debe tomarte escribir cuatro comandos: sl TUNOMBREDEUSUARIO, sl desktop, sl .., sl ... Pero en realidad puedes hacerlo con sólo dos. Deberías estar en C:\\Users&gt; ahora mismo. En lugar de escribir sl TUNOMBREDEUSUARIO y luego sl desktop, puedes escribir solamente:\n\nsl TUNOMBREDEUSUARIO\\desktop\n\n¡Y llegar al escritorio con un comando! Del mismo modo, desde el escritorio, escribiendo:\n\nsl ..\\..\n\nPuedes volver a donde comenzaste con un comando. Si no tienes la resistencia del dedo meñique para escribir \\ todo el tiempo, también puedes escribir sl ../ ... No sólo PowerShell no distingue entre mayúsculas y minúsculas, sino que tampoco le importa en qué dirección va la barra. Sl ../ .., SL .. \\ .., Set-Location .. \\ .. y set-location ../ .. todos hacen exactamente lo mismo.\n\nCreación de nuevos directorios con mkdir\n\nEstamos avanzando hacia el trabajo con archivos. Antes de comenzar, hagamos un directorio donde podamos almacenar todo lo que estamos usando para esta lección. Navega de regreso a casa escribiendo:\n\nsl ~\n\nHaremos un nuevo directorio dentro del directorio TUNOMBREDEUSUARIO. Para ello, utilizaremos el comando mkdir. Llama a tu directorio como quieras, pero trata de no usar espacios, ya que hacen que trabajar en línea de comandos sea más complicado de lo necesario. Voy a llamar a mi directorio “diversionConPowerShell”. Entonces yo escribo:\n\nmkdir diversionConPowerShell\n\n¿Viste cómo utilizo CamelCase para evitar los espacios?\n\nOtra forma común de hacer esto es insertando guión o guión bajo, como en diversion_con_power_shell. Sea cual sea el nombre de tu directorio, trata de evitar el uso de espacios. Una vez que has estado trabajando con PowerShell un poco, probablemente te encontrarás nombrando a tu nuevos archivos sin espacios por defecto. Este es un buen hábito ya que simplifica el trabajo en la línea de comandos, así como al trabajar con lenguajes de programación como Python.\n\nSin embargo, es probable que tengas un montón de archivos ya existentes con espacios en sus nombres. Para abrir estos en PowerShell, sólo tienes que utilizar comillas. Intentemos esto. Muevete a tu nuevo directorio utilizando:\n\nsl diversionConPowerShell\n\n(O como hayas nombrado tu directorio). Escribe:\n\ngci\n\nY verás que no hay nada aquí. ¡Eso es porque no has puesto nada en él! Vamos a poner un nuevo directorio dentro con mkdir. Llamaremos a este directorio “Directorio con un nombre largo y muchos espacios”. Debido a que el nombre tiene espacios en él, tendremos que usar comillas para crearlo. Tipo\n\nmkdir \"Directorio con un nombre largo y muchos espacios\"\n\nPresiona Enter. Ahora escribe:\n\ngci\n\nY verás tu nuevo directorio. Supongamos que queremos movernos a este directorio. Tendríamos que escribir sl \"Directorio con un nombre largo y muchos espacios\". No solo tomará un tiempo escribirlo sino que, si nos equivocamos, PowerShell no podrá encontrar nuestro directorio. En su lugar, escribe simplemente:\n\nsl d y entonces oprime la tecla de tabulador.\n\nVoilà! ¡PowerShell completa el nombre del directorio por nosotros, incluidas las comillas! El uso del tabulador para completar automáticamente te ahorrará mucho tiempo. Notarás que cuando PowerShell completó el nombre, también puso .\\ al principio del nombre del directorio. El punto es solo una abreviatura de directorio actual. Cuando escribes órdenes, PowerShell siempre asume que hay un .\\al principio -en otras palabras, que te estás refiriendo a algo en el directorio actual-. Por lo tanto, no es necesario que escribas esta parte, a menos que quieras que PowerShell busque en otro lugar lo que estás pidiendo que haga, en cuyo caso puedes escribir la ruta de ese directorio. Por ejemplo: C:\\directorio\\bla\\etc.\n\nPractiquemos un poco más con directorios antes de comenzar con archivos.\n\nUso de Explorerpara ver directorios en la GUI\n\nHasta ahora hemos hecho dos directorios. He mencionado anteriormente que “directorio” es solo otra palabra para “carpeta”. Puedes verlo al mirar tus nuevos directorios en la GUI. Windows llama a su GUI “Explorador de archivos” o simplemente “Explorador”. Podemos llamar al Explorador desde PowerShell utilizando el comando “Explorer”. Vuelve a la carpeta diversionConPowerShell con:\n\nsl ..\n\nAhora escribe:\n\nexplorer .\n\nRecuerda que el punto solamente significa “este directorio”, y no tienes que escribir con mayúscula “explorer” porque las mayúsculas no importan en PowerShell. Explorador debería haber abierto una ventana que muestra el contenido del directorio “diversiónConPowerShell”. Organiza tus ventanas para que puedas ver tanto la imagen en Explorador como en PowerShell. Ahora podrás ver que lo que haces en PowerShell aparece en Explorador. El comando “Explorer” es extremadamente útil. Básicamente, es como hacer doble clic en la GUI. De tal manera, puedes utilizarlo para abrir archivos y programas.\n\nEliminación con Remove-Item (rm)\n\nAhora que puedes ver los resultados de lo que haces en PowerShell, aprendamos a borrar cosas, por ejemplo, aquel directorio con el nombre largo. Primero crearemos algunos directorios más. Nómbralos “dir”, “dir1”, y “dir2”. Puedes crear los tres con un solo comando escribiendo:\n\nmkdir dir, dir1, dir2\n\nGenial, ¿no? Deberías ver tus tres nuevos directorios en la ventana abierta de Explorador (en la GUI).\n\nAhora vamos a deshacernos de ese directorio con el nombre largo. Para ello utilizaremos el cmdlet Remove-Item o rm. Tienes que ser muy cuidadoso con este cmdlet pues no transfiere los ítems borrados a la papelera o basurero de reciclaje, sino que los elimina de manera permanente, así que lo puedes considerar borrado sin posibilidad de recuperarlo. Escribe rm seguido de un espacio y el nombre largo de ese directorio del que nos queremos deshacer. Quizá quieras utilizar la tecla de tabulador para completar automáticamente el nombre. Sin embargo ten en cuenta que, como ahora tenemos varios directorios que comienzan con la letra “d”, tendrás que escribir algo más que la primera letra para que se complete automáticamente. Escribe:\n\nrm dire y entonces presiona la tecla de tabulación.\n\nDe manera alternativa, puedes escribir solamente rm y oprimir la tecla de tabulador varias veces para desplazarte por todos tus directorios. Si fuiste más allá del que te interesa, solamente oprime la tecla de mayúscula (shift) con tabulador para desplazarte hacia atrás.\n\nAntes de presionar la tecla Enter, yo observo con atención lo que escribí para asegurarme de que estoy borrando el ítem que quiero eliminar. Solo entonces hago clic en Enter.\n\nAdelante. Borra los otros tres directorios y observa cómo desaparecen del Explorador. Igual que con mkdir, puedes borrar los tres directorios de una sola vez con un comando. Inténtalo.\n\nAcabamos de eliminar los directorios dir, dir1 y dir2. Pero resulta que los necesitamos para el siguiente ejemplo. Así que vamos a crearlos de nuevo. Pero ahora, en lugar de escribir la instrucción, vamos a oprimir la flecha hacia arriba del teclado un par de veces (o las que sean necesarias). En algún punto deberás ver el comando que usaste para crear los tres directorios la primera vez. Una vez que encuentres esa línea pulsa Enter y se volverán a crear. De la misma manera que usar el tabulador (tab) para completar automáticamente, el uso de las flechas arriba y abajo para desplazarte por los comandos recientes te ahorrará mucho tiempo. Considera que no estamos deshaciendo el borrado que hicimos con anterioridad. Por el contrario, estamos usando un “acceso directo” para ingresar de nuevo un comando que hemos usado recientemente.\n\nEntender la estructura de árbol del sistema de archivos de tu computadora\n\nAhora debes tener tres directorios dentro de tu directorio diversionConPowerShell. Desplázate al interior del directorio dir (utiliza sl dir)\n\nEs importante entender la manera en la que tu computadora organiza las cosas. Observa la ruta a tu directorio actual. La ruta es todo lo que escribiste después del prompt. En mi caso es:\n\nC:\\Users\\Ted\\diverionConPowerShell\\dir\n\nTu ruta debe verse bastante similiar. Lo que representa esta ruta en realidad es una structura parecida a un árbol que sigue el ordenador para llegar al punto en el que estás. El tronco del árbol es C:, que es tu disco duro. En realidad, en la mayoría de las computadoras modernas C:es una partición de su disco duro. ¿Por qué se llama C? El ordenador asigna una letra a cada una de las unidades. Ay Bestán reservados para las dos unidades de disquettes que hace mucho tiempo utilizaban con frecuencia los usuarios para interactuar con los discos duros de sus computadoras. Aunque la mayoría de los ordenadores ya no los tienen, los nombres quedaron reservados.\n\nSi C: es el tronco del árbol, cada sección de la ruta después de C: es una rama, de la cual salen otras que están por encima de ella. Así, Users es una rama de C:, Ted es una rama más pequeña que sale de Users y así sucesivamente. También se puede usar la metáfora de la herencia en lugar de la de la botánica y llamar a cada rama un hijo del directorio por encima de ella. Este es el lenguaje más común para describir las relaciones entre los directorios (de ahí el cmdlet Get-ChildItem), pero nos quedaremos con la metáfora del árbol ya que, en la vida real, las relaciones de herencia pueden ser mucho más complejas que la extremadamente jerárquica estructura según la cual está organizada tu computadora.\n\nEntender que la ruta funciona como un árbol es importante para poder navegar por los directorios que no están inmediatamente por encima o por debajo de tu directorio actual. Sabemos que hay un directorio llamado “dir1”, y que éste directorio también está en el directorio “diverionConPowerShell”. Ve lo que sucede si intentas usar sl para pasar directamente a él escribiendo:\n\nsl dir1\n\n¡Esto arroja error!\n\n\n    \n\n    Error por intentar saltar entre ramas\n\n\n\n\nEl problema es que intentamos saltar de una rama a otra, y PowerShell sólo entiende nuestro movimiento si nos desplazamos a lo largo del árbol. Eso significa que primero tenemos que movernos hasta donde se encuentran las ramas de “dir1” y “dir”, y luego volver a “dir1”. Puedes hacerlo con un comando. Veamos si puedes imaginarlo antes de leer la siguiente línea.\n\nEl comando es:\n\nsl ..\\dir1\n\nEsto le indica a PowerShell subir un directorio a diversionConPowerShell, y luego bajar al directorio dir1.\n\nMoverse rápido con Push-Location(pushd) y Pop-Location (popd)\n\nAntes de trabajar con archivos vamos a probar los comandos pushy popd. Haz lo siguiente: ve hasta el tronco del árbol.C:.deben ser cuatro directorios arriba del directorio en el que estás, por lo cual podrías escribir:\n\nsl ..\\..\\..\\..\n\nEntonces cambia de nuevo a dir1. Pero en vez de escribir slantes de la ruta, escribe pushd. Como esto:\n\npushd users\\TUNOMBREDEUSUARIO\\diversionConPowerShell\\dir1\n\nAhora estarás en el directorio como si hubieras escrito sl al principio de la ruta. Pero aquí está la parte divertida. Ahora escribe:\n\npopd\n\nY pulsa Enter. Genial, ¿no? El comando pushd indica a PowerShell que se mueva a un directorio determinado desde tu directorio actual al que puedes ser devuelto con popd. En otras palabras, popd siempre te regresará al último directorio en el cual estuviste antes de usar pushd. Si quieres entender más sobre lo que está pasando, lee sobre la pila de llamadas en Wikipedia. El uso de pushd y popd es muy útil cuando te mueves con frecuencia entre dos directorios.\n\nTrabajar con archivos\n\nAhora que sabes cómo moverte a través del sistema de archivos de tu computadora desde la línea de comandos, vamos a trabajar manipulando archivos. Comenzaremos por aprender a crear nuevos archivos, copiarlos y moverlos.\n\nCrear archivos con New-Item (ni)\n\nPrimero, necesitamos algunos archivos para trabajar con ellos. Hagamos un nuevo documento de texto plano llamado “ejemplo.txt”. Navega hasta el directorio diversionConPowerShell -utiliza el tabulador para cada nombre de directorio que escribas y acelerar el proceso-, y escribe:\n\nni ejemplo.txt\n\nPresiona Enter. Después ecribe:\n\ngci\n\npara que confirmes, en efecto, que ahora tienes el archivo ejemplo.txt además de tus directorios. Necesitaremos varios archivos así que, adelante: crea ejemplo1.txt y ejemplo2.txt. No te sorprenderá saber que, incluyendo una coma, puedes hacer esto con un solo comando:\n\nni ejemplo1.txt, ejemplo2.txt\n\nCopiar y mover archivos con Copy-Item(cp) y Move-Item (mv)\n\nQuizá deberíamos haber puesto estos archivos en un directorio. Movámoslos. Pongamos ejemplo.txt en dir escribiendo:\n\nmv ejemplo.txt dir\n\nAhora escribe gci y verás que ejemplo.txt ha desaparecido. Entra a dir (sl dir) y escribe gci para que compruebes que ¡ahora está ahí! También puedes hacer esto sin cambiar de directorio escribiendo gci dir desde el directorio diversionConPowerShell. Regresa a diversionConPowerShell y mueve ejemplo1.txt a dir1 y ejemplo2.txt a dir2.\n\nTambién podemos utilizar mv para renombrar ítems. Usa sl para moverte a dir. Escribe gci y deberás ver tu archivo ejemplo.txt. Es un nombre aburrido, así que llamémosle benjamin.txt. Escribe:\n\nmv ejemplo.txt benjamin.txt\n\nUtiliza gci de nuevo para confirmnar que tu documento ahora se llama bejamin.txt.\n\nTe sorprenderá que el mismo cmdlet se utiliza tanto para mover como para renombrar archivos. De hecho, la operación es la misma. En ambos casos le estás diciendo a la computadora que cambie el “nombre” de la ubicación del archivo, es decir, que cambie la ruta que sigue para encontrar el archivo. En el primer ejemplo, la ruta comenzó como:\n\nC:\\Users\\Ted\\diversionConPowerShell\\ejemplo.txt\n\nY luego cambió a:\n\nC:\\Users\\Ted\\diversionConPowerShell\\dir\\ejemplo.txt\n\nEn el segundo ejemplo, la ruta cambió de:\n\nC:\\Users\\Ted\\diversionConPowerShell\\dir\\ejemplo.txt\n\na:\n\nC:\\Users\\Ted\\diversionConPowerShell\\dir\\benjamin.txt\n\nDicho de otro modo, en ambos ejemplos mv solamente cambia la ruta. No te preocupes si esto no te hace sentido por ahora. Sólo ten cuidado de escribir correctamente las rutas cuando utilices mv porque, si no lo haces, puedes cambiar el nombre cuando lo que quieres es mover el archivo, o viceversa.\n\nAdemás de mover archivos, también quisiéramos copiarlos o eliminarlos. Para copiar archivos, utilizamos el cmdlet Copy-Item o cp. Hagamos dos copias de benjamin.txt y llamémoslas steven.txt y susie.txt.\n\ncp benjamin.txt steven.txt\n\ncp benjamin.txt susie.txt\n\nTambién podemos eliminar estos dos nuevos archivos con rm, al igual que hicimnos con los directorios. Intenta hacerlo con un solo comando. Como siempre, ten cuidado cuando utilices rm.\n\nÉste es el comando:\n\nrm steven.txt, susie.txt\n\n¡Adiós Steven y Susie!\n\n\n    \n\n    Mover, copiar y borrar\n\n\n\n\nHaciendo más\n\nBien, ahora ya podemos navegar, crear archivos, moverlos y borrarlos en PowerShell. Nos sentimos muy bien, muy geeks porque podemos hacer estas cosas desde la línea de comandos. Pero esto no es realmente útil ya que podíamos hacer estas cosas muy fácilmente con la interfaz gráfica de usuario. Ahora que sabemos estos fundamentos, sin embargo, podemos comenzar a aprender comandos algo más complejos que pueden ser útiles en nuestro trabajo como humanistas digitales.\n\nEscribir en archivos con Write-Output (write, echo) y redirección\n\nTenemos un archivo vacío en nuestro directorio dir. Eso no es muy interesante, así que vamos a añadir un poco de contenido. Podríamos abrir el archivo en el Bloc de notas y modificarlo de esa manera. Pero también podemos añadirle contenido con órdenes desde la línea de comandos. El cmdlet que utilizamos para esto es Write-Output, o simplemente write.\n\nPrueba con esto:\n\nwrite \"La técnica de la reproducción separa el objeto reproducido del dominio de la tradición.\"\n\nPowerShell debe imprimir esta frase directamente en la ventana de la línea de comandos. Eso es todo lo que hace write. Le dice a PowerShell “Imprime lo que yo escriba”. Eso no es muy útil dado que queremos poner este texto en nuestro documento. Para ello, usaremos algo llamado redirección.\n\nRedirección es una forma de decirle a PowerShell que tome los resultados de un comando y los coloque en algún lugar que no sea en la ventana de PowerShell. Para redirigir un comando, ponemos un paréntesis angular derecho (&gt;) entre el comando y el lugar donde queremos que vaya su salida. En este caso, queremos que la salida de nuestro comando write termine en benjamin.txt. Así que usamos la flecha hacia arriba para recuperar la declaración, y añadimos &gt; benjamin.txt al final. Todo el asunto debería ser así:\n\nwrite \"La técnica de la reproducción separa el objeto reproducido del dominio de la tradición.\" &gt; benjamin.txt\n\nCuando presiones Enter parecerá que nada sucede. Esto se debe a que la instrucción write fue redirigida. Para ver qué es lo que realmente ocurrió, usa gci para ver el contenido de tu directorio. Ten en cuenta que la longitud de benjamin.txt ya no es 0. ¡Esto es porque acabamos de poner texto en él!\n\nLeer archivos con Get-Content (gc, cat)\n\nYa que gci nos muestrta que hay algo en el archivo, sería bueno poder ver qué frase pusimos en él. Podríamos hacerlo con el comando: notepad benjamin.txt, lo que abriría el documento en el Bloc de notas. Pero también hay un cmdlet para imprimir el contenido del archivo en PowerShell que se llama Get-Content. Escribe:\n\ngc benjamin.txt\n\n¡Y ahí está tu frase!\n\nUstilizar gc es útil por sí mismo, pero no resulta tan interesante. Si lo combinamos con la redirección, podemos hacer mucho más. Para empezar, podemos poner el contenido de un archivo en otro, casi igual que copiar un archivo. Ya sabes cómo hacerlo con cp. Haz una copia de benjamin.txt llamada benjamin1.txt usando cp. Ese comando se verá así:\n\ncp benjamin.txt benjamin1.txt\n\nAhora haz un archivo benjamin2.txt con el mismo contenido que benjamin.txt, pero usando gc y redirección. Intenta averiguar cómo se hace.\n\nEn caso de que no lo logres, aquí está la respuesta:\n\ngc benjamin.txt &gt; benjamin2.txt\n\nPor supuesto que esto es solamente una forma más engorrosa de hacer lo que ya podemos hacer con cp. Pero la diferencia en estos métodos es sustancial porque al usar gc podemos agregar información a un archivo de texto sin reemplazar lo que ya está allí, y también podemos obtener el contenido de varios archivos de texto y ponerlos en otro.\n\nEn primer lugar vamos a aprender a adjuntar. Necesitamos algo que añadir a texto así que hagamos un nuevo archivo llamado siguiente.txt y escribamos la frase “Haciendo muchas reproducciones sustituye una pluralidad de copias para una existencia única.” Podríamos hacer nuestro archivo primero con ni, pero no es necesario. Si le decimos a PowerShell que escriba en un archivo que no está en tu directorio, lo creará para nosotros. Así podemos simplemente escribir:\n\nwrite \"Haciendo muchas reproducciones sustituye una pluralidad de copias para una existencia única.\" &gt; siguiente.txt\n\nUtiliza gcpara comprobar que se creó siguiente.txt y que es realmente lo que queremos que sea.\n\nAhora vamos a agregar el contenido de siguiente.txt a benjamin.txt usando gcy redirección. Parece simple, ¿verdad? Inténtalo con este comando:\n\ngc siguiente.txt &gt; benjamin.txt\n\nLuego comprueba lo que sucedió con el comando gc benjamin.txt. Verás que efectivamente pusiste el contenido de siguiente.txt en benjamin.txt, pero has reemplazado el contenido que ya estaba allí y ¡esto no es lo que queríamos hacer!\n\nAl usar &gt;, le ordenamos a PowerShell que pusiera el contenido de un texto en otro y sobrescribió lo que ya estaba allí. Podemos arreglar esto usando &gt;&gt; para nuestro redireccionamiento en lugar de un solo &gt;. Esto le dice a PowerShell que agregue la nueva información. Prueba esto:\n\ngc siguiente.txt &gt;&gt; benjamin1.txt\n\nUtiliza gc para comprobar que benjamin1.text ahora tiene ambas frases.\n\n\n    \n\n    La diferencia entre &gt; y &gt;&gt;\n\n\n\n\nAhora veamos cómo obtener el contenido de varios archivos al mismo tiempo.\n\nTrabajar con varios archivos a la vez usando caracteres comodín (*)\n\nAhora debes tener cuatro archivos en tu directorio, cada uno con una o dos frases del ensayo sobre el arte de Walter Benjamin. Es posible que hayas perdido la pista de lo que está exactamente en ellos. Utilicemos gc para comprobar el contenido.\n\nPodríamos ver cada uno individualmente. Pero como puedes haber adivinado se puede mostrar el contenido de los cuatro archivos con un solo comando. Escribe:\n\ngc benjamin.txt, benjamin1.txt, benjamin2.txt, siguiente.txt\n\ny obtendrás la frase impresa tres veces. Podemos hacerlo aún más rápidamente. Inténtalo:\n\ngc *.txt\n\nEl resultado será exactamente el mismo. Lo que hace *.txt es decirle a PowerShell que encuentre todo lo que termine con .txt. El * se llama comodín, y se puede usar para reemplazar cualquier parte de un nombre de archivo. Escribe gc ben* y obtendrás sólo los textos que comiencen con “ben”. Dado que los únicos archivos de este directorio son los cuatro que queremos, puedes incluso escribir gc * y obtener el contenido que nos interesa haciendo que PowerShell juestre todo lo que está en el directorio.\n\nBúsquedas con Select-String (sls)\n\nPor supuesto que no siempre queremos ver todo el contenido sino que querramos encontrar contenido específico. Al utilizar *, podemos buscar varios archivos al mismo tiempo. Una de nuestras oraciones tenía algo acerca de “existencia única”, ¿no? ¿Donde fue eso? Podemos usar el cmdlet Select-String para buscar fragmentos específicos de texto. Escribe:\n\nsls \"existencia única\" *.txt\n\ny PowerShell arrojará todas las líneas que contengan esa cadena de caracteres de cualquier archivo de nuestro directorio que termine en .txt.\n\nEl uso de sls en archivos tan pequeños como los nuestros no nos ahorrará mucho tiempo comparado con el que ocuparíamos si leyéramos los archivos nosotros mismos. Pero el uso de este cmdlet con un mayor número de archivos, más largos, puede ser extraordinariamente útil.\n\nBucles infinitos y abortar procesos con control-c\n\nVeamos una tarea más útil que podemos lograr combinando gc, comodines y redirección. Supongamos que tenemos muchos archivos diferentes que queremos combinar en un nuevo archivo, por ejemplo, porque hemos descargado cientos de letras de canciones que necesitamos analizar y  agrupar las de un solo artista en un archivo único. Aunque podríamos hacer esto especificándolos todos, es decir, gc texto1, texto2, texto3&gt; nuevotexto, al tener cientos de textos puede resultar una tarea bastante engorrosa. Los comodines sirven para evitar esto.\n\nVamos a concatenar nuestros cuatro textos y colocar el resultado en un quinto texto. Quizá usar *.txt puede parecer un auxiliar práctico. Estamos a punto de hacer algo tonto, así que por favor, lee el siguiente párrafo antes de escribir este comando!\n\nIntentemos\n\ngc *.txt &gt; granben.txt\n\nParecerá que tu computadora no hace nada. Pero, a diferencia de otras veces cuando tu computadora aparenta que no ha hecho nada, esta vez el prompt del símbolo del sistema no vuelve a aparecer. Si intentas escribir otro comando no sucederá nada. Esto es porque PowerShell todavía está trabajando en tu último comando. A medida que haces más y más cosas complicadas con PowerShell, es algo que a veces sucede -¡estás haciendo sudar a tu computadora!-. Pero, en este caso, PowerShell nunca dejará de trabajar con este comando ya que está en un bucle infinito. Afortunadamente, puedes abortar esta tarea con:\n\ncontrol-c\n\nLa utilidad de control-c es grande, ya que a veces puedes quedar atrapado accidentalmente en un bucle infinito o, simplemente, puedes hartarte de esperar a que tu computadora haga ciertas tareas extremadamente largas.\n\n¿Cómo nos quedamos atrapados en ese bucle? Le dijimos a PowerShell que pusiera todos los archivos que terminaran en .txt en un nuevo archivo que terminara en .txt. Dado que ese nuevo archivo caía bajo la rúbrica de archivos que el equipo debía concatenar y agregar a granben.txt, lo añadió. Y luego, ya que tenía un archivo .txt con nuevo contenido, lo añadió también. Este es un excelente ejemplo de algo que a menudo olvidamos sobre nuestras computadoras: no son inteligentes. Son extremadamente potentes pero carecen absolutamente de sentido común. Los humanos miramos las instrucciones e intentamos interpretarlas. “No puede significar, para mí, agregar el contenido del texto final de nuevo en sí mismo una y otra vez para siempre.” Los ordenadores, por otro lado, hacen exactamente lo que les decimos, sin importar lo ilógicos que sean nuestros mandamientos. A medida que adquieras experiencia trabajando con la línea de comandos, te sentirás desconcertado por las interpretaciones excesivamente literales de sus comandos, pero también aprenderán a darle instrucciones que puede seguir. Los bucles infinitos deben evitarse a toda costa, pero se producirán, y cuando lo hagan, recuerda: control-c.\n\nEspecificación de cmdlets con parámetros\n\nHemos visto que tu computadora necesita que le digan cosas de manera muy exacta. Afortunadamente, PowerShell proporciona métodos para refinar los cmdlets añadiendo parámetros.\n\nVeamos un ejemplo: utiliza gci para comprobar que tienes cinco archivos en tu directorio. Uno de ellos, granben.txt, es muy grande. Escribe:\n\ngc granben.txt\n\nPowerShell comenzará a descargar una cantidad excesiva de texto en la pantalla. Es posible que quieras interrumpir el proceso con control-c, pero esto no es un bucle infinito, sólo se trasta de un archivo muy grande, por lo que puedes esperar a que todo se imprima, sólo que tardará un tiempo. Al final, puedes usar el cmdlet clear si te molesta el gran bloque de texto en la pantalla.\n\nLo que queremos comprobar es que “granben.txt” está compuesto por las líneas de los otros textos, repetidas una y otra vez. Podemos hacer esto mirando sólo al principio y al final, y para ello, agregamos un parámetro a nuestro cmdlet.\n\nIntroduce esto:\n\ngc granben.txt -totalcount 10\n\nVerás las primeras 10 líneas de tu texto. Asegúrate de incluir el guión, ya que de lo contrario PowerShell no sabrá que -TotalCount es un parámetro. Ahora escribe:\n\ngc granben.txt -tail 10\n\ny verás las últimas 10 líneas. Lo que hemos hecho es especificarle a nuestro cmdlet gc los parámetros -totalcount y -tail. Casi todos los cmdlets pueden ser refinados añadiendo parámetros como este. Pero, ¿cómo sabemos qué parámetros están disponibles?\n\nMás información sobre Get-Help\n\nPowerShell no espera que memorices todos los parámetros posibles para todos los cmdlets^. En su lugar, proporciona una forma sencilla de enumerarlos utilizando el cmdlet Get-Help. Escribe\n\nGet-Help gc\n\ny obtendrás una pantalla que se ve así:\n\n\n    \n\n    Páginas de ayuda de Get-Content\n\n\n\n\nTu página puede ser ligeramente distinta, pero la parte importante para mirar en este momento es la sección llamada “SYNTAX”. Esta nos muestra todos los parámetros que podemos agregar a Get-Content. Si estás tratando de recordar el nombre exacto de un parámetro que has utilizado antes, esta ayuda será suficiente. Sin embargo, no nos dice lo que realmente hacen los parámetros.\n\nAfortunadamente, el mismo Get-Help tiene parámetros y, agregando -online al cmdlet Get-Help, le indicas a PowerShell que pida a tu navegador abrir una página en el portal TechNet de Microsoft que explica todos los parámetros (en inglés). Escribe:\n\nGet-Help gc -online\n\n\n    \n\n    La página de ayuda en línea para Get-Content\n\n\n\n\nAhí podemos ver la descripción completa de los parámetros -TotalCount y -Tail.\n\nSolución del problema de bucle infinito con el parámetro -exclude\n\nObserva de nuevo la ayuda de Get-Content y verás que uno de los parámetros es -exclude. Esto suena prometedor para tratar con nuestro problema del bucle infinito. La descripción en línea dice: Omite los elementos especificados. El valor de este parámetro califica el parámetro de ruta. Introduzca un elemento o patrón de ruta, como “*.txt”. Los comodines están permitidos.” El “parámetro de ruta” es, normalmente, lo que escribes inmediatamente después de tu cmdlet. Indica a PowerShell dónde se va a aplicar el cmdlet. Cuando escribimos gc benjamin.txt, benjamin.txt es la ruta. En realidad, es una abreviatura de .\\Benjamin.txt, que a su vez es una abreviatura de C:\\Users\\TUNOMBREDEUSUARIO\\diversionConPowerShell\\dir\\benjamin.txt. Esa línea le dice a su computadora el camino a seguir a través de la estructura de tu sistema de archivos, similar a la de un árbol, para encontrar el archivo que deseas. Entonces, lo que la ayuda nos está diciendo es que podemos omitir elementos específicos de nuestro cmdlet gc añadiendo el parámetro -exclude y luego ingresando la ruta que queremos que excluya. Podemos utilizar esto para tomar el contenido de todos nuestros archivos .txt y ponerlos en un nuevo archivo sin crear un bucle infinito. Trata de averiguar qué escribir, utilizando lo que hicimos con -totalcount y -tail como referencia.\n\nEsto es lo que yo hice. Primero eliminé mi granben.txt actual con rm. Aunque esto no es realmente necesario, ya que al usar un solo &gt; en el rediccionamiento reemplazaría el contenido actual de todos modos, pero es agradable tener un inicio limpio. Entonces escribí:\n\ngc *.txt -exclude granben.txt &gt; granben.txt\n\nVoilà!\n\nA lo largo de este proceso, hemos estado agregando textos juntos o concatenándolos. Puedes obtener más información sobre concatenación en Wikipedia, y si quieres ver algunos ejemplos más de concatenación usando PowerShell, echa un vistazo a esta entrada de blog (en inglés), que te llevará al maravilloso mundo de las variables, algo más allá del alcance de este tutorial, pero acerca de las que vale la pena aprender.\n\nObtener más provecho de los cmdlets con Piping\n\nTenemos ahora cinco documentos en nuestro directorio. Con el fin de poder hacer cosas realmente útiles con ellos necesitamos una herramienta más: canalización. Ésta es una especie de redirección, pero en lugar de decirle a PowerShell que coloque los resultados de un cmdlet en otro lugar, le dice que tome la salida de un cmdlet y lo use como entrada para otro. Donde usamos &gt; para la redirección, para las canalizaciones usamos |.\n\nVamos a obtener aún mayor rendimiento de gc, canalizando los resultados al cmdlet measure-object (o simplemente measure). Este último cmdlet tiene varias propiedades. Para nuestro propósito, lo usaremos para obtener el número de líneas, palabras y caracteres en nuestros archivos agregando los parámetros -line, -word y -character, o simplemente -l, -w, -c. (Con los parámetros, sólo necesitas escribir el nombre adecuado para identificar el parámetro en cuestión. Utiliza Get-Help para averiguar cuál será para un determinado cmdlet).\n\nEscribe esto:\n\ngc benjamin.txt | measure -l -w -c\n\nLo que debes obtener es un recuento de las líneas, palabras y caracteres del texto. Por supuesto, podrías hacer esto fácilmente con tu procesador de textos. Sin embargo, el poder que te da trabajar en línea de comandos es el de ser capaz de manipular muchas cosas a la vez y especificar lo que quieres hacer con mucha mayor precisión. En este ejemplo significa que podemos contar palabras en varios de nuestros archivos a la vez, y que podemos agregar parámetros adicionales para especificar exactamente cómo queremos contarlos.\n\nObtén el recuento de líneas, palabras y caracteres de todos los archivos en el directorio. No debería sorprendernos que el comodín (*) pueda ser también de gran ayuda. Por ejemplo, puedes escribir:\n\ngc *.txt | measure -l -w -c\n\nCon nuestros cinco pequeños archivos esto todavía no resulta muy vistoso, pero habrías perdido más tiempo usando el procesador de textos. También podríamos hacerlo con un directorio que contenga miles de archivos largos. También podemos controlar nuestras acciones con mayor precisión con parámetros adicionales. Utiliza Get-Help measure para ver los parámetros a tu disposición. Podríamos ir a la ayuda en línea para aprender más sobre ellos, pero por ahora vamos a usar uno que se explica por sí mismo como un ejemplo que consiste en ignorar los espacios en blanco: -IgnoreWhiteSpace.\n\nUtiliza la flecha hacia arriba para recuperar tu último comando y agrega -ignorewhitespace al final. También puedes escribir -ig. Ten en cuenta que -i solo no es suficiente, ya que no diferencia el parámetro -IgnoreWhiteSpace del parámetro -InputObject, como te lo indicará un útil mensaje de error si lo intentarás. Verás el mismo recuento pero con menos caracteres, porque esta vez PowerShell no contó los espacios. La ventaja de la precisión es clara sobre el uso de un procesador de textos, donde es difícil determinar si se ignora o no el espacio en blanco en primer lugar, dejando de lado las posibilidades de cambiar funciones según tus necesidades.\n\nUtilización de herramientas de línea de comandos y ejecución de secuencias de comandos en Python\n\nLa razón más importante para familiarizarse con el uso de la línea de comandos no es la mayor precisión o capacidad para trabajar con archivos, si bien estas características son útiles. Su importancia radica en que permite el acceso a muchas herramientas adicionales, como se mencionó en la introducción. Cuando se configura PowerShell para trabajar con algunas de estas herramientas, puede tener problemas ya que, a veces, Windows dispone las rutas incorrectamente. La solución a este problema requiere de una configuración correcta de las variables de entorno, un tema que va más allá del alcance de este tutorial. Afortunadamente, hay mucha infortmación disponible en línea y con un poco de búsqueda darás con la solución que necesitas. Debido a que muchas lecciones de The Programming Historian en español requieren que utilices Python, echaremos un vistazo brevemente a la configuración para Python. Una vez hecho esto, estarás menos intimidado por las instrucciones para establecer variables de entorno para otros programas.\n\nSi aún no tienes Python, o si te preguntas por qué deberías usarlo, consulta el tutorial de Python aquí en The Historian en español. En dicho tutorial, aprenderás a configurar Python para ejecutar secuencias de comandos directamente en un editor de texto. Pero, generalmente, será muy útil poder ejecutar scripts desde la línea de comandos. Para ello, necesitamos establecer una variable de entorno. Primero, necesitas saber el nombre del directorio donde Python está instalado en tu computadora. Introduce sl C:\\ y luego utiliza gci. Deberías ver un directorio llamado “Python” con el número de versión al final. En mi computadora, el directorio es “Python27”. Ahora le ordenamos a Windows que cree una variable de ruta (Path) que apunte a ese directorio introduciendo esto en PowerShell, reemplazando “Python27” por el nombre del directorio en tu computadora:\n\n[Environment]::SetEnvironmentVariable(\"Path\", \"$env:Path;C:\\Python27\", \"User\")\n\nEsto le dice a Windows: “Oye, la ruta para Python es: C:\\Python27”. Si quieres entender exactamente cómo funciona esto, mira esta página (en inglés) en el portal TechNet de Microsoft (el mismo portal que utilizas en línea con Get-Help).\n\nUna vez que hayas corrido el comando anterior, sal de PowerShell y vuelve a iniciarlo. Entonces deberías poder abrir el intérprete de Python escribiendo python en PowerShell. Para ejecutar scripts, simplemente escribe python seguido de la ruta del script que quieres. Es más fácil navegar primero al directorio que contiene el script, y luego simplemente escribir python nombre-de-script.py.\n\nAhora ya estás preparado para ejecutar scripts de Python desde la línea de comandos.\n\nConclusión\n\nEn este tutorial has aprendido algunos de los conceptos básicos para trabajar con PowerShell, la interfaz de línea de comandos de Windows. Ya sabes lo suficiente para usar PowerShell para muchas de las tareas cotidianas que haces en tu computadora y yo recomendaría usarlo para eso. Al principio puede resultar más difícil copiar un archivo y moverlo a un nuevo directorio desde la línea de comandos, pero cuanto más practiques más natural será. Eventualmente, te encontrarás cómodamente trabajando en PowerShell, y serás capaz de hacer muchas tareas más fácilmente de esta manera.\n\nAunque sólo hemos dado un vistazo de lo que puede hacer PowerShell, ahora tienes suficientes conocimientos básicos para aprender a hacer más cosas. Hay muchos recursos útiles en línea y los puedes hacer tuyos con Google. También es útil saber que muchas discusiones sobre el uso de la línea de comandos se basarán en Unix y otros sistemas *nix. En la mayoría de los casos, si simplemente escribes en un buscador los nombres de los comandos que estás utilizando junto con “PowerShell”, encontrarás el cmdlet correspondiente.\n\nCuanto más utilices PowerShell más fácil será descubrir capacidades que ni siquiera sabías que tenía tu computadora. Eventualmente, notarás cómo el uso de la GUI te ha restringido en el uso de la potencialidad de tu máqiuna. No dejarás de usar la GUI, pero te encontrarás iniciando PowerShell cada vez con mayor frecuencia para liberarte de estas limitaciones y utilizar tu computadora de manera más completa. Tu computadora es como una navaja de bolsillo. La GUI sólo te permite abrir algunas cuchillas; ¡pero con la línea de comandos puedes abrirlas todas!\n\nReferencia rápida\n\nEsta tabla sirve como una referencia rápida a todos los cmdlets mencionados en esta lección. La primera columna muestra el nombre real; el segundo muestra la abreviatura que normalmente se escribe. El equivalente de Bash muestra el comando más similar en Bash. A menos que este comando esté entre paréntesis, también se puede utilizar en PowerShell como un alias para el cmdlet correspondiente. Para obtener una explicación más completa de cualquiera de los cmdlets, utiliza Get-Help con el parámetro -online (por ejemplo, Get-Help Get-ChildItem -online).\n\n\n  \n    \n      Cmdlet\n      Alias\n      Bash Equivalent\n      Description\n    \n  \n  \n    \n      Get-ChildItem\n      gci\n      ls\n      Enlista los directorios y archivos en la ubicación actual.\n    \n    \n      Set-Location\n      sl\n      cd\n      Cambia al directorio en la ruta de acceso dada. Si escribes .. en lugar de una ruta te moverá hacia arriba un directorio.\n    \n    \n      Push-Location\n      pushd\n      pushd\n      Cambiar al directorio.\n    \n    \n      Pop-Location\n      popd\n      popd\n      Regresa al directorio previo despues de usar pushd\n    \n    \n      New-Item\n      ni\n      (touch)\n      Crea un nuevo ítem. De no utilizarse un parámetro, el ítem será un archivo por defecto. El uso de mkdir es una abreviatura para incluir el parámetro -ItemType dir.\n    \n    \n      mkdir\n      none\n      mkdir\n      Crea un nuevo directorio. (Ver New-Item.)\n    \n    \n      Explorer\n      none\n      (open)\n      Abre algo utilizando el Explorador de archivos (la GUI)\n    \n    \n      Remove-Item\n      rm\n      rm\n      Borra algo… ¡de manera permanente!\n    \n    \n      Move-Item\n      mv\n      mv\n      Mueve algo. Necesita dos argumentos. Primero un nombre de archivo (i.e. su ruta actual), luego la ruta de nueva nueva locación (incluido el nombre que debe tener ahí). Si no se cambia la ruta, puede usarse para renombrar archivos.\n    \n    \n      Copy-Item\n      cp\n      cp\n      Copia un archivo en una nueva ubicación. Requiere los mismos argumentos que mover, pero mantiene el archivo original en su ubicación.\n    \n    \n      Write-Output\n      write\n      echo\n      Exporta lo que escribas. Utiliza la redirección para enviarlo a un archivo. La redirección con &gt;&gt; añadirá texto al archivo en lugar de sobrescribir el contenido.\n    \n    \n      Get-Content\n      gc\n      cat\n      Obtiene el contenido de un archivo y lo imprime en la pantalla. La adición del parámetro -TotalCount seguido de un número x sólo imprime las primeras x líneas. Añadiendo el parámetro -Tail seguido de un número x sólo imprime las x líneas finales.\n    \n    \n      Select-String\n      sls\n      (grep)\n      Busca contenido específico.\n    \n    \n      Measure-Object\n      measure\n      (wc)\n      Obtiene información estadística sobre un objeto. Utiliza Get-Content y dirige la salida a Measure-Object con los parámetros -line, -word y -character para obtener información sobre el recuento de líneas, palabras o caracteres.\n    \n    \n      &gt;\n      none\n      &gt;\n      Redirección. Pone la salida del comando a la izquierda de &gt; en un archivo a la derecha de &gt;.\n    \n    \n      |\n      none\n      |\n      Canalizar. Toma la salida del comando a la izquierda y la usa como entrada para el comando a la derecha.\n    \n    \n      Get-Help\n      none\n      man\n      Obtiene el archivo de ayuda de un cmdlet. La adición del parámetro -online abre la página de ayuda en TechNet.\n    \n    \n      exit\n      none\n      exit\n      Salir de PowerShell\n    \n  \n\n\nEn este tutorial aprenderás las bases de PowerShell de Windows, la interfaz de línea de comandos estándar de computadoras con Windows.\n\n"
  },


  {
    "id": 24,
    "url": "http://localhost:4000/es/lecciones/retirada/introduccion-control-versiones-github-desktop",
    "title": "Introducción al control de versiones con GitHub Desktop",
    "body": "\nIntroducción al control de versiones con GitHub Desktop\n\nContenidos\n\n\n  Objetivos de la lección\n  Programa necesario\n  ¿Qué es un control de versiones y por qué debería utilizarlo?    \n      ¿Por qué un control de versiones para documentos?\n    \n  \n  Diferencias entre Git y GitHub    \n      ¿Por qué no utilizar Dropbox o Google Drive?\n      Algunos proyectos académicos que utilizan control de versiones\n    \n  \n  Cómo empezar    \n      Una breve nota sobre la terminología\n      Regístrate con una cuenta en GitHub\n      Instala GitHub Desktop\n    \n  \n  Control de versiones y texto plano    \n      Editores de texto\n      Crear un documento\n      Añadir un documento\n      Anotar cambios\n      Describir anotaciones\n      Cómo crear un buen repositorio\n      Cómo publicar tu repositorio\n      Cómo hacer cambios remotamente\n    \n  \n  Gestionar conflictos\n  Control de versiones y flujo de trabajo con texto plano\n  Más recursos\n\n\nEsta lección fue escrita teniendo en cuenta una versión antigua de Github Desktop para OS X. Desde su publicación, Github ha lanzado una nueva versión de Github Desktop con cambios significativos en la interfaz. El tutorial solo cubre la la antigua versión para OS X, que ha pasado a denominarse “Github Desktop Classic” y que puede descargarse desde aquí.\n\n\nObjetivos de la lección\n\nCon esta lección aprenderás el funcionamiento básico de los sistemas de control de versiones, entenderás por qué son útiles y te familiarizarás con GitHub Desktop, un control de versiones de documentos en formato de texto plano. Al finalizar la lección, serás capaz de entender:\n\n\n  qué es un control de versiones y por qué puede ser útil\n  las diferencias entre Git y GitHub\n  cómo utilizar un control de versiones con la interfaz gráfica ‘GitHub Desktop’\n  qué otros recursos pueden ayudarte a implementar un control de versiones para investigar.\n\n\nPrograma necesario\n\nActualmente, GitHub Desktop Classic está disponible solamente para Mac. Si utilizas Linux probablemente estarás familiarizado con la línea de comandos y serás capaz de utilizar la versión de línea de comandos de Git.\n\n¿Qué es un control de versiones y por qué debería utilizarlo?\n\nAntes de ponerse manos a la obra, conviene comprender qué es un control de versiones y por qué puede ser útil para tu investigación. En términos generales, un control de versiones consiste en tomar instantáneas de tus archivos a lo largo del proceso de creación. La mayoría de personas, de hecho, trabajan con algún sistema de control de versiones para gestionar sus archivos. A menudo, el control tiene lugar guardando distintas versiones de un mismo archivo. Por ejemplo, no es raro encontrarnos ante un directorio que contiene los siguientes archivos:\n\nmidocumento.txt\nmidocumentoversion2.txt\nmidocumentoconrevisiones.txt\nmidocumentofinal.txt\n\nEsta forma de nombrar los archivos puede ser más o menos sistemática. Si añadimos fechas, puede ser un poco más fácil seguir los cambios:\n\nmidocumento2016-01-06.txt\nmidocumento2016-01-08.txt\n\nAunque este método sea un poco más claro, sigue habiendo problemas. En primer lugar, este método no registra o describe qué cambios se han producido entre uno y otro archivo guardado. Pueden ser pequeñas correcciones de erratas, o bien tratarse de la reescritura de pasajes enteros o incluso de una modificación mayor, por ejemplo, de la estructura del documento. Además si quieres revertir alguno de estos cambios, tendrás que averiguar cuándo se hizo el cambio y deshacerlo.\n\nCon un control de versiones se persigue solucionar este tipo de problemas mediante la puesta en marcha de un registro sistemático de cambios en los archivos. A grandes rasgos, puede afirmarse que el control de versiones realiza instantáneas de los archivos a lo largo del tiempo. Estas instantáneas documentan el momento en que fueron tomadas pero también qué cambios tuvieron lugar entre cada una de ellas, lo cual permite recuperar una versión más antigua de tu archivo. A partir de aquí se abre un sinfín de posibilidades gracias al control de versiones.\n\n¿Por qué un control de versiones para documentos?\n\nA medida que en nuestras investigaciones utilizamos herramientas digitales y almacenamiento en formato digital, se vuelve relevante reflexionar sobre cómo optimizar la gestión de nuestros datos. Más aún, el control de versiones puede ser indispensable si tenemos intención de colaborar con otros investigadores. Aunque el control de versiones fue diseñado en sus orígenes para tratar archivos de código, creemos que la gestión de documentos también se beneficiaría. La lección que proponemos no cubre todas las ventajas del control de versiones pero al finalizarla podrás llevar a cabo las siguientes tareas:\n\n\n  rastrear el desarrollo y los cambios de tus documentos\n  registrar los cambios que has hecho de una manera que puedas entender posteriormente\n  experimentar con versiones distintas de un documento al mismo tiempo que conservas la más antigua\n  fusionar dos versiones de un documento y administrar los conflictos existentes entre distintas versiones\n  revertir cambios y volver atrás gracias al historial de versiones anteriores de tu documento\n\n\nEn concreto, el control de versiones es útil para facilitar la colaboración. De hecho, una de las razones que explican el origen del control de cambios es que permitera a varias personas trabajar al mismo tiempo en un proyecto de considerables dimensiones y utilizar Git para administrar las fuentes del núcleo Linux. Utilizar un control de versiones favorece la colaboración debido a su flexibilidad. Por ejemplo, dos personas pueden trabajar en un mismo documento al mismo tiempo y ‘fusionar’ los cambios. Si existe un ‘conflicto’ entre las dos versiones, el sistema de control permitiría al usuario ver el conflicto y decidir cómo fusionar las dos versiones dando lugar a una ‘tercera’ versión. De esta manera, conservarías la ‘historia’ del documento, es decir, las versiones anteriores y, en consecuencia, podrías revertir el proceso eligiendo una versión más antigua.\n\nNo es necesario, sin embargo, poner en marcha un control de versiones para todos tus documentos. En algunas ocasiones resulta muy útil; por ejemplo, para escribir artículos, libros o tesis doctorales.\n\nLa implementación del control de versiones que proponemos en esta lección está pensada para que los documentos sean públicos. No obstante, puedes utilizar un control de versión y mantener tus documentos ocultos de manera permanente o bien hasta que decidas publicarlos en línea.\n\nDiferencias entre Git y GitHub\n\nAunque a veces se utilizan como sinónimos, Git y GitHub no son lo mismo. Git es un sistema específico diseñado para controlar versiones en un entorno Linux; fue desarrollado por Linus Torvalds con el objetivo primordial de gestionar código fuente. Por supuesto, existen otros controles de versiones pero su uso no está tan difundido. Git puede referirse tanto a una forma de controlar versiones como al programa utilizado para llevar a cabo dicha tarea.\n\nEn cambio, GitHub es una compañía que aloja repositorios Git (más detalles abajo) y que proporciona un programa específico para usar Git. Entre las modalidades de uso, destaca el programa ‘GitHub Desktop’, sobre el que trata este tutorial. Actualmente, si tenemos en cuenta el número de proyectos y de usuarios, es posible afirmar que GitHub es la plataforma más popular para alojar en abierto el código de proyectos digitales.\n\nPese a que GitHub está diseñado originalmente para publicar código fuente, algunos proyectos, como The Programming Historian en español, lo utilizan para controlar las versiones y para gestionar el flujo de trabajo de sus publicaciones, libros de texto, etc. Así que familiarizarte con GitHub no solo te permitirá controlar las versiones de tu documento sino contribuir a los proyectos que utilizan GitHub. En esta lección nuestro objetivo es ofrecer una introducción al funcionamiento básico de los objetivos y principios del control de versiones de un archivo de texto plano. La lección no es exhaustiva pero proporciona un punto de partida para que puedas seguir aprendiendo por tu cuenta.\n\n¿Por qué no utilizar Dropbox o Google Drive?\n\nDropbox, Google Drive y otros servicios ofrecen alguna forma de controlar las versiones en sus sistemas. A veces esto es suficiente para tus necesidades. Sin embargo, existen algunas ventajas por las que vale la pena utilizar un control de versiones como Git:\n\n\n  Mayor cobertura de lenguaje: Git admite tanto texto como lenguajes de programación. A medida que la investigación incluya métodos informáticos y herramientas digitales, se vuelve necesario disponer de una plataforma que gestione publicaciones tradicionales (artículos, libros, etc.) pero también nuevos tipos de publicaciones como código, conjunto de datos, etc.\n  Más control: un sistema de control de versiones te dará mayor poder para gestionar los cambios de tus documentos.\n  Historial más útil: si utilizas un sistema de control como Git, podrás producir un historial de tu documento. A través de este historial tú y tus colaboradores podréis navegar fácilmente por las distintas etapas del documento.\n\n\nAlgunos proyectos académicos que utilizan control de versiones\n\nUtilizar un control de versiones se ha consolidado en algunas disciplinas científicas, aunque su adopción está lejos de ser universal. En las humanidades y en las ciencias sociales, el uso de Git es mucho menos frecuente. Los proyectos que listamos a continuación muestran algunas de las posibilidades del uso de Git en un entorno académico:\n\n\n  The Programming Historian en español utiliza GitHub en su flujo de trabajo para gestionar la revista, las lecciones y para producir la web.\n  Python Programming for the Humanities es un tutorial introductorio sobre el lenguaje de programación Python.\n  ProfHacker ha publicado varias entradas de blog sobre proyectos que usan GitHub en un contexto académico.\n\n\nNuevos proyectos surgen de manera constante y muchas de las herramientas que utilizas en las humanidades digitales se hospedan en GitHub; por este motivo, GitHub puede ser útil para utilizar con mayor facilidad alguna de estas herramientas.\n\nCómo empezar\n\nGitHub Desktop, la aplicación de escritorio de GitHub, te permitirá empezar a utilizar un control de versiones sin problemas. GitHub Desktop es, de hecho, una Interfaz Gráfica de Usuario (GUI, por sus siglas en inglés) diseñada para facilitar el uso de Git. Las interfaces gráficas de usuario permiten al usuario interactuar con el programa a través de un dispositivo visual que reemplaza la línea de comandos. Aunque utilizar la línea de comandos ofrece muchas ventajas a largo plazo, si utilizas GitHub Desktop reducirás la curva de aprendizaje; encontrarás más recursos sobre la línea de comando al final de la lección.\n\nUna breve nota sobre la terminología\n\nUno de los aspectos más complejos del uso de GitHub es la terminología. El nombre de algunos de los comandos se entiende fácilmente porque son evidentes, pero otros no tanto. En este tutorial intentaremos explicar brevemente los términos poco comunes. Si te pierdes, puedes consultar el glosario de GitHub. Sin embargo, creemos que es mejor ir aprendiendo los términos sobre la marcha, a medida que se utiliza el programa, en lugar de intentar comprender toda la terminología antes de empezar.\n\nRegístrate con una cuenta en GitHub\n\nPuesto que vamos a utilizar GitHub, necesitarás regístrate con una cuenta en GitHub si no lo has hecho ya. Para estudiantes e investigadores, GitHub ofrece repositorios privados de manera gratuita. Este tipo de repositorios no son necesarios pero quizá esta opción te seduzca si quieres mantener tu trabajo en privado.\n\nInstala GitHub Desktop\n\nTe recomendamos que sigas el procedimiento explicado en la página de instalación de GitHub Classic. Tras descargar GitHub Desktop Classic e instalarlo, ya podemos empezar a usar el programa con un archivo de texto plano.\n\nControl de versiones y texto plano\n\nLos sistemas de control de versiones como Git funcionan mejor con archivos de texto plano. Este tipo de archivos contienen un marcado muy sencillo; por el contrario, los archivos Word (u otros generados con procesadores similares) producen código que no es legible para los humanos. Además, cualquier archivo guardado como ‘.txt’ puede abrirse sin problemas con Word, LibreOffice o Notepad. La portabilidad es la principal ventaja del texto plano pues estos archivos pueden abrirse y ejecutarse en la mayoría de ordenadores.\n\nPese a las ventajas evidentes de escribir nuestros documentos en texto plano, también debemos señalar algunas limitaciones. Los archivos de texto plano en sí no permiten marcar algunas palabras en cursiva o bien con negrita; tampoco es posible incluir encabezado o citaciones. Para realizar esto necesitaremos una sintaxis adicional: ‘markdown’.\n\nCon Markdown podremos, pues, dar formato a nuestro texto plano. Seguramente hayas utilizado HTML o LaTex en el pasado. Estos lenguajes de marcado también expresan información sobre el estilo y la estructura del documento. No obstante, el propósito de Markdown es minimizar el marcado, lo cual significa que es más fácil centrarse en el contenido, en la escritura, sin preocuparse en cómo marcar el texto -de ahí el nombre de ‘markdown’.\n\nEsta lección no cubre la sintaxis Markdown por razones de espacio, pero es útil explorar su funcionamiento cuando te sientas cómodo con el control de versiones. Conviene señalar, por otra parte, que GitHub integra una versión propia de la sintaxis Markdown. Si añades la sintaxis Markdown a tus documentos, tu control de versiones gestionado con GitHub Desktop visualizará de manera correcta tu documento en la web. La mejor manera de aprender Markdown es con un poco de práctica. Puedes empezar con nuestra Introducción a Markdown escrita por Sarah Simpkin, o bien con la lección  Escritura sostenible con Pandoc y Markdown escrita por Dennis Tenen y Grant Wythoff.\n\nEditores de texto\n\nPara escribir un documento de texto plano necesitamos un editor. Hay muchos editores disponibles, algunos gratuitos, otros de pago. Algunos son fáciles de usar mientras que otros tienen una curva de aprendizaje y un potencial que sobrepasa las funciones de un editor de texto. A largo plazo, un editor avanzado como Vim o Emacs puede ahorrarte tiempo pero de momento puedes empezar con un editor más simple. Por ejemplo, Atom es un buen editor desarrollado por GitHub que destaca la sintaxis Markdown y, además, se integra con la plataforma GitHub. Es gratuito y su código es abierto; además, incluye un manual de instrucciones muy exhaustivo.\n\nSi no quieres instalar un programa nuevo, puedes utilizar uno de los editores que incluidos en tu ordenador como TextEdit para Mac. Si decides continuar aprendiendo Markdown en el futuro, te recomendamos utilizar un editor de texto que destaque la sintaxis Markdown, entre otras funcionalidades.\n\nCrear un documento\n\nPodemos empezar creando un documento muy sencillo.\n\n¡Hola mundo!\n\n\nAñade este texto (o algo parecido) en documento de texto plano nuevo. ¿Listo? A continuación, guarda el archivo con la extensión ‘.md’. Esta extensión es la más popular para los archivos markdown aunque a veces es posible utilizar otras. A veces el editor de texto guarda los archivos como Rich Text Format (RTF) por defecto, así que asegúrate de que el archivo se guarda en formato de texto plano un directorio nuevo. Si ocurre esto, puedes cambiarlo en la pestaña preferencias u opciones de tu editor. En cualquier caso, identifica tu archivo y tu directorio con un nombre semánticamente claro. Aunque la extensión utilizada sea’.md’, hay que asegurarse de que el archivo es de ‘texto plano’. Por lo general, la codificación del documento no será ningún problema una vez te acostumbres a usar el editor de texto.\n\nPara utilizar de manera efectiva el control de versiones de Git, es importante organizar tu proyecto en directorios. Git rastrea el contenido de cada directorio creando un repositorio a partir de cada uno de ellos. Un repositorio se compone de todos los archivos que están siendo controlados por Git. Lo mejor es crear un directorio para cada proyecto en el que trabajas; por ejemplo, un repositorio para un artículo que estés escribiendo, otro para la composición de tu libro, uno más para el código en desarrollo, etc. Estos directorios son como las carpetas normales y corrientes que tienes en tu ordenador; la única particularidad es que los archivos deben ser añadidos de manera expresa al repositorio para que sean controlados mediante Git.\n\nAñadir un documento\n\nHay varias formas de añadir un archivo para que GitHub Desktop lo controle. Por ejemplo, podemos arrastrar un directorio con el archivo a GitHub Desktop. Si haces esto, el programa te preguntará si quieres crear un repositorio para este directorio. Otra manera consiste en hacer clic sobre el icono ‘más’ para abrir el buscador y elegir la carpeta que queremos añadir.\n\n\n    \n\n    Añade un repositorio\n\n\n\n\nUna vez hemos añadido nuestra carpeta podremos verla en la lista de repositorios situada en la columna izquierda.\n\n\n    \n\n    Añade un repositorio\n\n\n\n\nSi hacemos clic sobre el repositorio que acabamos de añadir, podremos ver los archivos contenidos. En este menú, además, podremos elegir qué archivos queremos rastrear pues a veces trabajamos en proyectos con archivos que no lo requieren. Al lado, a la derecha, se visualizan los documentos.\n\nSi seleccionamos mostrar las carpetas ocultas en el directorio que acabamos de añadir a GitHub, podremos ver que contiene una carpeta adicional llamada ‘.git’. En esta carpeta quedan registrados los cambios producidos en el control de versiones y también si los cambios son modificaciones efectuadas en archivos ya existentes o bien si hemos creado archivos nuevos.\n\nA continuación, volvamos a nuestros documentos y añadamos algo nuevo.\n\n¡Hola mundo!\nUna línea más\n\nGuarda los cambios efectuados y vuelve a GitHub Desktop. Verás que que en el texto aparecen la nueva línea que has añadido; esto quiere decir que GitHub es capaz de percibir los cambios efectuados en el archivo pero aún no han sido registrados en una ‘instantánea’ en tu repositorio.\n\nPara hacer esto debes anotar los cambios.\n\nAnotar cambios\n\nAl anotar (‘commit’) un cambio, comunicas a Git que quieres registrar las modificaciones realizadas. Aunque anotar puede parecer similar a guardar un archivo, el objetivo es distinto. A menudo guardamos diferentes versiones de un documento; ahora bien, guardar un documento, en realidad, significa que puedes cerrar el archivo y volver a él más tarde y que su estado será el mismo, es decir, no se habrán producido perdidas. Anotar, en cambio, implica tomar una instantánea de un archivo en un momento determinado y documentar información sobre los cambios realizados.\n\n\n    \n\n    Primera anotación\n\n\n\n\nPara anotar un cambio debes dar un resumen de los cambios y, de manera opcional, incluir un mensaje. Es importante que pienses con cuidado cuándo debes anotar los cambios. El control de versiones solo es útil si anotas los cambios de manera eficiente. A veces tendemos a anotar los cambios solo cuando hemos terminado de trabajar sobre un documento. Sin embargo, esto no refleja los cambios importantes realizados durante todo el proceso.\n\nCuando anotes el cambio verás que aparece el mensaje ‘anotar al master’. Esto quiere decir que te refieres a la rama ‘master’. En un repositorio Git es posible tener varias ramas. Estas ramas son, en esencia, lugares distintos en los que puedes trabajar. A menudo se utilizan para probar nuevas ideas o trabajar en un aspecto concreto. En principio, no es necesario utilizar crear ramas en GitHub pero quizás quieras aprender de cara al futuro, sobre todo si deseas colaborar con otras personas en un mismo proyecto.\n\nUna manera de entender las anotaciones es pensar en el ‘historial’ de tu documento. Cada anotación registra un desarrollo o cambio hecho en el documento alojada en el repositorio; el historial del documento, por tanto, puede ser recuperada consultando todas las anotaciones grabadas. Para que el historial sea útil más tarde, para ti o para un colaborador, es importante que los cambios queden registrados en momentos importantes del proceso. Merece la pena que las anotaciones sean modulares y que tengas sentido por sí mismas. En otras palabras, las anotaciones y los mensajes deberían entenderse sin tener que ver los cambios precedes o posteriores.\n\nSi pensamos cómo se utiliza el control de versiones con código también puede ser útil. Cuando una nueva función o cuando un error ha sido reparado, es importante que estos cambios se hagan de manera aislada. Si una anotación incluye cambios que afectan a distintos aspectos del código, se hace más difícil aislar los problemas que aparezcan posteriormente. También se hace más difícil eliminar un cambio en particular que ha causado problemas si este ha sido anotado junto con otros.\n\nAunque hay diferencias entre el control de versiones de código y de textos, las anotaciones deberían ser modulares. Por ejemplo, siempre es útil anotar cambios que afectan a la estructura del documento por una parte y anotar mejoras en el estilo o la ortografía por otra parte. Así, si más tarde decides cambiar la estructura, podrás conservar las otras correcciones.\n\nDescribir anotaciones\n\nEs importante que tus anotaciones y los mensajes asociados que las describen tengan sentido y sean específicos. Escribir buenas descripciones de las anotaciones requiere reflexión. A veces, los mensajes que para ti son claros en el momento de la anotación se vuelven difíciles de comprender en el futuro. Si vas a utilizar el control de versiones con otras personas es importante que tus colaboradores puedan entenderte. El control de versiones para gestionar cambios en documentos funciona mejor cuando nos esforzamos un poco en pensar cómo utilizamos el programa. Por tanto, cuando se lleva a cabo un trabajo colaborativo es importante aclarar estas cuestiones y compartir una misma visión para usar el control de cambios de manera efectiva.\n\nUna manera de enfrentarse a este problema es intentar seguir un ‘estilo de anotaciones’. Por ejemplo, te recomendamos seguir la influyente sugerencia de Tim Pope cuando realices anotaciones. La sugerencia de Tim Pope tiene en cuenta, parcialmente, la interfaz de GitHub Desktop para anotar cambios y describirlos pero entender el formato te ayudará a poner en práctica su estrategia. El siguiente mensaje es una adaptación de la propuesta de Tim Pope, que se centra en la anotación de texto (en lugar de código):\n\nBreve resumen (50 o menos caracteres) con mayúscula inicial.\n\nTexto más detallado, si es necesario. En algunos contextos, la primera frase puede tratarse como el asunto de un correo electrónico y el resto como el cuerpo del texto.\n\nEscribe tu mensaje en presente (\"Corrige errores\" y no \"Errores corregidos\"). Esta convención sigue el aspecto de las instrucciones ejecutadas con Git.\n\nTras algunas líneas en blanco, pueden seguir algunos párrafos.\n\n- las listas son adecuadas.\n- por lo común, un guion o un asterisco simbolizan uno de los ítems de la lista, pero las convenciones pueden variar.\n\n\nLa interfaz de GitHub Desktop proporciona cierta ayuda para escribir mensajes de esta manera pero es importante que seas consciente del formato sugerido. No siempre será necesario escribir un resumen detallado pero sí es fundamental que tu descripción sea clara y que los cambios realizados, así como las anotaciones, sean modulares.\n\nPara ejemplificar esto, a continuación, tienes una anotación descrita en el contexto de una obra escrita:\n\nReordena la estructura del documento\n\nDesplaza la sección sobre la metodología después de la sección sobre las fuentes.\n¿Por qué? Algunas ideas tratadas en la metodología no tienen sentido sin una descripción previa de las fuentes utilizadas.\n\nLos mensajes descriptivos que acompañan la edición de una página de Wikipedia o una Wiki son un paralelo a las anotaciones y pueden servirte de modelo para que escribas mensajes fáciles de entender. Cuando escribas estos mensajes debes explicar los cambios que has hecho y por qué los has hecho a fin de que otras personas puedan comprender tu razonamiento. Si tienes en cuenta un destinatario externo (un colaborador y no solo tú), te será más fácil escribir anotaciones claras y con sentido.\n\nCómo crear un buen repositorio\n\nLas ventajas de utilizar un control de versiones se fundamentan en gran medida en su uso efectivo. Es importante pensar cuándo se hacen las anotaciones y cómo identificar de manera correcta esos cambios cuando se describen con mensajes. Si te esfuerzas en hacer tus anotaciones y mensajes ‘modulares’, te será más fácil ‘moverte’ a través del historial de tu repositorio. Un buen repositorio debería permitir comprender los cambios realizados; no solo tú debería entenderlos sino también las personas con las que colabores.\n\nExisten algunas diferencias entre la administración de un repositorio que contiene principalmente código y otro que contiene texto. En ambos casos, sin embargo, una organización clara y lógica es imprescindible. Aunque no utilices un control de versiones o no pretendas hacer público tus datos, te recomendamos ser siempre organizado con los materiales de tu investigación. Para una introducción a la gestión de los datos de investigación, puedes consultar la lección Preservar tus datos de investigación.\n\nCómo publicar tu repositorio\n\nHasta ahora solo hemos registrado nuestros cambios de manera local. Aunque podríamos estar satisfechos con guardarlos en nuestro ordenador (es importante conservar copias), seguramente queremos subir los archivos a nuestro repositorio de GitHub para hacerlos públicos o bien, simplemente, para tener una copia que no esté alojada en nuestro ordenador. El proceso con GitHub Desktop es muy sencillo y rápido. En GitHub Desktop ‘publicas’ repositorios; es decir, los envías (‘push’) desde tu ordenador a la web de GitHub. Durante este proceso también creas un repositorio remoto.\n\n\n    \n\n    Cómo publicar el repositorio\n\n\n\n\nUna vez hayas ‘publicado’ tu repositorio, será visible en tu perfil de GitHub. Es posible crear un repositorio privado en GitHub pero solo si te registras como estudiante o investigador, o bien pagando una suscripción. Si no te has registrado como estudiante o investigador, solo podrás crear un repositorio privado cuando pagues por una suscripción. Por eso, a menos que quieras pagar, puedes ignorar la sección ‘Información sobre la compra’. En esta sección, será suficiente con publicar un repositorio abierto. Para acceder a tu repositorio en línea, en el menú puedes hacer clic sobre ‘Repository’ (‘Repositorio’) y luego elegir ‘View on GitHub’ (es decir, ‘Ver en GitHub’). Al hacer esto, se abrirá una ventana en tu navegador con tu repositorio en línea.\n\n\n    \n\n    Vista del menú\n\n\n\n\nA continuación, deberías ver tu documento en tu repositorio web.\n\n\n    \n\n    La versión en línea de tu repositorio\n\n\n\n\nUna vez que tu documento esté en línea, puedes continuar realizando cambios en tu documento localmente. Pero tendrás que sincronizar tus cambios locales para reflejarlos en el repositorio publicado en GitHub. Esta plataforma almacena los cambios en tu ordenador y remotamente (en sus servidores). Por eso es importante mantener ambos lugares sincronizados. Con GitHub Desktop este proceso se simplifica mientras que en la línea de comandos deberíamos ejecutar sync (‘sincronizar’) y luego pull (‘recibir’). Verás el botón ‘sync’ en el margen superior derecho de tu GitHub Desktop. Al pulsarlo, te aseguras de que tu entorno local (tu ordenador) y tu entorno remoto (el servidor de GitHub) contienen la misma información. Si quieres trabajar en tu documento antes de publicarlo, también puedes elegir anotar los cambios sin sincronizar. Esto te permitirá poner en marcha el control de versiones en local en una fase temprana.\n\nCómo hacer cambios remotamente\n\nTambién es posible realizar cambios en tu repositorio a través de la  interfaz web de GitHub. Para ello, haz clic sobre el nombre del archivo y accederás a una nueva página que muestra tu documento.\n\n\n    \n\n    Vista de tu documento en línea\n\n\n\n\n(Nota: puede parecer extraño que todo lo que has escrito aparezca en una línea, cuando tu archivo local tenía dos líneas. Esto se debe a que en Markdown, los párrafos deben marcarse dejando una línea en blanco; así pues, dos líneas consecutivas son interpretadas como un solo párrafo. Si hubiéramos utilizado la extensión ‘.txt’, tendríamos un salto de línea aquí, pero con la extensión ‘.md’ estamos indicando a GitHub que visualice el documento según las normas de Markdown. Esta es otra razón por la que utilizar un editor apto para Markdown puede serte útil para visualizar el formato).\n\nLa interfaz web ofrece otras opciones. Por ejemplo, puedes visualizar los cambios en el historial, puedes abrir el documento en GitHub Desktop, o bien puedes eliminarlo. Encontrarás más opciones junto a la opción ‘code’ (‘código’). Estas opciones no son importantes ahora mismo, al principio, pero quizás la uses en el futuro. A continuación, intentaremos editar un documento en la interfaz web y sincronizar los cambios con nuestro repositorio local.\n\nAsí, pues, haz clic sobre la opción ‘editar’ representada con un lápiz.\n\n\n    \n\n    El botón ‘Editar’\n\n\n\n\nTras esto deberías poder editar el archivo y añadir más texto.\n\n\n    \n\n    El modo edición\n\n\n\n\nUna vez hayas realizado cambios en tu archivo, verás que puedes anotar los cambios en la parte inferior de la ventana.\n\n\n    \n\n    Cómo anotar un cambio en línea\n\n\n\n\nUna vez hayas anotado los cambios, serán almacenados en tu repositorio remoto. Para recibirlos en tu ordenador deberás sincronizarlos. Para ello, haz clic en el botón ‘sync’ de tu GitHub Desktop.\n\n\n    \n\n    El botón de sincronización\n\n\n\n\n¡Ya tenemos nuestros cambios realizados remotamente en nuestro ordenador!\n\n\n    \n\n    El documento con los cambios remotos\n\n\n\n\nVerás que el texto modificado aparece marcado en verde y en rojo. El color rojo indica que se ha producido una eliminación mientras que el verde indica que se ha añadido algo. Esta forma de visualizar los cambios puede ser útil antes de anotar pues te permitirá localizarlos y asegurarte de que los quieres registrar. En la parte izquierda verás el historial de los cambios realizados. En este momento el historial es muy breve pero a medida que trabajes crecerá en tamaño. Ver los cambios realizados de esta manera, en cada una de las fases de tu proyecto, te será de gran utilidad.\n\nGestionar conflictos\n\nLos ‘conflictos’ emergen cuando intentas fusionar o sincronizar dos versiones de un documento con cambios que son incompatibles entre sí. Si tienes cuidado cuando anotas y sincronizas los cambios realizados en tu entorno local, en tu ordenador, entonces es bastante improbable de que te encuentres con este tipo de problemas; de todos modos, resolverlos es una tarea sencilla.\n\nA menudo, los conflictos surgen cuando realizas un cambio en remoto (en la web GitHub) y luego haces otro cambio local sin haber sincronizado previamente. Si los cambios tienen lugar en distintas partes del documento, no pasa nada, se pueden integrar o fusionar (‘merge’). Ahora bien, algunos cambios pueden entrar en conflicto cuando tienen lugar en la misma línea del documento.\n\nPor ejemplo, imaginemos que añadimos algo en nuestro repositorio remoto (en la web de GitHub).\n\n\n    \n\n    Un cambio remoto en el documento\n\n\n\n\nA continuación, anotas el cambio en la web y, acto seguido, hacemos otro cambio local.\n\n\n    \n\n    Un cambio local en el documento\n\n\n\n\nSi anotamos el cambio en local y sincronizamos, recibiremos un mensaje de alerta señalando que se ha producido un conflicto.\n\n\n    \n\n    GitHub nos alerta de un conflicto de sincronización\n\n\n\n\nNo te preocupes, no es un problema gordo. Simplemente hay que gestionar el conflicto. GitHub Desktop te ofrece la posibilidad de abrir el archivo y acceder al lugar en donde se halla el problema.\n\n\n    \n\n    Las opciones que nos da GitHub para abrir el documento\n\n\n\n\nSi elegimos abrir el archivo con un editor externo, el documento se visualizará el editor de texto que tengas por defecto para archivos escritos en Markdown. Si no tienes ninguno por defecto, puedes haz clic en ‘show in finder’ (‘mostrar en el buscador’) para acceder a la carpeta que contiene el archivo. A partir de aquí puedes abrirlo con el editor que prefieras.\n\nSi miras el archivo con atención, verás que Git ha marcado dónde se encuentra el conflicto.\n\n\n    \n\n    Marcas usadas para señalar los conflictos\n\n\n\n\nVerás que el conflicto está envuelto con las marcas &lt;&lt;&lt;&lt;&lt;&lt;&lt; y &gt;&gt;&gt;&gt;&gt;&gt;&gt;. Los dos bloques que están en conflicto se distinguen gracias a una línea como esta ======= line. Hay distintas formas de gestionar este tipo de conflicto. Por ejemplo, podrías eliminar la versión que ya no quieres y deshacerte de las marcas; o bien podrías eliminar todo el bloque y descartar ambas versiones. Una vez hayas ‘resuelto’ el conflicto, debes anotar el cambio y sincronizar como de costumbre. Cuando vayas a anotar el cambio, verás que el GitHub Desktop especifica que la anotación consiste en una fusión de un conflicto. Así, en el futuro, podrás volver sobre ello y revisar cómo lo resolviste.\n\nEsta forma de resolver conflictos puede parecer más compleja de lo que es, pero, sin duda, es muy útil porque te da mucho control. En una plataforma como Dropbox esto ocasionaría la duplicación de un archivo. Pese a que esta solución sea mejor que perder los cambios, deberías ver qué archivo contiene la versión que quieres y decidir cómo resolver el conflicto. En cualquier caso, si tienes cuidado al sincronizar los cambios evitarás muchos conflictos. Si colaboras con otras personas, el riesgo de crear conflictos es mucho mayor; por eso, es importante saber cómo resolverlos antes de empezar a colaborar con GitHub.\n\nControl de versiones y flujo de trabajo con texto plano\n\nHasta el momento hemos puesto en marcha un control de versiones con un documento muy básico. Si aprendes más acerca de Markdown y la escritura en texto plano, podrás usar el control de versiones de muchas maneras y te será muy útil para llevar a cabo tu investigación. Controlar las versiones de un documento Markdown te permitirá profundizar en esta sintaxis; para ello, te recomendamos consultar la lección Escritura sostenible en texto plano usando Pandoc y Markdown escrita por Dennis Tenen y Grant Wythoff; esta lección te ayudará a entender cómo puedes usar el texto plano para escribir con Pandoc y Markdown. Pandoc es muy útil para convertir tus archivos de texto plano escritos en Markdown a otros formatos como HTML, PDF o Word. Si combinas Markdown, Pandoc y el control de versiones, podrás implementar un sistema muy potente y sostenible para escribir tus artículos y trabajos académicos.\n\nAsimismo, el flujo de trabajo presentado en esta lección también puede convertirse en el fundamento para crear webs estáticas alojadas en GitHub. Una vez te sientas cómodo usando GitHub Desktop, puedes seguir con la lección escrita por Amanda Visconti, Construcción de sitios estáticos usando Jekyll GitHub Pages.\n\nMás recursos\n\nGitHub Desktop es una forma sencilla de aprender a controlar versiones con GitHub. En función de tus necesidades, GitHub será suficiente. Ahora bien, si ya conoces el funcionamiento de la línea de comandos, utilizar Git puede tener más ventajas. Los controles de versiones como Git ofrecen muchas más opciones; algunos tienen un uso concreto mientras que otros se pueden utilizar de manera más generalizable. Como complemento a esta lección, te sugerimos una serie de recursos que pueden ayudarte a mejorar tu comprensión del control de versiones.\n\n\n  GitHub ofrece ayuda a través de sus guías y ayuda.\n  El Glosario de GitHub explica la terminología más frecuente en Git.\n  Atlassian: contiene tutoriales más avanzados (pero fáciles de entender) de Git. Ponen el acento en las diferencias entre Git y otros controles de versiones; esto puede no ser relevante para ti pero te ayudará a comprender el funcionamiento de Git de manera más detallada.\n  Pro Git: un libro exclusivamente sobre Git. Empieza con el funcionamiento básico y luego pasa a tratar asuntos más avanzados de Git.\n  Para estudiantes e investigadores GitHub ofrece repositorios privados sin pagar por una suscripción. Estos repositorios pueden ser útiles para borradores o notas que no queremos publicar. Nota: no es muy aconsejable guardar contenido delicado incluso en un repositorio privado en GitHub.\n  ProfHacker tiene varias entradas sobre proyectos que utilizan GitHub en el contexto académico.\n  GitHub, Academia, and Collaborative Writing reflexioina sobre el uso de GitHub para la escritura colaborativa.\n  La lección Introducción a Bash te permitirá aprender más sobre la línea de comandos, muy útil para utilizar GitHub.\n\n\nEn esta lección aprenderás lo básico del control de versiones, comprenderás por qué es útil e implementarás el control básico de versiones en un documento de texto plano utilizando git y GitHub.\n\n"
  },


  {
    "id": 25,
    "url": "http://localhost:4000/es/lecciones/introduccion-datos-abiertos-enlazados",
    "title": "Introducción a los Datos abiertos enlazados",
    "body": "\nIntroducción a los Datos abiertos enlazados\nIntroducción y contexto de la lección\n\nEsta lección ofrece una introducción breve y concisa a los datos abiertos enlazados    (Linked Open Data, LOD). No es necesario ningún conocimiento previo. Los lectores lograrán comprender de forma clara los conceptos que fundamentan los datos abiertos enlazados, cómo se utilizan y cómo se crean. El tutorial se divide en cinco partes, más una de lecturas adicionales:\n\n\n  Datos abiertos enlazados: ¿qué son?\n  El papel del Identificador de Recursos Uniforme (URI)\n  Cómo los LOD organizan el conocimiento: ontologías\n  El Marco de descripción de recursos (RDF) y formatos de datos\n  Cómo interrogar los datos abiertos enlazados con SPARQL\n  Lecturas y recursos adicionales\n\n\nEl tutorial puede completarse en un par de horas, pero siempre es posible releer algunas secciones para reforzar la comprensión. Los términos técnicos se han enlazado con su página correspondiente en Wikipedia; te animamos a hacer una pausa y leer sobre los términos que encuentres más complejos. Después de haber aprendido algunos de los principios clave de LOD, la mejor manera de mejorar y consolidar ese conocimiento es practicar. Este tutorial ofrece oportunidades para hacerlo. Al final del curso deberías entender los fundamentos de LOD, incluyendo términos y conceptos clave.\n\nSi necesitas aprender a explorar los LOD usando el lenguaje de consulta SPARQL, recomiendo la lección ‘Uso de SPARQL para acceder a datos abiertos enlazados’ de Matthew Lincoln, que sigue de una forma práctica la perspectiva conceptual ofrecida en esta lección.\n\nCon el fin de proporcionar a los lectores una base sólida de los principios básicos de LOD, este tutorial no ofrecerá una cobertura completa de todos los conceptos LOD. Los siguientes dos conceptos de LOD no se explicarán en esta lección:\n\n\n  \n    La web semántica y el razonamiento semántico de conjuntos de datos. Un razonador semántico deduciría que Jorge VI es el hermano o medio hermano de Eduardo VIII, dado el hecho de que a) Eduardo VIII es el hijo de Jorge V y b) Jorge VI es el hijo de Jorge V. Este tutorial no se centra en este tipo de tareas.\n  \n  \n    La creación y subida de conjuntos de datos abiertos enlazados a la nube de datos enlazados. Compartir tus LOD es un principio importante, al que se anima más adelante. Sin embargo, los aspectos prácticos de contribuir con tus LOD a la nube de datos enlazados está fuera del alcance de esta lección. Al final de este tutorial hay algunos recursos disponibles que pueden ayudarte a comenzar con esta tarea.\n  \n\n\nDatos abiertos enlazados: ¿qué son?\nLOD es información estructurada en un formato destinado a las máquinas y, por tanto, no es necesariamente fácil de entender a primera vista. No te desanimes por esto, ya que una vez que entiendas los principios, puedes conseguir que una máquina los lea por ti.\n\nSi todos los conjuntos de datos se publicaran en abierto y se usara el mismo formato para estructurar la información, sería posible interrogar todos los conjuntos de datos a la vez. Analizar enormes volúmenes de datos es potencialmente mucho más efectivo que la publicación individual de los conjuntos de datos propios distribuidos por la web en lo que se conoce como silos de información. Estos conjuntos de datos interoperables son el destino al que los profesionales de los LOD desean acercarse.\n\nPara lograr este objetivo, al trabajar con LOD, recuerda siempre los tres principios siguientes:\n\n\n  \n    Utiliza un formato estándar de LOD reconocido. Para que los LOD funcionen, los datos deben estar estructurados usando estándares reconocidos para que los ordenadores que interrogan los datos puedan procesarlos de manera consistente. Existen varios formatos para LOD, algunos de los cuales se analizan más adelante.\n  \n  \n    Refiérete a una entidad de la misma forma que otras personas. Si tienes datos sobre la misma persona/lugar/cosa en dos o más sitios, asegúrate de referirte a la persona/lugar/cosa de la misma manera en todos los casos.\n  \n  \n    Publica tus datos en abierto. Con la expresión “en abierto” queremos decir que cualquier persona pueda usarlos sin pagar una cuota y en un formato que no requiera programas de pago.\n  \n\n\nComencemos con un ejemplo de datos sobre una persona, usando un habitual par atributo-valor típico en computación:\n\npersona=número\n\n\nEn este caso, el ‘atributo’ es una persona. Y el valor —o quien es esa persona— está representado por un número. El número podría ser asignado al azar o podrías utilizar un número que ya estaba asociado con ese individuo. Este último enfoque tiene grandes ventajas: si todo el mundo que crea un conjunto de datos que menciona esa persona utiliza exactamente el mismo número y en exactamente el mismo formato, entonces podemos encontrar de forma fiable a ese individuo en cualquier conjunto de datos que se adhiera a esas reglas.\n\nVamos a crear un ejemplo con Jack Straw. Con este nombre propio podemos referirnos tanto a un rebelde inglés del siglo XIV como a un prominente ministro del gabinete británico de Tony Blair. Claramente es útil poder diferenciar a las dos personas que comparten un nombre común. Utilizando el modelo anterior en el que cada persona está representada por un número único, identifiquemos al ministro británico Jack Straw con el número 64183282. Su par de atributo-valor entonces se vería así:\n\npersona=64183282\n\n\nA continuación, vamos a identificar al Jack Straw descrito por el Oxford Dictionary of National Biography como ‘el enigmático líder rebelde’ con el número 33059614. En consecuencia, su par atributo-valor sería el siguiente:\n\npersona=33059614\n\n\nProcurando que todo aquél que crea LOD use estos dos números para referirse al Jack Straw respectivo, podremos entonces buscar a la persona 64183282 en un conjunto de datos abierto enlazado y estar seguros de que estamos obteniendo a la persona adecuada -en este caso, el ministro-.\n\nLos pares atributo-valor también pueden almacenar información sobre otros tipos de entidades, como, por ejemplo, lugares. Jack Straw el político moderno fue miembro del parlamento británico, representando a Blackburn. Hay más de un lugar en el Reino Unido llamado Blackburn, por no hablar de otros Blackburns en todo el mundo. Usando los mismos principios descritos anteriormente, podemos desambiguar entre los diferentes Blackburns asignando un identificador único al lugar correcto: Blackburn en Lancashire, Inglaterra.\n\nlugar=2655524\n\n\nEn este momento podrías estar pensando, “esto es lo que hace el catálogo de la biblioteca”. Es cierto que la idea clave aquí es la de control de autoridades, que es central en biblioteconomía (un fichero de autoridad es una lista cerrada de términos que pueden ser utilizados en un contexto particular, por ejemplo cuando se cataloga un libro). En ambos ejemplos mencionados anteriormente, hemos utilizado los ficheros de autoridad para asignar los números (los identificadores únicos) a los Jacks y a Blackburn. Los números que utilizamos para los dos Jack Straws provienen del Virtual International Authority File - Archivo de Autoridades Internacional Virtual (VIAF), que es mantenido por un consorcio de bibliotecas de todo el mundo para tratar de abordar el problema de la miríada de formas en las que una misma persona podría ser nombrada. El identificador único que utilizamos para el distrito electoral de Blackburn provino de GeoNames, una base de datos geográfica gratuita.\n\nPero intentemos ser más precisos por lo que entendemos por Blackburn en este caso. Jack Straw ejerció su cargo parlamentario en representación de Blackburn (que cuenta con un solo miembro en el parlamento británico). Los límites de Blackburn han cambiado con el paso del tiempo, así que en el proyecto ‘Digging Into Linked Parliamentary Data’ (Dilipad) (en el que trabajé) se crearon identificadores únicos para las afiliaciones a partidos y para los distritos electorales de cada miembro del parlamento. En este ejemplo, Jack Straw representó a la circunscripción conocida como ‘Blackburn’ en su encarnación posterior a 1955:\n\nblackburn1955-current\n\n\nComo VIAF es un archivo de autoridad reputado y bien mantenido de personas notables, fue un conjunto obvio de identificadores a usar para Jack Straw. Como el electorado representado por Straw estaba cubierto perfectamente por los archivos de autoridad creados por el proyecto Dilipad, también fue lógico usarlos. Por desgracia, no siempre es tan obvio cuál de las listas publicadas en línea es mejor utilizar. Una podría ser más usada que otra, pero quizás esta última ofrezca información más completa para un propósito particular. GeoNames funcionaría mejor que los identificadores Dilipad en algunos casos. También habrá casos en los que no puedas encontrar un conjunto de datos con esa información. Por ejemplo, imagina que quisieras escribir pares de atributo-valor sobre ti y tus relaciones familiares cercanas. En este caso, tendrías que inventar tus propios identificadores.\n\nLa falta de archivos de autoridad consistentes es uno de los principales retos a los que los LOD se enfrentan en este momento. Tim Berners-Lee, quien ideó una forma de vincular documentos a través de una red creando así la World Wide Web, ha sido durante mucho tiempo uno de sus proponentes principales de los LOD. Para alentar un mayor uso de los LOD sugirió un ‘sistema de calificación de cinco estrellas’ que anime a todos a avanzar lo más posible hacia los LOD. En esencia, cree que es bueno publicar datos en abierto, especialmente si se utilizan formatos abiertos y estándares públicos, pero mejor si también se enlaza con los datos de otras personas.\n\nUna vez que se asignan identificadores únicos a todos los elementos, el siguiente paso es clave en la creación de LOD para tener una manera de describir la relación entre Jack Straw (64183282) y Blackburn (blackburn1955-current). En los LOD, las relaciones se expresan utilizando lo que se conoce como una ‘tripleta’. Hagamos una tripleta que representa la relación entre Jack Straw y su circunscripción electoral:\n\npersona:64183282 rol:representanteEnElParlamentoUK circunscripción:\"blackburn1955-current\"\n\n\nLa presentación (o sintaxis) de las tripletas, incluida la puntuación utilizada anteriormente, se analizará más adelante, en la sección sobre RDF y formatos de datos. Por ahora, concéntrate en la estructura básica. La tripleta, como es lógico, tiene tres partes. Éstas se conocen convencionalmente como sujeto, predicado y objeto:\n\n\n  \n    \n      sujeto\n      predicado\n      objeto\n    \n  \n  \n    \n      persona 64183282\n      representanteEnElParlamentoUK\n      “blackburn1955-current”\n    \n  \n\n\nLa forma tradicional de representar una tripleta en forma de diagrama es:\n\n\n    \n\n    Manera clásica de representar una tripleta\n\n\n\n\nAsí que nuestra tripleta de Jack Straw, en una forma más legible para los humanos, podría representarse así:\n\n\n    \n\n    Diagrama triple que muestra que Jack Straw representó a Blackburn\n\n\n\n\nPor ahora hay tres puntos clave que recordar:\n\n\n  Los LOD deben ser abiertos y estar disponibles para cualquier persona en Internet (de lo contrario, no son ‘abiertos’)\n  Los impulsores de los LOD tienen como objetivo estandarizar las formas de referirse a entidades únicas\n  Los LOD consisten en tripletas que describen relaciones entre entidades\n\n\nEl papel del Identificador Uniforme de Recursos (Uniform Resource Identifier - URI)\nUna parte esencial de los LOD es el Identificador Uniforme de Recursos o URI. El URI es una manera unívoca y fiable de representar una entidad (una persona, un objeto, una relación, etc.) en una forma que es utilizable por todo el mundo.\n\nEn la sección anterior usamos dos números distintos para identificar nuestros dos Jack Straws diferentes.\n\npersona=\"64183282\"\npersona=\"33059614\"\n\n\nEl problema es que en todo el mundo hay muchas bases de datos que contienen personas con estos números, y probablemente sean personas diferentes. Fuera de nuestro contexto inmediato, estas cifras no identifican individuos únicos. Tratemos de arreglar eso. Aquí están estos mismos identificadores pero como URI:\n\nhttp://viaf.org/viaf/64183282/\nhttp://viaf.org/viaf/33059614/\n\n\nAsí como el número único desambiguó nuestros dos Jack Straws, el URI completo anterior nos ayuda a eliminar la ambigüedad entre todos los diferentes archivos de autoridad que existen. En este caso, está claro que estamos usando VIAF como nuestro archivo de autoridad. Ya has visto esta forma de desambiguación muchas veces en la web. Hay muchos sitios web alrededor del mundo con páginas llamadas /home o /faq. Pero no hay confusión porque el dominio (la primera parte del Localizador Uniforme de Recursos (URL) - por ejemplo,bbc.co.uk) es único y, por lo tanto, todas las páginas que son parte de ese dominio son únicas, diferenciándose de otras páginas /faq de otros sitios web. En la dirección http://www.bbc.co.uk/faqs, es la parte bbc.co.uk la que hace únicas las páginas siguientes. Esto es tan obvio para las personas que usan la web todo el tiempo que no piensan en ello. Probablemente también sepas que si quieres iniciar un sitio web llamado bbc.co.uk no puedes hacerlo, porque ese nombre ya se ha registrado con la autoridad correspondiente, que es el Sistema de Nombres de Dominio (Domain Name System - DNS). El registro garantiza la unicidad. Los URIs también deben ser únicos.\n\nSi bien los ejemplos anteriores se parecen a las URLs, es posible también construir un URI que no se parezca en nada a una URL. Tenemos muchas maneras de identificar personas y cosas de manera única y rara vez lo pensamos o nos preocupamos de ello. Los códigos de barras, los números de pasaporte e incluso tu dirección postal están diseñados para ser únicos. En el mundo desarrollado los números de teléfono móvil se colocan con frecuencia en los carteles de las tiendas precisamente porque son únicos. Todos ellos podrían usarse como URIs.\n\nCuando quisimos crear URIs para las entidades descritas por el proyecto ‘Tobias’, elegimos una estructura tipo URL y elegimos utilizar nuestro espacio web institucional, dejando de lado  data.history.ac.uk/tobias-project/ como un lugar dedicado a alojar estos URI. Al ponerlo en data.history.ac.uk en lugar de en history.ac.uk, hubo una separación clara entre los URI y las páginas del sitio web. Por ejemplo, uno de los URIs del proyecto Tobias era http://data.history.ac.uk/tobias-project/person/15601. Si bien el formato de los URI mencionados anteriormente es el mismo que el de una URL, no se vinculan a páginas web (intenta pegarlas en un navegador web). Muchas personas nuevas con los LOD encuentran esto confuso. Todas las URL son URI, pero no todas las URI son URL. Una URI puede describir cualquier cosa, mientras que una URL describe la ubicación de algo en la web. Es decir, una URL te dice la ubicación de una página web o un archivo o algo similar. Un URI simplemente hace el trabajo de identificar algo. Así como el Número Estándar Internacional de Libro, o ISBN 978-0-1-873354-6 identifica de manera única una edición de tapa dura de Bautismo, Hermandad y Creencias en la Reforma de Alemania por Kat Hill, pero no te dice dónde conseguir una copia. Para eso, necesitarías algo como una signatura, que te da una ubicación exacta en un estante de una biblioteca específica.\n\nHay un poco de jerga alrededor de los URIs. La gente habla de si son, o no, desreferenciables. Eso solo significa que ¿se puede pasar desde una referencia abstracta a otra cosa? Por ejemplo, si pegas un URI en la barra de direcciones de un navegador, ¿devolverá algo? El URI de VIAF para el historiador Simon Schama es:\n\nhttp://viaf.org/viaf/46784579\n\n\nSi lo pones en el navegador, obtendrás una página web sobre Simon Schama que contiene datos estructurados sobre él y su historial de publicaciones. Esto es muy útil, pero, por otro lado, no es obvio desde la URI a quién o incluso a qué se refiere. Del mismo modo, si tratamos un número de teléfono móvil (con código internacional) como URI para una persona, entonces debería ser desreferenciable. Alguien podría responder el teléfono, e incluso podría ser Schama.\n\nPero esto no es esencial. Muchos de los URI no son desreferenciables, como en el ejemplo anterior del proyecto Tobias. No puedes encontrarlo en ningún sitio; es una convención.\n\nEl ejemplo de VIAF nos lleva a otra cosa importante sobre los URIs: no debes crearlos a menos que sea necesario. Las personas y las organizaciones han estado haciendo esfuerzos concertados para construir listas de URIs adecuadas y los LOD no funcionarán de manera efectiva si la gente duplica ese trabajo creando nuevos URIs innecesariamente. Por ejemplo, VIAF cuenta con el apoyo de muchas bibliotecas a nivel internacional. Si deseas construir URI para personas, VIAF es una muy buena opción. Si no puedes encontrar a algunas personas en VIAF, u otras listas de autoridades, sólo entonces podrías necesitar hacer las tuyas propias.\n\nCómo organizan los LOD el conocimiento: ontologías\nPuede que no haya sido obvio por las tripletas individuales que vimos en la sección de apertura, pero los LOD pueden responder preguntas complejas. Cuando unes las tripletas forman un grafo, debido a la forma en que las tripletas se entrelazan. Supongamos que queremos encontrar una lista de todas las personas que fueron alumnos del compositor Franz Liszt. Si la información está en tripletas de datos enlazados sobre pianistas y sus profesores, podemos averigüarlo con una consulta (veremos este lenguaje de consulta, llamado SPARQL, en la sección final).\n\nPor ejemplo, el pianista Charles Rosen fue alumno del pianista Moriz Rosenthal, quien a su vez fue alumno de Franz Liszt. Ahora expresemos eso como dos tripletas (nos limitaremos a usar cadenas para los nombres en lugar de números de ID para que los ejemplos sean más legibles):\n\n\"Franz Liszt\" enseñóPianoA \"Moriz Rosenthal\" .\n\"Moriz Rosenthal\" enseñóPianoA \"Charles Rosen\" .\n\n\nPodríamos haber creado nuestras tripletas igualmente de esta manera:\n\n\"Charles Rosen\" aprendióPianoCon \"Moriz Rosenthal\" .\n\"Moriz Rosenthal\" aprendióPianoCon \"Franz Liszt\" .\n\n\nEstamos poniendo ejemplos simplemente con el fin de ilustrar, pero si deseas enlazar tus datos a otros conjuntos de datos en la ‘nube de datos vinculados’ debes ver qué convenciones se utilizan en esos conjuntos de datos y hacer lo mismo. En realidad, esta es una de las características más útiles de los LOD porque gran parte del trabajo se ha realizado para ti. La gente ha dedicado mucho tiempo a desarrollar formas de modelar información dentro de un área particular de estudio y a pensar en cómo se pueden representar las relaciones dentro de esa área. Estos modelos generalmente se conocen como ontologías. Una ontología es una abstracción que permite que representar un conocimiento particular sobre el mundo. Las ontologías, en este sentido, son bastante nuevas y fueron diseñadas para hacer lo que hace una taxonomía jerárquica (como la clasificación de las especies del sistema de Linneo), pero de manera más flexible.\n\nUna ontología es más flexible porque no es jerárquica. Su objetivo es representar la fluidez del mundo real, donde las cosas se pueden relacionar entre sí de formas más complejas que las representadas por una estructura jerárquica de tipo arbóreo. En cambio, una ontología es más como una tela de araña.\n\nSea lo que sea que desees representar con los LOD, te sugerimos que busques un vocabulario existente y lo uses, en lugar de intentar escribir el tuyo propio. Esta página principal incluye una lista de algunos de los vocabularios más populares\n\n  N.T.: desplázate hacia la zona derecha/abajo de la página: “Popular Vocabularies”\n\n\nDado que nuestro anterior ejemplo se centra en los pianistas, sería una buena idea encontrar una ontología adecuada en lugar de crear nuestro propio sistema. De hecho, hay una ontología para la música. Además de una especificación bien desarrollada, tiene también algunos ejemplos útiles de su uso. Puedes echar un vistazo a las páginas de Introducción para tener una idea de cómo puedes usar esa ontología particular.\n\nLamentablemente, no encuentro nada que describa la relación entre un profesor y un alumno en Music Ontology. Pero la ontología se publica en abierto, así que puedo usarla para describir otras características de la música y luego crear mi propia extensión. Si luego publico mi extensión en abierto, otros pueden usarla si lo desean y puede convertirse en un estándar. Si bien el proyecto Music Ongology no tiene la relación que necesito, el proyecto Linked Jazz permite el uso de ‘mentorDe’, que parece que podría funcionar bien en nuestro caso. Aunque esta no es la solución ideal, conviene esforzarse por usar lo que ya existe.\n\nAhora bien, si estuvieras estudiando la historia de los pianistas, querrías identificar a muchos pianistas a quienes los alumnos de Liszt enseñaron, establecer una especie de árbol genealógico y ver si estos “nietos” de Liszt tienen algo en común. Podrías investigar a los alumnos de Liszt, hacer una gran lista de ellos, y luego investigar a cada uno de los alumnos e intentar hacer una lista de los alumnos que tuvieron. Con los LOD podrías (de nuevo, si es que las tripletas existen) hacer una consulta como:\n\n     Dame los nombres de todos los pianistas enseñados por x\n     donde x fue enseñado a tocar el piano por Liszt\n\n\nLa consulta devolvería todas las personas en el conjunto de datos que fueron alumnos de un alumno de Liszt. No nos entusiasmemos demasiado: esta consulta no nos dará a cada alumno de cada alumno de Liszt que haya existido alguna vez porque esa información probablemente no exista y no exista dentro de ningún grupo de tripletas existente. Lidiar con datos del mundo real muestra todo tipo de omisiones e inconsistencias que veremos cuando analicemos el mayor conjunto de LOD, DBpedia, en la sección final.\n\nSi has utilizado bases de datos relacionales, podrías pensar que pueden realizar la misma función. En el caso de Liszt, la información sobre pianistas descrita anteriormente podría organizarse en una tabla de base de datos llamada algo así como ‘Alumnos’.\n\n\n  \n    \n      alumnoID\n      profesorID\n    \n  \n  \n    \n      31\n      17\n    \n    \n      35\n      17\n    \n    \n      49\n      28\n    \n    \n      56\n      28\n    \n    \n      72\n      40\n    \n  \n\n\nSi no estás familiarizado con las bases de datos, no te preocupes. Pero probablemente aún puedas ver que algunos pianistas en esta tabla tenían el mismo profesor (números 17 y 28). Sin entrar en detalles, si Liszt está en esta tabla de la base de datos, sería bastante fácil extraer los alumnos de los alumnos de Liszt, utilizando la sentencia SQL join.\n\nDe hecho, las bases de datos relacionales pueden ofrecer resultados similares a los LOD. La gran diferencia es que los LOD pueden ir más allá: puede enlazar conjuntos de datos creados sin intención explícita de ser enlazados. El uso de Resource Description Framework (RDF) y las URIs permite que esto suceda.\n\nRDF y formatos de datos\nLos LOD usan un estándar, definido por el World Wide Web Consortium, o W3C, llamado Resource Description Framework, o simplemente RDF. Los estándares son útiles siempre que sean adoptados de forma generalizada -piensa en el metro o en los tamaños estándar de tornillo- incluso si son esencialmente arbitrarios. RDF ha sido adoptado como el estándar para los LOD.\n\nA menudo oirás que los LOD son denominados simplemente como RDF. Hemos retrasado hablar de RDF hasta ahora porque es bastante abstracto. RDF es un modelo de datos que describe cómo se estructuran los datos en un nivel teórico. Así, la insistencia en usar tripletas (en lugar de cuatro partes, o dos o nueve, por ejemplo) es una regla de RDF. Pero cuando se trata de asuntos más prácticos, tienes algunas opciones de implementación. Por tanto, RDF te dice lo que tienes que hacer, pero no exactamente cómo tienes que hacerlo. Estas opciones se dividen en dos áreas: cómo escribes las cosas (serialización) y las relaciones que describen tus tripletas.\n\nSerialización\nLa serialización es el término técnico para ‘cómo escribes las cosas’. El chino estándar (mandarín) se puede escribir en caracteres tradicionales, caracteres simplificados o romanización Pinyin y el idioma en sí no cambia. Del mismo modo, RDF se puede escribir en diversas formas. Aquí veremos dos (hay otros, pero por simplicidad, nos centraremos en estos):\n\n1) Turtle\n\n2) RDF/XML\n\nReconocer qué serialización estás viendo significa que puedes elegir las herramientas adecuadas diseñadas para ese formato. Por ejemplo, RDF puede venir serializado en formato XML. Luego puedes usar una herramienta o biblioteca de código diseñada para analizar ese formato en particular, lo que es útil si ya sabes cómo trabajar con él. El reconocimiento del formato también te brinda las palabras clave correctas para buscar ayuda en línea. Muchos recursos ofrecen sus bases de datos de LOD para su descarga y puedes elegir qué serialización deseas descargar.\n\nTurtle\n\n‘Turtle’ (Tortuga en español) es un juego de palabras. ‘Tur’ es la abreviatura de ‘terse’ (conciso), y ‘tle’ -es la abreviatura de ‘triple language’ (lenguaje de tripletas)-. Turtle es una forma gratamente simple de escribir tripletas.\n\nTurtle usa alias o atajos conocidos como prefijos, lo que nos ahorra tener que escribir URIs completos todo el tiempo. Regresemos al URI que inventamos en la sección anterior:\n\nhttp://data.history.ac.uk/tobias-project/person/15601\n\n\nNo queremos escribir esto cada vez que nos referimos a esta persona (Jack Straw, como recordarás). Entonces sólo tenemos que anunciar nuestro atajo:\n\n@prefix toby: &lt;http://data.history.ac.uk/tobias-project/person&gt; .\n\n\nAsí, Jack es toby:15601, que reemplaza el URI largo y es más fácil de leer. He elegido ‘toby’, pero podría haber elegido cualquier cadena de letras con la misma facilidad.\n\nPasemos ahora de Jack Straw a William Shakespeare y usemos Turtle para describir algunos elementos sobre sus obras. Tendremos que decidir qué archivos de autoridad usar, un proceso que, como se mencionó anteriormente, se optimiza si consultamos otros conjuntos de LOD. Aquí usaremos Dublin Core, un estándar de metadatos usado por las bibliotecas, como uno de nuestros prefijos, el archivo de autoridad del Número de control de la Biblioteca del Congreso para otro, y el último (VIAF) debería serte familiar. En conjunto, estos tres archivos de autoridad proporcionan identificadores únicos para todas las entidades que planeo usar en este ejemplo:\n\n@prefix lccn: &lt;http://id.loc.gov/authorities/names&gt; .\n@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .\n@prefix viaf: &lt;http://viaf.org/viaf&gt; .\n\nlccn:n82011242 dc:creator viaf:96994048 .\n\n\nTen en cuenta el espaciado del punto final después de la última línea. Esta es la forma de Turtle de indicar el final. Técnicamente no tiene que tener el espacio, pero lo hace más fácil de leer después de una larga cadena de caracteres.\n\nEn el ejemplo anterior, lccn: n82011242 representa a Macbeth; dc: creator vincula Macbeth a su autor; viaf: 96994048 representa a William Shakespeare.\n\nTurtle también te permite listar tripletas sin molestarte en repetir cada URI cuando acabas de usarlo. Agreguemos la fecha en la que los expertos creen que Macbeth fue escrita utilizando el par atributo-valor de Dublin Core:dc: created 'YYYY' :\n\n@prefix lccn: &lt;http://id.loc.gov/authorities/names&gt; .\n@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .\n@prefix viaf: &lt;http://viaf.org/viaf&gt; .\nlccn: n82011242   dc: creator   viaf: 96994048 ;\n        dc: created   \"1606\"   .\n\n\n¿Recuerdas la estructura de la tripleta, discutida en la sección 1? Allí pusimos este ejemplo:\n\n1 persona 15601 (el sujeto) 2  representanteEnElParlamentoUK (el predicado) 3 \"Blackburn\" (el objeto)\n\nLa clave es que el predicado conecta el sujeto y el objeto. Describe la relación entre ellos. El sujeto ocupa el primer lugar en la tripleta, pero eso es una cuestión de elección propia, como comentamos en el ejemplo de las personas a quienes Liszt enseñó piano.\n\nPuedes usar un punto y coma si el sujeto es el mismo pero el predicado y el objeto son diferentes, o una coma si el sujeto y el predicado son iguales y solo el objeto es diferente.\n\nno2010025398 dc:creator viaf:96994048 ;\n                viaf:12323361 .\n\n\nAquí estamos diciendo que Shakespeare (96994048) y John Fletcher (12323361) fueron los creadores de la obra Los dos nobles caballeros.\n\nCuando anteriormente vimos las ontologías, sugerí que le echaras un vistazo a los ejemplos de la Music Ontology. Espero que no te decepcionaran. Echa un vistazo de nuevo ahora. Todavía es algo complicado, pero ¿tiene más sentido ahora?\n\nUna de las ontologías más accesibles es Friend of a Friend, o FOAF. Está diseñada para describir personas y es, quizás por esa razón, bastante intuitiva. Si, por ejemplo, deseas escribirme para decirme que este tutorial es lo mejor que has leído, aquí está mi dirección de correo electrónico expresada como tripletas en FOAF:\n\n@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .\n:\"Jonathan Blaney\" foaf:mbox &lt;mailto:jonathan.blaney@sas.ac.uk&gt; .\n\n\nRDF/XML\n\nEn contraste con Turtle, RDF/XML puede parecer un poco pesado. Para empezar, convirtamos una tripleta del Turtle anterior, la que dice que Shakespeare fue el creador de Los dos parientes nobles:\n\nno2010025398 dc:creator viaf:96994048 .\n\n\nEn RDF/XML, con los prefijos declarados dentro del fragmento XML, es así:\n\n&lt;rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-\n         xmlns:dc=\"http://purl.org/dc/terms/\"&gt;\n    &lt;rdf:Description rdf:about=\"http://info:lccn/2010025398\"&gt;\n       &lt;dc:creator rdf:resource=\"http://viaf.org/96994048\"/&gt;\n    &lt;/rdf:Description&gt;\n&lt;/rdf:RDF&gt;\n\n\nEl formato RDF/XML tiene la misma información básica que Turtle, pero se escribe de forma muy diferente, basándose en los principios de las etiquetas XML anidadas.\n\nPasemos a un ejemplo diferente para mostrar cómo RDF/XML combina tripletas y, al mismo tiempo, presentamos SKOS (Simple Knowledge Organization System - Sistema Simple de Organización del Conocimiento), que está diseñado para codificar tesauros o taxonomías.\n\n &lt;skosConcept rdf:about=\"http://www.ihr-tobias.org/concepts/21250/Abdication\"&gt;\n    &lt;skos:prefLabel&gt;Abdication&lt;/skos:prefLabel&gt;\n  &lt;/skosConcept&gt;\n\n\nAquí estamos diciendo que el concepto SKOS 21250, abdicación, tiene una etiqueta preferida de “abdicación”. La forma en que funciona es que el elemento sujeto (incluida la parte de abdicación, que es un valor de atributo en términos XML) tiene el predicado y el objeto anidados dentro de él. El elemento anidado es el predicado y el nodo hoja (the leaf node), es el objeto. Este ejemplo está tomado de un proyecto para publicar un tesauro de historia británica e irlandesa.\n\nAl igual que con Turtle, podemos agregar más tripletas. Entonces, declaremos que el término más restringido en nuestra jerarquía de temas, uno más abajo de Abdicación será Crisis de la abdicación (1936).\n\n &lt;skosConcept rdf:about=\"http://www.ihr-tobias.org/concepts/21250/abdication\"&gt;\n    &lt;skos:prefLabel&gt;Abdication&lt;/skos:prefLabel&gt;\n  &lt;/skosConcept&gt;\n &lt;skosConcept rdf:about=\"http://www.ihr-tobias.org/concepts/21250/abdication\"&gt;\n    &lt;skos:narrower rdf:resource=\"http://www.ihr-tobias.org/concepts/19838/abdication_crisis_1936\"/&gt;\n  &lt;/skosConcept&gt;\n\n\n¿Recuerdas cómo los predicados y los objetos están anidados dentro del sujeto? Aquí lo hemos hecho dos veces con el mismo sujeto, por lo que podemos hacer esto menos detallado al anidar ambos conjuntos de predicados y objetos dentro de un sujeto:\n\n &lt;skosConcept rdf:about=\"http://www.ihr-tobias.org/concepts/21250/abdication\"&gt;\n    &lt;skos:prefLabel&gt;Abdication&lt;/skos:prefLabel&gt;\n    &lt;skos:narrower rdf:resource=\"http://www.ihr-tobias.org/concepts/19838/abdication_crisis_1936\"/&gt;\n\t&lt;/skosConcept&gt;\n\n\nSi estás familiarizado con XML, esto será muy fácil para ti. Si no lo estás, podrías preferir un formato como Turtle. Pero la ventaja aquí es que creando tu RDF/XML puedes usar las herramientas habituales disponibles para XML, como editores y analizadores XML, para verificar que tu RDF/XML esté formateado correctamente. Si no tienes experiencia con XML, recomiendo Turtle, para lo que puedes usar una herramienta en línea para verificar que tu sintaxis sea correcta.\n\nConsultas RDF con SPARQL\n\nPara esta sección final, interrogaremos algunos LOD y veremos qué podemos hacer con ellos.\n\nEl lenguaje de consulta que utilizamos para los LOD se llama SPARQL. Es uno de esos acrónimos recursivos amados por los tecnólogos: Protocolo y lenguaje de consulta SPARQL .\n\nComo mencioné al principio, The Programming Historian en español tiene una lección completa, por Matthew Lincoln, sobre el uso de SPARQL. Esta última sección sólo proporciona una descripción general de los conceptos básicos y, si SPARQL despierta tu interés, puedes obtener una base sólida con el tutorial de Lincoln.\n\nVamos a ejecutar nuestras consultas SPARQL en DBpedia, que es un gran conjunto de LOD derivado de Wikipedia. Además de estar lleno de información que es muy difícil de encontrar a través de la interfaz habitual de Wikipedia, tiene varios “puntos finales” SPARQL: interfaces donde puedes escribir consultas SPARQL y obtener resultados de las tripletas de DBpedia.\n\nEl punto de entrada (endpoint) de consulta SPARQL que yo uso se llama snorql. Estos puntos de entrada a veces parecen desconectarse, por lo que, si ese fuera el caso, busca dbpedia sparql en internet para encontrar un reemplazo similar.\n\nSi vas a la URL snorql indicada antes, verás que al principio ya están declarados varios prefijos, lo cual te será útil. También reconocerás ya algunos de los prefijos.\n\n\n    \n\n    cuadro de consulta predeterminado de snorql, con algunos prefijos declarados para ti\n\n\n\n\nEn el cuadro de consulta, debajo de las declaraciones de prefijo, deberías ver:\n\nSELECT * WHERE {\n...\n}\n\n\nSi alguna vez ha escrito una consulta de base de datos en Structured Query Language, más conocido como SQL, esto te resultará bastante familiar y te ayudará a aprender SPARQL. Si no, no te preocupes. Las palabras clave utilizadas aquí, SELECT y WHERE no distinguen entre mayúsculas y minúsculas, pero algunas partes de una consulta SPARQL lo pueden hacer (ver a continuación), por lo que te recomiendo que sigas fielmente los ejemplos mostrados a lo largo de las consultas en este curso.\n\nAquí  SELECT significa devolver algo y *  significa darme todo. WHEREintroduce una condición, que es donde pondremos los detalles de qué clase de cosas queremos que nos devuelva la consulta.\n\nComencemos con algo simple para ver cómo funciona esto. Pega esto (o, mejor, escríbelo) en el cuadro de consulta:\n\nSELECT * WHERE {\n:Lyndal_Roper ?b ?c\n}\n\n\nHaz clic en “Go!”(ir) y, si dejaste el cuadro desplegable como “Browse” (navegar), deberías obtener dos columnas con la etiqueta “b” y “c”. (Ten en cuenta que aquí, buscando una cadena, las mayúsculas y minúsculas sí importan: lyndal_roper no te dará ningún resultado).\n\n\n    \n\n    Parte inicial de la lista de resultados de una consulta para todas las tripletas con ‘Lyndal_Roper’ como sujeto\n\n\n\n\nRecapitulando, ¿qué acaba de pasar? ¿Y cómo sé qué escribir?\n\nEn realidad no lo sabía y ese es uno de los problemas con los puntos de entrada SPARQL. Al conocer un conjunto de datos, debes probar y descubrir qué términos se usan. Como este proviene de Wikipedia y me interesaba saber qué información sobre historiadores podía encontrar, fui a la página de Wikipedia del historiador Lyndal Roper.\n\nLa parte al final de la URL es Lyndal_Roper y llegué a la conclusión de que esta cadena es probablemente la forma en que se hace referencia a Roper en DBpedia. Como no sé qué más podría haber en las tripletas que mencionen a Roper, usé ?a y ?b. Estos son comodines: podría haber escrito igualmente  ?en_cualquier_sitio y ?como_gustes y las columnas tendrían esos títulos. Cuando desees ser más preciso sobre lo que estás  obteniendo, será más importante etiquetar las columnas de forma significativa.\n\nPrueba ahora tu propia consulta SPARQL ahora: elije una página de Wikipedia y copia la parte final de la URL, lo que aparece después de la barra diagonal final, y colócalo en lugar de Lyndal_Roper. Luego presiona ‘Go!’.\n\nA partir de la información que obtienes de estos resultados, es posible generar consultas más precisas. Esto puede ser un tanto impredecible, al menos para mí, así que no te preocupes si algunos no funcionan.\n\nVolvamos a los resultados de la consulta que ejecuté hace un momento:\n\nSELECT * WHERE {\n:Lyndal_Roper ?b ?c\n}\n\n\nPuedo ver una larga lista en la columna etiquetada como c . Estos son todos los atributos que Roper tiene en la DBpedia y nos ayudarán a encontrar otras personas con estos atributos. Por ejemplo, puedo ver http://dbpedia.org/class/yago/Historian110177150. ¿Puedo usar esto para obtener una lista de historiadores? Voy a poner esto en mi consulta pero en tercer lugar (porque ahí es donde estaba cuando lo encontré en los resultados de Lyndal Roper). Mi consulta se ve así:\n\nSELECT * WHERE {\n?historian_name ?predicate &lt;http://dbpedia.org/class/yago/Historian110177150&gt;\n}\n\n\nHe hecho un pequeño cambio aquí. Si esta consulta funciona entonces espero que mis historiadores estén en la primera columna, porque “historiador” no parece ser un predicado: no funciona como un verbo en una oración; así que voy a llamar a mi primera columna de resultados ‘nombre_historiador’ y a mi segunda (de la que no sé nada) ‘predicado’.\n\nEjecuta la consulta. ¿Te funciona? Yo obtuve una gran lista de historiadores.\n\n\n    \n\n    historiadores, según DBpedia\n\n\n\n\nAsí que esto funciona para crear listas, lo cual es útil, pero sería mucho más potente combinar listas, para obtener intersecciones de conjuntos. Encontré un par de cosas más que podrían ser interesantes para consultar en los atributos de DBpedia de Lyndal Roper: http://dbpedia.org/class/yago/WikicatBritishHistorians y http://dbpedia.org/class/yago/WikicatWomenHistorians. Es muy fácil combinarlos pidiendo una variable que retornará (en nuestro caso, esta es ?name) y luego usar eso en múltiples líneas de una consulta. Ten en cuenta también el espacio y el punto al final de la primera línea que comienza con ?name:\n\nSELECT ?name\nWHERE {\n?name ?b &lt;http://dbpedia.org/class/yago/WikicatBritishHistorians&gt; .\n?name ?b &lt;http://dbpedia.org/class/yago/WikicatWomenHistorians&gt;\n}\n\n\n¡Funciona! Obtengo cinco resultados. En el momento de escribir, hay cinco historiadoras británicas en DBpedia…\n\n\n    \n\n    Historiadoras británicas, según DBpedia\n\n\n\n\n¿Solo cinco mujeres británicas historiadoras? Por supuesto que hay, en realidad, muchas más que eso, como podríamos demostrar fácilmente sustituyendo el nombre de, digamos, Alison Weir en nuestra primera consulta de Lyndal Roper. Esto nos lleva al problema con Dbpedia que mencioné anteriormente: no está marcado de manera consistente con información estructural del tipo que usa DBpedia. Nuestra consulta puede enumerar algunas historiadoras británicas, pero resulta que no podemos usarla para generar una lista significativa de personas en esta categoría. Todo lo que hemos encontrado es la gente en las entradas en Wikipedia que alguien ha decidido categorizar como “Historiador británico” y “mujer historiadora”.\n\nCon SPARQL en DBpedia, debes tener cuidado con las inconsistencias del material de múltiples fuentes. Podrías usar SPARQL exactamente de la misma manera en un conjunto de datos más mantenido, por ejemplo, los datos del gobierno del Reino Unido: https://data-gov.tw.rpi.edu//sparql y esperar obtener resultados más sólidos (hay un breve resumen tutorial para este conjunto de datos aquí: https://data-gov.tw.rpi.edu/wiki/A_crash_course_in_SPARQL).\n\nSin embargo, a pesar de sus inconsistencias, DBpedia es un gran lugar para aprender SPARQL. Esto solo ha sido una breve introducción pero hay mucho más en ‘Uso de SPARQL para acceder a datos abiertos enlazados’.\n\nLecturas adicionales y recursos\n\n\n  \n    Dean Allemang y James Hendler, Semantic Web for the Working Ontologist, 2nd edn, Elsevier, 2011\n  \n  \n    Tim Berners-Lee Linked Data\n  \n  \n    Bob DuCharme, Learning SPARQL, O’Reilly, 2011\n  \n  \n    El blog de Bob DuCharme merece la pena leerlo también.\n  \n  \n    Richard Gartner, Metadata: Shaping Knowledge from Antiquity to the Semantic Web, Springer, 2016\n  \n  \n    Seth van Hooland y Ruben Verborgh, Linked Data for Libraries, Archives and Museums, 2015\n  \n  \n    Mira también la página web complementaria del libro\n  \n  \n    Matthew Lincoln ‘Using SPARQL to access Linked Open Data’\n  \n  \n    Linked Data guides and tutorials\n  \n  \n    Dominic Oldman, Martin Doerr y Stefan Gradmann, “Zen and the Art of Linked Data: New Strategies for a Semantic Web of Humanist Knowledge”, in A New Companion to Digital Humanities, editado por Susan Schreibman et al.\n  \n  \n    Max Schmachtenberg, Christian Bizer y Heiko Paulheim, State of the LOD Cloud 2017\n  \n  \n    David Wood, Marsha Zaidman y Luke Ruth, Linked Data: Structured data on the Web, Manning, 2014\n  \n  \n    Biblioteca del Congreso Nacional de Chile, Linked Open Data: ¿Qué es?\n  \n  \n    Ricardo Santos Muñoz, Introducción a Linked Open Data\n  \n  \n    Ana-Isabel Torre-Bastida, Marta González-Rodríguez y Esther Villar-Rodríguez, Datos abiertos enlazados (LOD) y su implantación en bibliotecas: iniciativas y tecnologías\n  \n\n\nAgradecimientos\n\nEl autor del tutorial agradece a los revisores del tutorial original, Matthew Lincoln y a Terhi Nurmikko-Fuller, y al editor, Admam Cyrmble, por dedicar tiempo generosamente a ayudarle a mejorar este tutorial con numerosas sugerencias, aclaraciones y correcciones. Esta lección se basa en un trabajo perteneciente al “Tesauro de historia Británica e Irlandsesa como SKOS” (proyecto Tobias), financiado por el AHRC. Ha sido revisado para The Programming Historian.\n\nCon este tutorial aprenderás los fundamentos (URIs, ontologías, formato RDF y, muy brevemente, SPARQL) de los Datos abiertos enlazados.\n\n"
  },


  {
    "id": 26,
    "url": "http://localhost:4000/es/lecciones/introduccion-e-instalacion",
    "title": "Introducción a Python e Instalación",
    "body": "\nIntroducción a Python e Instalación\n\nContenidos\n\n\n  Objetivos de la lección\n  El lenguaje de programación Python\n  ¡Respalda los datos de tu computadora!    \n      Selecciona tu sistema operativo\n    \n  \n  Paso 1.- Instalar el software\n\n\nObjetivos de la lección\n\nEsta primera lección de nuestra sección sobre recursos en línea está diseñada para introducirte en el tema y preparar tu computadora para comenzar a programar. Nos enfocaremos en la instalación del software necesario para hacerlo –que es software libre y de buena reputación-, y finalmente te ayudaremos a dar una probadita en programación (como dicen en inglés: “get your toes wet”), con unos programas sencillos que producen resultados inmediatos.\n\nEn este módulo inicial instalarás el Lenguaje de programación Python, el Analizador sintáctico (parser) Beautiful Soup HTML/XML, y un editor de texto. Las capturas de pantalla que se ofrecen como ejemplo provienen del editor de texto Komodo Edit, pero puedes utilizar cualquier otro editor de texto capaz de trabajar con Python. Aquí hay una lista de opciones al respecto: Editores de Texto para Python. Una vez que todo esté instalado, escribirás tu primer programa (el clásico “Hola Mundo”) en Python y HTML.\n\nEl lenguaje de programación Python\nPython fue el primer lenguaje de programación que se introdujo en Programming Historian. Es un lenguaje de programación libre y de código abierto. Antes de que descargues el software es necesario tomar nota de que en todas las lecciones se utilizará Python v.3.x porque la versión anterior, Python v.2., dejará de recibir actualizaciones. Si ya utilizabas la versión 2 reconocerás la mayor parte de la sintaxis pero deberás seguir los ejemplos con más detenimiento para estar pendiente a los cambios.\n\n¡Respalda los datos de tu computadora!\n\nAntes de descargar o instalar cualquier nuevo software en tu computadora, es muy importante hacer el respaldo de los datos en tu computadora. Todos los días y antes de programar cualquier cosa, asegúrate de hacer una copia de seguridad de la base de datos de Zotero. Al final de un día de trabajo, respalda nuevamente la base de datos de Zotero y de cualquier programa que hayas escrito ese día. Por lo menos una vez a la semana se debe hacer un respaldo de toda la computadora, aunque es recomendable hacerlo con más frecuencia (en el caso de computadoras Mac, el uso del Time Machine es imprescindible). También es muy buena idea hacer copias de seguridad de tu trabajo en línea; para que en el caso de que algo le pase a tu equipo, casa u oficina no pierdas todo lo hecho. Hay sitios que proveen formas fáciles y relativamente económicas de hacer copias de seguridad, como Jungle Disk y Dropbox.\n\nSelecciona tu sistema operativo\n\nPaso 1.- Instalar el software\n\nCon el fin de trabajar con las diversas técnicas que se ofrecen en Programming Historian, debes descargar e instalar algunos programas de software libre disponibles. Se ofrecen las instrucciones para hacerlo en Mac, Windows y Linux. Una vez que los hayas instalado de acuerdo al sistema operativo de tu equipo, sigue a la siguiente lección: Para entender páginas Web y HTML. Si tienes algún problema con las instrucciones o encuentras algo que no funciona en tu plataforma, ponte en contacto con nosotros.\n\n\n  Instalación de Python en Mac\n  Instalación de Python en Windows\n  Instalación de Python en Linux\n\n\n\nEsta primera lección de nuestra sección sobre recursos en línea está diseñada para introducirte en el tema y preparar tu computadora para comenzar a programar. Nos enfocaremos en la instalación del software necesario para hacerlo –que es software libre y de buena reputación-, y finalmente te ayudaremos a dar una probadita en programación (como dicen en inglés: “get your toes wet”), con unos programas sencillos que producen resultados inmediatos.\n\n"
  },


  {
    "id": 27,
    "url": "http://localhost:4000/es/lecciones/limpieza-de-datos-con-OpenRefine",
    "title": "Limpieza de datos con OpenRefine",
    "body": "\nLimpieza de datos con OpenRefine\n\nContenidos\n\n\n  Objetivos de la lección\n  ¿Por qué los historiadores deben preocuparse por la calidad de los datos?\n  Descripción de la herramienta: OpenRefine\n  Descripción del ejercicio Powerhouse Museum    \n      Comenzando: instalación de OpenRefine e importación de datos\n      Conoce tus datos\n      Eliminar filas en blanco\n      Eliminar duplicados\n      Separar\n      Hacer facetas y agrupar\n      Aplicación de transformaciones ad hoc mediante el uso de expresiones regulares\n      Exportación de tus datos limpios\n      Construir sobre tus datos limpios\n    \n  \n  Conclusiones\n  Notas de la traductora\n\n\nObjetivos de la lección\n\nNo confíes ciegamente en tus datos. Ese es el mensaje clave de este tutorial que se centra en mostrar cómo los investigadores pueden diagnosticar y proceder sobre la exactitud de los datos. En esta lección aprenderás los principios y la práctica de la limpieza de datos,  así como la forma de usar OpenRefine para realizar cuatro tareas esenciales que te ayudarán a limpiar tus datos:\n\n\n  Eliminar registros duplicados\n  Separar varios valores contenidos en el mismo campo\n  Analizar la distribución de valores a lo largo de un conjunto de datos\n  Agrupar diferentes representaciones de la misma realidad\n\n\nEstos pasos se ilustran con la ayuda de una serie de ejercicios basados en una colección de metadatos del Museo Powerhouse, que demuestran cómo los métodos (semi-)automatizados pueden ayudarte a corregir los errores que puedan presentar tus datos.\n\n¿Por qué los historiadores deben preocuparse por la calidad de los datos?\n\nLos registros duplicados, los valores vacíos y los formatos inconsistentes son fenómenos para los que debemos estar preparados cuando se usan conjuntos de datos históricos. Esta lección te enseñará a descubrir las inconsistencias en los datos incluidos en una hoja de cálculo o en una base de datos. A medida que incrementamos el compartir, agregar y reutilizar datos en la web, los historiadores tendrán que responder a los problemas de calidad de los datos que inevitablemente aparecerán. Usando un programa llamado OpenRefine, podrás identificar fácilmente errores sistemáticos tales como celdas en blanco, duplicados, inconsistencias de ortografía, etc. OpenRefine no sólo te permite diagnosticar rápidamente la exactitud de tus datos, sino también actuar sobre ciertos errores de forma automatizada.\n\nDescripción de la herramienta: OpenRefine\n\nTiempo atrás los historiadores debieron confiar en los especialistas en tecnologías de la información para diagnosticar la calidad de los datos y ejecutar tareas de limpieza. Estas tareas requerían el uso de programas de ordenador personalizados cuando se trabajaba con conjuntos de datos de gran tamaño. Por suerte, el advenimiento de las herramientas de transformación interactiva de datos (Interactive Data Transformation - IDTs) permiten realizar actualmente  operaciones rápidas y económicas sobre grandes cantidades de datos, incluso realizadas por profesionales que carecen de amplias habilidades técnicas.\n\nLas IDTs se asemejan a los programas de hojas de cálculo de escritorio con los que todos estamos familiarizados, con los que comparten algunas funcionalidades. Por ejemplo, puedes utilizar una aplicación como Microsoft Excel para ordenar los datos basándote en filtros numéricos, alfabéticos y desarrollados a medida, lo que te permite detectar errores con mayor facilidad. Configurar estos filtros en una hoja de cálculo puede resultar difícil, ya que son una funcionalidad secundaria. De forma genérica se puede decir que las hojas de cálculo están diseñadas para trabajar en filas y celdas individuales mientras que las IDTs operan en grandes rangos de datos a la vez. Estas “super-hojas de cálculo” ofrecen una interfaz integrada y fácil de usar a través de la cual los usuarios finales pueden detectar y corregir errores.\n\nEn los últimos años se han desarrollado varias herramientas de propósito general para la transformación interactiva de datos, tales como Potter’s Wheel ABC y Wrangler (actualmente Trifacta Wrangler). Aquí nos centraremos específicamente en OpenRefine (anteriormente Freebase Gridworks y Google Refine) pues, en opinión de los autores, es la herramienta más fácil de usar para procesar y limpiar eficientemente grandes cantidades de datos en una interfaz basada en navegador.\n\nAdemás del perfilado de datos y las operaciones de limpieza, las extensiones de OpenRefine permiten a los usuarios identificar conceptos en texto no estructurado, un proceso denominado reconocimiento de nombres de entidades (named-entity recognition, NER, en inglés), pudiendo también cotejar1 sus propios datos con bases de conocimiento existentes. Así, OpenRefine puede ser una práctica herramienta para vincular datos con conceptos y autoridades que ya han sido publicadas en la Web por instituciones como la Biblioteca del Congreso de los EEUU u OCLC. La limpieza de datos es un requisito previo para estos pasos; la tasa de éxito del NER y un proceso de coincidencia fructífera entre tus datos y las autoridades externas depende de tu capacidad para hacer tus datos tan coherentes como sea posible.\n\nDescripción del ejercicio Powerhouse Museum\n\nEl Museo Powerhouse de Sydney ofrece la exportación gratuita de metadatos de su colección en su sitio web. Este museo es uno de los mayores de ciencia y tecnología de todo el mundo, proporcionando acceso a casi 90.000 objetos, que van desde máquinas de vapor a cristalería fina y desde  alta costura a chips de ordenador.\n\nEste museo ha estado divulgando activamente su colección en línea y haciendo que la mayoría de sus datos estén disponibles libremente. Desde el sitio web del museo, se puede descargar un archivo de texto separado por tabulaciones llamado phm-collection.tsv, que se puede abrir como una hoja de cálculo. El archivo descomprimido (58MB) contiene metadatos básicos (17 campos) para 75.823 objetos, publicados bajo una licencia Creative Commons de Reconocimiento-Compartir-Igual 2.5. En este tutorial usaremos una copia de los datos que hemos archivado para descargarlos (en un momento). Esto asegura que si el Museo Powerhouse actualiza los datos, te seguirá siendo posible el seguir esta Lección.\n\nA través del proceso de perfilado de datos y de limpieza, el estudio de caso se centrará específicamente en el campo Categorías, que se rellena con términos del Tesauro de nombres de objetos del museo Powerhouse (PONT). PONT reconoce el uso y la ortografía de Australia, y refleja de forma muy directa las fortalezas de la colección. En la colección encontrarás las mejores representaciones de la historia social y las artes decorativas y, en comparación, pocos nombres de objetos relacionados con las bellas artes y la historia natural.\n\nLos términos del campo Categorías constituyen lo que llamamos un vocabulario controlado. Un vocabulario controlado consiste en palabras clave que describen el contenido de una colección usando un número limitado de términos, y a menudo es un punto de entrada clave en los conjuntos de datos utilizados por los historiadores en las bibliotecas, archivos y museos. Por esta razón vamos a prestar especial atención al campo ‘Categorías’. Una vez que se han limpiado los datos, debería ser posible reutilizar los términos del vocabulario controlado para encontrar información adicional sobre ellos en otros sitios en línea, lo que se conoce como creación de datos enlazados.\n\nComenzando: instalación de OpenRefine e importación de datos\n\nDescarga OpenRefine y sigue las instrucciones de instalación. OpenRefine funciona en todas las plataformas: Windows, Mac y Linux. OpenRefine se abrirá en tu navegador, pero es importante señalar que la aplicación se ejecuta localmente y que tus datos no se almacenarán en línea. Los archivos de datos están disponibles en nuestro sitio web FreeYourMetadata, que serán los que se utilizarán a lo largo de este tutorial. Descarga el archivo phm-collection.tsv antes de continuar.\n\n\n  Nota de la traductora: Open Refine se instala por defecto en inglés. Para usarlo en español sólo necesitas cambiar la configuración del lenguaje. Pulsa Language settings y se mostrará en la ventana un desplegable donde podrás escoger el español. Pulsa Change language y la página te dirá que necesita refrescarse para aplicar los cambios. Haz clic en Aceptar y la página y el resto del programa aparecerán en español.\n\n\nEn la página de inicio de OpenRefine, crea un nuevo proyecto utilizando el archivo de datos descargado y haz clic en ‘Siguiente’. De forma predeterminada, la primera línea se analizará correctamente como el nombre de una columna, pero es necesario desmarcar la casilla de verificación ‘Las comillas se usan para agrupar celdas que contienen separadores de columna’, ya que las comillas dentro del archivo no tienen ningún significado para OpenRefine. Ahora haz clic en ‘Crear proyecto’. Si todo va bien, verás 75.814 filas. Como alternativa, puedes descargarte directamente el proyecto inicial de OpenRefine.\n\nEl conjunto de datos del museo Powerhouse está formado por metadatos detallados de todos los objetos de la colección, incluyendo título, descripción, varias categorías a las que pertenece el objeto, información de procedencia y un vínculo persistente al objeto en el sitio web del museo. Para tener una idea de a qué objeto corresponden los metadatos simplemente haz clic en el vínculo persistente y se abrirá el sitio web.2\n\n\n    \n\n    Figura 1: Captura de pantalla de un Objeto de Muestra del sitio web del Museo Powerhouse\n\n\n\n\nConoce tus datos\n\nLo primero que debes hacer es echar un vistazo general y conocer tus datos. Puedes inspeccionar los diferentes valores de datos mostrándolos en facetas. Se podría considerar una faceta como una lente a través de la cual se visualiza un subconjunto específico de los datos, basado en un criterio de su elección. Haz clic en el triángulo situado delante del nombre de la columna, selecciona Facetas y crea una faceta. Por ejemplo, intenta crear una faceta de texto o una faceta numérica, dependiendo de la naturaleza de los valores contenidos en los campos (los valores numéricos se muestran en color verde 3). Sin embargo, debes tener en cuenta que las facetas de texto son más útiles en campos con valores redundantes (por ejemplo, Categorías); si al ejecutarse te aparece el error ‘son muchas para mostrar’, puedes optar por aumentar el límite de recuento de opciones por encima de los 2.000 predeterminados, aunque un límite demasiado alto puede enlentecer la aplicación (5.000 suele ser una opción segura). Las facetas numéricas no tienen esta restricción. Para más opciones, selecciona Facetas personalizadas: la faceta por blanco, por ejemplo, resulta útil para saber cuántos valores se rellenaron para cada campo. Las exploraremos más adelante en los siguientes ejercicios.\n\nEliminar filas en blanco\n\nUna cosa que notarás al crear una faceta numérica 4 para la columna Record ID (Identificador del registro) es que tres filas están vacías. Puedes encontrarlos deseleccionando la casilla Numérico, dejando sólo valores No-numéricos. En realidad, estos valores no están realmente en blanco sino que contienen un solo carácter de espacio en blanco, que puede verse moviendo el cursor hasta donde debería haber estado y haciendo clic en el botón ‘Editar’ que aparece. Para eliminar estas filas, haz clic en el triángulo que se encuentra delante de la primera columna denominada ‘Todas’, selecciona ‘Editar filas’ y, a continuación, ‘Eliminar todas las filas que encajen’. Cierra la faceta numérica para ver las restantes 75.811 filas.\n\nEliminar duplicados\n\nUn segundo paso es detectar y eliminar duplicados. Estos pueden ser localizados clasificándolos por un valor único, como el Record ID (en este caso estamos asumiendo que el ID de registro debería ser único para cada entrada). La operación se puede realizar haciendo clic en el triángulo izquierdo de Record ID, luego eligiendo ‘Ordenar’ … y seleccionando la viñeta ‘números’. En OpenRefine, la clasificación es sólo una ayuda visual, a menos que hagas permanente el reordenamiento. Para ello, haz clic en el menú Sort que aparece en la parte superior y selecciona ‘Reordenar filas permanentemente’. Si olvidas hacer esto, obtendrás resultados impredecibles más adelante en este tutorial.\n\nLas filas idénticas son ahora adyacentes entre sí. A continuación, dejaremos en blanco el Record ID de las filas que tienen el mismo ID de registro que la fila superior a ellos, marcándolos como duplicados. Para ello, haz clic en el triángulo del campo Record ID, elije Editar celdas &gt; Vaciar hacia abajo. El mensaje de estado indica que la operación ha afectado a 84 columnas (si olvidaste reordenar las filas permanentemente, obtendrás sólo 19, si es así, deshaz la operación en la pestaña ‘Deshacer / Rehacer’ y vuelve al párrafo anterior para asegurarte de que las filas se reordenan y no están simplemente ordenadas). Elimina estas filas creando una faceta de ‘celdas en blanco’ en la columna Record ID (‘Facetas’ &gt; ‘Facetas personalizadas’ &gt; ‘Faceta por blanco’), seleccionando las 84 líneas en blanco haciendo clic en ‘true’ y quitándolas usando el triángulo ‘Todos’ (‘Editar filas’ &gt; ‘Eliminar todas las filas que encajen’). Al cerrar la faceta, verás 75.727 filas únicas.\n\nTen en cuenta que se necesita especial precaución al eliminar duplicados. En el paso antes mencionado, suponemos que el conjunto de datos tiene un campo con valores únicos, lo que indica que la fila entera representa un duplicado. Esto no tiene porqué ser necesariamente el caso, por lo que se debe adoptar gran precaución para verificar manualmente si la fila entera representa o no un duplicado.\n\nSeparar\n\nUna vez eliminados los registros duplicados, podemos observar más de cerca el campo Categorías. En promedio, a cada objeto se le han atribuido 2,25 categorías. Estas categorías están contenidas dentro del mismo campo, separadas por barras verticales, el carácter ‘|’. El registro 9, por ejemplo, contiene tres: Mineral samples|Specimens|Mineral Samples-Geological. Para analizar en detalle el uso de las palabras clave, los valores del campo Categorías deben separarse en celdas individuales ayudándonos con la barra vertical, expandiendo los 75.727 registros en 170.167 filas. Seleccione ‘Editar celdas’, ‘Dividir celdas multi-valuadas’, introduciendo ‘|’ como el carácter separador de valores. OpenRefine te informa que tiene ahora 170.167 filas.\n\nEs importante entender bien el paradigma filas/registros. Haz que la columna Record ID sea visible para ver qué está pasando. Puedes cambiar entre las vistas ‘filas’ y ‘registros’ haciendo clic en los enlaces con ese nombre que están justo encima de los encabezados de las columnas. En la ‘vista de filas’, cada fila representa un Record ID y una sola categoría emparejados, permitiendo la manipulación de cada uno individualmente. La ‘vista de registros’ tiene una entrada para cada Record ID, que puede tener diferentes categorías en filas diferentes (agrupadas en gris o blanco), pero cada registro se manipula como un todo. Concretamente, ahora hay 170.167 asignaciones de categoría (filas), distribuidas en 75.736 items de la colección (registros). Quizás notaste que hay 9 registros más que los 75.727 originales, pero no te preocupes por esto de momento, regresaremos a esta pequeña diferencia más tarde.\n\nHacer facetas y agrupar\n\nUna vez que el contenido de un campo ha sido separado correctamente, pueden aplicarse los filtros, las facetas y los clústeres para dar una visión general rápida y sencilla de los clásicos problemas con metadatos. Mediante la aplicación de la faceta personalizada ‘faceta por blanco’, se pueden identificar inmediatamente los 461 registros que no tienen una categoría, lo que representa el 0,6% de la colección. La aplicación de una faceta de texto al campo Categorías permite obtener una visión general de las 4.934 categorías diferentes utilizadas en la colección (el límite predeterminado es de 2.000, puedes hacer clic en ‘Establecer límite de recuento de opciones’ para aumentarlo a 5.000). Los encabezados pueden ordenarse alfabéticamente o por frecuencia (‘conteo’), dando una lista de los términos más utilizados para indexar la colección. Los tres títulos principales son ‘Numismatics’ (8.041), ‘Ceramics’ (7.390) y ‘Clothing and dress’ (7.279).\n\nTras la aplicación de una faceta, OpenRefine propone agrupar facetas que han sido elegidas para ser agrupadas basándose en  varios métodos de similitud. Como muestra la Figura 2, el agrupamiento te permite resolver problemas relacionados con inconsistencias de casos, uso incoherente de la forma singular o plural y errores ortográficos sencillos. OpenRefine presenta los valores relacionados y propone fusionarlos en el valor más frecuente. Selecciona los valores que desees agrupar seleccionando individualmente sus casillas o haciendo clic en ‘Seleccionar todos’ en la parte inferior, luego selecciona ‘Unir seleccionados y reagrupar’.\n\n\n    \n\n    Figura 2: Visión general de algunas agrupaciones\n\n\n\n\nEl método de agrupación por defecto no es demasiado complejo, por eso no encuentra aún todos los grupos. Experimenta con diferentes métodos para ver qué resultados obtienen. No obstante, ten cuidado: algunos métodos son demasiado agresivos, de forma que podrías terminar agrupando valores que no están relacionados. Ahora que los valores han sido agrupados individualmente, podemos volverlos a unir en una sola celda. Haz clic en el triángulo Categorías y elije Editar celdas, Unir celdas multi-valuadas, Aceptar. Elije el carácter barra vertical (|) como separador. Las filas ahora se ven como antes, con un campo de Categorías de valor múltiple.\n\nAplicación de transformaciones ad hoc mediante el uso de expresiones regulares\n\nComo recordarás se produjo un aumento en el número de registros tras el proceso de separación: nueve registros aparecieron de la nada. Para encontrar la causa de esta disparidad, necesitamos retroceder en el tiempo hasta antes de que separáramos las categorías en filas diferentes. Para ello, activa la ficha Deshacer/Rehacer a la derecha de la ficha Facetas/Filtros y obtendrás un historial de todas las acciones que realizaste desde la creación del proyecto. Selecciona el paso justo antes de ‘Split multi-valued cells in column Categories’5 (Dividir celdas multi-valuadas en la columna categorías) (si has seguido nuestro ejemplo este debería ser ‘Remove 84 rows’ (Eliminar 84 filas)) y luego vuelve a la ficha Facetas/Filtros.\n\nLa cuestión surgió durante la operación de división con el carácter barra vertical, por lo que hay una gran probabilidad de que todo lo que salió mal esté vinculado a este carácter. Apliquemos un filtro en la columna Categorías seleccionando ‘Filtro de texto’ en el menú. Primero escribe un solo | en el campo de la izquierda: OpenRefine te informa que hay 71.064 registros coincidentes (es decir, registros que contienen una barra vertical) de un total de 75.727. Las celdas que no contienen una barra vertical pueden estar en blanco, pero también pueden ser celdas que contienen una sola categoría sin separador, como el registro 29 que sólo tiene ‘Scientific instruments’.\n\nAhora ingresa una segunda | después de la primera para obtener ||` (doble barra vertical): podrás ver que 9 registros coinciden con este patrón. Estos son probablemente los 9 registros culpables de nuestra discrepancia: cuando OpenRefine los divide la doble barra vertical se interpreta como una ruptura entre dos registros en lugar de un separador doble sin sentido. Y ahora, ¿cómo corregimos estos valores? Ve al menú del campo ‘Categorías’ y elije ‘Editar celdas’ &gt; ‘Transformar…’. Bienvenido a la interfaz de transformación de texto personalizado, una potente funcionalidad de OpenRefine que usa el Lenguaje de Expresión OpenRefine (GREL).\n\nLa palabra ‘valor’ en el campo de texto representa el valor actual de cada celda, que puedes ver a continuación. Podemos modificar este valor aplicándole funciones (véase la documentación de GREL para una lista completa). En este caso, queremos reemplazar las barras verticales dobles por una sola. Esto puede lograrse introduciendo la siguiente expresión regular (asegúrate de no olvidar las comillas):\n\nvalue.replace('||','|')\n\n\nBajo el campo de texto ‘Expression’, obtienes una vista previa de los valores modificados, con las barras verticales dobles eliminadas. Haz clic en Aceptar y vuelve a intentar dividir las categorías con ‘Editar celdas’ &gt; ‘Dividir celdas multi-valuadas…’, el número de registros se mantendrá ahora en 75.727 (haz clic en el vínculo ‘registros’ para realizar una doble comprobación).\n\n* * *\\\nOtro problema que se puede resolver con la ayuda de GREL es el problema de los registros para los que la misma categoría se enumera dos veces. Tomemos el registro 41, por ejemplo, cuyas categorías son ‘Models|Botanical specimens|Botanical Specimens|Didactic Displays|Models’. La categoría ‘Models’ aparece dos veces sin ningún motivo, por lo que queremos eliminar este duplicado. Haz clic en el triángulo del campo Categorías y elije Editar celdas, Unir celdas multi-valuadas, Aceptar. Elije el carácter barra vertical como separador. Ahora las categorías se listan como anteriormente. Luego selecciona ‘Editar celdas’ &gt; ‘Transformar’, también en la columna de categorías. Utilizando GREL podemos dividir sucesivamente las categorías mediante el carácter barra vertical, buscar categorías únicas y unirlas de nuevo. Para hacerlo, simplemente escribe la siguiente expresión:\n\nvalue.split('|').uniques().join('|')\n\n\nNotarás que 32.599 celdas están afectadas, más de la mitad de la colección.\n\nExportación de tus datos limpios\n\nDesde que cargaste tus datos por primera vez en OpenRefine, todas las operaciones de limpieza se han realizado en la memoria del programa, dejando intacto el conjunto original de datos. Si deseas guardar los datos que has estado limpiando debes exportarlos haciendo clic en el menú ‘Exportar’ en la parte superior derecha de la pantalla. OpenRefine soporta una gran variedad de formatos, como CSV, HTML o Excel: selecciona lo que mejor te convenga o añade tu propia plantilla de exportación haciendo clic en ‘Plantilla’. También puedes exportar tu proyecto en el formato interno de OpenRefine para compartirlo con otras personas.\n\nConstruir sobre tus datos limpios\n\nUna vez que tus datos han sido limpiados, puedes dar el siguiente paso y explorar otras características interesantes de OpenRefine. La comunidad de usuarios de OpenRefine ha desarrollado dos extensiones particularmente interesantes que te permiten vincular tus datos a datos que ya se han publicado en la Web. La extensión RDF Refine transforma las palabras clave de texto sin formato en URLs. La extensión NER te permite aplicar el reconocimiento de nombres de entidades (NER), que identifica palabras clave en el texto de los campos textuales y les inserta una URL.\n\nConclusiones\n\nSi sólo recordaras una cosa de esta lección, debería ser lo siguiente: todos los datos están sucios, pero tú puedes hacer algo para remediarlo. Como te hemos mostrado, hay ya bastantes cosas que puedes hacer tú mismo para aumentar significativamente la calidad de los datos. En primer lugar, has aprendido cómo puedes obtener una panorámica rápida de cuántos valores vacíos contiene tu conjunto de datos y con qué frecuencia se utiliza un valor determinado (por ejemplo, una palabra clave) en toda una colección. Estas lecciones también han demostrado cómo resolver problemas recurrentes tales como duplicados e inconsistencias ortográficas de forma automatizada con la ayuda de OpenRefine. No dudes en experimentar con las funciones de limpieza, ya que estás realizando estos pasos en una copia de tu conjunto de datos, y OpenRefine te permite rastrear todos tus pasos (y volver atrás) en el caso de que hayas cometido un error.\n\nNotas de la traductora\n\n\n  \n    \n      Denominado también conciliar o reconciliar. &#8617;\n    \n    \n      La página del Museo Powerhouse ha sido modificada desde la publicación original de esta lección en 2013. La página actual que muestra la información de este mismo objeto de la imagen es https://collection.maas.museum/object/11848 &#8617;\n    \n    \n      Es posible que al cargar este proyecto no veas ninguna columna con este color. Esto significa que ningún campo tiene definidos sus valores como numéricos. &#8617;\n    \n    \n      Al cargar el proyecto es muy posible que esta columna aparezca con formato de texto. Para poder aplicar una faceta numérica primero hay que convertirla a formato numérico: ‘Editar celdas’ &gt; ‘Transformaciones comunes’ &gt; ‘a número’. &#8617;\n    \n    \n      Esta parte de la interfaz del programa no aparece traducida. &#8617;\n    \n  \n\n\nEste tutorial se enfoca en cómo los académicos pueden diagnosticar y tomar acciones para asegurar la precisión de sus datos.\n\n"
  },


  {
    "id": 28,
    "url": "http://localhost:4000/es/lecciones/manipular-cadenas-de-caracteres-en-python",
    "title": "Manipular cadenas de caracteres en Python",
    "body": "\nManipular cadenas de caracteres en Python\n\nContenidos\n\n\n  Objetivos de la lección\n  Manipular cadenas de caracteres en Python\n  Operadores de cadenas de caracteres: adición y multiplicación    \n      Concatenar\n      Multiplicar\n      Añadir\n    \n  \n  Métodos para cadenas de caracteres: buscar, cambiar    \n      Extensión\n      Encontrar\n      Minúsculas\n      Reemplazar\n      Cortar\n      Secuencias de escape\n    \n  \n  Lecturas sugeridas    \n      Sicronización de código\n    \n  \n\n\nObjetivos de la lección\n\nEsta lección es una rápida introducción a técnicas de manipulación de cadenas de caracteres (o strings) en Python. Saber cómo manipular cadenas de caracteres juega un papel fundamental en la mayoría de las tareas de procesamiento de texto. Si quieres experimentar con las siguientes lecciones puedes escribir y ejecutar pequeños programas tal como lo hicimos en lecciones previas, o puedes abrir tu intérprete de comandos de Python / Terminal para probarlos ahí.\n\nManipular cadenas de caracteres en Python\n\nSi has estado expuesto antes a otro lenguaje de programación, sabrás que necesitas declarar o escribir variables antes de que puedas almacenar cualquier cosa en ellas. Esto no es necesario cuando trabajas con cadenas de caracteres en Python. Podemos crear una cadena de caracteres simplemente encerrando contenido entre comillas después de un signo de igual (=).\n\nmensaje = “Hola Mundo”\n\n\nOperadores de cadenas de caracteres: adición y multiplicación\n\nUna cadena de caracteres en un objeto que consiste precisamente en una serie de signos o caracteres. Python sabe cómo tratar un número de representaciones poderosas y de propósito general, incluidas las cadenas de caracteres. Una forma de manipular cadenas de caracteres es utilizar operadores de cadenas de caracteres. Dichos operadores se representan con símbolos que asociamos a las matemáticas, como +, -, *, / y =. Estos signos realizan acciones similares a sus contrapartes matemáticas cuando se usan con las cadenas de carateres, aunque no iguales.\n\nConcatenar\n\nEste término significa juntar cadenas de caracteres. El proceso de concatenación se realiza mediante el operador de suma (+). Ten en cuenta que debes marcar explícitamente dónde quieres los espacios en blanco y colocarlos entre comillas.\n\nEn este ejemplo, la cadena de caracteres “mensaje1” tiene el contenido “Hola Mundo”\n\nmensaje1 = 'Hola' + ' ' + 'Mundo'\nprint(mensaje1)\n-&gt; Hola Mundo\n\n\nMultiplicar\n\nSi quieres varias copias de una cadena de caracteres utiliza el operador de multiplicación (*). En este ejemplo, la cadena de caracteres mensaje2a lleva el contenido “Hola” tres veces, mientras que la cadena de caracteres mensaje2b tiene el contenido “Mundo”. Ordenemos imprimir las dos cadenas.\n\nmensaje2a = 'Hola ' * 3\nmensaje2b = 'Mundo'\nprint(mensaje2a + mensaje2b)\n-&gt; Hola Hola Hola Mundo\n\n\nAñadir\n\n¿Qué pasa si quieres añadir material de manera sucesiva al final de una cadena de caracteres? El operador especial para ello es compuesto (+=).\n\nmensaje3 = 'Hola'\nmensaje3 += ' '\nmensaje3 += 'Mundo'\nprint(mensaje3)\n-&gt; Hola Mundo\n\n\nMétodos para cadenas de caracteres: buscar, cambiar\n\nEn adición a los operadores, Python trae preinstalado docenas de métodos que te permiten hacer cosas con las cadenas de caracteres. Solos o en combinación, los métodos pueden hacer casi todo lo que te imagines con las cadenas de caracteres. Puedes usar como referencia la lista de métodos de cadenas de caracteres (String Methods) en el sitio web de Python, que incluye información de cómo utilizar correctamente cada uno. Para asegurar que tengas una comprensión básica de métodos para cadenas de caracteres, lo que sigue es una breve descripción de los utilizados más comúnmente.\n\nExtensión\n\nPuedes determinar el número de caracteres en una cadena utilizando el método len. Acuérdate que los espacios en blanco cuentan como un carácter.\n\nmensaje4 = 'hola' + ' ' + 'mundo'\nprint(len(mensaje4))\n-&gt; 10\n\n\nEncontrar\n\nPuedes buscar una sub-cadena en una cadena de caracteres utilizando el método find y tu programa te indicará el índice de inicio de la misma. Esto es muy útil para procesos que veremos más adelante. Ten en mente que los índices están numerados de izquierda a derecha y que el número en el que se comienza a contar la posición es el 0, no el 1.\n\nmensaje5 = \"Hola Mundo\"\nmensaje5a = mensaje5.find(\"Mundo\")\nprint(mensaje5a)\n-&gt; 5\n\n\nSi la sub-cadena no está presente el programa imprimirá el valor -1.\n\nmensaje6 = \"Hola Mundo\"\nmensaje6a = mensaje6.find(\"ardilla\")\nprint(mensaje6a)\n-&gt; -1\n\n\nMinúsculas\n\nA veces es útil convertir una cadena de caracteres a minúsculas. Para ello se utiliza el método lower. Por ejemplo, al uniformar los caracteres permitimos que la computadora reconozca fácilmente que “Algunas Veces” y “algunas veces” son la misma frase.\n\nmensaje7 = \"HOLA MUNDO\"\nmensaje7a = mensaje7.lower()\nprint(mensaje7a)\n-&gt; hola mundo\n\n\nConvertir las minúsculas en mayúsculas se logra cambiando .lower() por upper().\n\nReemplazar\n\nSi necesitas cambiar una sub-cadena de una cadena se puede utilizar el método replace.\n\nmensaje8 = \"HOLA MUNDO\"\nmensaje8a = mensaje7.replace(\"L\", \"pizza\")\nprint(mensaje8a)\n-&gt; HOpizzaA MUNDO\n\n\nCortar\n\nSi quieres cortar partes que no quieras del principio o del final de la cadena de caracteres, lo puedes hacer creando una sub-cadena. El mismo tipo de técnica te permite separar una cadena muy larga en componentes más manejables.\n\nmensaje9 = \"Hola Mundo\"\nmensaje9a = mensaje9[1:8]\nprint(mensaje9a)\n-&gt; ola Mun\n\n\nPuedes sustituir las variables por números enteros como en este ejemplo:\n\nmensaje9 = \"Hola Mundo\"\nstartLoc = 2\nendLoc = 8\nmensaje9b = mensaje9[startLoc: endLoc]\nprint(mensaje9b)\n-&gt; la Mun\n\n\nEsto hace mucho más simple usar este método en conjunción con el método find como en el próximo ejemplo, que busca la letra “d” en los seis primeros caracteres de “Hola Mundo” y correctamente nos dice que no se encuentra ahí (-1). Esta técnica es mucho más eficaz en cadenas largas -documentos enteros, por ejemplo. Observa que la ausencia de un número entero antes de los dos puntos significa que queremos empezar desde el principio de la cadena. Podemos usar la misma técnica para decirle al programa que pase hasta el final de la cadena de caracteres dejando vacío después de los dos puntos. Y recuerda que la posición del índice empieza a contar desde 0, no desde 1.\n\nmensaje9 = \"Hola Mundo\"\nprint(mensaje9[:5].find(\"d\"))\n-&gt; -1\n\n\nHay muchos más, pero los métodos para cadenas de caracteres anteriores son un buen comienzo. Fíjate que en el ejemplo anterior utilizamos corchetes en vez de paréntesis. Esta diferencia en los símbolos de la sintaxis es muy importante. Los paréntesis en Python son utilizados generalmente para llevar un argumento a una función. De tal manera que cuando vemos algo como:\n\nprint(len(mensaje7))\n\n\nquiere decir que se lleva la cadena de caracteres “mensaje7” a la función len y entonces enviar el valor resultante de esa función a la declaración print para ser impresa. Una función puede ser llamada sin un argumento, pero de todas formas tienes que incluir un par de paréntesis vacíos después del nombre de la función. Vimos un ejemplo de ello también.\n\nmensaje7 = \"Hola Mundo\"\nmensaje7a = mensaje7.lower()\nprint(mensaje7a)\n-&gt; Hola Mundo\n\n\nEsta declaración le dice a Python que aplique la función lower a la cadena mensaje7 y guarde el valor resultante en la cadena mensaje7a.\n\nLos corchetes sirven para propósitos diferentes. La cadena es una secuencia de caracteres; así que si quieres acceder al contenido de la cadena a partir de su posición en la secuencia, tienes que indicarle a Python un lugar en la secuencia. Eso es lo que hacen los corchetes: señalan el lugar del principio y del final de la secuencia, tal y como vimos en el método cortar.\n\nSecuencias de escape\n\n¿Qué haces cuando necesitas incluir comillas en una cadena de caracteres? No quieres que el intérprete de Python se equivoque y piense que la cadena termina en donde se encuentre una comilla. En Python puedes poner una barra invertida (\\) enfrente de la comilla para que no acabe ahí la cadena. Esto es conocido como secuencia de escape.\n\nprint('\\\"')\n-&gt; \"\n\n\nprint('El programa imprime \\\"Hola Mundo\\\"')\n-&gt; El programa imprime \"Hola Mundo\"\n\n\nOtras dos secuencias de escape te permiten incluir marcas de tabulación (t) y saltos de línea (n):\n\nprint('Hola\\tHola\\tHola\\nMundo')\n-&gt; Hola Hola Hola\nMundo\n\n\nLecturas sugeridas\n\n\n  Lutz, Learning Python\n    \n      Ch. 7: Strings\n      Ch. 8: Lists and Dictionaries\n      Ch. 10: Introducing Python Statements\n      Ch. 15: Function Basics\n    \n  \n\n\nSicronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones1.zip (zip)\n\n\n\nEsta lección es una rápida introducción a técnicas de manipulación de cadenas de caracteres (o strings) en Python.\n\n"
  },


  {
    "id": 29,
    "url": "http://localhost:4000/es/lecciones/mineria-de-datos-en-internet-archive",
    "title": "Minería de datos en las colecciones del Internet Archive",
    "body": "\nMinería de datos en las colecciones del Internet Archive\n\nContenidos\n\n\n  Objetivos de la lección\n  ¿Para quién es útil esta lección?\n  Antes de empezar\n  La Antislavery Collection en el Internet Archive\n  Acceder a una colección del IA con Python\n  Aceder a un elemento del IA en Python\n  Descargar los registros MARC de una colección\n  Entender el bucle for\n  Descargar todos los archivos MARC XML de una colección\n  Construir un reporte de errores en el programa\n  Recolección automática de información desde un archivo MARC\n\n\nObjetivos de la lección\n\nLas colecciones del Internet Archive (IA) incluyen muchas fuentes digitalizadas de interés para los historiadores, entre las cuales se incluyen el JSTOR Early Journal\nContent, la biblioteca personal de John Adams y la colección Haití de la biblioteca John Carter Brown. En resumen, para citar al historiador-programador Ian Milligan, “The Internet Archive rocks.”\n\nEn esta lección aprenderás a descargar archivos desde esas colecciones usando un módulo de Python diseñado específicamente para el análisis semántico de registros MARC XML, un estándar usado comúnmente para dar formato a los metadatos bibliográficos.\n\nPara fines demostrativos, esta lección se enfocará en trabajar con la versión digitalizada de la Anti-Slavery Collection de la Biblioteca Pública de Boston de Copley Square. Primero descargaremos una cantidad relativamente grande de registros MARC desde esa colección, luego, usaremos Python para recolectar y analizar la información bibliográfica asociada a los elementos en esta colección. Por ejemplo, al finalizar esta lección, serás capaz de crear una lista con el nombre de cada lugar desde el cual las cartas de la Anti-Slavery Collection fueron escritas, la cual podrás utilizar posteriormente para un proyecto de creación de mapas o algún otro tipo de análisis.\n\n¿Para quién es útil esta lección?\n\nEsta lección de nivel intermedio es útil para los usuarios de Programming Historian que hayan completado las lecciones generales acerca de cómo descargar archivos y llevar a cabo análisis de textos en ellos, o que quieran ejemplos aplicados de aquellos principios. También puede ser de interés para historiadores o archivistas que trabajen regularmente con formato MARC o con el Internet Archive.\n\nAntes de empezar\n\nEs necesario crear una cuenta para poder esccribir scripts que interactúen con el Internet Archive. Sigue los pasos necesarios para confirmar tu cuenta, con especial cuidado de tu cuenta de correo y  contraseña.\n\nTrabajaremos con dos módulos de Python que no están incluidos en la librería estándar.\n\nEl primero, internetarchive, provee acceso programático al Internet Archive. El segundo, pymarc, hace más sencillo el análisis  de los registros MARC.\n\nLa manera más sencilla para descargarlos es mediante el uso de pip, el administrador de paquetes de Python. Comienza por instalar pip siguiendo la lección de Fred Gibbs: Instalar módulos de Python con pip. Escribe lo siguiente en la línea de comandos para instalar internetarchive:\n\nsudo pip install internetarchive\n\n\nAhora debes configurar tu ordenador de tal manera que el nuevo paquete funcione. Escribe ia configure en la línea de comandos y después ingresa el nombre de la cuenta de correo y la contraseña con las que creaste tu cuenta en el Internet Archive.\n\nDespués instala pymarc:\n\nsudo pip install pymarc\n\n¡Ahora estás listo para trabajar!\n\nLa Antislavery Collection en el Internet Archive\n\nLa Anti-Slavery Collection de la Biblioteca Pública de Boston en Copley Square contiene no solo las cartas de William Lloyd Garrison, uno de los personajes icónicos en el movimiento abolicionista estadounidense; también custodia una inmensa colección de cartas enviadas y recibidas por los reformadores conectados de alguna manera con su persona. Y por “inmensa colección” me refiero a gigantesca. De acuerdo con los cálculos de la biblioteca hay más de 16 000 elementos en Copley.\n\nEn el momento de escribir esta lección, aproximadamente 7 000 de aquellos elementos habían sido digitalizados y subidos al Internet Archive. Esta es una buena noticia, no solo porque IA esté comprometido en poner sus considerables recursos culturales para la libre consulta, también porque cada elemento incorporado está acompañado por una riqueza de metadatos apropiada para la lectura por parte del ordenador.\n\nConsulta esta carta enviada por Frederick Douglass a William Lloyd\nGarrison. Cualquiera puede leer el manuscrito original en línea sin hacer el viaje a Boston, y solo eso sería suficiente para revolucionar y democratizar la futura historiografía del abolicionismo. Pero puedes, también, descargar múltiples archivos asociados con la carta, que ha sido enriquecida con metadatos, como un registro Dublin Core y un completo registro MARCXML que usa el formato MARC 21 de la Biblioteca del Congreso para datos bibliográficos.\n\nDetente y piensa por un momento: ahora mismo, cada elemento subido a la colección contiene esas cosas, lo cual significa que los historiadores tienen acceso a metadatos enriquecidos, imágenes completas y descripciones parciales de cientos de cartas, manuscritos y  publicaciones antiesclavistas.\n\nAcceder a una colección del IA con Python\n\nTodas las colecciones y archivos del Internet Archive (IA) tienen un identificador único, por lo cual todas las URL de las colecciones y archivos se ven así:\n\nhttp://archive.org/details/[IDENTIFIER]\n\n\nPor ejemplo, esta es una URL al elemento mencionado arriba, la carta de Douglass a Garrison:\n\nhttp://archive.org/details/lettertowilliaml00doug\n\n\nY esta es la URL a la Anti-Slavery Collection de la Biblioteca Pública de Boston:\n\nhttp://archive.org/details/bplscas/\n\n\nDebido a que estas URL son tan similares, la única manera de distinguir si se está consultando la página de una colección, en lugar de la de un elemento particular, consiste en examinar la distribución (layout) de la página. La página de un elemento contiene una previsualización del libro en la cabecera de la página y en la columna derecha un listado de enlaces para descargar el archivo en otros formatos. La página de una colección despliega una galería de miniaturas y una serie de opciones para refinar la búsqueda en la columna izquierda. Puedes navegar por diferentes colecciones a través del portal eBook and Texts. También querrás leer algo acerca de cómo los elementos y sus URL están estructurados.\n\nUna vez que tengas el identificador de una colección —bplscas en este caso— ver todos los elementos de la colección es tan sencillo como navegar a la página de búsqueda avanzada del IA, seleccionar la id del menú desplegable junto a Collection, y hacer clic en el botón de búsqueda Search. Al seleccionar bplscas en al búsqueda se obtiene esta página, que al momento de escribir esta lección mostraba 7 029 resultados.\n\nTambién podemos buscar en el Internet Archive usando el módulo de Python que instalamos: al hacerlo es más fácil iterar sobre todos los elementos de la colección con el propósito de realizar posteriores inspecciones y descargas.\n\nPor ejemplo, vamos a modificar el código de ejemplo de la documentación del módulo con el fin de ver si podemos saber, con Python, cuántos elementos hay en la Anti-Slavery Collection. El código de ejemplo luce similar al que ves debajo. La única diferencia es que en lugar de importar tan solo los módulos search_items desde internetarchive vamos a importar la totalidad de la biblioteca.\n\nimport internetarchive\nbuscar = internetarchive.search_items('collection:bplscas')\nprint buscar.num_found\n\n\nTodo lo que debemos hacer consiste en modificar el identificador de la colección: de nasa  a bplscas. Después de iniciar el intérprete del ordenador intenta ingresar cada una de las líneas anteriores seguidas por Enter, pero modificando el id de la colección en el segundo comando:\n\nbuscar = internetarchive.search_items('collection:bplscas')\n\n\nDespués de pulsar Enter en el comando de impresión deberías ser capaz de ver un número que corresponde con la cantidad de resultados que verías al hacer una búsqueda avanzada en una colección desde el navegador.\n\nAceder a un elemento del IA en Python\n\nEl módulo internetarchive también permite acceder a elementos individuales mediante el uso de sus identificadores. Probemos modificando el código de ejemplo de la documentación del módulo de tal manera que obtengamos la carta de Douglass que discutimos anteriormente.\n\nSi estás todavía en el intérprete de comandos de Python no necesitas declarar import internetarchive de nuevo. Como ya hemos importado el módulo completo tan sólo necesitamos modificar el código de ejemplo para que nuestro intérprete sepa que get_item pertenece al módulo internetarchive. También necesitamos modificar el identificador de ejemplo stairs por nuestro identificador del elemento, lettertowilliaml00doug (nótese que el carácter entre los dos ceros es una L minúscula, no el número 1):\n\nelemento = internetarchive.get_item('lettertowilliaml00doug')\nelemento.download()\n\n\nCopia cada una de esas líneas en tu intérpete seguidas por Enter. Según la velocidad de tu conexión a Internet tomará aproximadamente un minuto o dos para que el intérprete de comandos retorne, esto se debe a que tu ordenador se encuentra descargando todos los archivos asociados a ese elemento, incluyendo algunas imágenes muy pesadas. Cuando se haya descargado podrás ver una nueva carpeta en tu ordenador cuyo nombre es el mismo del identificador del elemento. Para verificarlo, primero sal de tu intérprete de Python:\n\nexit()\n\n\nA continuación puedes listar los contenidos del directorio presente para corroborar que ahora existe una carpeta llamada lettertowilliaml00doug. Si despliegas el contenido de esa carpeta podrás ver una lista similar a esta:\n\n39999066767938.djvu\n39999066767938.epub\n39999066767938.gif\n39999066767938.pdf\n39999066767938_abbyy.gz\n39999066767938_djvu.txt\n39999066767938_djvu.xml\n39999066767938_images.zip\n39999066767938_jp2.zip\n39999066767938_scandata.xml\nlettertowilliaml00doug_archive.torrent\nlettertowilliaml00doug_dc.xml\nlettertowilliaml00doug_files.xml\nlettertowilliaml00doug_marc.xml\nlettertowilliaml00doug_meta.mrc\nlettertowilliaml00doug_meta.xml\nlettertowilliaml00doug_metasource.xml\n\n\nAhora que sabemos cómo usar las funciones Search y Item en el \nmódulo internetarchive podemos pensar en cómo llevar a cabo este proceso de manera más eficaz para descargar grupos de información desde las colecciones para un posterior análisis.\n\nDescargar los registros MARC de una colección\n\nDescargar un elemento está bien, pero ¿y si queremos revisar miles de elementos en una colección? Estamos de suerte, porque la función Search del módulo internetarchive nos permite iterar sobre todos los resultados de una búsqueda.\n\nPara ver cómo, comencemos iniciando nuevamente el intérprete de Python. Necesitaremos importar una vez más nuestro módulo y hacer de nuevo una búsqueda:\n\nimport internetarchive\nbuscar = internetarchive.search_items('collection:bplscas')\n\n\nAhora escribamos el código de ejemplo de la documentación para imprimir (print) los identificadores de cada uno de los elementos encontrados en la búsqueda:\n\nfor resultado in buscar:\n   print resultado['identifier']\n\n\nNótese que, después de ingresar la primera línea, tu intéprete de Python imprimirá puntos suspensivos automáticamente en la línea dos: esto se debe a que iniciaste un bucle (for loop) y Python espera que haya más. El intérprete intenta saber lo que quieres conocer de cada resultado de búsqueda, por ello, una vez que des Enter en la segunda línea verás una tercera con otros puntos suspensivos, esto se debe a que Python no sabe cuándo has terminado de decirle qué hacer con cada resultado. Haz clic en Enter una vez más para finalizar el bucle y ejecutar el comando.\n\nDeberías ver entonces que tu terminal empieza a imprimir los identificadores de cada resultado obtenido de nuestro buscar en bplscas–(en este caso, ¡de todos los 7 029 elementos!) Puedes interrumpir la impresión pulsando ctrl-c en tu teclado, lo cual te regresará al intérprete de comandos.\n\nSi en lugar de ver los identificadores imprimiéndose en tu pantalla observas un mensaje de error como el siguiente, tal vez hayas olvidado ingresar algunos espacios en tu intérprete de comandos:\n\nfor resultado in buscar:\nprint resultado['identifier']\nFile \"\", line 2\n   print resultado['identifier']\n      ^\nIndentationError: expected an indented block\n\n\nRecuerda que los espacios en blanco cuentan en Python y necesitas indentar las líneas en un for loop para que Python pueda saber qué comandos ejecutar en cada elemento del bucle.\n\nEntender el bucle for\n\nEl bucle for, explicado de manera simple, le dice a Python que debe hacer algo en cada cosa dentro de un grupo de cosas. En el ejemplo anterior, hemos impreso el identificador para cada producto dentro de los resultados de la búsqueda hecha en nuestra colección. Dos consideraciones adicionales acerca del bucle for:\n\nPrimero, la palabra que usamos antes de for es denominada en Python variable local (local variable) y funciona como un marcador de posición para cualquier instancia o elemento con el cual vayamos a trabajar dentro del bucle. En general, tiene sentido escoger un nombre que describa el tipo de cosa con la que estemos trabajando (en este caso, un resultado de búsqueda) pero podemos utilizar otros nombres en su lugar. Por ejemplo, intenta ejecutar el bucle anterior de nuevo pero esta vez substituye la variable local por otro nombre como:\n\nfor elemento in buscar:\n   print elemento['identifier']\n\n\nObtendrás los mismos resultados.\n\nLo segundo que deberás tener en cuenta acerca del bucle for es que puede contener otros comandos en el bloque indentado. En este caso, hemos impreso cada identificador para cada resultado de búsqueda, pero podríamos elegir qué hacer para cada resultado, cualquier cosa que podemos hacer con un elemento individual del Internet Archive.\n\nPor ejemplo, anteriormente descargamos todos los archivos asociados con el elemento lettertowilliaml00doug. Podríamos haber hecho lo mismo para cada elemento de nuestra búsqueda si cambiáramos la línea print resultado['identifier'] por resultado.download() en nuestro bucle for.\n\nProbablemente sea mejor pensarlo dos veces antes de hacer algo así (descargar todos los archivos de cada uno de los 7 029 elementos de la colección bplscas representa un montón de archivos). Afortunadamente, la función download en el módulo internetarchive permite descargar archivos específicos asociados con un elemento. Si quisiéramos descargar solamente los archivos MARC XML asociados con un ítem en particular deberíamos hacer lo siguiente:\n\nelemento = internetarchive.get_item('lettertowilliaml00doug')\nmarc = elemento.get_file('lettertowilliaml00doug_marc.xml')\nmarc.download()\n\n\nDebido a que los archivos del IA son nombrados de acuerdo a reglas específicas podemos saber con anterioridad cuál es el nombre del archivo MARC con tan sólo conocer el identificador único del elemento. Armados de tal conocimiento podemos proceder a…\n\nDescargar todos los archivos MARC XML de una colección\n\nPara la próxima sección pasaremos de usar el intérprete de Python a escribir un archivo script que descargue los archivos MARC de cada elemento en la BPL Anti-Slavery Collection. Intenta escribir este programa en Komodo o en tu editor de texto preferido:\n\n#!/usr/bin/python\n\nimport internetarchive\n\nbuscar = internetarchive.search_items('collection:bplscas')\n\nfor resultado in buscar:\n   elementoid = resultado['identifier']\n   elemento = internetarchive.get_item(elementoid)\n   marc = elemento.get_file(elementoid + '_marc.xml')\n   marc.download()\n   print \"En proceso de descarga de \" + elementoid + \" ...\"\n\n\nEste programa se parece mucho a los experimentos que hicimos previamente con la carta de Frederick Douglass, pero debido a que queremos descargar los archivos MARC de cada elemento de nuestra búsqueda en la colección, estamos usando una variable elementoid para considerar el hecho que el identificador y el nombre del archivo serán diferentes para cada resultado.\n\nAntes de iniciar el programa (que, debo aclarar, va a descargar miles de pequeños archivos XML en tu ordenador) crea una carpeta donde quieras que se almacenen los archivos MARC y ubica el programa en ese directorio. Después, inicia el programa desde la carpeta de tal manera que los archivos se guarden en un lugar fácil de encontrar.\n\n(En caso de recibir una mensaje como ConnectionError en tu primer intento debes revisar tu conexión a Internet, esperar unos minutos e intentarlo de nuevo.)\n\nSi todo funciona correctamente, podrás ver que el programa empieza a imprimir mensajes de actualización diciéndote que está en proceso de descarga de los archivos MARC, pero permitir que el programa ejecute la función hasta finalizar tomará, probablemente, unas cuantas horas, así que detén el programa y revisa más detenidamente posibles maneras de mejorarlo. Presiona ctrl-c mientras estés en la ventana de tu terminal y harás que se detenga el programa.\n\nConstruir un reporte de errores en el programa\n\nDescargar todos esos archivos puede tomar un tiempo y probablemente queramos alejarnos de la computadora mientras tanto. Sin embargo, hay altas probabilidades de que durante esas dos horas algo salga mal e impida que nuestro programa funcione.\n\nDigamos, por ejemplo, que hemos olvidado descargar previamente un archivo individual en esa carpeta o tal vez tu ordenador pierda brevemente la conexión a Internet o algún tipo de corte suceda en el servidor del IA que impida que el programa descargue el archivo que quiere.\n\nEn estos y otros casos de error, Python puede hacer una “excepción” al decirte cuál es el problema. Desafortunadamente una excepción también hará que tu programa deje de funcionar en lugar de continuar con el siguiente archivo.\n\nPara prevenir esto podemos usar lo que se denomina en Python como una declaración try (try statement), la cual “intenta” ejecutar una cierta parte del código cuando se encuentra con una excepción, en cuyo caso puedes brindar otras opciones de código para ejecutar. Puedes leer más acerca del manejo de excepciones en la documentación de Python, pero por ahora tan sólo actualicemos nuestro programa para que luzca de esta manera:\n\n#!/usr/bin/python\n\nimport internetarchive\nimport time\n\nreporte_error = open('errores-bpl-marcs.log', 'a')\n\nbuscar = internetarchive.search_items('collection:bplscas')\n\nfor resultado in buscar:\n   elementoid = resultado['identifier']\n   elemento = internetarchive.get_item(elementoid)\n   marc = elemento.get_file(elementoid + '_marc.xml')\n   try:\n      marc.download()\n   except Exception as e:\n      reporte_error.write('No es posible descargar' + elementoid + ' debido al error: %s\\n' % e)\n      print \"Hubo un error, escribiendo reporte.\"\n   else:\n      print \"En proceso de descarga de \" + elementoid + \" ...\"\n      time.sleep(1)\n\n\nLo más importante que añadimos aquí, después de las declaraciones para importar los módulos, fue una línea que abre un archivo de texto llamado errores-bpl-marcs.log y lo prepara para incluir texto en él. Vamos a utilizar ese archivo para registrar las excepciones que encuentre el programa. La declaración try que añadimos a nuestro for loop intentará descargar el archivo MARC, en caso de que no pueda hacerlo escribirá un registro descriptivo del fallo en nuestro archivo log. De esta manera podremos revisar posteriormente el archivo e identificar cuáles elementos debemos intentar descargar nuevamente. Si la declaración try funciona y puede descargar el archivo el programa ejecutará el código sin la cláusula else.\n\nOtra cosa que añadimos, tras una descarga exitosa, fue esta línea:\n\ntime.sleep(1)\n\n\nDicha línea usa el módulo time que importamos al inicio para decirle a nuestro programa que se detenga por un segundo antes de proceder, lo que es básicamente una manera en la que podemos ser amables con los servidores del IA para no sobrecargarlos cada tantos milisegundos con una solicitud.\n\nIntenta actualizar tu programa para que se vea como el de arriba y ejecútalo nuevamente en el directorio donde guardaste tus archivos MARC. No te sorprendas si inmediatamente encuentras una cadena con un mensaje de error ¡eso significa que el programa hace lo que se supone debe hacer! Revisa tranquilamente tu editor de texto mientras el programa sigue ejecutándose y abre el archivo errores-bpl-marcs.log para ver cuáles excepciones han sido registradas. Probablemente veas que el programa registró la excepción “File already exist” para cada uno de los archivos que se habían descargado anteriormente cuando se ejecutó el programa más corto.\n\nSi ejecutas el programa por un tiempo más el código llegará hasta los elementos que no has descargado ¡y continuarán recolectando tus archivos MARC!\n\nRecolección automática de información desde un archivo MARC\n\nUna vez que hayas el programa de descarga haya terminado estarás en la posesión de cerca de 7 000 registros detallados MARC XML relacionados con elementos de la Anti-Slavery Collection (o cualquier otra colección que hayas decidido descargar, el método arriba explicado puede funcionar en cualquier colección cuyos elementos tengan archivos MARC asociados).\n\nY ¿ahora qué?\n\nEl próximo paso depende de cual tipo de pregunta quieras responder relacionada con la colección. El formato de lenguaje MARC captura una rica cantidad de datos relativos a un elemento, como puedes ver si revisas el registro MARC XML de la carta de Frederick Douglass mencionado al inicio.\n\nObserva, por ejemplo, que la carta de Douglass contiene información acerca del lugar donde fue escrita en el campo de datos (datafield) marcado con el número 260, dentro del subcampo (subfield) con el código a. La persona que preparó este registro MARC sabía poner información en ese campo gracias a las reglas específicas para el campo 260 según los estándares MARC.\n\nEsto significa que es posible para nosotros revisar el interior de los archivos MARC que hemos descargado y recolectar la información almacenada dentro del campo de datos 260, subcampo a, y hacer una lista del nombre de cada lugar donde fueron publicados los elementos de la colección.\n\nPara hacer esto, usaremos otro módulo útil de Python que hemos descargado al inicio con pip: pymarc\n\nEse módulo facilita la recolección de información de los subcampos. Asumiendo que tenemos un registro MARC preparado para analizar por el módulo asignado a la variable del registro, podemos obtener la información relativa a los nombres de los lugares de publicación de esta manera:\n\nlugar_de_pub = record['260']['a']\n\n\nLa documentación de pymarc es un poco menos completa que la del IA, en particular cuando se trata de analizar registros XML. Pero un poco de exploración alrededor de la raíz del código fuente del módulo revela algunas funciones que provee para trabajar con archivos MARC XML. Una de ella, llamada map_xml(), se describe de la siguiente manera:\n\ndef map_xml(function, *files):\n    \"\"\"\n    mapea una función dentro del archivo, de tal manera que cada registro que analiza la función será llamado con el registro extraído\n        \n    def do_it(r):\n    print r\n    \n    map_xml(do_it, 'marc.xml')\n    \"\"\"\n\n\nEn lenguaje llano significa que esta función puede tomar un archivo XML que contiene datos MARC (como los cerca de 7 000 que ahora tenemos en nuestro ordenador), los pasa por la función map_xml en el módulo de pymarc y especifica una función adicional (que deberemos escribir) diciéndole a nuestro programa qué hacer con los datos recolectados del registro MARC contenidos en el archivo XML. Un diseño preliminar de nuestro código se verá como sigue:\n\nimport pymarc\n\ndef obtener_lugar_de_pub(record):\n    lugar_de_pub = record['260']['a']\n    print lugar_de_pub\n\npymarc.map_xml(obtener_lugar_de_pub, 'lettertowilliaml00doug_marc.xml')\n\n\nIntenta guardar el código en un programa y ejecútalo desde una carpeta donde esté guardado el XML de la carta de Douglass. Si todo funciona correctamente el programa mostrará lo siguiente:\n\nBelfast, [Northern Ireland],\n\n\nVoilà! Desde luego, este programa tiene más utilidad si recolectamos la ubicación de cada carta en nuestra colección de archivos MARC. Agrupando toddo lo que hemos aprendido desde el inicio en esta lección podemos escribir un programa que lucirá como el siguiente:\n\n#!/usr/bin/python\n\nimport os\nimport pymarc\n\npath = '/ruta/al/directorio/con/archivosxml/'\n\ndef obtener_lugar_de_pub(record):\n    try:\n        lugar_de_pub = record['260']['a']\n        print lugar_de_pub\n    except Exception as e:\n        print e\n\nfor file in os.listdir(path):\n    if file.endswith('.xml'):\n        pymarc.map_xml(obtener_lugar_de_pub, path + file)\n\n\nEste programa modifica nuestro código anterior de varias maneras. Primero, usa una declaración for looop para iterar sobre cada archivo de nuestro directorio. En lugar de la pesquisa de resultados con internetarchive con la cual iteramos en los resultados de búsqueda durante la primera parte de la lección, ahora iteramos sobre los archivos recolectados con os.listdir(path) que usa el módulo os de Python para listar los contenidos de los directorios especificados en la ruta de la variable, la cual debes modificar para que concuerde con la carpeta en la cual almacenaste todos tus archivos MARC.\n\nTambién añadimos un manejador de error a nuestra función obtener_lugar_de_pub() para enfrentar el hecho de que algunos registros puedan (por cualquier razón) carecer de la información que buscamos. La función intentará imprimir el lugar de publicación, pero si llega a una excepción imprimirá la información obtenida por la misma excepción. En este caso, si la declaración falla la excepción problablemente imprimirá None. Entender por qué es asunto de otra lección acerca de los tipos de errores de Python, pero por ahora el mensaje None es suficientemente descriptivo para lo que sucede, por lo cual puede ser útil para nosotros.\n\nIntenta ejecutar este programa. Si todo funciona correctamente, tu pantalla se llenará con un listado de lugares donde las cartas fueron escritas. Si sirve, intenta modificar tu programa para que guarde los nombres de los lugares en un archivo de texto en lugar de imprimirlos en pantalla. Puedes servirte de la lección Contar frecuencias para saber cuáles lugares son los más comunes en la colección. También puedes trabajar con las ubicaciones para encontrar coordenadas que puedan ser ubicadas en un mapa usando la lección de introducción a Google Maps.\n\nAsimismo, para obtener una visualización preliminar de los lugares donde las cartas fueron escritas, puedes hacer lo que yo he hecho abajo y simplemente hacer una nube de palabras en Wordle con el archivo de texto.\n\n\n    \n\n    Nube de palabras en Wordle de los lugares de publicación de cartas abolicionistas\n\n\n\n\nDesde luego, para que esta técnica sea útil se requiere hacer algo de limpieza de tus datos. Esta lección también puede ser aplicada de otras maneras. Por ejemplo, trabajar con los campos de datos relativos a nombres de personas, con ellos puedes crear una red de corresponsales, o puedes analizar cuales temas (subjects) son comunes en los registros MARC. Ahora que has descargado los archivos MARC y puedes usar pymarc para extraer información de los campos ¡las posibilidades se multiplican rápidamente!\n\n\nLas colecciones del Internet Archive incluyen una gran cantidad de fuentes históricas digitalizadas. Muchas de ellas contienen datos bibliográficos importantes en un formato llamado MARC. En esta lección aprenderás a usar Python para automatizar la descarga de archivos MARC en grandes cantidades desde el Internet Archive, así como el análisis sintáctico de archivos MARC con información específica tal como autores, lugar de publicación y fechas. La lección puede aplicarse de una manera general para otros elementos del Internet Archive así como en archivos MARC en cualquier otro repositorio.\n\n"
  },


  {
    "id": 30,
    "url": "http://localhost:4000/es/lecciones/normalizar-datos",
    "title": "Normalizar datos de texto con Python",
    "body": "\nNormalizar datos de texto con Python\n\nContenidos\n\n\n  Objetivos de la lección\n  Archivos necesarios para esta lección\n  Limpiar la lista\n  Convertir a minúsculas\n  Expresiones regulares en Python\n  Lecturas sugeridas    \n      Sicronización de código\n    \n  \n\n\nObjetivos de la lección\n\nLa lista que creamos en De HTML a lista de palabras (parte 2) necesita cierta “normalización” antes de que podamos usarla más adelante. Vamos a hacer esto aplicando métodos adicionales para cadenas de caracteres, así como utilizar expresiones regulares. Una vez normalizadas seremos capaces de analizar nuestros datos de una manera más fácil.\n\nArchivos necesarios para esta lección\n\n\n  html-a-lista-1.py\n  obo.py\n\n\nSi no tienes estos archivos de la lección previa, puedes descargar un zip.\n\nLimpiar la lista\n\nEn De HTML a lista de palabras (parte 2), escribimos un programa en Python llamado html-a-lista-1.py que descargó una página Web, retiró el formato HTML y los metadatos y nos devolvió una lista de “palabras” como la que se muestra más abajo. Técnicamente, estas entidades son llamadas “tokens” (o “componente léxico”) en vez de “palabras”. Estos incluyen cosas que nos son palabras estrictamente hablando (como la abreviatura &amp;c. de “etcétera”). También incluyen algunas cosas que se podrían considerar componentes de más de una palabra.  El posesivo “Akerman’s” en idioma inglés, por ejemplo, algunas veces es analizado por los lingüístas como dos palabras: “Akerman” más un marcador posesivo. En inglés también, ¿”o’clock” es una o dos palabras? Y así.\n\nRegresa a tu programa html-a-lista-1.py y asegúrate de que tus resultados se vean como algo por el estilo de esto:\n\n['324.', '\\xc2\\xa0', 'BENJAMIN', 'BOWSEY', '(a', 'blackmoor', ')', 'was',\n'indicted', 'for', 'that', 'he', 'together', 'with', 'five', 'hundred',\n'other', 'persons', 'and', 'more,', 'did,', 'unlawfully,', 'riotously,',\n'and', 'tumultuously', 'assemble', 'on', 'the', '6th', 'of', 'June', 'to',\n'the', 'disturbance', 'of', 'the', 'public', 'peace', 'and', 'did', 'begin',\n'to', 'demolish', 'and', 'pull', 'down', 'the', 'dwelling', 'house', 'of',\n'\\xc2\\xa0', 'Richard', 'Akerman', ',', 'against', 'the', 'form', 'of',\n'the', 'statute,', '&amp;amp;c.', '\\xc2\\xa0', 'ROSE', 'JENNINGS', ',', 'Esq.',\n'sworn.', 'Had', 'you', 'any', 'occasion', 'to', 'be', 'in', 'this', 'part',\n'of', 'the', 'town,', 'on', 'the', '6th', 'of', 'June', 'in', 'the',\n'evening?', '-', 'I', 'dined', 'with', 'my', 'brother', 'who', 'lives',\n'opposite', 'Mr.', \"Akerman's\", 'house.', 'They', 'attacked', 'Mr.',\n\"Akerman's\", 'house', 'precisely', 'at', 'seven', \"o'clock;\", 'they',\n'were', 'preceded', 'by', 'a', 'man', 'better', 'dressed', 'than', 'the',\n'rest,', 'who']\n\n\nPor sí misma, esta habilidad de separar el documento en palabras no nos ayuda mucho porque nosotros ya sabemos cómo leerlo. Sin embargo, podemos usar el texto para hacer cosas que normalmente no son posibles sin un programa especial. Vamos a comenzar por computar la frecuencia de los tokens y otras unidades lingüísticas, una medida clásica de un texto.\n\nQueda claro que nuestra lista va a necesitar cierta limpieza antes de que la podamos utilizar para contar frecuencias. Conservando la práctica establecida en De HTML a lista de palabras (parte 1), tratemos de describir nuestro algoritmo primero en lenguaje llano. Queremos saber la frecuencia con la que aparece cada palabra con significado en la transcripción del juicio. De tal manera, los pasos a seguir deben verse de la siguiente manera:\n\n\n  Convierte todas las palabras a minúsculas para que “BENJAMIN” y “benjamin” sean contadas como una misma palabra\n  Retira cualquier carácter extraño o inusual\n  Cuenta el número de veces que aparece cada palabra\n  Retira palabras demasiado comunes como “eso”, “el”, “y”, etc.\n\n\nConvertir a minúsculas\n\nTípicamente los componentes léxicos (tokens) son compactados como minúsculas cuando se cuentan frecuencias, así que lo haremos utilizando el método de cadena “lower” que aprendimos en Manipular cadenas de caracteres en Python. Ya que este es un método para cadenas, tendremos que aplicarlo en la cadena texto en el programa html-a-lista-1.py. Enmienda html-a-lista-1.py añadiendo la etiqueta de cadena lower() al final de la cadena texto.\n\n# html-a-lista-1.py\nimport urllib.request, urllib.error, urllib.parse, obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nhtml = respuesta.read()\ntexto = obo.quitarEtiquetas(html).lower() #incluye el metodo de cadena aqui\nlistaPalabras = texto.split()\n\nprint((listaPalabras[0:120]))\n\n\nAhora debes ver la misma lista de palabras que antes pero con todos los caracteres en minúsculas.\n\nAl “llamar” métodos uno tras otro, como en este caso, podemos mantener nuestro código corto y hacer algunos cambios muy significativos en nuestro programa.\n\nComo hemos dicho antes, Python facilita hacer mucho con muy poco código.\n\nEn este punto podríamos mirar con atención otras entradas del Old Bailey en línea así como una amplia gama de otras fuentes potenciales para asegurarnos de que no hay otros caracteres especiales que podrían causar problemas más adelante. También podríamos tratar de anticipar situaciones en las que no queremos deshacernos de cierta puntuación (por ejemplo, los distintivos de cantidades monetarios como “$1629” o “£1295”, de fechas, o el reconocer que “1629-40” tiene un significado distinto que “1629 40”). Esto es lo que a lo programadores profesionales se les paga por hacer: trata de pensar en todo lo que podría ir mal y trátalo de antemano.\n\nVeámoslo desde otra perspectiva. Nuestro objetivo principal es desarrollar técnicas que un historiador puede utilizar durante el proceso de investigación. Esto significa que casi siempre preferimos soluciones aproximadamente correctas que puedan desarrollarse rápidamente. Así que, en lugar de invertir tiempo en hacer nuestro programa sólido de cara a excepciones, simplemente queremos deshacernos de todo aquello que no sea un carácter con o sin acentos o un número arábigo. La programación generalmente es un proceso de “refinamiento paso a paso”. Empiezas con un problema y partes de una solución, y luego sigues refinando tu solución hasta que tienes algo que funciona mejor.\n\nExpresiones regulares en Python\n\nHemos eliminado las mayúsculas. Ahora nos toca deshacernos de los signos de puntuación. Si dejamos la puntuación, ésta echa a perder nuestras cuentas de frecuencia. ¿Queremos que “evening?” sea contada como “evening” y “1780.” como “1780”? ¡Por supuesto!\n\nEs posible utilizar el método de cadena “replace” para retirar cada tipo de puntuación:\n\ntexto = texto.replace('[', '')\ntexto = texto.replace(']', '')\ntexto = texto.replace(',', '')\n#etc...\n\n\nPero esto no es verdaderamente eficiente. Ateniéndonos a nuestro objetivo de crear programas breves y poderosos, vamos a utilizar un mecanismo llamado “expresiones regulares”. Las expresiones regulares son provistas por varios lenguajes de programación en un abanico de formas distintas.\n\nLas expresiones regulares te permiten buscar patrones bien definidos y pueden acortar drásticamente la longitud de tu código. Por ejemplo, si deseas saber si una subcadena coincidió con una letra del alfabeto, en lugar de utilizar la sentencia if / else para comprobar la coincidencia con la letra “a”, luego la “b” y luego la “c”, y así sucesivamente, se podría utilizar una expresión regular para ver si cualquier letra entre la “a” y la “z” coincide con la subcadena. O bien, puedes comprobar la presencia de un dígito o una letra mayúscula, o de cualquier carácter alfanumérico, un retorno de carro o cualquier combinación de los anteriores y mucho más.\n\nEn Python, las expresiones regulares están disponibles como un módulo de Python. Para acelerar el procesamiento, éste no se carga automáticamente porque no todos los programas lo requieren. Por lo tanto, tendrás que importar (import) el módulo (llamado re) de la misma manera en la que has importado tu propio módulo obo.py.\n\nDado que nos interesan solamente los caracteres alfanuméricos, vamos a crear una expresión regular que aislará sólo estos y eliminará el resto. Copia la siguiente función y pégala al final del módulo obo.py. Puedes dejar las otras funciones en el módulo solo, ya que seguiremos utilizándolas.\n\n# Dada una cadena de caracteres, retira todos los caracteres\n# no-alfanuméricos (utilizando la definición Unicode de alfanumérico).\n\ndef quitaNoAlfaNum(texto):\n    import re\n    return re.compile(r'\\W+', re.UNICODE).split(texto)\n\n\nLa expresión regular en el código anterior es el material dentro de la cadena, en otras palabras W+. La W es la abreviatura de la clase de caracteres no-alfanuméricos. En una expresión regular de Python, el signo de adición (+) coincide con una o más copias de un carácter dado. La expresión re.UNICODE le dice al intérprete que queremos que incluya los caracteres de todas las lenguas del mundo en nuestra definición de “alfanumérico”, así como de la A a la Z, de a-z y de 0-9 en inglés. Las expresiones regulares deben ser compiladas antes de poder ser utilizadas, que es lo que hace el resto de la declaración. No te preocupes en entender ahora mismo la parte de la compilación.\n\nCuando redefinamos nuestro programa html-a-lista-1.py, entonces se verá como esto:\n\n# html-a-lista-1.py\nimport urllib.request, urllib.error, urllib.parse, obo\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\nhtml = respuesta.read()\ntexto = obo.quitarEtiquetas(html).lower()\nlistaPalabras = obo.quitaNoAlfaNum(texto)\n\nprint(listaPalabras)\n\n\nCuando ejecutes el programa y veas a través de su salida en el panel de “comando de salida”, verás que ha hecho un maravilloso trabajo. Este código separará expresiones con guiones como “coach-wells” en dos palabras y convertirá la partícula posesiva “s” o “o’clock” en palabras separadas perdiéndo el apóstrofe. Pero es una aproximación lo suficientemente buena a lo que queremos, así que podemos proceder a contar frecuencias antes de intentar mejorarlo. (Si trabajas con fuentes documentales en más de una lengua, necesitaras aprender más acerca del estándar Unicode y acerca del soporte de Python para el mismo).\n\nLecturas sugeridas\n\nPara una práctica extra en expresiones regulares, encontrarás que el Capítulo 7 del libro de Mark Pilgrim Dive into Python es un tutorial muy útil.\n\nSicronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones4.zip (zip sync)\n\n\n\nEn esta lección haremos que la lista que creamos en’De HTML a lista de palabras (parte 2)’ sea más fácil de analizar al “normalizar” los datos.\n\n"
  },


  {
    "id": 31,
    "url": "http://localhost:4000/es/lecciones/palabras-clave-en-contexto-n-grams",
    "title": "Palabras clave en contexto (usando n-grams) con Python",
    "body": "\nPalabras clave en contexto (usando n-grams) con Python\n\nContenidos\n\n\n  Objetivos de la lección\n  Archivos necesarios para esta lección\n  De texto a n-gramas a KWIC\n  De texto a n-gramas    \n      Sincronización de código\n    \n  \n\n\nObjetivos de la lección\n\nAl igual que en Salida de datos como archivo HTML, esta lección retoma los pares de frecuencias recolectados en Contar frecuencias de palabras y crea una salida de datos en HTML. Esta vez el objetivo son las palabras clave en contexto (“KWIC”, por sus siglas en inglés) que crea n-gramas del contenido del documento original -en este caso la transcripción de un juicio del “Old Bailey Online”. Puedes utilizar tu programa para seleccionar una palabra clave y la computadora producirá una salida de datos con todas las veces en que aparece esa palabra clave, junto con las palabras a la derecha e izquierda de la misma, haciendo sencillo observar a simple vista cómo es utilizada dicha palabra.\n\nUna vez que se han creado las KWCIs, se envuelven en HTML y se envían al navegador en donde se pueden ver. Esto refuerza lo aprendido en Salida de datos como archivo HTML optando por una salida ligeramente distinta.\n\nAl final de la lección serás capaz de extraer todos los n-gramas posibles del texto. En la siguiente lección, aprenderás cómo crear salida de todos los n-gramas de una palabra clave dada en un documento descargado de Internet, y visualizarla claramente en la ventana de tu navegador.\n\nArchivos necesarios para esta lección\n\n\n  obo.py\n\n\nSi no tienes estos archivos de las lecciones anteriores, puedes descargar python-es-lecciones7, un archivo zip de las lecciones anteriores.\n\nDe texto a n-gramas a KWIC\n\nAhora que ya sabes cómo recolectar el contenido textual de una página Web de manera automática con Python, y has empezado a utilizar cadenas de caracteres, listas y diccionarios para procesamiento de texto, hay muchas otras cosas que puedes hacer con los textos aparte de contar frecuencias. Quienes estudian las propiedades estadísticas del lenguaje han encontrado que el estudiar las secuencias lineales de unidades lingüísticas puede decirnos muchas cosas acerca de un texto. Estas secuencias lineales son conocidas como bigramas+ (2 unidades), *trigramas (3 unidades) o más generalmente como n-gramas.\n\nProbablemente has visto con anterioridad n-gramas muchas veces. Se utilizan generalmente en páginas de resultados de investigación para dar una previsualización del lugar en que aparece tu palabra clave en un documento y cuál es el contexto que la rodea. Esta aplicación de los n-gramas es conocida como “palabras clave en contexto” (generalmente abreviada como KWIC). Por ejemplo, si la cadena en cuestión fuese “it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness”, entonces un 7-grama para la palabra clave “wisdom” sería:\n\nthe age of wisdom it was the\n\n\nUn n-grama puede contener cualquier tipo de unidad lingüística que quieras. Los historiadores tienen más probabilidades de utilizar caracteres como en el bigrama “qu” o palabras como en el trigrama “el perro ladró”; sin embargo, puedes utilizar también fonemas, sílabas o cualquier número de otras unidades en función de tu pregunta de investigación.\n\nLo que vamos a hacer ahora es desarrollar la habilidad de visualizar KWIC para cualquier palabra clave en un cuerpo de texto y mostrarla en el contexto de un número fijo de palabras en cada lado. Como antes, vamos a “encerrar” (en HTML) la salida de datos para que se pueda ver en Firefox y añadir fácilmente a Zotero.\n\nDe texto a n-gramas\n\nDado que queremos trabajar con palabras en lugar de caracteres o fonemas, será mucho más fácil crear n-gramas utilizando una lista de palabras en vez de cadenas. Como ya sabes, Python puede convertir fácilmente una cadena en una lista utilizando la operación dividir (split). Una vez dividida resulta sencillo recuperar una subsecuencia de palabras adyacentes en la lista utilizando un fragmento representado por dos índices separados por dos puntos. Aprendimos esto cuando trabajamos con cadenas en Manipular cadenas de caracteres en Python\n\nmensaje9 = \"Hola Mundo\"\nmensaje9a = mensaje9[1:8]\nprint(mensaje9a)\n-&gt; ola Mun\n\n\nSin embargo, también podemos utilizar esta técnica para tomar un número predeterminado de palabras vecinas de la lista con poco esfuerzo. Estudia los siguientes ejemplos que puedes probar en un intérprete de Python.\n\ncadenaPalabras = 'it was the best of times it was the worst of times '\ncadenaPalabras += 'it was the age of wisdom it was the age of foolishness'\nlistaPalabras = cadenaPalabras.split()\n\nprint(listaPalabras[0:4])\n-&gt; ['it', 'was', 'the', 'best']\n\nprint(listaPalabras[0:6])\n-&gt; ['it', 'was', 'the', 'best', 'of', 'times']\n\nprint(listaPalabras[6:10])\n-&gt; ['it', 'was', 'the', 'worst']\n\nprint(listaPalabras[0:12])\n-&gt; ['it', 'was', 'the', 'best', 'of', 'times', 'it', 'was', 'the', 'worst', 'of', 'times']\n\nprint(listaPalabras[:12])\n-&gt; ['it', 'was', 'the', 'best', 'of', 'times', 'it', 'was', 'the', 'worst', 'of', 'times']\n\nprint(listaPalabras[12:])\n-&gt; ['it', 'was', 'the', 'age', 'of', 'wisdom', 'it', 'was', 'the', 'age', 'of', 'foolishness']\n\n\nEn estos ejemplos se ha utilizado el método de división (slice) para recuperar partes de nuestra lista. Ten en cuenta que hay dos lados respecto a los dos puntos en un slice. Si a la derecha de los dos puntos se deja en blanco como en el último ejemplo anterior, el programa sabe continuar automáticamente hasta el final -en este caso, el final de la lista. En el penúltimo ejemplo anterior se muestra que podemos comenzar desde el principio dejando vacío el espacio anterior a los dos puntos. Este es un atajo útil y que está disponible para mantener tu código más corto.\n\nTambién puedes utilizar variables para representar las posiciones del índice. Utilizado conjuntamente con un bucle for, puedes crear fácilmente cualquier n-grama posible a partir de tu lista. El siguiente ejemplo recupera todos los 5-gramas de nuestra cadena a partir del ejemplo anterior.\n\ni = 0\nfor items in listaPalabras:\n    print(listaPalabras[i: i+5])\n    i += 1\n\n\nSiguiendo con nuestro enfoque modular, vamos a crear una función y a guardarla en el módulo obo.py que puede crear n-gramas. Estudia y escribe o copia el siguiente código:\n\n# Dada una lista de palabras y un número n, recupera una lista\n# de n-gramas.\n\ndef obtenNGramas(listaPalabras, n):\n    return [listaPalabras[i:i+n] for i in range(len(listaPalabras)-(n-1))]\n\n\nEsta función puede parecer un poco confusa ya que hace muchas cosas sin mucho código. Utiliza una lista por comprensión para mantener el código compacto. El siguiente ejemplo hace exactamente lo mismo:\n\ndef obtenNGramas(listaPalabras, n):\n    ngramas = []\n    for i in range(len(listaPalabras)-(n-1)):\n        ngramas.append(listaPalabras[i:i+n])\n    return ngramas\n\n\nUtiliza el que tenga más sentido para ti.\n\nUn concepto que todavía te puede resultar confuso es el par de argumentos de la función. Ten en cuenta que nuestra función tiene dos nombres de variables en el paréntesis después de su nombre cuando la declaramos: listaPalabras, n. Estas dos variables son los argumentos de la función. Cuando llamas (ejecutas) esta función, estas variables serán utilizadas por la función para su solución. Sin estos argumentos no hay suficiente información para hacer los cálculos. En este caso, las dos piezas de información son la lista de palabras que quieres covertir en n-gramas (listaPalabras), y el número de palabras que quieres en cada n-grama (n). Para que la función trabaje necesita ambas, así que la llamas como en este ejemplo (guarda el siguiente programa como usaobtenNGramas.pyy ejecútalo):\n\n#usaobtenNGramas.py\n\nimport obo\n\ncadenaPalabras = 'it was the best of times it was the worst of times '\ncadenaPalabras += 'it was the age of wisdom it was the age of foolishness'\ntodasMisPalabras = cadenaPalabras.split()\n\nprint(obo.obtenNGramas(todasMisPalabras, 5))\n\n\nObserva que los argumentos introducidos no tienen que tener el mismo nombre que los argumentos mencionados en la declaración de la función. Python sabe utilizar todasMisPalabras en cualquier lugar de la función en la que aparezca listaPalabras, ya que esto se dio desde el primer argumento. Del mismo modo, todas las apariciones de n serán remplazadas por el entero 5 en este caso. Intenta cambiar el 5 a una cadena, como “elefantes” y observa lo que sucede cuando ejecutas tu programa. Ten en cuenta que debido a que n se utiliza como un entero, debes asegurarte que el argumento enviado es también un entero. Lo mismo es válido para cadenas de caracteres, puntos flotantes o cualquier otro tipo de variable enviada como argumento.\n\nTambién puedes utilizar un terminal de Python para jugar con el código y tener una mejor comprensión de cómo funciona. Pega la declaración de función para obtenNGramas (cualquiera de las dos funciones anteriores) en el intérprete de Python.\n\nprueba1 = 'aqui hay cuatro palabras'\nprueba2 = 'en la frase de prueba hay ocho palabras'\n\nobtenNGramas(prueba1.split(), 5)\n-&gt; []\n\nobtenNGramas(prueba2.split(), 5)\n-&gt; [['en', 'la', 'frase', 'de', 'prueba'],\n['la', 'frase', 'de', 'prueba', 'hay'],\n['frase', 'de', 'prueba', 'hay', 'ocho'],\n['de', 'prueba', 'hay', 'ocho', 'palabras']]\n\n\nEn este ejemplo vemos dos cosas que debes tener en cuenta. En primer lugar, como nuestra función espera una lista de palabras en lugar de una cadena, tenemos que convertir las cadenas en listas antes de que nuestro programa pueda manejarlas. Podríamos haberlo hecho mediante la adición de otra línea de código por encima de la llamada a la función, pero en su lugar utilizamos el método split directamente en el argumento de la función como una especie de atajo.\n\nEn segundo lugar, ¿por qué el primer ejemplo devuelve una lista vacía en lugar del n-grama que buscamos? En test1 hemos pedido un n-grama que es más largo que el número de palabras en nuestra lista, lo cual ha resutado en una lista en blanco. En test2 no tenemos tal problema y obtuvimos todos los posibles 5-gramas para una lista de palabras más larga. Si quieres puedes adaptar tu función para que imprima un mensaje de advertencia o para recuperar toda la cadena en lugar de una lista vacía.\n\nAhora tenemos una manera de extraer todos los posibles n-gramas de un cuerpo de texto. En la siguiente lección podemos centrar nuestra atención en aislar los n-gramas que sean de interés para nosotros.\n\nSincronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto. Si estás trabajando con la versión Mac o Linux de las lecciones deberás abrir el archivo obo.py y cambiar “file:///Users/username/Desktop/programming-historian/” a la ruta del directorio de tu propia computadora.\n\n\n  python-es-lecciones8.zip (zip sync)\n\n\n\nEsta lección retoma los pares de frecuencias recolectados en [Contar frecuencias de palabras][] y crea una salida de datos en HTML.\n\n"
  },


  {
    "id": 32,
    "url": "http://localhost:4000/es/lecciones/poniendo-omeka-a-funcionar",
    "title": "Poniendo Omeka a funcionar",
    "body": "\nPoniendo Omeka a funcionar\n\nContenidos\n\n\n  Crea tu nuevo sitio en Omeka\n  ¡Ahora tienes un nuevo sitio en Omeka!\n  Un sitio vacío de Omeka\n  Cambia de plantilla\n  ¡Ahora tienes una nueva plantilla!\n  Instala algunos plugins\n  Añade un ítem a tu archivo\n  Describe tu nuevo ítem\n  Una cuestión compleja\n  Adjunta un archivo al registro de tu ítem\n  ¡Ya tienes un ítem!\n  Esta no es la página pública de tu ítem\n  Esta es la página pública para tu ítem\n  Crea una colección\n  Introduce información sobre tu colección\n  Añade ítems a tu colección\n  Escoge la colección\n  Revisa tu nueva colección\n  Recursos adicionales\n\n\nOmeka.net facilita la creación de sitios web para mostrar colecciones de ítems.\n\n  Nota de la traductora: Antes de empezar es importante aclarar las diferencias entre Omeka.net y Omeka.org. Este tutorial es sobre Omeka.net, una plataforma de publicación en línea que permite a cualquier persona con una cuenta de acceso crear o colaborar en un sitio web para exhibir colecciones y construir exposiciones digitales. Omeka.net es una extensión de Omeka.org que está disponible para bajar e instalar en un servidor de tu propiedad. La traducción al español del tutorial de The Programming Historian sobre cómo instalar Omeka en un servidor se encuentra en proceso.\nal\nRegístrate para abrir una cuenta en Omeka\n—————————-\n\n\n\n    \n\n    Regístrate para una cuenta de prueba\n\n\n\n\nEntra a www.omeka.net y haz clic en Sign Up. Elige el plan “Omeka trial” (Plan de prueba). Rellena el formulario de registro. Revisa tu correo electrónico y haz clic en el enlace para activar tu cuenta.\n\nCrea tu nuevo sitio en Omeka\n\n\n    \n\n    Página de la cuenta de Omeka.net\n\n\n\n\nTras hacer clic en el enlace en tu correo electrónico, haz clic en Add a Site (Añadir un sitio).\n\nLlena la información sobre el URL de tu sitio, el título que quieres usar y si quieres una descripción. Haz clic en Add Your Site (Añade tu sitio).\n\n¡Ahora tienes un nuevo sitio en Omeka!\n\n\n    \n\n    Ver sitio\n\n\n\n\nPara ver tu sitio, haz clic en View Site (Ver sitio).\n\nUn sitio vacío de Omeka\n\n\n    \n\n    Vista pública\n\n\n\n\nEste es tu sitio vacío de Omeka esperando a ser llenado. Para regresar a tu panel de control (dashboard) haz clic en el botón Back (Atrás) o escribe  http://www.omeka.net/dashboard. Esta vez haz clic en Manage Site (Administra el sitio).\n\nCambia de plantilla\n\n\n    \n\n    Página de configuración de plantillas\n\n\n\n\nOmeka te permite cambiar la apariencia de tu sitio público por medio de las plantillas (themes). Para hacer esto, haz clic en Appearance (Apariencia) (en la esquina superior derecha de tu panel de control / dashboard). Cambia de plantilla seleccionando una de las opciones en la página. Presiona el botón verde Use this theme (Usa esta plantilla) para activar la nueva plantilla. Después visita tu sitio público haciendo clic en el nombre de tu sitio en la esquina superior izquierda de la página.\n\n¡Ahora tienes una nueva plantilla!\n\n\n    \n\n    Vista pública con la nueva plantilla\n\n\n\n\nUna vez hayas revisado tu nueva plantilla, regresa al tu panel de control (dashboard). Puedes regresar a tu plantilla antigua, quedarte con este o seleccionar una de las otras opciones.\n\nInstala algunos plugins\n\n\n    \n\n    Página de plugins\n\n\n\n\nTu sitio de Omeka viene con plugins que ofrecen funciones adicionales. Necesitamos habilitarlos. Para hacer esto, haz clic en el menú Plugins en la parte superior. En la siguiente página haz clic en el botón Install (Instalar) para Exhibit Builder (Constructor de exposiciones) (deja las opciones como están en la página siguiente ) y para Simple Pages (Páginas simples).\n\nAñade un ítem a tu archivo\n\n\n    \n\n    Add and Item (Añade un ítem)\n\n\n\n\nHaz clic en Items en el menú del lado izquierdo y después (¡naturalmente!) haz clic en Add an item (Añade un ítem).\n\nDescribe tu nuevo ítem\n\n\n    \n\n    Haz tu ítem público marcando la caja que está circulada acá\n\n\n\n\nRecuerda, Dublin Core se refiere a la información descriptiva que introducirás sobre tu ítem. Toda esta información es opcional y no hay forma de que lo hagas incorrectamente. Pero trata de ser consistente.\n\nAsegúrate de marcar la caja de Public para que tu ítem sea visible por el público general. Si no marcas esa caja, solamente las personas que hayan iniciado sesión en tu sitio podrán ver el ítem.\n\nPara añadir múltiples campos —por ejemplo, si quieres añadirle múltiples temas (subjects) a tu ítem— usa el botón verde Add input situado a la izquierda de las cajas de texto.\n\nUna cuestión compleja\n\n\n    \n\n    ¿Qué es esto?\n\n\n\n\nEstoy creando un registro de un ítem para mi perro Bertie. Pero, ¿estoy describiendo al mismo Bertie o una fotografía de Bertie? Si es lo primero, el Creator sería… bueno, supongo que eso depende de tus creencias religiosas. Si es lo segundo, el creador sería Brad Wallace, quien tomó la foto.\n\nLa decisión de si vas a describir un objeto o la representación del objecto es tuya. Una vez hayas decidido sé consistente.\n\nAdjunta un archivo al registro de tu ítem\n\n\n    \n\n    Adjuntando archivos a un ítem\n\n\n\n\nUna vez hayas terminado de añadir metadatos Dublin Core, puedes adjuntar un archivo a tu ítem haciendo clic en Files en la parte superior del formulario de Dublin Core. (No tienes que hacer clic en Add Item, antes de hacer esto; Omeka guardará automáticamente tu información). Puedes adjuntar múltiples archivos, pero ten encuenta que el plan básico solo viene con 500 MB de espacio de almacenamiento.\n\nUna vez hayas añadido un archivo o archivos, puedes añadir Tags (Etiquetas) haciendo clic en el botón. También puedes hacer clic en Item Type Metadata (Tipos de metadatos del ítem) para seleccionar el tipo de objeto —persona, lugar, animal, vegetal, mineral— que sea tu ítem. Si no ves el tipo apropiado de ítem para tu ítem, no te preocupes. Más adelante podremos añadir un nuevo tipo de ítem.\n\nCuando hayas acabado haz clic en el botón verde Add Item (Añadir ítem).\n\n¡Ya tienes un ítem!\n\n\n    \n\n    Explora ítems, vista de administrador\n\n\n\n\nEsta lista contiene todos los ítems que has añadido. Si el ítem no estuviera público, tendría (Private) después del título.  Para ver cómo se ve la página de tu nuevo ítem haz clic en el nombre del ítem.\n\nEsta no es la página pública de tu ítem\n\n\n    \n\n    Vista del ítem, vista de administrador\n\n\n\n\nPodría parecer que lo es, pero esta página no es lo que un usuario que no ha iniciado sesión verá cuando navegue por la página de tu ítem. Para ver lo que un usuarío vería haz clic en el botón azul View Public Page (Ver Página pública) a la derecha. (O puedes editar el ítem haciendo clic en Edit this item (Editar este ítem) arriba a la derecha).\n\nEsta es la página pública para tu ítem\n\n\n    \n\n    Vista del ítem, vista pública\n\n\n\n\nEsto es lo que un usuario general verá si navega por tu página.\n\nCrea una colección\n\n\n    \n\n    Añade una collección\n\n\n\n\nPuedes empezar a ordenar tu lista de ítems al agruparlos en colecciones. Para hacer esto, regresa a tu panel de control (dashboard) y haz clic en la pestaña Collections (Colecciones) y en Add a Collection (Añade una colección).\n\nIntroduce información sobre tu colección\n\n\n    \n\n    Añade metadatos a tu colección\n\n\n\n\n¡En Omeka, los metadatos son clave! Introduce alguna información sobre tu colección y acuérdate de hacer clic en el botón Public cerca a la parte inferior de la página. Después guarda tu colección.\n\nAñade ítems a tu colección\n\n\n    \n\n    Haz clic en la caja al lado de cada ítem para editar en grupo\n\n\n\n\nPara llenar la colección que acabas de crear haz clic en la pestaña de Items. Desde tu lista de Browse Items, haz clic en las cajas de los ítems que pertenecen a tu nueva colección. Después haz clic en el botón Edit (Editar).\n\nEscoge la colección\n\n\n    \n\n    Selecciona una colección del menú desplegable\n\n\n\n\nEn la página de Batch Edit Items (Editar ítems en grupo), selecciona la colección a la que le quieres añadir tus ítems. (También ten en cuenta todas las otras cosas que puedes hacer en esta página).\n\nRevisa tu nueva colección\n\n\n    \n\n    Navega colecciones (Browse collections), vista pública\n\n\n\n\nRegresa a tu sitio público. Si haces clic en la pestaña Browse Collections (Navega colecciones) en el sitio público, debes ahora poder ver la nueva colección que contiene los ítems que identificaste en el paso anterior.\n\nAhora que has añadido algunos ítems y los has agrupado en una colección, tómate un tiempo para jugar con tu sitio. Está empezando a tomar forma ahora que tienes ítems individuales y unidades temáticas. Pero Omeka puede hacer mucho más. Hablaremos sobre esto en la siguiente lección.\n\nRecursos adicionales\nEl equipo de Omeka ha compilado un conjunto de muy buenos recursos en las páginas de ayuda del software.\nEste manual en español contiene información útil para evaluar las ventajas y desventajas de usar Omeka.net u Omeka.org, al igual que instrucciones generales sobre cómo instalar Omeka en tu servidor.\n\nCon Omeka.net es fácil crear sitios web que contengan colecciones de ítems.\n\n"
  },


  {
    "id": 33,
    "url": "http://localhost:4000/es/lecciones/preservar-datos-de-investigacion",
    "title": "Preservar tus datos de investigación",
    "body": "\nPreservar tus datos de investigación\n\nContenidos\n\n\n  La cuestión de fondo\n  Documentar los datos de investigación\n  Formatos de archivo\n  Resumen 1\n  Estructuración de los datos de investigación\n  Resumen 2\n  Lecturas recomendadas\n\n\nLa cuestión de fondo\n\nEn su ensayo de 2003, “Scarcity or Abundance?”, Roy Rosenzweig trató de alertar a los historiadores contra lo que llamó “la fragilidad de las pruebas en la era digital” (Rosenzweig, 736). Y aunque sus preocupaciones se centraron en los recursos disponibles en la web abierta, fácilmente pueden extenderse a los materiales de origen digital -o datos- que los historiadores crean a lo largo de su investigación.\n\nEsta guía se va a dedicar a la preservación de los datos de investigación. ¿Por qué es esto necesario?\n\nLos historiadores usan las computadoras cada vez más como medios predeterminados para almacenar todos sus datos de investigación. Desde hace algún tiempo, sus manuscritos se han convertido en objetos digitales y en consecuencia su investigación ha cambiado -ya sea como notas, fotografías de archivos o tablas de datos. Además, tener los datos de investigación en formato digital tiene una clara ventaja sobre sus antecedentes físicos: pueden ser navegables y buscables, alojados de manera que puedan ser accesibles en muchos lugares y fusionados o consultados con otros datos de investigación.\n\nPero el hecho de poner todos los datos de investigación en formato digital no garantiza su supervivencia. Y cuando digo sobrevivir no me refiero a su permanencia en un sentido literal o en el sentido de ser capaz de permanecer legible en la próxima versión de Microsoft Word; sino más bien en el sentido de que un archivo pueda ser utilizado por la gente. Los apectos prácticos de cómo conservar los datos de investigación para el futuro es un problema cuya solución ha sido abordada en detalle con y sin los historiadores en mente. Asimismo, los expertos en gestión de datos, servicios y similares han hablado al igual acerca de las mejores prácticas académicas en lo que respecta a la documentación, estructuración y organización de los datos de investigación. A pesar de todo esto, los datos de investigación generados por un historiador individual están en riesgo de perderse si ese historiador no es capaz de generarlos y preservarlos en una forma en que los pueda entender, así como encontrarlos significativos años o décadas más tarde, por no hablar de cualquier otra persona vadeando a través de las idiosincrasias de su proceso de investigación. En resumen, hay un riesgo de pérdida de los datos cuando se separan de su contexto de creación y del conocimiento tácito de que fueron útiles para la preparación de la conferencia X o el manuscrito Y. Como dijo William Stafford Noble:\n\n\n  El principio guía básico es simple: alguien no familiarizado con tu\nproyecto debe ser capaz de ver los archivos de tu computadora y entender\nen detalle qué es lo que hiciste y por qué […]. Pero por lo común resulta que ese “alguien” eres tú. En unos meses a partir de ahora, podrás no recordar lo que estabas haciendo cuando creaste un conjunto de archivos en particular, o podrás olvidar qué conclusiones esbozaste. Tendrás entonces que pasar tiempo reconstruyendo tus experimentos anteriores y percepciones adquiridas a partir de esos experimentos.\n\n  William Stafford Noble (2009) A Quick Guide to Organizing\nComputational Biology Projects. PLoSComputBiol 5(7): e1000424.\ndoi:10.1371/journal.pcbi.1000424\n\n\nTeniendo en cuenta las lecciones y la experiencia de los expertos en datos de investigación, esta guía te sugerirá formas en las que los historiadores pueden documentar y estructurar sus datos de investigación con el fin de asegurar que permanecerán útiles en el futuro. La guía no pretende ser prescriptiva pues se espera que los lectores repitan, cambien y adapten las ideas que se presentan de acuerdo con sus investigaciones.\n\n\n\nDocumentar los datos de investigación\n\n\n  Birkwood, Katie (girlinthe). “Victory is mine: while ago I worked out\nsome Clever Stuff ™ in Excel. And I MADE NOTES ON IT. And those notes\nENABLED ME TO DO IT AGAIN.” 7 October 2013, 3:46 a.m.. Tweet.\n\n  https://twitter.com/Girlinthe/status/387166944094199809\n\n\nEl propósito de documentar es capturar el proceso de creación de datos, los cambios hechos a los datos y el conocimiento tácito asociado con los datos. Las metodologías de gestión de proyectos, como PRINCE2, pone un gran énfasis en una documentación precisa, estructurada y detallada. Mientras que este enfoque beneficia especialmente a proyectos grandes y complejos, con múltiples asociados, el historiador promedio probablemente pueda beneficiarse de un enfoque más flexible y que se nutra, pero no se ate, a los principios de la gestión de proyectos. En el caso de la investigación histórica, el tipo de documentación que podría producirse para preservar la utilidad de los datos de investigación incluye:\n\n\n  Documentación que describa las notas tomadas durante el examen de un documento de archivo, como la referencia del archivo para el documento original, la representatividad de las notas (por ejemplo, transcipciones completas, transcripciones parciales o resúmenes), cuánto del documento fue examinado o las decisiones tomadas para excluir secciones del documento del proceso de investigación.\n  Documentación que describa los datos tabulares, como la forma en que fueron generados (por ejemplo, a mano o de forma automatizada), referencias de archivo para las fuentes originales de donde provienen los datos, qué atributos de las fuentes originales fueron conservados y el porqué.\n  Documentación que describa un directorio de imágenes digitales, cómo se creó cada imagen, de dónde fueron descargadas esas imágenes o notas de investigación que se refieran a ellas.\n\n\nComo sugiere el último ejemplo, uno de los propósitos principales de la documentación es describir los vínculos significativos que existen entre los datos de la investigación, vínculos que pueden dejar de ser evidentes con el tiempo.\n\nEl momento de documentar depende en gran medida de la persona y del ritmo de la investigación. La regla general es adquirir un hábito de escritura y actualizar la documentación a intervalos regulares, idealmente cada vez que se termina un lote de trabajo por la mañana, la tarde o día. Al mismo tiempo es importante no preocuparse por la perfección sino aspirar a escribir documentación consistente y eficiente que será útil para ti y es de esperarse también que para otras personas puedan utilizar tus datos de investigación años después de realizados.\n\n\n\nFormatos de archivo\n\nIdealmente, los datos de investigación y la documentación deben ser guardados en archivos independientes de plataforma como .txt para notas y .csv (valores separados por comas) o .tsv (valores separados por tabuladores) para los datos en tablas. Estos formatos de texto plano son preferibles a los formatos propietarios utilizados por defecto por Microsoft Office o iWork porque pueden abrirse con muchos paquetes de programas y tienen una gran probabilidad de permanecer visibles o editables en el futuro. Muchas suites de ofimática (o paquetes de software para oficina) incluyen la opción de guardar archivos en formatos .txt, .csv y .tsv, lo que significa que se puede continuar trabajando con programas familiares y aún así tomar las acciones apropiadas para hacer accesible tu trabajo. Comparados con .doc o .xls, estos formatos tienen el beneficio adicional, desde una perspectiva de preservación, de contener solamente elementos legibles por la computadora. Mientras que es una práctica común el uso de negritas, itálicas o colores para indicar encabezados o para establecer una conexión visual entre elementos de los datos, estas anotaciones orientadas a la visualización no son legibles por la computadora y, por lo tanto, no puede ser consultadas ni buscadas, ni son adecuadas para grandes cantidades de información. Son preferibles los esquemas simples de anotación como el uso de un doble asterisco o tres signos de almohadilla para representar una característica de los datos; en mis propias notas, por ejemplo, tres signos de interrogación indica algo a lo que necesito dar seguimiento, y lo elegí porque “???” se puede encontrar fácilmente con una búsqueda mediante CTRL + F.\n\nEs probable que en muchas ocasiones estos esquemas de anotación se desprendan de la práctica individual (y en consecuencia deban ser documentados), aunque hay sintaxis disponibles como Markdown (los archivos Markdown se guardan como .md). En GitHub  https://github.com/adam-p/markdown-here se pueden encontrar estos excelentes apuntes para quien quiera seguir -o adaptar- esta sintaxis. Se recomienda el uso de Notepad++ http://notepad-plus-plus.org/ a los usuarios de Windows, aunque de ninguna manera es esencial para trabajar con archivos .md. Los usuarios de Mac o Unix pueden encontrar útil Komodo Edit o Text Wrangler.\n\nResumen 1\n\nRecapitulando, los puntos clave acerca de la documentación y los formatos de archivo son:\n\n\n  Intenta que la documentación capture de una manera precisa y consistente el conocimiento tácito que rodea al proceso de investigación, ya sea en relación con las notas tomadas, la generación de datos en tablas o la acumulación de pruebas visuales.\n  Mantén una documentación sencilla utilizando formatos y prácticas de anotación independientes de la plataforma y legibles por la computadora.\n  Haz espacio para actualizar y crear documentación en tu flujo de trabajo sin permitir que el proceso de documentación se convierta en una carga.\n  Invierte en dejar un registro en papel ahora para ahorrar tiempo intentando reconstruirlo en el futuro.\n\n\n\n\nEstructuración de los datos de investigación\n\nDocumentar tu investigación se torna más fácil estructurando los datos de investigación de una manera consistente y predecible.\n\n¿Por qué?\n\nLa respuesta es que cada vez que usamos una biblioteca o un catálogo de archivo dependemos de la información estructurada para ayudarnos a navegar por los datos (tanto físicos como digitales) que contiene el repositorio. Sin esta información estructurada, nuestra investigación sería muy pobre.\n\nExaminar los URLs es una buena forma de pensar una estructura de datos de investigación, consistente y predecible, que puede ser útil para tu investigación. Las URL malas no son reproducibles y, por tanto, en un contexto académico no son citables. Por el contrario, las buenas URL representan con claridad el contenido de la página que identifican, ya sea porque contienen elementos semánticos o porque utilizan un elemento único encontrado en un conjunto o en la mayoría de las páginas.\n\nUn buen ejemplo de los primeros son los URLs utilizados por los sitios web de noticias o los servicios de blogging. Los URLs de WordPress utilizan el siguiente formato:\n\n\n  Nombre del sitio web/año (4 dígitos)/mes (2 dígitos)/día (2 dígitos)/palabras-del-titulo-separadas-por-guiones\n  http://cradledincaricature.com/2014/02/06/comic-art-beyond-the-print-shop/\n\n\nUn estilo similar es utilizado por las agencias de noticias como el periódico The Guardian:\n\n\n  Nombre del sitio web/subdivisión de seccción/año (4 dígitos)/mes (3 caracteres)/día (2 dígitos)/palabras-que-describen-contenido-separadas-por-guiones\n  http://www.theguardian.com/uk-news/2014/feb/20/rebekah-brooks-rupert-murdoch-phone-hacking-trial\n\n\nEn los catálogos de archivo, se suelen utilizar URLs estructurados por un elemento de datos. The British Cartoon Archive estructura su archivo en línea utilizando el formato:\n\n\n  nombre del sitio web/registro/número de referencia\n  http://www.cartoons.ac.uk/record/SBD0931\n\n\nY el sitio Old Bailey Online usa este formato:\n\n\n  nombre del sitio web/browse.jsp?ref=número de referencia\n  http://www.oldbaileyonline.org/browse.jsp?ref=OA16780417\n\n\nLo que aprendemos de estos ejemplos es que la combinación de descripciones semánticas con elementos de datos hacen consistente y predecible la lectura de los datos estructurados tanto por máquinas como por seres humanos. Transferir esto a los datos digitales acumulados durante el curso de la investigación histórica hace que los datos de investigación sean más fácilmente navegables, así como buscar y consultar utilizando las herramientas estándar provistas por nuestros sistemas operativos (y, como veremos en próximas lecciones, por herramientas más avanzadas).\n\nEn la práctica, la estructura de un buen archivo de datos de investigación puede verse como sigue (para los usuarios de OS X y Linux, reemplaza las barras invertidas por diagonales).\n\nUn directorio raíz o base quizá llamado ‘trabajo’.\n\n\\trabajo\\\n\n\nUna serie de subdirectorios.\n\n\\trabajo\\eventos\\\n        \\investigacion\\\n        \\docencia\\\n        \\escritos\\\n\n\nDentro de estos directorios habrá una serie de subdirectorios para cada evento, proyecto de investigación, módulo o escrito. La introducción de una nomenclatura convencional que incluya elementos de fecha permite tener la información organizada sin la necesidad de organizar los subdirectorios, digamos, por año o mes.\n\n\\trabajo\\investigacion\\2014-01_articulos_revistas\n              \t\t    \\2014-02_Infraestructura\n\n\nPor último, se pueden utilizar más subdirectorios para separar la información a la vez que crece el proyecto.\n\n\\trabajo\\investigación\\2014_articulos_revista\\analisis\n                                             \\datos\n                                             \\notas\n\n\nPor supuesto, no toda la información encajará perfectamente en una estructura predeterminada y, a medida que surjan nuevos proyectos, tendrán que revisarse las taxonomías. De cualquier manera, el sistema resulta correcto siempre y cuando la estructura global del directorio sea consistente y predecible. No será así cuando el historiador no encuentre claramente el documento. Por ejemplo, el subdirectorio ‘escritos’ de la estructura anterior podría incluir un archivo .txt que indique lo que contiene (borradores, la versión final del trabajo) y lo que no contiene (investigación relativa a lo escrito).\n\nDebe tenerse presente que el nombre de este archivo de texto, así como los de toda la documentación y datos de investigación, debería servir para identificar el mismo archivo y su contenido. “Notas sobre esta carpeta.docx” no es un nombre que cumpla con este propósito, mientras que “2014-01-31\\escritura\\leeme.txt” reproduce el título del directorio e introduce alguna información de fecha. Un archivo ‘leeme’ que hice para un proyecto reciente, contiene el tipo de información que tú y otros usuarios de tus datos pueden encontrar útil.\n\nPara confirmar el valor de este enfoque quizá valga la pena explicar una breve experiencia personal. Durante el curso de un proyecto de investigación anterior, recolecté unas 2.000 imágenes digitales de grabados satíricos sobre Georgia de una serie de recursos en línea, conservando los nombres de los archivos en el momento de la descarga. Si en un primer momento yo hubiese establecido una convención para nombrar estos archivos (por ejemplo, ‘AÑO DE PUBLICACIÓN\\NOMBRE DEL ARTISTA\\TÍTULO DEL TRABAJO\\FORMATO’) hoy yo sería capaz de buscar y consultar estas imágenes. De hecho, comenzar cada nombre de archivo con alguna versión para indicar la fecha (YYYYMMDD) habría significado poder organizarlas de manera cronológica en Window, OS X o Linux. Y de haber retirado todos los espacios o signos de puntuación (salvo guiones, puntos, o guiones bajos) de los nombres de los archivos, podría haberlos hecho consistentes y predecibles. Esta sencilla medida habría hecho posible la gestión de esos archivos mediante la interfaz de línea de comandos. Pero no lo hice y, tal y como están ahora, yo tendría que perder mucho tiempo en modificar cada nombre de archivo individualmente a fin de que los datos puedan utilizarse de esta forma.\n\nLa aplicación de estas convenciones de nombre a todos los datos de investigación de manera consistente y predecible ayuda a la legibilidad y comprensión de la estructura de datos. Por ejemplo, para un proyecto sobre artículos de revistas pueden elegir el directorio:\n\n\\trabajo\\investigación\\2014-01_articulos_revistas\\\n\n\nEn el ejemplo mostrado, los elementos de fecha ‘año-mes’ indican cúando se inició el proyecto.\n\nDentro de este directorio se puede incluir un directorio de \\datos\\ para guardar los datos originales utilizados en el proyecto.\n\n2014-01-31_articulos_revistas.tsv\n\n\nJunto con estos datos habrá una documentación que describa el archivo 2014-01-31_articulos_revistas.tsv\n\n2014-01-31_articulos_revistas_notas.txt\n\n\nSubiendo un nivel de directorio a \\2014-01_articulos_revistas\\ creamos un directorio \\analisis\\ en el cual colocamos:\n\n2014-02-02_articulos_revistas_analisis.txt\n2014-02-15_articulos_revistas_analisis.txt\n\n\nObserva los diferentes atributos de fechas. Estos reflejan el momento en que se hizo el análisis de datos que se describirá brevemente de manera convencional en:\n\n2014-02-02\\_articulos\\_revistas\\_analisis\\_leeme.txt.\n\n\nFinalmente, podemos crear un directorio dentro de la carpeta \\datos\\ que contenga los datos derivados de 2014-01-31_articulos_revistas.tsv, que llamaremos \\datos_derivados\\. En este caso, cada archivo .tsv derivado contiene líneas que incluyen palabras clave como ‘africa’, ‘america’, ‘arte’, etcétera, y se nombran de acuerdo a ello [Nota del traductor: las palabras clave se escriben a propósito sin acentos para facilitar la estructura de datos en los directorios y su búsqueda independiente de plataforma].\n\n2014-01-31_articulos_revista_KW_africa.tsv\n\n2014-01-31_articulos_revista__KW_america.tsv\n\n2014-02-01_articulos_revista__KW_arte.tsv\n\n2014-02-02_articulos_revista__KW_bretaña.tsv\n\n\n\n\nResumen 2\n\nRecapitulando, los puntos clave sobre la creación de una estructura de datos de investigación son:\n\n\n  La estructura de datos debe ser consistente y predecible.\n  Considera la utilización de elementos semánticos o identificacores de datos para estructurar los directorios de investigación.\n  Ajusta y adapta la estructura de datos de investigación a tus necesidades.\n  Establece convenciones de nomenclatura en los directorios y archivos para identificarlos, crear asociaciones entre elementos de datos, y para ayudar a una lectura y comprensión a largo plazo de tu estructura de datos.\n\n\n\n\nEsta lección ha sugerido maneras para documentar y estructurar datos de investigación. El objetivo ha sido asegurar que tus datos se conserven mediante la captura del conocimiento tácito adquirido en tu proceso de investigación y, por lo tanto, haciendo dicha información asequible y fácil de utilizar en el futuro. Se ha recomendado el uso de formatos independientes de plataforma y legibles por computadoras. También se han analizado las URLs como un ejemplo de buenas (y malas) prácticas de estructuración de datos que se puede replicar para organizar los datos de investigación de un historiador.\n\nEstas sugerencias son solamente guías pues se espera que los investigadores las adapten para satisfacer sus propias necesidades. Al hacerlo, se recomienda que cada investigador mantenga sus estrategias de conservación digital, pero que tenga en mente las mejores prácticas de gestión de proyectos. De esta manera, nos aseguramos que el tiempo que pasamos en documentar y estructurar los datos de investigación no sea un lastre. Después de todo, el propósito de esta guía es hacer eficiente la investigación histórica que genera datos. Es decir: tu investigación.\n\n\n\nLecturas recomendadas\n\nAshton, Neil, ‘Seven deadly sins of data publication’, School of Data\nblog (17 October 2013)\nhttp://schoolofdata.org/2013/10/17/seven-deadly-sins-of-data-publication/\n\nHitchcock, Tim, ‘Judging a book by its URLs’, Historyonics blog (3\nJanuary 2014)\nhttp://historyonics.blogspot.co.uk/2014/01/judging-book-by-its-url.html\n\nHoward, Sharon, ‘Unclean, unclean! What historians can do about sharing\nour messy research data’, Early Modern Notes blog (18 May 2013)\nhttp://earlymodernnotes.wordpress.com/2013/05/18/unclean-unclean-what-historians-can-do-about-sharing-our-messy-research-data/\n\nNoble, William Stafford, A Quick Guide to Organizing Computational\nBiology Projects.PLoSComputBiol 5(7): e1000424 (2009)\nhttps://doi.org/10.1371/journal.pcbi.1000424\n\nOxford University Computing Services, ‘Sudamih Project. Research\nInformation Management: Organising Humanities Material’ (2011)\nhttps://doi.org/10.5281/zenodo.28329\n\nPennock, Maureen, ‘The Twelve Principles of Digital Preservation (and a\ncartridge in a repository…)’, British Library Collection Care blog (3\nSeptember 2013)\nhttp://britishlibrary.typepad.co.uk/collectioncare/2013/09/the-twelve-principles-of-digital-preservation.html\n\nPritchard, Adam, ‘Markdown Cheatsheet’ (2013)\nhttps://github.com/adam-p/markdown-here\n\nRosenzweig, Roy, ‘Scarcity or Abundance? Preserving the Past in a\nDigital Era’, The American Historical Review 108:3 (2003), 735-762.\n\nUK Data Archive, ‘Documenting your Data’\nhttp://data-archive.ac.uk/create-manage/document\n\n\nEsta lección te sugerirá formas en las que los historiadores pueden documentar y estructurar sus datos de investigación con el fin de asegurar que permanecerán útiles en el futuro.\n\n"
  },


  {
    "id": 34,
    "url": "http://localhost:4000/es/lecciones/procesamiento-basico-de-textos-en-r",
    "title": "Procesamiento básico de textos en R",
    "body": "\nProcesamiento básico de textos en R\n\nContenidos\n\n\n  Objetivos\n  Un pequeño ejemplo    \n      Configuración de paquetes\n      Segmentación de palabras\n      Detectar oraciones\n    \n  \n  Análisis del discurso del Estado de la Unión de 2016 de Barak Obama    \n      Análisis exploratorio\n      Resumen del documento\n    \n  \n  Análisis de los discursos del Estado de la Unión desde 1790 a 2016    \n      Cargar el corpus\n      Forma alternativa de cargar el corpus (opcional)\n      Análisis exploratorio\n      Análisis estilométrico\n      Resumen de documento\n    \n  \n  Siguientes pasos\n  Notas\n\n\nObjetivos\n\nHoy en día hay una cantidad sustancial de datos históricos disponibles en forma de texto simple digitalizado. Algunos ejemplos comunes son cartas, artículos periodísticos, notas personales, entradas de diario, documentos legales y transcripciones de discursos. Mientras que algunas aplicaciones de software independientes ofrecen herramientas para el análisis de datos textuales, el uso de lenguajes de programación presenta una mayor flexibilidad para analizar un corpus de documentos de texto. En este tutorial se introduce a los usuarios en las bases del análisis de texto con el lenguaje de programación R. Nuestro acercamiento involucra únicamente el uso de un tokenizador (tokenizer) que realiza un análisis sintáctico del texto con elementos como palabras, frases y oraciones. Al final de esta lección los usuarios podrán:\n\n  utilizar análisis exploratorios para verificar errores y detectar patrones de nivel general;\n  aplicar métodos básicos de estilometría a lo largo del tiempo y entre autores;\n  enfocarse en el resumen de resultados para ofrecer descripciones de nivel general de los elementos en un corpus.\n\n\nPara el particular se utilizará un conjunto de datos compuesto por los textos de los discursos del Estado de la Unión de los Estados Unidos1.\n\nAsumimos que los usuarios tienen un conocimiento básico del lenguaje de programación R. La lección ‘R Basics with Tabular Data’ de Taryn Dewar2 es una excelente guía que trata todo el conocimiento sobre R aquí asumido: instalar y abrir R, instalar y cargar paquetes, e importar y trabajar con datos básicos de R. Los usuarios pueden descargar R para su sistema operativo desde The Comprehensive R Archive Network. Aunque no es un requisito, también recomendamos que los nuevos usuarios descarguen R Studio, un entorno de desarrollo de código abierto para escribir y ejecutar programas en R.\n\nTodo el código de esta lección fue probado en la versión 3.3.2 de R, pero creemos que funcionará correctamente en versiones futuras del programa.\n\nUn pequeño ejemplo\n\nConfiguración de paquetes\nEs necesario instalar dos paquetes de R antes de comenzar con el tutorial. Estos son tidyverse3 y tokenizers4. El primero proporciona herramientas cómodas para leer y trabajar con grupos de datos y el segundo contiene funciones para dividir los datos de texto en palabras y oraciones. Para instalarlos, abre R en tu ordenador y ejecuta estas dos líneas de código en la consola:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tokenizers\")\n\n\nDependiendo de la configuración de tu sistema, puede que se abra un cuadro de diálogo pidiéndote que elijas un sitio espejo (mirror) del que realizar la descarga. Escoge uno cerca de tu localización. La descarga y la instalación deberían realizarse automáticamente.\n\nAhora que estos paquetes están descargados en tu ordenador, tenemos que decirle a R que los cargue para usarlos. Hacemos esto mediante el comando library(librería); puede que aparezcan algunos avisos mientras se cargan otras dependencias, pero por lo general se pueden ignorar sin mayor problema.\n\nlibrary(tidyverse)\nlibrary(tokenizers)\n\n\nMientras que solo necesitas ejecutar el comando install.packages (instalar paquetes) la primera vez que inicias este tutorial, tendrás que ejecutar el comando library cada vez que reinicies R5.\n\nSegmentación de palabras\n\nEn esta sección vamos a trabajar con un único párrafo. Este ejemplo pertenece al comienzo del último discurso sobre el Estado de la Unión de Barack Obama en 2016. Para facilitar la comprensión del tutorial en esta primera etapa, estudiamos este párrafo en su versión en español6.\n\nPara cargar el texto copia y pega lo siguiente en la consola de R.\n\ntexto &lt;- paste(\"También entiendo que como es temporada de elecciones, las expectativas para lo que lograremos este año son bajas. Aún así, señor Presidente de la Cámara de Representantes, aprecio el enfoque constructivo que usted y los otros líderes adoptaron a finales del año pasado para aprobar un presupuesto, y hacer permanentes los recortes de impuestos para las familias trabajadoras. Así que espero que este año podamos trabajar juntos en prioridades bipartidistas como la reforma de la justicia penal y ayudar a la gente que está luchando contra la adicción a fármacos de prescripción. Tal vez podamos sorprender de nuevo a los cínicos.\")\n\n\nDespués de ejecutar esto (haciendo clic en ‘Intro’), escribe la palabra texto en la consola y haz clic en ‘Intro’. R imprimirá el párrafo de texto porque la variable ‘texto’ ahora contiene el documento.\n\nComo primer paso en el procesamiento del texto vamos a usar la función tokenize_words (segmentar palabras) del paquete tokenizers para dividir el texto en palabras individuales.\n\npalabras &lt;- tokenize_words(texto)\n\n\nPara imprimir los resultados en la ventana de la consola de R, mostrando tanto el resultado tokenizado como la posición de cada elemento en el margen izquierdo, ejecuta palabras en la consola:\n\npalabras\n\n\nEsto produce el siguiente resultado:\n\n&gt; [[1]]\n  [1] \"también\"        \"entiendo\"       \"que\"            \"como\"\n  [5] \"es\"             \"temporada\"      \"de\"             \"elecciones\"\n  [9] \"las\"            \"expectativas\"   \"para\"           \"lo\"\n [13] \"que\"            \"lograremos\"     \"este\"           \"año\"\n [17] \"son\"            \"bajas\"          \"aún\"            \"así\"\n [21] \"señor\"          \"presidente\"     \"de\"             \"la\"\n [25] \"cámara\"         \"de\"             \"representantes\" \"aprecio\"\n [29] \"el\"             \"enfoque\"        \"constructivo\"   \"que\"\n [33] \"usted\"          \"y\"              \"los\"            \"otros\"\n [37] \"líderes\"        \"adoptaron\"      \"a\"              \"finales\"\n [41] \"del\"            \"año\"            \"pasado\"         \"para\"\n [45] \"aprobar\"        \"un\"             \"presupuesto\"    \"y\"\n [49] \"hacer\"          \"permanentes\"    \"los\"            \"recortes\"\n [53] \"de\"             \"impuestos\"      \"para\"           \"las\"\n [57] \"familias\"       \"trabajadoras\"   \"así\"            \"que\"\n [61] \"espero\"         \"que\"            \"este\"           \"año\"\n [65] \"podamos\"        \"trabajar\"       \"juntos\"         \"en\"\n [69] \"prioridades\"    \"bipartidistas\"  \"como\"           \"la\"\n [73] \"reforma\"        \"de\"             \"la\"             \"justicia\"\n [77] \"penal\"          \"y\"              \"ayudar\"         \"a\"\n [81] \"la\"             \"gente\"          \"que\"            \"está\"\n [85] \"luchando\"       \"contra\"         \"la\"             \"adicción\"\n [89] \"a\"              \"fármacos\"       \"de\"             \"prescripción\"\n [93] \"tal\"            \"vez\"            \"podamos\"        \"sorprender\"\n [97] \"de\"             \"nuevo\"          \"a\"              \"los\"\n[101] \"cínicos\"\n\n\n¿Cómo ha cambiado el texto cargado después de ejecutar esa función de R? Ha eliminado todos los signos de puntuación, ha dividido el texto en palabras individuales y ha convertido todo a minúsculas. Veremos a continuación por qué todas estas intervenciones son útiles para nuestro análisis.\n\n¿Cuántas palabras hay en este fragmento de texto? Si usamos la función length (longitud) directamente en el objeto palabras, el resultado no es muy útil que digamos.\n\nlength(palabras)\n\n\nEl resultado es igual a:\n\n[1] 1\n\n\nLa razón por la cual la longitud equivale a 1 es que la función tokenize_words devuelve una lista de objetos con una entrada por documento cargado. Nuestro ingreso solo tiene un documento y, por tanto, la lista contiene solo un elemento. Para ver las palabras dentro del primer documento, usamos el símbolo del corchete para seleccionar solo el primer elemento de la lista, así:\n\nlength(palabras[[1]])\n\n\nEl resultado es 101, lo cual indica que hay 101 palabras en nuestro párrafo.\n\nLa separación del documento en palabras individuales hace posible calcular cuántas veces se utilizó cada palabra en el texto. Para hacer esto, primero aplicamos la función table(tabla) a las palabras en el primer (y aquí, único) documento y después separamos los nombres y los valores de la tabla en un único objeto llamado marco de datos (data frame). Los marcos de datos en R son utilizados de manera similar a como se utiliza una tabla en una base de datos. Estos pasos, junto con la impresión de los resultados, son conseguidos con las siguientes líneas de código:\n\ntabla &lt;- table(palabras[[1]])\ntabla &lt;- data_frame(palabra = names(tabla), recuento = as.numeric(tabla))\ntabla\n\n\nEl resultado de este comando debería parecerse a este en tu consola (una tibble es una variedad específica de marco de datos creado bajo el enfoque Tidy Data):\n\n   # A tibble: 70 x 2\n   palabra   recuento\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 a               4.\n 2 adicción        1.\n 3 adoptaron       1.\n 4 año             3.\n 5 aprecio         1.\n 6 aprobar         1.\n 7 así             2.\n 8 aún             1.\n 9 ayudar          1.\n10 bajas           1.\n# ... with 60 more rows\n\n\nHay una gran cantidad de información en esta muestra. Vemos que hay 70 palabras únicas, como indica la dimensión de la tabla. Se imprimen las 10 primeras filas del conjunto de datos con la segunda columna indicando el número de veces que la palabra de la primera columna ha sido usada. Por ejemplo, “a” se usó 4 veces pero “ayudar” solo se usó una vez.\n\nTambién podemos ordenar la tabla usando la función arrange(organizar). Esta función toma el conjunto de datos sobre el que trabajar, aquí tabla, y después el nombre de la columna que toma como referencia para ordenarlo. La función desc en el segundo argumento indica que queremos clasificar en orden descendiente.\n\narrange(tabla, desc(recuento))\n\n\nY el resultado ahora será:\n\n# A tibble: 70 x 2\n   palabra recuento\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 de            7.\n 2 que           6.\n 3 la            5.\n 4 a             4.\n 5 año           3.\n 6 los           3.\n 7 para          3.\n 8 y             3.\n 9 así           2.\n10 como          2.\n# ... with 60 more rows\n\n\nLas palabras más comunes son pronombres y palabras de función como “de”, “que”, “la” y “a”. Advierte como se facilita el análisis al usar la versión en minúscula de cada palabra. La palabra “así” en la segunda oración no es tratada de diferente manera a “Así” al comienzo de la tercera oración.\n\nUna técnica popular es cargar una lista de palabras usadas con gran frecuencia y eliminarlas antes del análisis formal. Las palabras en dicha lista se denominan “stopwords” o “palabras vacías” y normalmente se trata de pronombres, conjugaciones de los verbos más comunes y conjunciones. En este tutorial usaremos una variación matizada de esta técnica.\n\nDetectar oraciones\n\nEl paquete tokenizer también contiene la función tokenize_sentences que divide el texto en oraciones en vez de en palabras. Se puede ejecutar de la siguiente manera:\n\noraciones &lt;- tokenize_sentences(texto)\noraciones\n\n\nCon el resultado:\n\n&gt; oraciones\n[[1]]\n[1] \"También entiendo que como es temporada de elecciones, las expectativas para lo que lograremos este año son bajas.\"\n[2] \"Aún así, señor Presidente de la Cámara de Representantes, aprecio el enfoque constructivo que usted y los otros líderes adoptaron a finales del año pasado para aprobar un presupuesto, y hacer permanentes los recortes de impuestos para las familias trabajadoras.\"\n[3] \"Así que espero que este año podamos trabajar juntos en prioridades bipartidistas como la reforma de la justicia penal y ayudar a la gente que está luchando contra la adicción a fármacos de prescripción.\"\n[4] \"Tal vez podamos sorprender de nuevo a los cínicos.\"\n\n\nEl resultado es un vector de caracteres, un objeto unidimensional que consta únicamente de elementos representados como caracteres. Advierte que el resultado ha marcado cada oración como un elemento separado.\n\nEs posible conectar el resultado de la división de oraciones con el de la división por palabras. Si ejecutamos la división de oraciones del párrafo con la función tokenize_words, cada oración es tratada como un único documento. Ejecuta esto usando la siguiente línea de código y observa si el resultado se parece al que estabas esperando; usa la segunda línea para imprimir el resultado.\n\noraciones_palabras &lt;- tokenize_words(oraciones[[1]])\noraciones_palabras\n\n\nSi miramos el tamaño del resultado directamente podemos ver que hay cuatro “documentos” en el objeto oraciones_palabras:\n\nlength(oraciones_palabras)\n\n\nAccediendo a cada uno directamente, es posible saber cuántas palabras hay en cada oración del párrafo:\n\nlength(oraciones_palabras[[1]])\nlength(oraciones_palabras[[2]])\nlength(oraciones_palabras[[3]])\nlength(oraciones_palabras[[4]])\n\n\nEsto puede ser algo engorroso pero, afortunadamente, hay una forma más sencilla de hacerlo. La función sapply ejecuta la función en el segundo argumento a cada elemento en el primer argumento. Como resultado, podemos calcular la longitud de cada oración en el primer párrafo con una sola línea de código:\n\nsapply(oraciones_palabras, length)\n\n\nEl resultado es este:\n[1] 18 40 34 9\n\n\nPodemos ver que hay cuatro oraciones con una longitud de 18, 40, 34 y 9 palabras. Utilizaremos esta función para manejar documentos más grandes.\n\nAnálisis del discurso del Estado de la Unión de 2016 de Barak Obama\n\nAnálisis exploratorio\n\nVamos a aplicar las técnicas de la sección previa a un discurso del Estado de la Unión completo. Por motivos de consistencia, vamos a usar el mismo discurso de 2016 de Obama. Aquí vamos a cargar los datos desde un archivo puesto que copiarlo directamente se vuelve difícil a gran escala.\n\nPara hacer esto, vamos a combinar la función readLines (leer líneas) para cargar el texto en R y la función paste (pegar) para combinar todas las líneas en un único objeto. Vamos a crear la URL del archivo de texto usando la función sprintf puesto que este formato permitirá su fácil modificación para otras direcciones web78.\n\nbase_url &lt;- \"https://programminghistorian.org/assets/basic-text-processing-in-r\"\nurl &lt;- sprintf(\"%s/sotu_text/236.txt\", base_url)\ntexto &lt;- paste(readLines(url), collapse = \"\\n\")\n\n\nComo antes, vamos a segmentar el texto y ver el número de palabras que hay en el documento.\n\npalabras &lt;- tokenize_words(texto)\nlength(palabras[[1]])\n\n\nVemos que este discurso contiene un total de 6113 palabras. Combinando las funciones de table (tabla), data_frame (marco de datos) y arrange (organizar), como lo hicimos en el ejemplo, obtenemos las palabras más frecuentes del discurso entero. Mientras haces esto, advierte lo fácil que es reutilizar código previo para repetir el análisis en un nuevo grupo de datos; esto es uno de los mayores beneficios de usar un lenguaje de programación para realizar un análisis basado en datos.\n\ntabla &lt;- table(palabras[[1]])\ntabla &lt;- data_frame(word = names(tabla), count = as.numeric(tabla))\ntabla &lt;- arrange(tabla, desc(count))\ntabla\n\n9\n\nEl resultado debería ser:\n\n&gt;#A tibble: 1,590 x 2\n   word  count\n   &lt;chr&gt; &lt;dbl&gt;\n 1 the    281.\n 2 to     209.\n 3 and    189.\n 4 of     148.\n 5 that   125.\n 6 we     124.\n 7 a      120.\n 8 in     105.\n 9 our     96.\n10 is      72.\n&gt;#... with 1,580 more rows\n\n\nDe nuevo, palabras extremamente comunes como “the”, “to”, “and” y “of” están a la cabeza de la tabla. Estos términos no son particularmente esclarecedores si queremos saber el tema del discurso. En realidad, queremos encontrar palabras que destaquen más en este texto que en un corpus externo amplio en inglés. Para lograr esto necesitamos un grupo de datos que proporcione estas frecuencias. Aquí está el conjunto de datos de Peter Norviq usando el Google Web Trillion Word Corpus (Corpus de un trillón de palabras web de Google), recogido de los datos recopilados a través del rastreo de sitios web más conocidos en inglés realizado por Google10:\n\npalabras_frecuentes &lt;- read_csv(sprintf(\"%s/%s\", base_url, \"word_frequency.csv\"))\npalabras_frecuentes\n\n\nLa primera columna indica el lenguaje (siempre “en” por el inglés en este caso), la segunda aporta la palabra en cuestión y la tercera el porcentaje con que aparece en el Corpus de un trillón de palabras de Google. Por ejemplo, la palabra “for” aparece casi exactamente 1 vez cada 100 palabras, por lo menos en los textos de webs indexadas por Google.\n\nPara combinar estas palabras frecuentes con el grupo de datos en la tabla construida a partir de este discurso del Estado de la Unión, podemos utilizar la función inner_join (unión interna). Esta función toma dos grupos de datos y los combina en todas las columnas que tengan el mismo nombre; en este caso la columna común es la que se llama “palabra”.\n\ntabla &lt;- inner_join(tabla, palabras_frecuentes)\ntabla\n\n\nTen en cuenta que ahora nuestro grupo de datos tiene dos columnas extras que aportan el lenguaje (aquí relativamente poco útil ya que siempre es “en”) y la frecuencia de la palabra en el corpus externo. Esta segunda nueva columna será muy útil porque podemos filtrar filas que tengan una frecuencia menor al 0.1%, esto es, que aparezcan más de una vez en cada 1000 palabras:\n\nfilter(tabla, frequency &lt; 0.1)\n\n\nEsto da:\n\n&gt;#A tibble: 1,457 x 4\n   word     count language frequency\n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 america    28. en          0.0232\n 2 people     27. en          0.0817\n 3 just       25. en          0.0787\n 4 world      23. en          0.0734\n 5 american   22. en          0.0387\n 6 work       22. en          0.0713\n 7 make       20. en          0.0689\n 8 want       19. en          0.0440\n 9 change     18. en          0.0358\n10 years      18. en          0.0574\n&gt;#... with 1,447 more rows\n\n\nEsta lista ya comienza a ser más interesante. Un término como “america” aparece a la cabeza de la lista porque,  podemos pensar, se utiliza mucho en los discursos de los políticos y menos en otros ámbitos. Al establecer el umbral aun más bajo, a 0.002, obtenemos un mejor resumen del discurso. Puesto que sería útil ver más que las diez líneas por defecto, vamos a usar la función print (imprimir) junto con la opción n (de número) configurada a 15 para poder ver más líneas.\n\nprint(filter(tabla, frequency &lt; 0.002), n = 15)\n\n\nEsto ahora nos muestra el siguiente resultado:\n\n&gt;#A tibble: 463 x 4\n   word        count language frequency\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 laughter      11. en        0.000643\n 2 voices         8. en        0.00189\n 3 allies         4. en        0.000844\n 4 harder         4. en        0.00152\n 5 qaida          4. en        0.000183\n 6 terrorists     4. en        0.00122\n 7 bipartisan     3. en        0.000145\n 8 generations    3. en        0.00123\n 9 stamp          3. en        0.00166\n10 strongest      3. en        0.000591\n11 syria          3. en        0.00136\n12 terrorist      3. en        0.00181\n13 tougher        3. en        0.000247\n14 weaken         3. en        0.000181\n15 accelerate     2. en        0.000544\n&gt;#... with 448 more rows\n\n\nLos resultados parecen sugerir algunos de los temas principales de este discurso como “syria” (Siria), “terrorist” (terrorismo) y “qaida” (Qaeda) (al-qaida está dividido en “al” y “qaida” por el tokenizador).\n\nResumen del documento\n\nPara proporcionar información contextual al conjunto de datos que estamos analizando, tenemos una tabla con metadatos sobre cada uno de los discursos del Estado de la Unión. Vamos a cargarla a R:\n\nmetadatos &lt;- read_csv(sprintf(\"%s/%s\", base_url, \"metadata.csv\"))\nmetadatos\n\n\nAparecerán las primeras diez líneas del grupo de datos así:\n\n&gt;#A tibble: 236 x 4\n   president          year party       sotu_type\n   &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;\n 1 George Washington  1790 Nonpartisan speech\n 2 George Washington  1790 Nonpartisan speech\n 3 George Washington  1791 Nonpartisan speech\n 4 George Washington  1792 Nonpartisan speech\n 5 George Washington  1793 Nonpartisan speech\n 6 George Washington  1794 Nonpartisan speech\n 7 George Washington  1795 Nonpartisan speech\n 8 George Washington  1796 Nonpartisan speech\n 9 John Adams         1797 Federalist  speech\n10 John Adams         1798 Federalist  speech\n&gt;#... with 226 more rows\n\n\nTenemos el nombre del presidente, el año, el partido político del presidente y el formato del discurso del Estado de la Unión (oral o escrito) de cada discurso en el conjunto. El discurso de 2016 está en la línea 236 de los metadatos, que casualmente es la última línea.\n\nEn la siguiente sección puede ser útil resumir los datos de un discurso en una única línea de texto. Podemos hacer esto extrayendo las cinco palabras más frecuentes con una frecuencia menor al 0.002% en el Corpus de un trillón de palabras de Google y combinando esto con los datos sobre el presidente y el año.\n\ntabla &lt;- filter(tabla, frequency &lt; 0.002)\nresultado &lt;- c(metadatos$president[236], metadatos$year[236], tabla$word[1:5])\npaste(resultado, collapse = \"; \")\n\n\nEsto debería darnos el siguiente resultado:\n\n[1] \"Barack Obama; 2016; laughter; voices; allies; harder; qaida\"\n[1] \"Barack Obama; 2016; risa; voces; aliados; más duro; qaeda\"\n\n\n¿Capta esta línea todo lo relativo al discurso? Por supuesto que no. El procesamiento de texto nunca va a reemplazar a la lectura atenta de un texto, pero ayuda a dar un resumen de alto nivel de los temas discutidos (la “risa” aparece aquí porque en el texto del discurso están anotadas las reacciones de la audiencia). Este resumen es útil de varias formas. Puede dar un buen título y resumen para un documento que carece de ellos; puede servir para recordar a los lectores que han leído o escuchado el discurso cuáles fueron los temas principales discutidos en él; y recopilar varios resúmenes con una sola acción puede mostrar patrones de gran escala que suelen perderse en corpus amplios. Es este último uso al que recurrimos ahora al aplicar las técnicas de esta sección a un grupo más amplio de discursos del Estado de la Unión.\n\nAnálisis de los discursos del Estado de la Unión desde 1790 a 2016\n\nCargar el corpus\n\nLo primero que hay que hacer para analizar el corpus de discursos sobre el Estado de la Unión es cargarlos todos en R. Esto implica las mismas funciones paste (pegar) y readLines (leer líneas) que antes, pero tenemos que generar un bucle for (para) que ejecuta las funciones en los 236 archivos de texto. Estos se combinan con la función c.\n\narchivos &lt;- sprintf(\"%s/sotu_text/%03d.txt\", base_url, 1:236)\ntexto &lt;- c()\nfor (f in archivos) {\ntexto &lt;- c(texto, paste(readLines(f), collapse = \"\\n\"))\n}\n\n\nEsta técnica carga todos los archivos uno por uno desde Github. Opcionalmente, puedes descargar una archivo zip (comprimido) con el corpus completo y cargar los archivos manualmente. Esta técnica es descrita en la siguiente sección.\n\nForma alternativa de cargar el corpus (opcional)\n\nEl corpus completo puede descargarse aquí: sotu_text.zip. Descomprime el repositorio en algún lugar de tu ordenador y fija la variable input_loc (localización de carga) a la ruta de directorio donde has descomprimido el archivo. Por ejemplo, si los archivos están en el escritorio de un ordenador con el sistema operativo macOS y el usuario es stevejobs, input_loc debería ser:\n\ninput_loc &lt;- \"/Users/stevejobs/Desktop/sotu_text\"\n\n\nUna vez hecho esto, puedes usar el siguiente bloque de código para cargar todos los textos:\n\narchivos &lt;- dir(input_loc, full.names = TRUE)\ntexto &lt;- c()\nfor (f in archivos) {\ntexto &lt;- c(texto, paste(readLines(f), collapse = \"\\n\"))\n}\n\n\nPuedes usar esta misma técnica para cargar tu propio corpus de textos.\n\nAnálisis exploratorio\n\nUna vez más, con la función tokenize_words podemos calcular la longitud de cada discurso en número de palabras.\n\npalabras &lt;- tokenize_words(texto)\nsapply(palabras, length)\n\n\n¿Existe un patrón temporal sobre la longitud de los discursos? ¿Cómo se compara la longitud de los discursos de otros presidentes a los de Franklin D. Roosevelt, Abraham Lincoln y George Washington?\n\nLa mejor forma de saberlo es mediante la creación un gráfico de dispersión. Puedes construir uno usando qplot (gráfico), con el año (year) en el eje-x u horizontal y el número de palabras (length) en el eje-y o vertical.\n\nqplot(metadatos$year, sapply(palabras, length)) + labs(x = \"Año\", y = \"Número de palabras\")\n\n\nEsto crea un gráfico como este:\n\n\n    \n\n    Número de palabras en cada Estado de la Unión dispuestos por año\n\n\n\n\nUtiliza la opción `+ labs(x = \"nombre\", y = \"nombre\")` para añadir un nombre a los ejes de tu gráfico y facilitar así su lectura. [N. de la T.]\n\n\nParece que en su mayor parte los discursos incrementaron su longitud de 1790 a 1850 y después incrementaron de nuevo hacia finales del siglo XIX. La longitud disminuyó drásticamente alrededor de la Primera Guerra Mundial, con unos pocos valores atípicos dispersos a lo largo del siglo XX.\n\n¿Hay algún tipo de razón tras estos cambios? Para explicar esta variación podemos configurar el color de los puntos para denotar si se trata de discursos que fueron presentados de forma escrita o de forma oral. El comando para realizar este gráfico solo conlleva un pequeño cambio en el comando del gráfico:\n\nqplot(metadatos$year, sapply(palabras, length), color = metadatos$sotu_type) + labs(x = \"Año\", y = \"Número de palabras\", color = \"Modalidad del discurso\")\n\n\nEsto proporciona el siguiente gráfico:\n\n\n    \n\n    Número de palabras en cada Estado de la Unión dispuestos por año y con el color denotando si se trató de un discurso escrito u oral\n\n\n\n\nVemos que el incremento en el siglo XIX se dio cuando los discursos pasaron a ser documentos escritos y que la caída drástica se dio cuando Woodrow Wilson (28º presidente de los EEUU de 1913 a 1921) rompió con la tradición y dio su discurso sobre el Estado de la Unión de forma oral en el Congreso. Los valores atípicos que vimos previamente fueron discursos dados de forma escrita después de la Segunda Guerra Mundial.\n\nAnálisis estilométrico\n\nLa estilometría, el estudio lingüístico del estilo, utiliza ampliamente los métodos computacionales para describir el estilo de escritura de un autor. Con nuestro corpus, es posible detectar cambios en el estilo de escritura a lo largo de los siglos XIX y XX. Un estudio estilométrico más formal usualmente implica el uso de código de análisis sintáctico o de reducciones dimensionales algorítmicas complejas como el análisis de componentes principales para el estudio a lo largo del tiempo y en varios autores. En este tutorial nos seguiremos enfocando en el estudio de la longitud de las oraciones.\n\nEl corpus puede dividirse en oraciones usando la función tokenize_sentences. En este caso el resultado es una lista con 236 objetos en ella, cada uno representando un documento específico.\n\noraciones &lt;- tokenize_sentences(texto)\n\n\nLo siguiente es dividir cada oración en palabras. Se puede usar la función tokenize_words pero no directamente sobre las oraciones en la lista de objetos. Podríamos hacer esto con un bucle for nuevo pero hay una forma más sencilla de hacerlo. La función sapply ofrece un acercamiento más directo. Aquí, queremos aplicar la segmentación de palabras individualmente a cada documento y, por tanto, esta función es perfecta.\n\n oraciones_palabras &lt;- sapply(oraciones, tokenize_words)\n\n\nAhora tenemos una lista (con cada elemento representando un documento) de listas (con cada elemento representando las palabras en una oración dada). El resultado que necesitamos es una lista de objetos que dé la longitud de cada oración en un documento dado. Para ello, combinamos el bucle for con la función sapply.\n\nlongitud_oraciones &lt;- list()\nfor (i in 1:nrow(metadatos)) {\nlongitud_oraciones[[i]] &lt;- sapply(oraciones_palabras[[i]], length)\n}\n\n\nEl resultado de longitud_oraciones puede ser visualizado sobre una línea temporal. Primero tenemos que resumir la longitud de todas las oraciones en un documento a un único número. La función median, que encuentra el percentil 50º de los datos ingresados, es una buena opción para resumirlos, puesto que no se verá demasiado afectada por el error de segmentación que haya podido crear una oración artificalmente larga11.\n\nmedia_longitud_oraciones &lt;- sapply(longitud_oraciones, median)\n\n\nAhora creamos un diagrama con esta variable junto con los años de los discursos usando, una vez más, la función qplot.\n\nqplot(metadatos$year, media_longitud_oraciones) + labs(x = \"Año\", y = \"Longitud media de las oraciones\")\n\n\n\n    \n\n    Longitud media de las oraciones por cada discurso del Estado de la Unión\n\n\n\n\nEl gráfico muestra una fuerte evolución a oraciones más cortas a lo largo de los dos siglos de nuestro corpus. Recuerda que algunos discursos hacia el final de la segunda mitad del siglo XX eran discursos escritos largos parecidos a los del siglo XIX. Es particularmente interesante que estos no destacan en cuanto a la media de la longitud de sus oraciones. Esto apunta al menos a una forma en que los discursos del Estado de la Unión han cambiado adaptándose a lo largo del tiempo.\n\nPara ver el patrón de forma más explícita, es posible añadir una línea de tendencia sobre el diagrama con la función geom_smooth (geometrización suave).\n\nqplot(metadatos$year, media_longitud_oraciones) + geom_smooth() + labs(x = \"Año\", y = \"Longitud media de las oraciones\")\n\n\n\n    \n\n    Longitud media de cada discurso del Estado de la Unión con una línea de tendencia\n\n\n\n\nLas líneas de tendencia son un gran añadido a los gráficos. Tienen la doble función de mostrar la corriente general de los datos en el tiempo mientras destaca puntos de datos atípicos o periféricos.\n\nResumen de documento\n\nComo última tarea vamos a aplicar la función de resumen simple que hemos usado en la sección previa a cada uno de los documentos en este corpus más amplio. Necesitamos usar un bucle otra vez, pero el código interior sigue siendo casi el mismo a excepción de que vamos a guardar los resultados como un elemento del vector descripcion.\n\ndescripcion &lt;- c()\n\nfor (i in 1:length(palabras)) {\n  tabla &lt;- table(palabras[[i]])\n  tabla &lt;- data_frame(word = names(tabla), count = as.numeric(tabla))\n  tabla &lt;- arrange(tabla, desc(count))\n  tabla &lt;- inner_join(tabla, palabras_frecuentes)\n  tabla &lt;- filter(tabla, frequency &lt; 0.002)\n  resultado &lt;- c(metadatos$president[i], metadatos$year[i], tabla$word[1:5])\n  descripcion &lt;- c(descripcion, paste(resultado, collapse = \"; \"))\n}\n\n\nMientras se procesa cada archivo como resultado de la función inner_join, verás una línea que dice Joining, by = “word”. Como el bucle puede tardar uno o más minutos en procesar la función, dicha línea sirve para asegurarse de que el código está procesando los archivos. Podemos ver el resultado del bucle escribiendo descripcion en la consola, pero con la función cat obtenemos una vista más clara de los resultados.\n\ncat(descripcion, sep = \"\\n\")\n\n\nLos resultados ofrecen una línea por cada discurso del Estado de la Unión. Aquí, por ejemplo, están las líneas de las presidencias de Bill Clinton, George W. Bush y Barack Obama:\n\n&gt;William J. Clinton; 1993; deficit; propose; incomes; invest; decade\nWilliam J. Clinton; 1994; deficit; renew; ought; brady; cannot\nWilliam J. Clinton; 1995; ought; covenant; deficit; bureaucracy; voted\nWilliam J. Clinton; 1996; bipartisan; gangs; medicare; deficit; harder\nWilliam J. Clinton; 1997; bipartisan; cannot; balanced; nato; immigrants\nWilliam J. Clinton; 1998; bipartisan; deficit; propose; bosnia; millennium\nWilliam J. Clinton; 1999; medicare; propose; surplus; balanced; bipartisan\nWilliam J. Clinton; 2000; propose; laughter; medicare; bipartisan; prosperity\nGeorge W. Bush; 2001; medicare; courage; surplus; josefina; laughter\nGeorge W. Bush; 2002; terrorist; terrorists; allies; camps; homeland\nGeorge W. Bush; 2003; hussein; saddam; inspectors; qaida; terrorists\nGeorge W. Bush; 2004; terrorists; propose; medicare; seniors; killers\nGeorge W. Bush; 2005; terrorists; iraqis; reforms; decades; generations\nGeorge W. Bush; 2006; hopeful; offensive; retreat; terrorists; terrorist\nGeorge W. Bush; 2007; terrorists; qaida; extremists; struggle; baghdad\nGeorge W. Bush; 2008; terrorists; empower; qaida; extremists; deny\nBarack Obama; 2009; deficit; afford; cannot; lending; invest\nBarack Obama; 2010; deficit; laughter; afford; decade; decades\nBarack Obama; 2011; deficit; republicans; democrats; laughter; afghan\nBarack Obama; 2012; afford; deficit; tuition; cannot; doubling\nBarack Obama; 2013; deficit; deserve; stronger; bipartisan; medicare\nBarack Obama; 2014; cory; laughter; decades; diplomacy; invest\nBarack Obama; 2015; laughter; childcare; democrats; rebekah; republicans\nBarack Obama; 2016; laughter; voices; allies; harder; qaida\n\n\nComo ya habíamos señalado, estos resúmenes temáticos no reemplazan de ninguna manera la lectura atenta de cada documento. Sin embargo, sirven como un resumen de nivel general de cada presidencia. Vemos, por ejemplo, el enfoque inicial en el déficit durante los primeros años de la presidencia de Bill Clinton, su cambio hacia el bipartidismo cuando la Cámara y el Senado se inclinaron hacia los Republicanos en la mitad de los 90 y un cambio hacia una reforma en Medicare al final de su presidencia. Los discursos de George W. Bush se central principalmente en terrorismo, con la excepción del discurso de 2001, ofrecido antes de los ataques terroristas del 11 de Septiembre. Barack Obama volvió a preocuparse por la economía bajo la sombra de la recesión de 2008. La palabra “risa” (laughter) aparece con frecuencia porque se añade a las transcripciones cuando la risa de la audiencia hizo que el emisor tuviera que hacer una pausa.\n\nSiguientes pasos\n\nEn este tutorial breve hemos explorado algunas formas básicas para analizar datos textuales con el lenguaje de programación R. Existen varias direcciones que puedes tomar para adentrarte más en las nuevas técnicas del análisis de texto. Estos son tres ejemplos particularmente interesantes:\n\n\n  procesar un flujo completo de anotación de procesamiento de lenguajes naturales (NLP) en un texto para extraer características como nombres de entidades, categorías gramaticales y relaciones de dependencia. Estos están disponibles en varios paquetes de R, incluyendo cleanNLP, y para varios idiomas12.\n  ajustar modelos temáticos (topic models) para detectar discursos particulares en el corpus usando paquetes como mallet13 y topicmodels14.\n  aplicar técnicas de reducción dimensional para crear gráficos de tendencias estilísticas a lo largo del tiempo o entre múltiples autores. Por ejemplo, el paquete tsne15 realiza una forma poderosa de reducción dimensional particularmente apta para gráficos detallados.\n\n\nExisten muchos tutoriales genéricos para estos tres ejemplos, además de documentación detallada de los paquetes16. Esperamos ofrecer tutoriales enfocados en aplicaciones históricas en particular en el futuro.\n\nNotas\n\n\n  \n    \n      Nuestro corpus contiene 236 discursos del Estado de la Unión. Dependiendo de lo que se cuente, este número puede ser ligeramente más alto o más bajo. &#8617;\n    \n    \n      Dewar, Taryn. “Datos tabulares en R”, traducido por Jennifer Isasi, The Programming Historian en español 3 (2018), https://programminghistorian.org/es/lecciones/datos-tabulares-en-r. &#8617;\n    \n    \n      Hadley Wickham. “tidyverse: Easily Install and Load ‘Tidyverse’ Packages”. R Package, Version 1.1.1. https://cran.r-project.org/web/packages/tidyverse/index.html &#8617;\n    \n    \n      Lincoln Mullen and Dmitriy Selivanov. “tokenizers: A Consistent Interface to Tokenize Natural Language Text Convert”. R Package, Version 0.1.4. https://cran.r-project.org/web/packages/tokenizers/index.html &#8617;\n    \n    \n      Ten en cuenta que los nombres de las funciones como library o install.packages siempre estarán en inglés. No obstante, se proporciona una traducción de su significado para facilitar la comprensión y se traducen el nombre de las variables.[N. de la T.] &#8617;\n    \n    \n      Traducción publicada en CNN en español (12 de enero de 2016) http://cnnespanol.cnn.com/2016/01/12/discurso-completo-de-obama-sobre-el-estado-de-la-union/ [N. de la T.] &#8617;\n    \n    \n      Todos los discursos presidenciales del Estado de la Unión fueron descargados de The American Presidency Project at the University of California Santa Barbara (Accedido el 11 de noviembre de 2016) http://www.presidency.ucsb.edu/sou.php &#8617;\n    \n    \n      Aquí volvemos a la versión del discurso en su original (inglés) por motivos de continuación del análisis y, en particular, el listado de las palabras más frecuentes usadas en inglés. Seguimos traduciendo los nombres de las variables y de las funciones para facilitar la comprensión en español.[N. de la T.] &#8617;\n    \n    \n      Aquí optamos por nombrar a las columnas de la tabla en inglés, como “word” (palabra) y “count” (recuento), para facilitar su interoperabilidad con el conjunto de datos que introducimos más adelante con la función inner_join de más adelante. [N. de la T.] &#8617;\n    \n    \n      Peter Norvig. “Google Web Trillion Word Corpus”. (Accedido el 11 de noviembre de 2016) http://norvig.com/ngrams/. &#8617;\n    \n    \n      Esto ocurre en algunos discursos escritos del Estado de la Unión, donde una lista con puntos de enumeración es segmentada como una única oración larga. &#8617;\n    \n    \n      Taylor Arnold. “cleanNLP: A Tidy Data Model for Natural Language Processing”. R Package, Version 0.24. https://cran.r-project.org/web/packages/cleanNLP/index.html &#8617;\n    \n    \n      David Mimno. “mallet: A wrapper around the Java machine learning tool MALLET”. R Package, Version 1.0. https://cran.r-project.org/web/packages/mallet/index.html &#8617;\n    \n    \n      Bettina Grün and Kurt Hornik. “https://cran.r-project.org/web/packages/topicmodels/index.html”. R Package, Version 0.2-4. https://cran.r-project.org/web/packages/topicmodels/index.html &#8617;\n    \n    \n      Ver el artículo t-distributed stochastic neighbor embedding (en inglés) en Wikipedia. https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding [N. de la T.] &#8617;\n    \n    \n      Ver, por ejemplo, el libro de los autores: Taylor Arnold and Lauren Tilton. Humanities Data in R: Exploring Networks, Geospatial Data, Images, and Text. Springer, 2015. &#8617;\n    \n  \n\n\nAprende a utilizar R para analizar patrones a nivel general en textos, para aplicar métodos de estilometría a lo largo del tiempo y entre autores y para aprender metodologías de resumen con las que describir objetos de un corpus.\n\n"
  },


  {
    "id": 35,
    "url": "http://localhost:4000/es/lecciones/reutilizacion-de-codigo-y-modularidad",
    "title": "Reutilización de código y modularidad en Python",
    "body": "\nReutilización de código y modularidad en Python\n\nContenidos\n\n\n  Objetivos de la lección    \n      Funciones\n    \n  \n  Modularidad\n  Lecturas recomendadas:\n\n\nObjetivos de la lección\n\nLos programas de computadora pueden resultar largos, inmanejables y confusos si no contamos con mecanismos especiales para la gestión de su complejidad. Esta lección te mostrará la manera de reutilizar partes de su código mediante la escritura de Funciones y cómo fraccionar tus programas en Módulos con el fin de mantener todo de una manera concisa y fácil de depurar. Ser capaz de extraer un módulo que no resulte útil nos ahorra tiempo y esfuerzo.\n\nFunciones\n\nA menudo encontrarás que deseas volver a utilizar un conjunto particular de enunciados, generalmente porque tiene una tarea que vas a utilizar una y otra vez. Los programas están compuestos, sobre todo, de rutinas que son lo suficientemente potentes y con propósitos generales y que por lo tanto pueden ser reutilizadas. Estas rutinas se conocen como funciones, y Python tiene los mecanismos para permitirte definir nuevas funciones. Vamos a trabajar con un ejemplo muy simple de una función. Supongamos que deseas crear una función general para saludar a la gente. Copia la siguiente definición de función en el editor de Komodo y guárdalo como saludo.py\n\n# saludo.py\n\ndef saludoEntidad (x):\n\tprint(\"Hola \" + x)\n\nsaludoEntidad(\"Todos\")\nsaludoEntidad(\"Programming Historian\")\n\n\nLa línea que comienza con def es la declaración de función. Vamos a definir (“def”) una función que en este caso hemos llamado “saludoEntidad”. La (x) es el parámetro de la función. En un momento entenderás cómo trabaja. La segunda línea contiene el código de la función. Éste puede contener las líneas que necesitemos, pero en este caso es una sola línea.\n\nTen en cuenta que la sangría es muy importante en Python. El espacio en blanco antes de la declaración print le dice al intérprete que es parte de la función que ha sido definida. Aprenderás más acerca de esto a medida que avanzamos; por ahora, asegúrate de mantener la sangría de la manera en que te demostramos. Ejecuta el programa y debes ver algo como esto:\n\nHola Todos\nHola Programming Historian\n\n\nEste ejemplo contiene una función: saludoEntidad. Esta función entonces es llamada (a veces se le denomina invocada) dos veces. Llamar o invocar una función solamente significa que le hemos dicho al programa que ejecute el código en esa función. Como darle al perro su recompensa sabor a pollo (*guau* *guau*). En este caso, cada vez que hemos llamado a la función le hemos dado un parámetro diferente. Intenta editar saludo.py para que invoque a la función saludoEntidad una tercera vez utilizando tu propio nombre como parámetro. Ejecuta el programa de nuevo. Debes ser capaz de imaginarte qué es lo que hace ‘(x)’ en la declaración de la función.\n\nAntes de ir al siguiente paso, edita saludo.py para borrar las llamadas de la función dejando solamente la declaración de la función. Vas a aprender cómo llamar a la función desde otro programa. Cuando termines, tu  archivosaludo.py deberá verse como esto:\n\n# saludo.py\n\ndef saludoEntidad (x):\n\tprint(\"Hola \" + x)\n\n\nModularidad\n\nCuando los programas son pequeños, como en el ejemplo anterior, generalmente se almacenan en un solo archivo. Cuando deseas ejecutar uno de tus programas simplemente puedes enviar el archivo al intérprete. Cuando los programas se hacen más grandes, tiene sentido cortarlos en archivos separados conocidos como módulos. Esta modularidad hace que te sea más fácil trabajar en secciones de tus programas más largos. Al perfeccionar cada sección del programa antes de poner todas las secciones juntas haces más fácil el reutilizar módulos individuales en otros programas y haces más sencillo resolver problemas al ser capaz de precisar la fuente del error. Cuando se corta un programa en módulos también eres capaz de ocultar detalles de cómo se hace algo dentro del módulo que lo hace. Otros módulos no necesitan saber cómo se logra algo si no son responsables de hacerlo. Este principio, necesario de conocer, se llama encapsulamiento.\n\nSupongamos que estamos construyendo un automóvil. Podrías empezar a juntar piezas de cualquier modo, pero tendría más sentido comenzar a construir y probar cada modulo -quizá el motor- antes de pasar a otros. El motor, a su vez, podría idearse a partir de un número de otros pequeños módulos, como el sistema de carburación y de encendido, los cuales se componen de módulos básicos aún más pequeños. Lo mismo aplica cuando escribes código. Trata de separar un problema en partes más pequeñas y resuélvelas primero.\n\nAcabas de crear un módulo cuando escribiste el programa saludo.py. Ahora vas a escribir un segundo programa, usar-saludo.py, que importará el código de tu módulo y hará uso de él. Python tiene una declaración especial de importación (import) que permite a un programa tener acceso al contenido de otro archivo de programa. Esto es lo que estarás utilizando.\n\nCopia este código en el Komodo Edit y guárdalo como usar-saludo.py . Este archivo es tu programa y saludo.py es tu módulo.\n\n# usar-saludo.py\n\nimport saludo\nsaludo.saludoEntidad(\"todos\")\nsaludo.saludoEntidad(\"programming historian\")\n\n\nHemos hecho algunas cosas aquí. Primero, le dijimos a Python que cargara (import ) el módulo saludo.py que creamos previamente.\n\nTambién te darás cuenta que si antes hemos podido ejecutar la función llamándola solo por su nombre saludoEntidad(“todos”), ahora tenemos que incluir el nombre del módulo seguido por un punto (.) antes del nombre de la función. En lenguaje llano esto significa: ejecuta la función saludoEntidad que deberás encontrar en el módulo saludo.py.\n\nPuedes ejecutar tu programa usar-saludo.py con el comando “Ejecutar Python” que creaste en Komodo Edit. Ten en cuenta que no necesitas ejecutar tu módulo… solamente el programa que lo llama. Si todo se hizo bien, deberás ver lo siguiente en el panel de salida de Komodo Edit:\n\nHola todos\nHola programming historian\n\n\nAntes de seguir adelante, asegúrate de entender la diferencia entre cargar un archivo de datos (por ejemplo: hola-mundo.txt) e importar un archivo de programa (por ejemplo: saludo.py ).\n\nLecturas recomendadas:\n\n  Python Basics\n\n\n\nLos programas de computadora pueden resultar largos, inmanejables y confusos si no contamos con mecanismos especiales para la gestión de su complejidad. Esta lección te mostrará la manera de reutilizar partes de su código mediante la escritura de Funciones y cómo fraccionar tus programas en Módulos con el fin de mantener todo de una manera concisa y fácil de depurar.\n\n"
  },


  {
    "id": 36,
    "url": "http://localhost:4000/es/lecciones/salida-de-datos-como-archivo-html",
    "title": "Salida de datos como archivo HTML con Python",
    "body": "\nSalida de datos como archivo HTML con Python\n\nContenidos\n\n\n  Objetivo de la lección\n  Archivos necesarios para esta lección\n  Construcción de un contenedor de HTML\n  Metadatos\n  Formato de cadenas de texto en Python\n  Archivo de datos auto-documentado    \n      Instrucciones para Mac\n      Instrucciones para Windows\n    \n  \n  Ensamblar todo    \n      Leturas sugeridas\n      Sincronización de código\n    \n  \n\n\nObjetivo de la lección\n\nEsta lección toma los pares de frecuencia creados en Contar frecuencias de palabras con Python y crea una salida de datos a un archivo HTML.\n\nAquí aprenderás a crear esta salida de datos como archivo HTML utilizando Python. También aprenderás acerca del formato de cadenas. El resultado final es un archivo HTML que muestra las palabras clave encontradas en la fuente original en orden de frecuencia descendente junto con el número de veces que aparece cada palabra clave.\n\nArchivos necesarios para esta lección\n\n\n  obo.py\n\n\nSi no tienes estos archivos de las lecciones anteriores, puedes descargar python-es-lecciones6, un archivo zip de las lecciones anteriores.\n\nConstrucción de un contenedor de HTML\n\nEn la lección anterior aprendiste cómo etiquetar el mensaje “Hola Mundo” en HTML, escribir el resultado en un archivo y abrirlo automáticamente en el navegador. Un programa que pone códigos de formato alrededor de algo para que pueda ser usado por otro programa es llamado a veces “contenedor” (wrapper). Lo que vamos a hacer ahora es desarrollar un contenedor de HTML para la salida de nuestro código que computa frecuencias de palabras. También añadiremos algunos metadatos dinámicos útiles para complementar los datos de frecuencia recogidos en Contar frecuencias.\n\nMetadatos\n\nLa distinción entre datos y metadatos es crucial en las ciencias de la información. Los metadatos son datos acerca de datos. Este concepto ya te debe ser familiar incluso si no has escuchado antes el término. Considera un libro tradicional. Si tomamos el texto del libro como los datos, hay un número de otras características que están asociadas con el texto pero que pueden o no estar impresas en el libro de manera explícita. El título del libro, el autor, el editor y el lugar y fecha de la publicación son metadatos y generalmente están impresos en el trabajo. El lugar y fecha del escrito, el nombre del corrector de estilo, los datos de catalogación de la Biblioteca del Congreso y el nombre del tipo de fuente utilizado para la composición tipográfica, a veces están impresas en él. La persona que compra una copia particular puede escribir o no su nombre en el libro. Si el libro pertenece a la colección de una biblioteca, esa biblioteca mantendrá metadatos adicionales, pero solamente algunos de ellos estarán unidos físicamente al libro. El registro de los préstamos, por ejemplo, se mantiene generalmente en una especie de base de datos y se vincula al libro con un identificador único. Bibliotecas, archivos y museos tienen complejos sistemas para generar y mantener un registro de metadatos.\n\nCuando trabajas con datos digitales es buena idea incorporar metadatos en tus propios archivos siempre que sea posible. Ahora vamos a desarrollar algunas estrategias básicas para hacer que nuestros archivos de datos sean auto-documentados. En nuestro contenedor queremos incluir información dinámica acerca del archivo, tales como la hora y fecha en el que fue creado así como un título HTML que es relevante para el archivo. En este caso podríamos darle un nombre nosotros mismos, pero cuando empecemos a trabajar con múltiples archivos, crear automáticamente archivos autodocumentados nos ahorrará mucho tiempo, así que lo practicaremos ahora. Y para ello tendremos que aprender algunas opciones más potentes de formato de cadenas de texto.\n\nFormato de cadenas de texto en Python\n\nPython incluye un operador especial para formato que te permite insertar una cadena dentro de otra. Está representado por un signo de porcentaje seguido por una “s”. Abre el shell de Python e intenta los ejemplos siguientes:\n\n\nformula = 'Esta fruta es una %s'\nprint(formula)\n-&gt; Esta fruta es una %s\n\nprint(formula % 'banana')\n-&gt; Esta fruta es una banana\n\nprint(formula % 'pera')\n-&gt; Esta fruta es una pera\n\n\nTambién hay una manera que te permite interpolar una lista de cadenas dentro de otra.\n\nformula2 = 'Éstas son %s, aquellas son %s'\nprint(formula2)\n-&gt; Éstas son %s, aquellas son %s\n\nprint(formula2 % ('bananas', 'peras'))\n-&gt; Éstas son bananas, aquellas son peras\n\n\nEn estos ejemplos, un %s en una cadena indica que otra cadena será incrustada en ese punto. Hay una serie de otros códigos de formato de cadenas, la mayoría de los cuales permiten introducir números en las cadenas con varios formatos como %i para enteros (i.e. 1, 2, 3), %f para punto decimal flotante (por ejemplo: 3.023, 4.59, 1.0) y demás. Al utilizar este método podemos introducir información que es única para ese archivo.\n\nArchivo de datos auto-documentado\n\nVamos a convertir en funciones algo del código que ya hemos escrito. Uno de ellos descargará el contenido de un URL y nos regresará una cadena de texto en minúsculas de la página Web. Copia este código en el módulo obo.py.\n\n# Dado un URL, regresa una cadena de texto en mínusculas de una página.\n\ndef paginaWebATexto(url):\n    import urllib.request, urllib.error, urllib.parse\n    respuesta = urllib.request.urlopen(url)\n    html = respuesta.read()\n    texto = quitarEtiquetas(html).lower()\n    return texto\n\n\nTambién queremos una función que tome una cadena de texto en cualquier orden y la haga el cuerpo de un archivo HTML que se abra automáticamente en Firefox. Esta función debe incluir algunos metadatos básicos, como la hora y la fecha en la que se creó y el nombre del programa que lo creó. Estudia el siguiente código con atención y luego cópialo en el módulo obo.py.\n\nInstrucciones para Mac\n\nSi estás usado una Mac asegúrate de incluir la variable de la ruta de nombre de archivo adecuada en la segunda línea del último párrafo del código para reflejar en dónde estás guardando tus archivos.\n\n# Dado el nombre de un programa de llamada, un url y una cadena a envolver,\n# crea una cadena en body de html con metadatos basicos y abrela en Firefox.\n\ndef envuelveCadenaenHTMLMac(programa, url, body):\n    import datetime\n    from webbrowser import open_new_tab\n\n    ahora = datetime.datetime.today().strftime(\"%Y%m%d-%H%M%S\")\n    nombreArchivo = programa + '.html'\n    f = open(nombreArchivo,'wb')\n\n    wrapper = \"\"\"&lt;html&gt;\n    &lt;head&gt;\n    &lt;title&gt;%s output - %s&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;&lt;p&gt;URL: &lt;a href=\\\"%s\\\"&gt;%s&lt;/a&gt;&lt;/p&gt;&lt;p&gt;%s&lt;/p&gt;&lt;/body&gt;\n    &lt;/html&gt;\"\"\"\n\n    todo = wrapper % (programa, ahora, url, url, body)\n    f.write(todo)\n    f.close()\n\n    #Cambia la ruta de la variable siguiente para que coincida la localizacion en tu directorio\n    nombreArchivo = 'file:///Users/username/Desktop/programming-historian/' + nombreArchivo\n\n    open_new_tab(nombreArchivo)\n\n\nInstrucciones para Windows\n\n# Dado el nombre de un programa de llamada, un url y una cadena a envolver,\n# crea una cadena en body de html con metadatos basicos y abrela en Firefox.\n\ndef envuelveCadenaenHTMLWindows(programa, url, body):\n    import datetime\n    from webbrowser import open_new_tab\n\n    ahora = datetime.datetime.today().strftime(\"%Y%m%d-%H%M%S\")\n\n    nombreArchivo = programa + '.html'\n    f = open(nombreArchivo,'wb')\n\n    wrapper = \"\"\"&lt;html&gt;\n    &lt;head&gt;\n    &lt;title&gt;%s output - %s&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;&lt;p&gt;URL: &lt;a href=\\\"%s\\\"&gt;%s&lt;/a&gt;&lt;/p&gt;&lt;p&gt;%s&lt;/p&gt;&lt;/body&gt;\n    &lt;/html&gt;\"\"\"\n\n    todo = wrapper % (programa, ahora, url, url, body)\n    f.write(todo)\n    f.close()\n\n    open_new_tab(nombreArchivo)\n\n\n***\n\nTen en cuenta que esta función utiliza el operador de formato de cadenas que apenas aprendimos. Si aún tienes problema con esta idea, echa una mirada al archivo HTML que se abrió en la nueva pestaña de tu Firefox y podrás ver cómo funcionó. Si aún estás atascado en esta parte, échale un ojo a:\n\nURL: http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33\n\n\nen el archivo HTML y rastrea cómo el programa sabe poner ahí el valor del URL.\n\nLa función también convoca una biblioteca datetime de Python para determinar la hora y fecha actuales. Como el operador de formato de cadena %s, esta biblioteca utiliza el % como reemplazo de valores. En este caso, %Y %m %d %H %M %S representan año, mes, día, hora, minutos y segundos respectivamente. A diferencia de %s, el programa determinará para ti el valor de estas variables utilizando el reloj de tu computadora. Es importante que entiendas esta diferencia.\n\nEstos metadatos de fecha junto con el nombre del programa que llamó a la función, se guarda en la etiqueta de título del HTML. El archivo HTML que es creado tiene el mismo nombre que el programa de Python que lo creó pero con la extensión .html en vez de .py.\n\nEnsamblar todo\n\nAhora podemos crear otra versión de nuestro programa para computar frecuencias. En vez de enviar su salida de datos a un archivo de texto o a una ventana de salida, envía la salida de datos a un archivo HTML que será abierto en una nueva pestaña de Firefox. De ahí, la salida de datos del programa puede agregarse fácilmente como una entrada bibliográfica a Zotero. Escribe o copia el código siguiente en tu editor de texto, guárdalo como html-a-frec-3.py y ejecútalo para confirmar que trabaja como se espera.\n\nUtiliza lo más apropiado para tu sistema: obo.envuelveCadenaenHTMLMac() u obo.envuelveCadenaenHTMLWindows().\n\n# html-a-frec-3.py\nimport obo\n\n# crea un diccionario ordenado de pares de frecuencia de palabras\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\ntexto = obo.paginaWebATexto(url)\nlistaPalabrasCompleta = obo.quitaNoAlfaNum(texto)\nlistaPalabras = obo.quitarPalabrasvac(listaPalabrasCompleta, obo.palabrasvac)\ndiccionario = obo.listaPalabrasDicFrec(listaPalabras)\ndiccOrdenado = obo.ordenaDicFrec(diccionario)\n\n# compila el diccionario en una cadena y envuelve con HTML\nsalidaCadena = \"\"\nfor s in diccOrdenado:\n    salidaCadena += str(s)\n    salidaCadena += \"&lt;br /&gt;\"\nobo.envuelveCadenaenHTMLMac(\"html-a-frec-3\", url, salidaCadena)\n\n\nObserva que intercalamos nuestros pares de frecuencia de palabras con la etiqueta de salto &lt;br\\&gt; de HTML, la cual actúa como una nueva línea. Si todo va bien, deberías ver las mismas frecuencias de palabras que computamos en la última sección pero esta vez en la ventana de tu navegador.\n\nLeturas sugeridas\n\n\n  Lutz, Learning Python\n    \n      Re-read and review Chs. 1-17\n    \n  \n\n\nSincronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto. Si estás trabajando con la versión Mac o Linux de las lecciones deberás abrir el archivo obo.py y cambiar “file:///Users/username/Desktop/programming-historian/” a la ruta del directorio de tu propia computadora.\n\n\n  python-es-lecciones7.zip zip sync\n\n\n\nEsta lección toma los pares de frecuencia creados en ‘Contar frecuencias de palabras con Python’ y crea una salida de datos a un archivo HTML.\n\n"
  },


  {
    "id": 37,
    "url": "http://localhost:4000/es/lecciones/salida-palabras-clave-contexto-ngrams",
    "title": "Salida de palabras clave en contexto en un archivo HTML con Python",
    "body": "\nSalida de palabras clave en contexto en un archivo HTML con Python\n\nContenidos\n\n\n  Objetivo de la lección\n  Archivos necesarios para esta lección\n  Crear un diccionario de n-gramas\n  Salida de datos a HTML    \n      Pretty Printing de una KWIC\n    \n  \n  Ensamblando todo\n  Sincronía de código\n\n\nObjetivo de la lección\n\nEsta lección se basa en Palabras clave en contexto (usando n-grams), en la que se extrajeron n-gramas de un texto. Aquí aprenderás cómo generar una salidad de todos los n-gramas de una palabra clave dada en un documento descargado de Internet, y visualizarlos claramente en la ventana de tu navegador.\n\nArchivos necesarios para esta lección\n\n\n  obo.py\n\n\nSi no tienes estos archivos de las lecciones anteriores, puedes descargar un archivo zip de las lecciones anteriores.\n\nCrear un diccionario de n-gramas\n\nNuestros n-gramas tienen un número impar de palabras por una razón. En este punto, los n-gramas no contienen en realidad una palabra clave; son solamente una lista de palabras. Sin  embargo, si tenemos un n-grama impar, la palabra central siempre tendrá el mismo número de palabras a la izquierda y a la derecha. Entonces, podemos utilizar esa palabra del medio como nuestra palabra clave. Por ejemplo, [“it”, “was”, “the”, “best”, “of”, “times”, “it”] es un 7-grama de la palabra clave “best”.\n\nYa que tenemos un texto largo, quisieramos ser capaces de generar una salida para todos los n-gramas de nuestra palabra clave. Para ello, vamos a poner cada n-grama en un diccionario utilizando la palabra de en medio como clave. Para averiguar la palabra clave de cada n-grama podemos utilizar la posición de índice de la lista. Si estamos trabajando con 5-gramas, por ejemplo, el contexto izquierdo consistirá en términos indexados en 0, 1; la palabra clave en 2 y los términos del contexto derecho en 3, 4. Dado que los índices en Python comienzan en 0, la palabra clave de un 5-grama siempre estará en la posición de índice 2.\n\nEso está bien para 5-gramas; pero para hacer el código un poco más robusto queremos asegurarnos de que funcionará para cualquier longitud de n-gramas, asumiendo que su longitud será un número impar. Para ello, vamos a tomar la longitud del n-grama, dividirla entre 2 y dejar aparte el resto. Podemos lograrlo usando un operador de división de piso representado por dos barras, que divide y da como resultado el número entero más cercano, siempre redondeando hacia abajo -de ahí el término piso.\n\nprint(7 // 2)\nprint(5 // 2)\nprint(3 // 2)\n\n\nConstruyamos una función que pueda identificar la posición de índice de la palabra clave cuando se le de un n-grama con un número impar de palabras. Guarda lo siguiente en obo.py\n\n# Dada una lista de n-gramas identifica el índice de la palabra clave.\n\ndef nGramasAdicKWIC(ngramas):\n    indicePClave = len(ngramas[0]) // 2\n\n    return indicePClave\n\n\nPara determinar el índice de la palabra clave hemos utilizado la propiedad len para decirnos cuántos elementos hay en el primer n-grama, a continuación hacemos una división de piso para aislar la posición de índice media. Puedes ver si esto funciona mediante la creación de un nuevo programa obten-palabraClave.py y ejecutarlo. Si todo va bien y ya que estamos tratando con un 5-grama, debes obtener 2 como la posición de índice de la palabra clave tal y como se determinó anteriormente.\n\n#obten-palabraClave.py\n\nimport obo\n\nprueba = 'en la frase de prueba hay ocho palabras'\nngramas = obo.obtenNGramas(prueba.split(), 5)\n\nprint(obo.nGramasAdicKWIC(ngramas))\n\n\nAhora que sabemos la ubicación de las palabras clave, vamos a añadir todo en un diccionario que pueda utilizarse para generar la salida de todos los n-gramas KWIC para una palabra clave determinada. Estudia este código y luego remplaza tu nGramasAdicKWIC con lo que sigue en tu módulo obo.py.\n\n# Dada una lista de n-gramas, regresa un diccionario de KWICs,\n# indexado por palabras clave.\n\ndef nGramasAdicKWIC(ngramas):\n    indicePClave = len(ngramas[0]) // 2\n\n    kwicdicc = {}\n\n    for k in ngramas:\n        if k[indicePClave] not in kwicdicc:\n            kwicdicc[k[indicePClave]] = [k]\n        else:\n            kwicdicc[k[indicePClave]].append(k)\n    return kwicdicc\n\n\nUn bucle fory una declaración if comprueban cada n-grama para ver si su palabra clave está ya almacenada en el diccionario. Si no es así, se añade una nueva entrada. Si lo es, añade a una entrada anterior. Ahora tenemos un diccionario llamado kwicdicc que contiene todos los n-gramas, clasificables por palabra clave y podemos regresar a la tarea de dar salida a la información en un formato más útil como lo hicimos en Salida de datos como archivo HTML.\n\nPrueba volver a ejecutar el programa obten-palabraClave.py y ahora podrás ver qué es lo que hay en tu diccionario KWIC.\n\nSalida de datos a HTML\n\nPretty Printing de una KWIC\n\n“Pretty Printing” es un proceso de formateo de salida que puede ser leído fácilmente por seres humanos. En el caso de nuestras palabras clave en contexto, las queremos tener alineadas en una columna con los términos del contexto de la izquierda alineados a la derecha y los términos del contexto de la derecha alineados a la izquierda. En otras palabras, queremos que la visualización de nuestro KWIC se vea parecido a esto:\n\n               amongst them a black there was one\n                first saw the black i turned to\n             had observed the black in the mob\n                 say who that black was no seeing\n                      i saw a black at first but\n                 swear to any black yes there is\n                   swear to a black than to a\n                              ... \n\n\nEsta técnica no es la mejor manera de formatear texto desde la perspectiva de un diseñador de páginas Web. Si tienes experiencia con HTML te animamos a que utilices otro método que permita crear un archivo HTML compatible con los estándares, pero para los nuevos estudiantes, simplemente no podemos resistirnos a la facilidad de la técnica que vamos a describir. Después de todo, el objetivo es integrar los principios de programación rápidamente en nuestra investigación.\n\nPara conseguir este efecto, vamos a tener que hacer un número de manipulaciones de listas y cadenas. Empecemos por averiguar cómo se ve nuestro diccionario de salida en su estado actual. Entonces podremos trabajar en perfeccionarlo para lo que queremos.\n\n# html-a-pretty-print.py\nimport obo\n\n# crea un diccionario de n-gramas\nn = 7\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\ntexto = obo.paginaWebATexto(url)\nlistaPalabrasCompleta = obo.quitaNoAlfaNum(texto)\nngramas = obo.obtenNGramas(listaPalabrasCompleta, n)\ndiccionarioPalabras = obo.nGramasAdicKWIC(ngramas)\n\nprint(diccionarioPalabras[\"black\"])\n\n\nComo puedes observar al ejecutar el programa anterior, la salida de datos aún no es muy legible. Lo que tenemos que hacer es dividir el n-grama en tres partes: antes de la palabra clave, la palabra clave y después de la palabra clave. Podemos utilizar las técnicas aprendidas en los capítulos anteriores para encerrar todo en HTML para que sea fácil de leer.\n\nUtilizando el mismo método anterior de slice, vamos a crear nuestras tres partes. Abre un intérprete de Python para ensayar los siguiente ejemplos. Pon especial atención a lo que aparece antes y después de los dos puntos en cada caso. Saber cómo manipular el método de slice es una poderosa habilidad para un nuevo historiador programador.\n\n# ParseError: Could not check this chunk!\n# calcula la longitud del n-grama\nkwic = 'amongst them a black there was one'.split()\nn = len(kwic)\nprint(n)\n-&gt; 7\n\n# calcula la posición de índice de la palabra clave\nindicePClave = n // 2\nprint(indicePClave)\n-&gt; 3\n\n# muestra los elementos antes de la palabra clave\nprint(kwic[:indicePClave])\n-&gt; ['amongst', 'them', 'a']\n\n# muestra solo la palabra clave\nprint(kwic[indicePClave])\n-&gt; black\n\n# muestra los elementos después de la palabra clave\nprint(kwic[(indicePClave+1):])\n-&gt; ['there', 'was', 'one']\n\n\nAhora que sabemos cómo encontrar cada uno de los tres segmentos, necesitamos dar formato a cada uno en cada una de las columnas de nuestra pantalla.\n\nEl contexto de la derecha consistirá simplemente en una cadena de términos separados por espacios en blanco. Utilizaremos el método join para convertir las entradas de la lista en una cadena.\n\n\nprint(' '.join(kwic[(indicePClave+1):]))\n-&gt; there was one\n\n\nQueremos que las palabras clave tengan un poco de espacio blanco de relleno a su alrededor. Podemos lograr esto mediante el uso de un método de cadena llamado center que servirá para adaptar el texto a la mitad de la pantalla. Podemos agregar relleno al hacer la longitud de la cadena más larga que la palabra clave. La expresión que sige añade tres espacios en blanco (6/2) a cada lado de la palabra clave. Hemos añadido marcas de almohadilla al principio y al final de la expresión para que puedas ver los espacios en blanco inciales y finales.\n\nprint('#' + str(kwic[indicePClave]).center(len(kwic[indicePClave])+6) + '#')\n-&gt; #   black   #\n\n\nPor último, queremos que el contexto de la izquierda esté alineado a la derecha. Dependiendo de qué tan grande sea n, vamos a necesitar incrementar la longitud total de esta columna. Haremos esto mediante la definición de una variable llamada width (ancho) y luego hacer que la longitud de la columna sea un múltiplo de esa variable (se utilizó un ancho de 10 caracteres, pero se puede hacer más grande o más pequeña según se desee). El método rjust se encarga de alinear a la derecha. Una vez más, hemos añadido marcas de almohadilla para que puedas ver los espacios en blanco.\n\nwidth = 10\nprint('#' + ' '.join(kwic[:indicePClave]).rjust(width*indicePClave) + '#')\n-&gt; #                 amongst them a#\n\n\nAhora podemos combinar esto en una función que tome una KWIC y nos regrese una cadena “pretty-printed”. Añade esto al módulo obo.py. Estudia el código para asegurarte que lo entiendes antes de seguir adelante.\n\n# Dada una KWIC, regresa una cadena que esté formateada para\n# pretty printing.\n\ndef prettyPrintKWIC(kwic):\n    n = len(kwic)\n    indicePClave = n // 2\n    width = 10\n\n    salidaCadena = ' '.join(kwic[:indicePClave]).rjust(width*indicePClave)\n    salidaCadena += str(kwic[indicePClave]).center(len(kwic[indicePClave])+6)\n    salidaCadena += ' '.join(kwic[(indicePClave+1):])\n\n    return salidaCadena\n\n\nEnsamblando todo\n\nAhora podemos crear un programa que, dado un URL y una palabra clave, envuelve en HTML la visualización de una KWIC y genera su salida en Firefox. Este programa empieza y termina de una manera similar como el programa que calcula la frecuencia de palabras. Escribe o copia el código en tu editor de texto, guárdalo como html-a-kwic.py y ejecútalo. Deberás elegir entre obo.envuelveCadenaenHTMLMac() u obo.envuelveCadenaenHTMLWindows() según corresponda a tu sistema, como hicimos antes.\n\n# html-a-kwic.py\n\nimport obo\n\n# crea un diccionario de n-gramas\nn = 7\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\ntexto = obo.paginaWebATexto(url)\nlistaPalabrasCompleta = ('# ' * (n//2)).split()\nlistaPalabrasCompleta = obo.quitaNoAlfaNum(texto)\nlistaPalabrasCompleta += ('# ' * (n//2)).split()\nngramas = obo.obtenNGramas(listaPalabrasCompleta, n)\ndiccionarioPalabras = obo.nGramasAdicKWIC(ngramas)\n\n# genera salida de KWIC y envuelve con html\nobjetivo = 'black'\noutstr = '&lt;pre&gt;'\nif objetivo in diccionarioPalabras:\n    for k in diccionarioPalabras[objetivo]:\n        outstr += obo.prettyPrintKWIC(k)\n        outstr += '&lt;br /&gt;'\nelse:\n    outstr += 'Keyword not found in source'\n\noutstr += '&lt;/pre&gt;'\nobo.envuelveCadenaenHTML('html-a-kwic', url, outstr)\n\n\nLa primera parte del programa es igual que en el caso anterior. En la segunda parte del programa hemos encerrado todo en una etiqueta HTML pre (pre-formateada), lo cual le indica al navegador que no se confunda con los espacios que hemos agregado.\n\nAdemás, observa que hemos utilizado el método has_key en el diccionario para asegurarnos que la palabra clave realmente se encuentra en nuestro texto. Si no es así, podemos imprimir un mensaje para el usuario antes de enviar la salida a Firefox. Prueba cambiar la variable objetivo a algunas otras palabras clave. Intenta con alguna que tú sepas que no se encuentra en el texto para asegurarte que tu programa no genere salida de datos cuando no deba.\n\nAhora hemos creado un programa que busca una palabra clave en un diccionario creado a partir de una página HTML de la Web, y luego produce una salida de datos con n-gramas de esa palabra clave en otro archivo HTML para visualizar en la Web. Todas las lecciones hasta este punto han incluido partes del vocabulario de Python y métodos necesarios para crear este programa final. Al referirte a esas lecciones, ahora puedes experimentar con Python para crear programas que realicen tareas específicas que te ayudarán en tu proceso de investigación.\n\nSincronía de código\n\nEsta lección marca el final de la serie de lecciones originales sobre Python. El código terminado de la serie puede descargarse como un archivo zip. Si las estás siguiendo con Mac o Linux deberás abrir el archivo obo.py y cambiar “file:///Users/username/Desktop/programming-historian/” a la ruta del archivo en el directorio de tu propia computadora.\n\n\n  python-es-lecciones9.zip zip sync\n\n\nNota: Ahora puedes ir a la siguiente lección (en inglés) para aprender a Descargar registros múltiples\n\n\nEsta lección se basa en ‘Palabras clave en contexto (usando n-grams)’, en la que se extrajeron n-gramas de un texto. Aquí aprenderás cómo generar una salidad de todos los n-gramas de una palabra clave dada en un documento descargado de Internet, y visualizarlos claramente en la ventana de tu navegador.\n\n"
  },


  {
    "id": 38,
    "url": "http://localhost:4000/es/lecciones/retirada/sparql-datos-abiertos-enlazados",
    "title": "Uso de SPARQL para acceder a datos abiertos enlazados\n",
    "body": "\nUso de SPARQL para acceder a datos abiertos enlazados\n\nObjetivos de la lección\n\nEsta lección explica por qué numerosas instituciones culturales están adoptando bases de datos orientadas a grafos (graph databases) y cómo los investigadores pueden acceder a estos datos a través de consultas realizadas en el lenguaje llamado SPARQL.\n\n{% include toc.html %}\n\nBases de datos orientadas a grafo, RDF y datos abiertos enlazados (Linked Open Data, LOD)\n\nActualmente, numerosas instituciones culturales están  ofreciendo información sobre sus colecciones a través de las denominadas API (Application Programming Interfaces). Estas API son instrumentos muy eficaces para acceder de manera automatizada a registros individuales, sin embargo, no constituyen el procedimiento ideal cuando tratamos con datos culturales debido a que las API están estructuradas para trabajar con un conjunto predeterminado de consultas (queries). Por ejemplo, un museo puede tener información sobre donantes, artistas, obras de arte, exposiciones, procedencia de sus obras (provenance), etc., pero su API puede ofrecer solo una recuperación orientada a objetos, haciendo difícil o imposible buscar datos relacionados con donantes, artistas, etc. Así pues, esta estructura es interesante si el objetivo es buscar información sobre objetos particulares; sin embargo, puede complicar la operación de agregar información sobre los artistas o donantes que también se encuentran registrados en la base de datos.\n\nLas bases de datos RDF son muy apropiadas para expresar relaciones complejas entre múltiples entidades, como personas, lugares, eventos y conceptos ligados a objetos individuales. Estas bases de datos se denominan habitualmente bases de datos orientadas a grafos (graph databases) porque estructuran la información como un grafo o red, donde un conjunto de recursos o nodos están conectados entre sí mediante aristas (o enlaces) que describen las relaciones establecidas entre dichos recursos y/o nodos.\n\nDado que las bases de datos RDF admiten el uso de URL, estas pueden estar accesibles online y también pueden enlazarse a otras bases de datos, de ahí el término “datos abiertos enlazados” (Linked Open Data, LOD). Importantes colecciones artísticas, entre las que se incluyen las del British Museum, Europeana, el Smithsonian American Art Museum y el Yale Center for British Art, han publicado sus colecciones de datos como LOD. El Getty Vocabulary Program también ha publicado sus vocabularios controlados (TGN, ULAN y AAT) como LOD.\n\nSPARQL es el lenguaje utilizado para interrogar este tipo de bases de datos. Este lenguaje es particularmente potente porque obvia las perspectivas que los usuarios transfieren a los datos. Una consulta sobre objetos y una consulta sobre donantes son prácticamente equivalentes en estas bases de datos. Lamentablemente, numerosos tutoriales sobre SPARQL utilizan modelos de datos tan extremadamente simplificados que no son operativos cuando se trata de utilizar las complejas bases de datos desarrolladas por las instituciones culturales. Este tutorial ofrece un curso intensivo sobre SPARQL utilizando un conjunto de datos (dataset) que un humanista podría realmente encontrar en Internet. En concreto, en este tutorial aprenderemos cómo interrogar la colección LOD del British Museum.\n\nRDF en pocas palabras\n\nRDF representa la información en una declaración triple -también llamada tripleta- que sigue la estructura sujeto-predicado-objeto. Por ejemplo:\n\n&lt;La ronda de noche&gt; &lt;fue creada por&gt; &lt;Rembrandt van Rijn&gt; .\n\n\n\n(Observa que, como toda buena oración, estas declaraciones terminan con un punto y final).\n\nEn este ejemplo, el sujeto &lt;La ronda de noche&gt; y el objeto &lt;Rembrandt van Rijn&gt; pueden ser considerados como dos nodos de un grafo, donde el predicado &lt;fue creada por&gt; define la arista -o relación- entre ellos. (Técnicamente,  puede ser tratado en otras consultas como un objeto o un sujeto, pero esta cuestión escapa el alcance de este tutorial).\n\nUna seudobase de datos RDF podría contener declaraciones interrelacionadas entre sí, como las siguientes:\n\n...\n&lt;La ronda de noche&gt; &lt;fue creada por&gt; &lt;Rembrandt van Rijn&gt;.\n&lt;La ronda de noche&gt; &lt;fue creada en&gt; &lt;1642&gt;.\n&lt;La ronda de noche&gt; &lt;utiliza la técnica de&gt; &lt;óleo sobre lienzo&gt;.\n&lt;Rembrandt van Rijn&gt; &lt;nació en&gt; &lt;1606&gt;.\n&lt;Rembrandt van Rijn&gt; &lt;es de nacionalidad&gt; &lt;holandesa&gt;.\n&lt;Johannes Vermeer&gt; &lt;es de nacionalidad&gt; &lt;holandesa&gt;.\n&lt;La tasadora de perlas&gt; &lt;fue creada por&gt; &lt;Johannes Vermeer&gt;.\n&lt;La tasadora de peras&gt; &lt;utiliza la técnica de&gt; &lt;óleo sobre lienzo&gt;.\n...\n\n\nSi visualizásemos estas declaraciones como nodos y aristas de un grafo o red, la representación sería como sigue:\n\n{% include figure.html caption=”Visualización en red del seudoRDF mostrado más arriba. Las flechas indican la ‘dirección’ del predicado. Por ejemplo, que ‘La tasadora de perlas fue creada por Vermeer’ y no al revés. Diagrama reconstruido por Nuria Rodríguez Ortega.” filename=”sparql-lod-01.png” %}\n\nLas tradicionales bases de datos relacionales pueden distribuir atributos sobre obras de arte y artistas en tablas separadas. En las bases de datos RDF u orientadas a grafos, todos estos datos pertenencen a un mismo mismo grafo interconectado, lo que permite a los usuarios una mayor flexibilidad a la hora de decidir cómo quieren interrogar estos recursos.\n\nBuscando RDF con SPARQL\n\nSPARQL nos permite traducir datos en grafo, intensamente enlazados, en datos normalizados en formato tabular, esto es,  distribuidos en filas y columnas, que se pueden abrir en programas como Excel o importar a programas de visualización, tales como plot.ly o Palladio.\n\nResulta útil pensar las consultas SPARQL como un Mad Lib -un conjunto de oraciones con espacios en blanco-. La base de datos tomará esta consulta y encontrará cada conjunto de oraciones que encaje correctamente en estos espacios en blanco, devolviéndonos los valores coincidentes como una tabla. Veamos esta consulta SPARQL:\n\nSELECT ?pintura\nWHERE {\n\t?pintura &lt;utiliza la técnica de&gt; &lt;óleo sobre lienzo&gt; .\n}\n\n\nEn este consulta, ?pintura representa el nodo (o nodos) que la bases de datos nos devolverá. Una vez recibida la consulta, la base de datos buscará todos los valores para ?pintura que adecuadamente complete la declaración RDF &lt;utiliza la técnica de&gt; &lt;óleo sobre lienzo&gt;.\n\n{% include figure.html caption=”Visualización de lo que nuestra consulta está buscando. Diagrama reconstruido por Nuria Rodríguez Ortega.” filename=”sparql-lod-02.png” %}\n\nCuando la consulta interroga la base de datos completa, esta busca los sujetos, predicados y objetos que coinciden con esta declaración, exluyendo, al mismo tiempo, el resto de datos.\n\n{% include figure.html filename=”sparql-lod-03.png” caption=”Visualización de la consulta SPARQL con los elementos mencionados en naranja y los elementos seleccionados (aquellos que nos serán devueltos en los resultados) en rojo. Diagrama reconstruido por Nuria Rodríguez Ortega.” %}\n\nNuestros resultados podrían tener este aspecto:\n\n\n  \n    \n      pinturas\n    \n  \n  \n    \n      La ronda de noche\n    \n    \n      La tasadora de perlas\n    \n  \n\n\nAhora bien, lo que hace a RDF y a SPARQL herramientas tan potentes es su habilidad para crear consultas complejas que referencian múltiples variables al mismo tiempo. Por ejemplo, podríamos buscar en nuestra seudobase de datos RDF pinturas creadas por cualquier artista que fuese holandés:\n\nSELECT ?artista ?pintura\nWHERE {\n\t?artista &lt;es de nacionalidad&gt; &lt;holandesa&gt; .\n\t?pintura &lt;fue creada por&gt; ?artista .\n\t}\n\n\nEn este ejemplo, hemos introducido una segunda variable: ?artista. La base de datos RDF devolverá todas las combinaciones conincidentes de ?artista y ?pintura que encajen en ambas declaraciones.\n\n{% include figure.html filename=”sparql-lod-04.png” caption=”Visualización de la consulta SPARQL con los elementos mencionados en naranja y los elementos seleccionados (aquellos que serán recuperados en los resultados en rojo). Diagrama reconstruido por Nuria Rodríguez Ortega.” %}\n\n\n  \n    \n      artistas\n      pinturas\n    \n  \n  \n    \n      Rembrandt van Rijn\n      La ronda de noche\n    \n    \n      Johannes Vermeer\n      La tasadora de perlas\n    \n  \n\n\nURI y literales\n\nHasta ahora, hemos visto una representación facticia de RDF que utiliza un texto fácil de leer. Sin embargo, RDF se almacena principalmente en formato URI (Uniform Resource Identifiers), que separa las entidades conceptuales de sus etiquetas lingüísticas. (Ten en cuenta que una URL, o Uniform Resource Locator, es una URI accesible desde la web). En RDF real, nuestra declaración original:\n\n&lt;La ronda de noche&gt; &lt;fue creada por&gt; &lt;Rembrandt van  Rijn&gt;.\n\n\nsería más parecido a lo siguiente:\n\n&lt;http://data.rijksmuseum.nl/item/8909812347&gt; &lt;http://purl.org/dc/terms/creator&gt; &lt;http://dbpedia.org/resource/Rembrandt&gt; .\n\n\nN.B. el Rijksmuseum todavía no ha desarrollado su propio sitio LOD, por lo que en esta consulta la URI responde únicamente a objetivos de demostración.\n\nA fin de obtener una versión legible desde el punto de vista humano de la información representada por cada una de estas URI, lo que hacemos realmente es recuperar más declaraciones RDF. Incluso el predicado en esta declaración tiene su propia etiqueta literal:\n\n&lt;http://data.rijksmuseum.nl/item/8909812347&gt; &lt;http://purl.org/dc/terms/title&gt; \"La ronda de noche\".\n&lt;http://purl.dc.terms/creator&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#label&gt; \"fue creado por\".\n&lt;http://dbpedia.org/resource/Rembrandt&gt; &lt;http://xmlns.com/foaf/0.1/name&gt; \"Rembrandt van Rijn\".\n\n\nComo se puede observar, a diferencia de las URI que en esta consulta están enmarcadas por los signos &lt;&gt;, los objetos son cadenas de texto entrecomilladas. Esto es lo que se conoce como literales (literals). Los literales representan valores, mientras que las URI representan referencias. Por ejemplo, &lt;http://dbpedia.org/resources/Rembrandt&gt; representa una entidad que puede referenciar (y puede ser referenciada por) muchas otras declaraciones (fechas de nacimiento, discípulos, miembros de la familia, etc.), mientras que la cadena de texto \"Rembrandt van Rijn\" solo se representa a sí misma. Otros valores literales en RDF incluyen fechas y números.\n\nFijémenos ahora en los predicados de estas declaraciones, con nombres de dominio como purl.org, w3.org y xmlns.com. Estos son algunos de los numerosos proveedores de ontologías que ayudan a estandarizar el modo en que describimos relaciones entre bits de información como, “título”, “etiqueta”, “creador” o “nombre”. Cuanto más trabajemos con RDF/LOD, más proveedores de este tipo encontraremos.\n\nLas URI pueden llegar a ser difíciles de manejar cuando se componen consultas SPARQL. Para simplificar este proceso se utilizan los prefijos (prefixes). Los prefijos son atajos que nos liberan de tener que escribir toda la larga cadena de  caracteres que constituye una URI. Por ejemplo, recordemos el predicado para recuperar el título de La ronda de noche, http://purl.org/dc/terms/title&gt;. Con los siguientes prefijos, solo necesitamos escribir dct:title cuando queramos utilizar un predicado purl.org. dct: representa la cadena completa http://purl.org.dc/terms, y 'title' simplemente se agrega al final de este enlace.\n\nPor ejemplo, con el prefijo PREFIX rkm: que representa la cadena completa &lt;http//data.rijksmuseum.nl&gt;, agregado al inicio de nuestra consulta SPARQL, http://data.rijksmuseum.nl/item/8909812347 &lt; se convierte en rkm:item/8909812347.\n\nDebemos ser conscientes de que los prefijos se pueden asignar arbitrariamente a cualquier abreviatura que queramos; así, diferentes puntos de entrada (endpoints) pueden utilizar prefijos ligeramente diferentes para el mismo espacio de nombre (namespace) (por ejemplo: dct vs. dcterms para &lt;http://purl.org/dc/terms&gt;).\n\nTérminos para revisar\n\n\n  SPARQL - Protocol and RDF Query Language - El lenguaje utilizado para interrogar bases de datos RDF u orientadas a grafos.\n  RDF - Resource Description Framework - Un método para estructurar datos en forma de grafo o como una red de declaraciones conectadas más que como una serie de tablas.\n  LOD - Linked Open Data (datos abiertos enlazados) - LOD son datos RDF publicados online en formato URI de modo que los desarrolladores pueden referenciarlos de manera fiable y sin ambigüedad.\n  declaración - a veces denominada “tripleta”, una declaración RDF es una unidad de conocimiento que comprende sujeto, predicado y objeto.\n  URI - Uniform Resource Identifier - una cadena de caracteres que identifica un recurso. Las declaraciones RDF utilizan URI para enlazar varios recursos. Una URL, o Uniform Resource Locator, es un tipo de URI que apunta a un determinado recurso en la web.\n  literal - En las declaraciones RDF, algunos objetos no referencian recursos con una URI sino que vehiculan un valor, que puede ser un texto (\"Rembrandt van Rijn\"), un número (5) o una fecha (1606-06-15). Estos objetos se conocen como literales.\n  prefijo - A fin de simplificar las consultas SPARQL, un usuario puede especificar prefijos que funcionan como abreviaturas de las URI completas. Estas abreviaturas, o QNAmes, se utilizan también en los espacios de nombre (namespaces) de los documentos XML.\n\n\nConsultas basadas en casos reales\n\nTodas las declaraciones para un objeto\n\nVamos a empezar nuestra primera consulta utilizando el punto de entrada SPARQL del British Museum. Un punto de entrada SPARQL es una dirección web que acepta consultas SPARQL y devuelve resultados. El punto de entrada del British Museum funciona como muchos otros: cuando accedemos a él a través de un navegador web, encontramos una caja de texto para componer las consultas.\n\n{% include figure.html filename=”sparql-lod-05.png” caption=”Web del punto de entrada SPARQL del British Museum. Para todas las consultas de este tutorial, hay que asegurarse de haber dejado las casillas ‘Include inferred’ y ‘Expand results over equivalent URIs’ sin marcar.” %}\n\nCuando empezamos a explorar una nueva base de datos RDF, resulta últil examinar, a modo de ejemplo, las relaciones que emanan de un objeto en concreto.\n\n(Para cada una de las siguientes consultas, clica en el enlace “Run query” situado más abajo para ver los resultados. La puedes ejecutar tal y como está o modificarla antes. En este último caso, recuerda que es necesario dejar sin marcar la casilla “Include inferred” antes de ejecutar la consulta).\n\nSELECT ?p ?o\nWHERE {\n\t&lt;http://collection.britishmuseum.org/id/object/PPA82633&gt; ?p ?o .\n}\n\n\nRun query\n\nCon la orden SELECT ?p ?o, le estamos diciendo a la base de datos que nos devuelva los valores de ?p y ?o descritos en el comando WHERE {}. Esta consulta devuelve cada declaración para la cual nuestra obra de arte seleccionada, &lt;http://collection.britishmuseum.org/id/object/PPA82633&gt;, es el sujeto. ?p ocupa la posición central en la declaración RDF en el comando WHERE {}, por lo que esta devuelve cualquier predicado que coincide con la declaración, mientras que ?o, en la posición final, devuelve todos los objetos. Aunque yo las he nombrado como ?p y ?o, en realidad, tal y como se puede ver en el ejemplo inferior, es posible nombrar estas variables del modo que nosotros queramos. De hecho, será útil darles nombres significativos para las  consultas complejas que siguen a continuación.\n\n{% include figure.html filename=”sparql-lod-06.png” caption=”Listado inicial de todos los predicados y objetos asociados con una obra de arte en el British Museum.” %}\n\nEl punto de entrada del Britism Museum formatea la tabla de resultados con enlaces para cada una de las variables, que son, en realidad, nodos RDF, por lo que clicando en cada uno de estos enlaces podemos ver todos los predicados y objetos para cada uno de los nodos seleccionados. Advierte que el British Musuem incluye automáticamente un amplio rango de prefijos SPARQL en sus consultas, por lo que encontraremos numerosos enlaces mostrados en su versión abreviada; si pasamos el ratón sobre ellos, podremos ver las URI sin abreviar.\n\n{% include figure.html filename=”sparql-lod-07.png” caption=”Visualización del conjunto de nodos recuperados a través de la primera consulta realizada a la base de datos del British Museum. Los elementos de este grafo coloreados en rojo se encuentran también en la tabla de resultados mostrada más arriba. Se han incluido niveles adicionales en la jerarquía para mostrar cómo esta obra en particular se encuentra conectada en el grafo general que constituye la base de datos del BM.” %}\n\nVeamos ahora cómo se almacena la información de tipo objeto: busca el predicado &lt;bmo:PX_object_type&gt; (marcado en la tabla anterior) y clica en el enlace thes:x8577 para acceder al nodo que describe el tipo de objeto “print” (grabado).\n\n{% include figure.html filename=”sparql-lod-08.png” caption=”Página del recurso thes:x8577 (‘print’) en el conjunto de datos enlazados del British Museum.” %}\n\nComo se puede observar, este nodo tiene una etiqueta (label) en texto plano, así como enlaces a nodos del tipo “objetos artísticos” con los que se relaciona en el conjunto de la base de datos.\n\nConsultas complejas\n\nPara encontrar otros objetos del mismo tipo descritos con la etiqueta “print”, podemos invocar esta consulta:\n\nPREFIX bmo: &lt;http://www.researchspace.org/ontology/&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\n\nSELECT ?object\nWHERE {\n\n  # Busca todos los valores de ?object que tengan un \"object type\" dado\n  ?object bmo:PX_object_type ?object_type .\n\n  # El \"object type\" debería tener la etiqueta \"print\"\n  ?object_type skos:prefLabel \"print\" .\n}\nLIMIT 10\n\n\nRun query / User-generated query\n\n{% include figure.html filename=”sparql-lod-09.png” caption=”Tabla resultantes de nuestra consulta para todos los objetos del tipo ‘print’.” %}\n\nRecuerda que, dado que \"print\" funciona aquí como un literal, lo escribimos entrecomillado en nuestra consulta. Cuando se incluyen literales en las consultas SPARQL, la base de datos solo devuelve coincidencias exactas para estos valores.\n\nAdvierte también que, dado que ?object_type no se encuentra presente en el comando SELECT, este no se mostrará en la tabla de resultados. Sin embargo, resulta esencial estructurar nuestra consulta, porque es esto lo que permite conectar los puntos desde ?object con la etiqueta \"print\".\n\nFILTER\n\nEn los ejemplos anteriores, nuestra consulta SPARQL ha buscado una coincidencia exacta para el tipo de objeto con la etiqueta “print”. Sin embargo, con frecuencia querremos encontrar valores literales que caen dentro de un determinado rango, como son las fechas. Para ello utilizaremos el comando FILTER.\n\nPara localizar las URI de todos los grabados presentes en la base de datos del British Museum creados entre 1580 y 1600, necesitaremos, en primer lugar, averiguar dónde se almacenan en la base de datos las fechas en relación con los objetos, y entonces añadir referencias a estas fechas en nuestra consulta. De manera similar al procedimiento que hemos seguido de un único enlace para determinar un tipo de objeto, debemos ahora movernos a través de diversos nodos para encontrar las fechas de producción asociadas a un objeto dado:\n\n{% include figure.html filename=”sparql-lod-10.png” caption=”Visualización de la parte del modelo de datos del British Museum donde las fechas de producción están conectadas a los objetos.” %}\n\nPREFIX bmo: &lt;http://www.researchspace.org/ontology/&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX ecrm: &lt;http://www.cidoc-crm.org/cidoc-crm/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n# Recupera enlaces de objetos y fechas de creación\nSELECT ?object ?date\nWHERE {\n\n  # Utilizaremos nuestro comando previo para buscar solo\n  # objetos del tipo \"print\"\n  ?object bmo:PX_object_type ?object_type .\n  ?object_type skos:prefLabel \"print\" .\n\n  # Necesitamos enlazar diversos nodos para encontrar la\n  # fecha de creación asociada con un objeto\n  ?object ecrm:P108i_was_produced_by ?production .\n  ?production ecrm:P9_consists_of ?date_node .\n  ?date_node ecrm:P4_has_time-span ?timespan .\n  ?timespan ecrm:P82a_begin_of_the_begin ?date .\n\n  # Como se ve, es necesario conectar unos cuantos pocos de puntos\n  # para llegar al nodo de la fecha. Ahora que lo tehemos, podemos\n  # filtrar nuestros resultados. Dado que estamos filtrando por fecha,\n  # debemos agregar la etiqueta ^^xsd:date después de nuestra cadena de fecha.\n  # Esta etiqueta le dice a la base de datos que interprete la cadena\n  # \"1580-01-01\" como la fecha 1 de enero de 1580.\n\n  FILTER(?date &gt;= \"1580-01-01\"^^xsd:date &amp;&amp;\n         ?date &lt;= \"1600-01-01\"^^xsd:date)\n}\n\n\nRun query\n\n{% include figure.html filename=”sparql-lod-11.png” caption=”Todos los grabados del British Museum realizados entre 1580-1600.” %}\n\nAgregación\n\nHasta ahora, solo hemos utilizado el comando SELECT para recuperar una tabla de objetos. Sin embargo, SPARQL nos permite realizar análisis muchos más avanzados, como agrupaciones, cálculos y clasificaciones.\n\nPongamos por caso que estuviésemos interesados en examinar los objetos realizados entre 1580 y 1600, pero que asimismo quisiésemos conocer cuántos objetos de cada tipo tiene el British Museum en su colección. En vez de limitar nuestros resultados a los objetos del tipo “print”, en este caso utilizaríamos el operador COUNT para sumar los resultados de nuestra búsqueda en función del tipo al que pertenezcan.\n\nPREFIX bmo: &lt;http://www.researchspace.org/ontology/&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX ecrm: &lt;http://www.cidoc-crm.org/cidoc-crm/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\nSELECT ?type (COUNT(?type) as ?n)\nWHERE {\n  # Es necesario que indiquemos la variable ?object_type,\n  # sin embargo, ahora no es necesario que esta coincida con el valor \"print\"\n\n  ?object bmo:PX_object_type ?object_type .\n  ?object_type skos:prefLabel ?type .\n\n  # De nuevo, filtraremos por fecha\n  ?object ecrm:P108i_was_produced_by ?production .\n  ?production ecrm:P9_consists_of ?date_node .\n  ?date_node ecrm:P4_has_time-span ?timespan .\n  ?timespan ecrm:P82a_begin_of_the_begin ?date .\n  FILTER(?date &gt;= \"1580-01-01\"^^xsd:date &amp;&amp;\n         ?date &lt;= \"1600-01-01\"^^xsd:date)\n}\n# El comando GROUP BY designa la variable que se sumará,\n# y el comando ORDER BY DESC() clasifica los resultados\n# en orden descedente.\n\nGROUP BY ?type\nORDER BY DESC(?n)\n\n\nRun query\n\n{% include figure.html filename=”sparql-lod-12.png” caption=”Recuento de los objetos producidos entre 1580 y 1600 según el tipo al que pertenecen.” %}\n\nEnlazando múltiples puntos de entrada SPARQL\n\n2018-06-13: Desafortunadamente, Europeana ha eliminado la opción de enlazar puntos de entrada externos por medio de consultas `SERVICE`, y, en consecuencia, esta sección ha dejado de funcionar. Mantenemos el texto que sigue porque creemos que puede tener valor como referencia y porque esperamos que el servicio de Europeana vuelva a estar operativo en el futuro.\n\nHasta ahora, hemos construido consultas que buscan patrones en un único conjunto de datos. Sin embargo, el escenario ideal al que aspiran los partidarios de LOD viene dado por la posibilidad de enlazar múltiples bases de datos, lo que permitirá realizar consultas mucho más complejas al estar estas basadas en el conocimiento distribuido que es posible extraer de diversos espacios web. No obstante, esto resulta más fácil de decir que de hacer, y muchos puntos de entrada (incluido el del British Museum) todavía no referencian recursos de autoridad externos.\n\nUn punto de entrada que sí lo hace es el de Europeana. Europeana ha creado enlaces entre los objetos de sus bases de datos y los registros de personas en DBPedia y VIAF, los registros de lugares en GeoNames, y los conceptos resgistrados el Tesauro de Arte y Arquitectura (AAT) del Getty Research Institute. SPARQL nos permite insertar declaraciones SERVICE que ordenan a la base de datos “llamar a un amigo” y ejecutar una porción de la consulta en una base de datos externa, utilizando estos resultados para completar la consulta en la base de datos local. Si bien esta lección no se dentendrá en los modelos de datos de Europeana y DBPedia en profundidad, la siguiente consulta nos permite ver cómo funciona la declaración SELECT. Cada uno de los lectores puede ejecutarla por sí mismo copiando y pegando el texto de la consulta en el punto de entrada de Europeana. (A fin de que la consulta funcione, en el punto de entrada de Europeana se debe configurar el menú “Sponging” para “Retrieve remote RDF data for all missing source graphs”).\n\nPREFIX ore:    &lt;http://www.openarchives.org/ore/terms/&gt;\nPREFIX edm:    &lt;http://www.europeana.eu/schemas/edm/&gt;\nPREFIX rdf:    &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX dbo:    &lt;http://dbpedia.org/ontology/&gt;\nPREFIX dbr:    &lt;http://dbpedia.org/resource/&gt;\nPREFIX rdaGr2: &lt;http://rdvocab.info/ElementsGr2/&gt;\n\n# Encuentra todos los ?object relacionados por alguna ?property con un ?agent nacido en una\n# ?dutch_city\nSELECT ?object ?property ?agent ?dutch_city\nWHERE {\n    ?proxy ?property ?agent .\n    ?proxy ore:proxyFor ?object .\n\n    ?agent rdf:type edm:Agent .\n    ?agent rdaGr2:placeOfBirth ?dutch_city .\n\n    # En DBPedia, ?dutch_city está definida por pertenecer al país \"Netherlands\"\n    # La declaración SERVICE pregunta a\n    # http://dbpdeia.org/sparql qué ciudades pertenecen al país\n    # \"Netherlands\". La respuesta obtenida de esta subconsulta se utilizará para\n    # completar nuestra consulta originaria sobre los objetos\n    # presentes en la base de datos de Europeana\n\n    SERVICE &lt;http://dbpedia.org/sparql&gt; {\n        ?dutch_city dbo:country dbr:Netherlands .\n   }\n}\n# Potencialmente, esta consulta puede devolvernos un elevado número de objetos, por lo que vamos\n# a solicitar solo los cien primeros a fin de agilizar la búsqueda\nLIMIT 100\n\n\n{% include figure.html filename=”sparql-lod-13.png” caption=”Visualización de la secuencia de la consulta de la solicitud SPARQL definida más arriba.” %}\n\nUna consulta interconectada como esta significa que podemos interrogar a Europeana sobre los objetos que cuentan con información geográfica (¿cuáles son las ciudades de Holanda?) sin necesidad de que Europeana tenga que almacenar y mantener esta información por sí misma. Es de esperar que, en el futuro, cada vez mayor cantidad de información LOD de carácter cultural esté enlazada con bases de datos autorizadas, como el ULAN (Union List of Artist Names) del Getty Research Institute. Esto permitirá, por ejemplo, que el British Museum “externalice” la información biográfica acudiendo a los recursos más completos del GRI.\n\nTrabajando con resultados SPARQL\n\nUna vez que hemos construido y ejecutado una consulta, ¿qué hacemos ahora con estos resultados? Muchos puntos de entrada, como el del British Museum, ofrecen un navegador web que devuelve resultados legibles para los humanos. Sin embargo, el objetivo de los puntos de entrada SPARQL (y para eso están diseñados) es devolver datos estructurados para ser utilizados por otros programas.\n\nExportar resultados en formato CSV\n\nEn la esquina superior derecha de la página de resultados del punto de entrada del BM, se encuentran enlaces para descargas en formato JSON y XML. Otros puntos de entrada también pueden ofrecer la opción de descargar los resultados en CSV/TSV; sin embargo, esta opción no siempre se encuentra disponible. Las salidas JSON y XML desde un punto de entrada SPARQL contienen no solo los valores devueltos por la declaración SELECT, sino también metadatos adicionales sobre tipos de variables e idiomas.\n\nEl procesamiento de la versión XML de los resultados se puede realizar con herramientas tales como Beautiful Soup (véase la lección correspondiente en The Programming Historian u OpenRefine). Para convertir rápidamente los resultados JSON desde un punto de entrada SPARQL en un formato tabular, yo recomiendo la utilidad de la línea de comando gratuita jg. (Para un tutorial sobre cómo utilizar programas de línea de comando, véase “Introduction to the Bash Command Line”). La siguiente consulta convertirá el formato especial JSON RDF en un fichero CSV, que podremos cargar en nuestro programa preferido para su posterior análisis y visualización:\n\njq -r '.head.vars as $fields | ($fields | @csv), (.results.bindings[] | [.[$fields[]].value] | @csv)' sparql.json &gt; sparql.csv\n\n\nExportar resultados a Palladio\n\nLa popular plataforma de análisis de datos Palladio puede cargar directamente datos desde un punto de entrada SPARQL. En la parte inferior de la pantalla “Create a new project”, el enlace “Load data from a SPARQL endpoint (beta)” nos proporciona un campo para escribir la dirección del punto de entrada y una caja para la consulta propiamente dicha. Dependiendo del punto de entrada, podemos necesitar especifidar el tipo de fichero de salida en la dirección del punto de entrada; por ejemplo, para cargar datos desde el punto de entrada del British Museum, debemos utilizar la dirección http://collection.britishmuseum.org/sparql.json. Trata de pegar la consulta de agregación que utilizamos más arriba para el recuento de obras de arte según su tipología y clica en “Run query”. Palladio debería mostrar una tabla de previsualización como esta:\n\n{% include figure.html filename=”sparql-lod-14.png” caption=”Interfaz de Palladio para las consultas SPARQL.” %}\n\nDespués de previsualizar los datos devueltos por el punto de entrada, clica en en botón “Load data” en la parte inferior de la pantalla para empezar a trabajar con ellos. (Véase esta lección de Programming Historian para un tutorial más detallado sobre Palladio). Por ejemplo, podríamos realizar una consulta que devuelva enlaces a las imágenes de los grabados realizados entre 1580 y 1600, y representar estos datos como una galería de imágenes clasificadas por fecha:\n\n{% include figure.html filename=”sparql-lod-15.png” caption=”Galería de imágenes con línea de tiempo de sus fechas de creación generada utilizando Palladio.” %}\n\nAdviértase que Palladio está diseñado para funcionar con un conjunto relativamente pequeño de datos (del orden de cientos de miles de filas, no decenas de miles), por lo que pudiera ser necesario utilizar el comando LIMIT, que ya empleamos anteriormente en la consulta en el punto de entrada de Europeana, para reducir el número de resultados obtenidos y así evitar que el programa se quede bloqueado.\n\nLecturas adicionales\n\nEn este tutorial hemos examinado la estructura de LOD y hemos realizado un ejemplo real de cómo escribir consultas SPARQL para la base de datos del British Museum. También hemos aprendido cómo utilizar comandos de agregación en SPARQL para agrupar, contar y clasificar resultados más allá de la simple operación de listarlos.\n\nCon todo, existen otras muchas maneras de modificar estas consultas, tales como introducir operadores OR y UNION (para describir consultas condicionales) y declaraciones CONSTRUCT (para inferir nuevos enlaces basados en reglas definidas), búsqueda de texto completo o llevar a cabo otras operaciones matemáticas más complejas que la del recuento. Para un informe más detallado de los comandos disponibles en SPARQL, véanse estos enlaces:\n\n\n  Wikibooks SPARQL tutorial\n  Full W3C Overview of SPARQL\n\n\nTanto la web de Europeana como la del Getty Vocabularies ofrecen ejemplos extensos y bastante complejos de consultas que pueden constituir buenos recursos para comprender cómo buscar en sus datos:\n\n\n  Europeana SPARQL how-to\n  Getty Vocabularies Example Queries\n\n\nEsta lección explica por qué numerosas instituciones culturales están adoptando bases de datos orientadas a grafos y cómo los investigadores pueden acceder a estos datos a través de consultas realizadas en el lenguaje llamado SPARQL.\n\n"
  },


  {
    "id": 39,
    "url": "http://localhost:4000/es/lecciones/topic-modeling-y-mallet",
    "title": "Introducción a Topic Modeling y MALLET",
    "body": "\nIntroducción a Topic Modeling y MALLET\n{% include toc.html %}\n\nNota del editor\n\nEn esta lección es necesario utilizar la línea de comandos. Si no tienes experiencia previa utilizándola, consulta la lección Introducción a la línea de comandos en Bash de Programming Historian.\n\nObjetivos de la lección\n\nEn esta lección, primero aprenderás qué es topic modeling1 y por qué podrías querer utilizarlo en tus investigaciones. Luego aprenderás cómo instalar y trabajar con MALLET, una caja de herramientas para procesamiento de lenguajes naturales (PLN) que sirve para realizar este tipo de análisis. MALLET requiere que se modifique una variable de entorno (esto es, configurar un atajo para que la computadora sepa en todo momento dónde encontrar el programa MALLET) y que se trabaje con la línea de comandos (es decir, tecleando comandos manualmente en vez de hacer clic en íconos o menús).\n\nAplicaremos el modelador de tópicos a algunos archivos de ejemplo y veremos los tipos de output que genera MALLET. Esto nos dará una buena idea de cómo se puede aplicar topic modeling a un corpus de textos para identificar tópicos o temas que se encuentran en los documentos, sin tener que leerlos individualmente.\n\nPor favor, remítete a la lista de discusión de los usuarios de MALLET para aprender más sobre todo lo que se pueda hacer con este programa.\n\n(Queremos agradecer a Robert Nelson y Elijah Meeks por consejos y sugerencias sobre cómo empezar a utilizar MALLET por primera vez y por sus ejemplos de lo que se puede hacer con esta herramienta.)\n\n¿Qué es Topic Modeling y para quién es útil?\n\nUna herramienta de topic modeling toma un texto individual (o un corpus) y busca patrones en el uso de las palabras; es un intento de encontrar significado semántico en el vocabulario de ese texto (o corpus). Antes de empezar con topic modeling deberías preguntarte si es o no útil para tu proyecto. Para empezar a entender en qué circunstancias una técnica como esta es la más efectiva, te recomendamos Distant Reading de Matthew Kirschenbaum (una charla dada en el simposio de la Fundación Nacional de Ciencias de los Estados Unidos en 2009, sobre la próxima generación de extracción de datos y descubrimiento cibernético para la inovación) y Reading Machines de Stephen Ramsay.\n\nComo toda herramienta, el hecho de que se pueda utilizar no significa que deberías hacerlo. Si trabajas con pocos documentos (o incluso con un solo documento) puede ser que cálculos de frecuencia sean suficientes, en cuyo caso algo como las herramientas Voyant quizá serían convenientes. Si, en cambio, tienes cientos de documentos procedentes de un archivo y quieres comprender qué contiene el archivo, pero sin necesariamente leer cada documento, entonces topic modeling podría ser una buena opción.\n\nLos modelos de tópicos son una familia de programas informáticos que extraen tópicos de textos. Para la computadora, un tópico es una lista de palabras que se presenta de manera que sea estadísticamente significativa. Un texto puede ser un email, una entrada de blog, un capítulo de libro, un artículo periodístico, una entrada de diario – es decir, todo tipo de texto no estructurado. No estructurado quiere decir que no haya anotaciones legibles por la computadora que indiquen el significado semántico de las palabras del texto.\n\nLos programas de modelización de tópicos no saben nada sobre el significado de las palabras en un texto. En vez de eso, asumen que cada fragmento de texto está compuesto (por un autor(a)) a través de la selección de palabras desde posibles canastas de palabras, donde cada canasta corresponde a un tópico. Si eso es cierto, entonces es posible descomponer matemáticamente un texto  en las canastas desde las que con mayor probabilidad provienen las palabras que lo componen. La herramienta repite el proceso una y otra vez hasta que se establezca la distribución más probable de las palabras dentro de las canastas, que es lo que llamamos tópicos (o topics, en inglés).\n\nHay muchos programas diferentes para topic modeling; esta lección utiliza uno que se llama MALLET. Si este método se aplicara, por ejemplo, a un conjunto de discursos políticos, se obtendría una lista de tópicos y las palabras clave que los constituyen. Cada una de esas listas es un tópico de acuerdo con el algoritmo. En el caso del ejemplo de discursos políticos, la lista podría verse así:\n\n\n  empleo empleos pérdida desempleo crecimiento\n  economía sector bolsa bancos\n  Afganistán guerra tropa Medio_Oriente taliban terror\n  elección adversario futuro presidente\n  etc.\n\n\nExaminando las palabras clave podemos ver que el político que dio los discursos se refirió a la economía, los empleos, el Medio Oriente, las próximas elecciones, etc.\n\nComo advierte Scott Weingart, quienes utilizan topic modeling sin entenderlo completamente enfrentan muchos peligros. Por ejemplo, podría interesarnos el uso de las palabras como un indicador para la ubicación en un espectro político. Topic modeling sin duda podría ayudar con eso, pero hay que recordar que el indicador no es en sí lo que queremos comprender - como lo muestra Andrew Gelman en su estudio de maqueta sobre zombis, utilizando Google Trends. Ted Underwood y Lisa Rhody (véase Lecturas adicionales) sostienen que para nosotros como historiadores sería mejor considerar estas categorías como discursos; sin embargo, para nuestros objetivos, continuaremos utilizando la palabra: tópico.\n\nNota: En la bibliografía sobre topic modeling, a veces encontrarás el término “LDA”. Muchas veces, LDA y topic modeling se usan como sinónimos, pero la técnica LDA es, en realidad, un caso especial de topic modeling desarrollado por David Blei y amigos en 2002. No fue la primera técnica considerada como topic modeling pero es la más popular. Las innumerables variaciones de topic modeling han resultado en una sopa de letras de técnicas y programas para implementarlas, lo cual puede ser desconcertante o agobiante para los no iniciados en la materia y por esto no nos detendremos en ellos por ahora. Todos los algoritmos trabajan casi del mismo modo y MALLET en particular utiliza LDA.\n\nEjemplos de modelos de tópicos usados por historiadores:\n\n\n  Rob Nelson, Mining the Dispatch\n  Cameron Blevins, “Topic Modeling Martha Ballard’s Diary” Historying, April 1, 2010.\n  David J Newman y Sharon Block, “Probabilistic topic decomposition of an eighteenth century American newspaper,” Journal of the American Society for Information Science and Technology vol. 57, no. 6 (April 1, 2006): 753-767.2\n\n\nInstalar MALLET\n\nHay muchas herramientas que se podrían utilizar para crear modelos de tópicos, pero al momento de escribir estas líneas (en el verano de 2007) la herramienta más sencilla es MALLET.3 MALLET utiliza una implementación del Muestreo de Gibbs, una técnica estadística destinada a construir rápidamente una distribución de muestras, para luego crear los modelos de tópicos correspondientes. Para utilizar MALLET es necesario trabajar en la línea de comandos – hablaremos más de esto en un instante. Lo bueno es que normalmente los mismos comandos se usan repetidamente.\n\nLas instrucciones de instalación son diferentes para Windows y Mac. Sigue las instrucciones apropiadadas para ti:\n\n{% include figure.html filename=”windows-150x150.png” caption=”” %}\n\nInstrucciones para Windows\n\n\n  Ve a la página del proyecto MALLET. Puedes descargar MALLET aquí.\n  También necesitarás el Kit de desarrollo de Java (JDK) - esto es, no el Java normal que se encuentra en cada computadora sino el que permite programar cosas. Instala este en tu computadora.\n  Descomprime MALLET en tu directorio C:. Esto es importante: no puede ser en ningún otro lugar. Tendrás un directorio llamado C:\\mallet-2.0.8 o parecido. Para simplificar, cambia el nombre simplemente a mallet.\n  MALLET utiliza una variable de entorno para indicar a la computadora donde encontrar todos los componentes necesarios para sus procesos en el momento de ejecutarse. Es como un atajo para el programa. Un(a) programador(a) no puede saber exactamente donde cada usuario instala un programa. Por eso, él o ella crea una variable en el código que representa el lugar de instalación en cada momento. Por medio de la variable de entorno indicamos a la computadora donde se encuentra ese lugar. Si mueves el programa a otro lugar tendrás que cambiar esa variable.\n\n\nPara crear una variable de entorno en Windows 10, ve a Este equipo. Este equipo se encuentra o como ícono en el escritorio o en el explorador de archivos que se puede abrir haciendo clic en el menú Inicio -&gt; Explorador de archivos. Haz clic derecho en Este equipo y selecciona Propiedades. Se abre una nueva ventana. Selecciona la opción Configuración avanzada del sistema (figuras 1, 2, 3). Haz clic en Nueva... y escribe MALLET_HOME en la casilla Nombre de la variable. Tiene que ser así – todo en mayúsculas y con un guión bajo – porque ese es el atajo que el o la programador(a) ha incluido en el programa y todos sus subprogramas. Entonces escribe la ruta exacta (ubicación) de donde descomprimiste MALLET en la casilla Valor de la variable, por ejemplo C:\\mallet\\.\n\nPara ver si lo lograste, por favor continúa leyendo el próximo apartado.\n\n{% include figure.html filename=”fig1-configuracion-avanzada-del-sistema.png” caption=”Figura 1: Configuración avanzada del sistema en Windows” %}\n\n{% include figure.html filename=”fig2-lugar-variables-de-entorno.png” caption=”Figura 2: Lugar de las variables de entorno” %}\n\n{% include figure.html filename=”fig3-variable-de-entorno.png” caption=”Figura 3: Variable de entorno” %}\n\nEjecutar MALLET usando la línea de comandos\n\nMALLET se ejecuta desde la línea de comandos, conocida también como Símbolo del sistema (figura 4). Si recuerdas MS-DOS o alguna vez has experimentado con un terminal de computadora Unix, ya reconocerás esto. En la línea de comandos puedes teclear comandos directamente en vez de hacer clic en íconos o menús.\n\n{% include figure.html filename=”fig4-ventana-linea-de-comandos.png” caption=”Figura 4: Línea de comandos en Windows” %}\n\n\n  Haz clic en tu menú Inicio -&gt; Sistema de Windows -&gt; Símbolo del sistema. Se abre la ventana de la línea de comandos que tendrá el cursor en C:\\Users\\User&gt; (o parecido; véase figura 4).4\n  Teclea cd .. (Es decir: cd-espacio-punto-punto) y presiona Entrar para cambiar directorio.5 Sigue haciendo esto hasta llegar a C:\\ (como en la figura 5).\n  Luego escribe cd mallet y estarás en el directorio de MALLET. Todo lo que escribas en la ventana de la línea de comandos es un comando. Hay comandos como cd (cambiar directorio) o dir (listar los contenidos del directorio) que la computatora entiende. Si quieres utilizar MALLET tienes que decirle de manera explícita ‘esto es un comando de MALLET’. Para esto, se le especifica a la computadora que tiene que tomar sus instrucciones de la carpeta bin, un subdirectorio de MALLET que contiene las rutinas operacionales principales.\n  Teclea bin\\mallet como en la figura 6. Si todo ha ido bien deberías ver una lista de comandos de MALLET – ¡felicitaciones! Si recibes un mensaje de error comprueba lo que has escrito. ¿Utilizaste un tipo de barra equivocado? ¿Configuraste la variable de entorno correctamente?6 ¿Se encuentra MALLET en C:\\mallet?\n\n\n{% include figure.html filename=”fig5-ventana-linea-de-comandos-llegar-a-c.png” caption=”Figura 5: Navegar al directorio C:\\ en la línea de comandos” %}\n\n{% include figure.html filename=”fig6-linea-de-comandos-mallet-instalado.png” caption=”Figura 6: Línea de comandos: MALLET instalado” %}\n\nAhora estás preparado para avanzar a la próxima sección.\n\n{% include figure.html filename=”apple-150x150.png” caption=”” %}\n\nInstrucciones para Mac\n\nMuchas de las instrucciones para la instalación en OS X se parecen a las instrucciones para Windows, con pocas excepciones. En realidad, es un poco más fácil ejecutar comandos de MALLET en Mac.\n\n\n  Descarga e instala MALLET.\n  Descarga el Kit de desarrollo de Java (JDK).\n\n\nDescomprime MALLET en un directorio en tu sistema (para seguir esta lección con facilidad, escoge tu directorio /User/, aunque otro lugar funcionará igualmente). Cuando esté descomprimido, abre tu ventana Terminal (dentro del directorio Aplicaciones en tu Finder). Usando la Terminal, navega al directorio donde descomprimiste MALLET (será mallet-2.0.8 o mallet si cambiaste el nombre de la carpeta para simplificarlo. Si descomprimiste MALLET en tu directorio /User/ como se sugiere en esta lección, puedes navegar al directorio correcto tecleando cd mallet-2.0.8 o bien cd mallet). cd es la abreviatura para “cambiar directorio” cuando se trabaja en la Terminal.\n\nEn adelante, los comandos de MALLET en Mac son casi idénticos a los de Windows, con excepción de la dirección de las barras (hay algunas otras diferencias menores que se señalarán cuando resulte necesario). Si el comando es \\bin\\mallet en Windows, en Mac sería:\n\nbin/mallet\n\n\nDebería aparecer una lista de comandos. De ser así, ¡felicitaciones – has instalado MALLET correctamente!\n\nEjecutar comandos de MALLET\n\nAhora que has instalado MALLET, es hora de aprender qué comandos se pueden ejecutar con el programa. Hay nueve comandos diferentes (véase figura 6 arriba). A veces puedes combinar varias instrucciones. Según tu sistema operativo, teclea en el Símbolo del sistema o la Terminal:\n\nimport-dir --help\n\n\nSe te presentará un mensaje de error indicando que import-dir no se reconoce como orden o comando. Eso es así porque olvidamos decir a la computadora que buscara el comando dentro de MALLET bin. Inténtalo otra vez con\n\nbin\\mallet import-dir --help\n\n\nRecuerda que la dirección de las barras es importante (tal como se ve en la figura 7 que muestra una transcripción completa de lo que hemos hecho en la lección hasta ahora). Al teclear bin\\mallet, comprobamos que MALLET está instalado. Luego generamos el error con import-dir algunas líneas más adelante. Después de esto, conseguimos llamar al archivo de ayuda correctamente, el cual nos dijo lo que hace el comando import-dir y qué tipo de parámetros se pueden fijar para esta herramienta.\n\n{% include figure.html filename=”fig7-linea-de-comandos-teclear-ayuda.png” caption=”Figura 7: El menú de ayuda en MALLET” %}\n\nNota: en los comandos de MALLET hay una diferencia entre un guión simple y un guión doble. El guión simple es parte del nombre y sustituye un espacio (por ejemplo, import-dir en vez de import dir), porque los espacios tienen la función de separar diferentes comandos o parámetros. Mediante estos parámetros podemos ajustar el archivo que se crea cuando importamos nuestros textos a MALLET. Un guión doble (como por ejemplo --help arriba) modifica o añade un subcomando, o bien especifica algún tipo de parámetro para el comando.\n\nPara usuarios de Windows, si recibes el mensaje de error ‘exception in thread “main”\njava.lang.NoClassDefFoundError:’ puede deberse a que instalaste MALLET en algún otro lugar que no sea el directorio C:\\. Por ejemplo, instalando MALLET en C:\\Archivos de programa\\mallet producirá este mensaje de error. Lo segundo que se debe comprobar es si la variable de entorno está configurada correctamente. En cualquier caso, consulta las instrucciones de instalación en Windows y verifica que las seguiste correctamente.\n\nTrabajar con datos\nMALLET exige datos en texto plano. Para ello, cada texto suele guardarse en un archivo .txt. El conjunto de esos archivos conformará el corpus. Puedes descargar un corpus de muestra con textos en español aquí7. Descomprime el archivo ZIP en algún lugar de tu computadora y recuerda este lugar. En esta lección lo guardamos en el escritorio del usuario para poder encontrarlo fácilmente.\n\nPara navegar al directorio del corpus teclea cd C:\\Users\\User\\Desktop\\ensayos-de-jose-marti en la línea de comandos (o similar dependiendo de dónde guardaste la carpeta descomprimida en tu computadora). Escribe dir (ls para Mac) para que se te muestre la lista de los contenidos del directorio ensayos-de-jose-marti (véase figura 8). Para abrir uno de los archivos de texto, escribe el nombre entero del archivo incluyendo la extensión al final.\n\n{% include figure.html filename=”fig8-linea-de-comandos-corpus.png” caption=”Figura 8: Navegar al corpus de textos” %}\n\nTen en cuenta que ahora no puedes ejecutar ningún comando MALLET dentro de este directorio. Inténtalo:\n\nbin\\mallet import-dir --help\n\n\nSi recibes un mensaje de error, tendrás que volver al directorio principal de MALLET para poder ejecutar los comandos (por ejemplo con cd C:\\mallet\\). Esto se debe a la manera como están estructurados MALLET y sus componentes.\n\nImportar datos\n\nEn el directorio ensayos-de-jose-marti se encuentran varios archivos .txt. Cada uno de estos archivos es un documento individual, en este caso, el texto de un ensayo. El directorio entero se puede considerar un corpus de datos. Para trabajar con este corpus y descubrir cuáles son los tópicos (o temas) que componen los documentos individuales, necesitamos transformarlos desde varios archivos de texto individuales a un único archivo en formato MALLET. MALLET puede importar más de un archivo a la vez. Podemos importar todo el directorio de archivos de texto mediante el comando import. Los comandos de más abajo importan el directorio, lo convierten a un archivo MALLET, mantienen los archivos originales en el orden en que estaban listados y eliminan stop words (esto es, palabras de función como y, el, la, pero, si, que ocurren en frecuencias tan altas que obstruyen el análisis).\n\nMALLET viene provisto de algunos diccionarios de palabras vacías, por ejemplo para inglés. Si se quiere utilizar el diccionario predeterminado, el parámetro --remove-stopwords es suficiente.8 Como no hay ningún diccionario predeterminado para español, es necesario incluirlo a través del parámetro --stoplist-file. Para la mayoría de los idiomas es fácil encontrar listas de stop words en la red. Por ejemplo, puedes descargar una lista de palabras vacías en español en GitHub. Guárdala en tu computadora e indica la ruta a este fichero en el comando tal como está arriba: --stoplist-file C:\\Users\\User\\Desktop\\stopwords-es.txt (nombre del parámetro-espacio-ruta al fichero).\n\nbin\\mallet import-dir --input C:\\Users\\User\\Desktop\\ensayos-jose-marti --output C:\\Users\\User\\Desktop\\leccion.mallet --keep-sequence --remove-stopwords --stoplist-file C:\\Users\\User\\Desktop\\stopwords-es.txt\n\n\nEl parámetro --output junto con una ruta de fichero indica donde se guarda el corpus importado en formato MALLET, en este caso en el escritorio: C:\\Users\\User\\Desktop\\leccion.mallet. (Si aparece un mensaje de error en el momento de ejecutar el comando, puedes usar la tecla de flecha arriba para recuperar el último comando que escribiste y checar si hay erratas). Ahora el fichero leccion.mallet contiene todos los datos en un formato que MALLET reconoce.\n\nTambién podrías utilizar tus propios datos. Cambia C:\\Users\\User\\Desktop\\ensayos-jose-marti a un directorio que contenga tus propios archivos de investigación. ¡Buena suerte!\n\nSi no estás seguro de cómo funcionan los directorios, te recomendamos la lección Introducción a la línea de comandos en Bash de Programming Historian.\n\nPara Mac\nLas instrucciones para Mac son parecidas a las de Windows, con algunas diferencias que puedes notar en el siguiente ejemplo:\n\nbin/mallet import-dir --input /Users/User/Desktop/ensayos-jose-marti --output /Users/User/Desktop/leccion.mallet --keep-sequence --remove-stopwords --stoplist-file /Users/User/Desktop/stopwords-es.txt\n\n\nProblemas con datos a gran escala\n\nSi trabajas con colecciones grandes de archivos – o también archivos muy grandes – puedes enfrentar problemas con tu heap space, la memoria de trabajo de tu computadora. Si es relevante, este asunto suele surgir al principo, durante el proceso de importación. Por defecto, MALLET permite trabajar con una memoria de 1 GB. Si recibes el siguiente mensaje de error, alcanzaste tu límite:\n\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n\n\nSi tu sistema tiene más memoria, puedes tratar de aumentar la memoria asignada a tu máquina virtual Java. Para hacerlo, tienes que editar el código en el fichero mallet que se encuentra en el subdirectorio bin de tu carpeta MALLET. Abre el archivo Mallet.bat (C:\\Mallet\\bin\\mallet.bat) si trabajas en Windows o el archivo mallet (~/Mallet/bin/mallet) si trabajas en Linux u OS X. Ábrelo con el programa Komodo Edit (véase Mac, Windows, Linux para instrucciones de instalación).\n\nEncuentra la línea siguiente:\n\nMEMORY=1g\n\nPuedes aumentar el valor de 1g a 2g, 4g o aun más según la memoria de trabajo (RAM) que tenga tu sistema. Puedes encontrar esa información checando la información del sistema.\n\nGuarda los cambios. Ahora no debería aparecer el error. Si no, aumenta el valor otra vez.\n\nTu primer modelo de tópicos\n\nEscribe en la línea de comandos en el directorio MALLET:\n\nbin\\mallet train-topics  --input C:\\Users\\User\\Desktop\\leccion.mallet\n\n\nEste comando abre tu archivo leccion.mallet y ejecuta la rutina de topic modeling, en este caso con la configuración predeterminada. La rutina se repite tratando de encontrar la mejor asignación de palabras a tópicos. Tu línea de comandos se llena con los resultados de cada iteración. Cuando concluya puedes desplazarte hacia arriba para ver lo que se imprimió (como en la figura 9).\n\n{% include figure.html filename=”fig9-resultados-topic-model-basico.png” caption=”Figura 9: Resultados de un modelo de tópicos básico” %}\n\nLa computadora imprime las palabras clave, es decir, las palabras que ayudan a definir un tópico estadísticamente significativo, según la rutina. En la figura 9, el primer tópico que se imprime podría verse así (tus palabras clave podrían ser un poco diferentes):9\n\n0    0,5    unidos moneda plata comisión comercio unión delegados washington política congreso new internacional delegado york hispanoamérica argentina podía conferencia monetaria político\n\n\nReconocerás que muchas de las palabras se refieren a economía y política. De hecho, en el corpus hay un documento con el nombre el-congreso-de-Washington.txt que contiene un ensayo de José Martí sobre un congreso que se celebró en Washington en 1889 y que fue parte de la primera conferencia panamericana. Es de suponer que este y algunos otros documentos del corpus contribuyeron a la lista de palabras clave del primer tópico.10 Más adelante explicaremos qué significan los números 0 y 0,5. Observa que MALLET incluye elementos aleatorios, así que las listas de palabras clave serán diferentes cada vez que el programa se ejecute, incluso cuando se utilice el mismo conjunto de datos.\n\nVuelve al escritorio y teclea dir. Verás que no hay ningún output nuevo. ¡Creamos un topic model con éxito pero no guardamos los resultados! Vuelve al directorio de MALLET y escribe en la línea de comandos:\n\nbin\\mallet train-topics --input C:\\Users\\User\\Desktop\\leccion.mallet --num-topics 10 --output-state C:\\Users\\User\\Desktop\\topic-state.gz --output-topic-keys C:\\Users\\User\\Desktop\\leccion_topicos.txt --output-doc-topics C:\\Users\\User\\Desktop\\leccion_topicos_en_docs.txt \n\n\nAquí, le decimos a MALLET que cree un modelo de tópicos (train-topics). Todo lo que empieza con guión doble después del comando principal sirve para configurar parámetros:\n\nEste comando\n\n\n  abre tu archivo leccion.mallet\n  prepara MALLET a encontrar 10 tópicos\n  imprime cada palabra de tu corpus y el tópico al que pertenece en un archivo comprimido (.gz; véase gzip sobre cómo descomprimirlo)\n  produce un documento de texto que muestra cuáles son las palabras clave principales para cada tópico (leccion_topicos.txt)\n  y produce un archivo de texto que indica el porcentaje de cada tópico en cada documento de texto que importaste (leccion_topicos_en_docs.txt). (Para ver todos los parámetros del comando train-topics que se pueden ajustar, teclea bin\\mallet train-topics --help en la línea de comandos.)\n\n\nTeclea dir C:\\Users\\User\\Desktop. Tus outputs aparecerán en la lista de archivos y directorios dentro del directorio del escritorio. Abre leccion_topicos.txt en un procesador de texto (figura 10). Puedes ver una serie de párrafos. El primer párrafo corresponde al tópico 0; el segundo párrafo al tópico 1; el tercero al tópico 2, etc. (En el output, la cuenta comienza en 0 y no 1; así que con 10 tópicos, la lista va desde 0 a 9). El segundo número en cada párrafo es el parámetro Dirichlet para el tópico. Ese parámetro está relacionado con una opción que no utilizamos, por lo que tiene el valor por defecto (por eso cada tópico en este fichero lleva el número 0,5).11\n\n{% include figure.html filename=”fig10-palabras-clave-en-writer.png” caption=”Figura 10: Palabras clave en un procesador de texto” %}\n\nSi al ejecutar la rutina de topic modeling hubieras incluido\n\n--optimize-interval 20\n\n\ncomo abajo\n\nbin\\mallet train-topics  --input C:\\Users\\User\\Desktop\\leccion.mallet  --num-topics 10 --optimize-interval 20 --output-state C:\\Users\\User\\Desktop\\topic-state.gz  --output-topic-keys C:\\Users\\User\\Desktop\\leccion_topicos.txt --output-doc-topics C:\\Users\\User\\Desktop\\leccion_topicos_en_docs.txt\n\n\nla salida podría haber sido:\n\n0\t0,02991\tpoesía whitman canto walt muerte libro siente poeta frase sol yerba lenguaje palabras aparente justicia literatura puesto dolores movimiento entera\n\n\nEl primer número es el tópico (topic 0) y el segundo número indica el peso de este tópico. Generalmente, los tópicos resultan mejores si se incluye el parámetro --optimize-interval.\n\nLa composición de tus documentos\n\n¿Qué tópicos componen tus documentos? La respuesta está en el archivo leccion_topicos_en_docs.txt. Para mantener todo organizado, importa el archivo leccion_topicos_en_docs.txt a una hoja de cálculo (en Excel, Open Office, etc.). Tendrás una tabla con las columnas número de documento, fuente, proporción del tópico. Todas las columnas subsiguientes son proporciones de los tópicos, como en la figura 11.12\n\n{% include figure.html filename=”fig11-topicos-en-docs.png” caption=”Figura 11: Tópicos en documentos” %}\n\nPuede resultar difícil leer estos datos. Los tópicos comienzan en la tercera columna, en este caso en la columna C, y continúan hasta el último tópico en la columna L. Es así porque entrenamos 10 tópicos – si hubiéramos entrenado 20, por ejemplo, llegarían hasta la columna V.\n\nA partir de esto, se puede ver que en el documento número 0 (es decir, el primer documento cargado en MALLET), a-aprender-en-las-haciendas.txt, el tópico 0 tiene un porcentaje de 0.33% (columna C). Si buscamos el valor más alto en esta fila, podemos ver que el tópico 3 es el más importante en este documento, con un porcentaje de 69.24%. Dada la naturaleza de MALLET, tus propios tópicos pueden tener valores diferentes.\n\nSi tienes un corpus de archivos de texto que están organizados en orden cronológico (por ejemplo que 1.txt sea anterior a 2.txt), podrías generar un gráfico en tu programa de hoja de cálculo y empezar a ver cambios con el tiempo, tal como lo hizo Robert Nelson en Mining the Dispatch.\n\n¿Cómo puedes saber cuál es la cantidad adecuada de tópicos? ¿Hay una cantidad natural de tópicos? Hemos descubierto que hay que ejecutar train-topics varias veces con distintas cantidades de tópicos para ver cómo la distribución de los tópicos en los documentos cambia. Si encontramos que la mayoría de los textos están dominados por muy pocos tópicos, lo interpretamos como una señal de necesitar aumentar la cantidad de tópicos; las preferencias fueron demasiado amplias. Hay maneras de buscar la mejor configuración automáticamente, por ejemplo mediante el comando hlda de MALLET, pero para los lectores de esta lección probablemente es más rápido realizar algunas iteraciones (para más información consulta Griffiths, T. L., &amp; Steyvers, M. (2004). Finding scientific\ntopics. Proceedings of the National Academy of Science, 101, 5228-5235).\n\nAnalizar tus propios textos con MALLET\n\nLa carpeta sample data en el directorio de MALLET (C:\\mallet\\sample-data) te puede servir como guía para saber cómo organizar tus textos. Pon todo lo que deseas en una sola carpeta, por ejemplo C:\\mis-datos. Tus archivos deben contener texto llano y estar en el formato .txt (puedes crearlos en un procesador de textos como Notepad, Sublime Text o Atom, por ejemplo, y guardarlos como Texto (*.txt) o Texto sin formato). Tienes que tomar algunas decisiones. ¿Quieres explorar los tópicos a nivel de párrafos? Entonces cada archivo .txt debería contener solo un párrafo. En los nombres de los archivos puedes agregar información como el número de la página u otros identificadores, por ejemplo: pag32_parr1.txt. Si trabajas con un diario, cada archivo de texto podría ser una entrada de diario, por ejemplo: abril_25_1887.txt. (Nota que es importante no dejar espacios en los nombres de carpetas y archivos). Si los textos que te interesan están en la red, podrías automatizar este proceso.\n\nLecturas adicionales sobre Topic Modeling\n\nPara ver un ejemplo desarrollado de topic modeling basado en materiales obtenidos de páginas web, véase Mining the Open Web with Looted\nHeritage Draft.\n\nPuedes reutilizar los datos tomándolos de Figshare.com donde están incluidos algunos archivos .txt. Cada uno de los ficheros .txt contiene una noticia individual.\n\n\n  Para amplia información adicional y una bibliografía sobre topic modeling podrías empezar con el Guided Tour to Topic Modeling de Scott Weingart.\n  Una discusión importante sobre la interpretación del significado de los tópicos es ‘Topic modeling made just simple enough’ de Ted Underwood.\n  El artículo de blog ‘Some Assembly Required’ Lisa @ Work 22 de agosto de 2012 escrito por Lisa Rhody también es muy revelador.\n  Clay Templeton, ‘Topic Modeling in the Humanities: An Overview’, Maryland Institute for Technology in the Humanities, n.d.\n  David Blei, Andrew Ng, and Michael Jordan, ‘Latent dirichlet allocation’, The Journal of Machine Learning Research 3 (2003).\n  Finalmente, te recomendamos que consultes la bibliografía de artículos sobre topic modeling de David Mimno. Están clasificados por temas para facilitar encontrar el artículo más adecuado para una aplicación determinada. También puedes echar un vistazo a su reciente artículo sobre Historiografía Computacional en la revista ACM Transactions on Computational Logic en el que analiza revistas científicas de los Clásicos a lo largo de cien años para aprender algo sobre este campo. Mientras el artículo debe leerse como un buen ejemplo de topic modeling, su sección sobre ‘métodos’ es especialmente relevante porque incluye una discusión sobre cómo preparar los textos para un análisis de ese tipo.13\n\n\nNotas de traducción\n\n  \n    \n      En esta traducción se utiliza la expresión topic modeling en inglés porque en la literatura publicada sobre el tema en español es lo más común. Por supuesto sería posible traducir topic modeling por modelaje de tópicos o algo parecido, pero hasta ahora no es habitual. Por otro lado, se ha optado por traducir todas las demás palabras relacionadas al método para estimular su uso en español, por ejemplo topic por tópico o topic model por modelo de tópicos. &#8617;\n    \n    \n      También hay algunos ejemplos de modelos de tópicos creados a partir de textos (literarios) en español. Por ejemplo: Borja Navarro-Colorado, On Poetic Topic Modeling: Extracting Themes and Motifs From a Corpus of Spanish Poetry, frontiers in Digital Humanities, 20 de junio de 2018, https://doi.org/10.3389/fdigh.2018.00015; Borja Navarro-Colorado y David Tomás, A fully unsupervised Topic Modeling approach to metaphor identification / Una aproximación no supervisada a la detección de metáforas basada en Topic Modeling, Actas del XXXI Congreso de la Sociedad Española para el Procesamiento del Lenguaje Natural, 2015; Christof Schöch, Ulrike Henny, José Calvo Tello, Daniel Schlör, Stefanie Popp, Topic, Genre, Text. Topics im Textverlauf von Untergattungen des spanischen und hispanoamerikanischen Romans (1880-1930), DHd 2016. Modellierung, Vernetzung, Visualisierung. Die Digital Humanities als fächerübergreifendes Forschungsparadigma. Universität Leipzig, 7.-12. März 2016. &#8617;\n    \n    \n      En esta traducción, las instrucciones para la instalación de MALLET fueron actualizadas para ajustarse a Windows 10. En el original inglés las instrucciones se refieren a Windows 7. Las capturas de pantalla fueron sustituidas para que el idioma de la pantalla sea español. &#8617;\n    \n    \n      En todos los ejemplos de esta lección en los que aparece la palabra User, deberás sustituirla con tu propio nombre de usuario. &#8617;\n    \n    \n      Al final de un comando escrito en la línea de comandos siempre se teclea Entrar para confirmar el comando y ejecutarlo. En adelante no lo mencionaremos más. &#8617;\n    \n    \n      Puede ser necesario reiniciar el sistema operativo para que se reconozca la nueva variable de entorno. &#8617;\n    \n    \n      En la versión inglesa de esta lección se utilizan datos de muestra incluidos en MALLET, pero actualmente, estos solo existen en inglés y alemán. Por eso se trabaja con otros datos en esta versión española y el contenido de la lección difiere del original en este aspecto. Los datos de muestra consisten en 19 ensayos escritos por José Martí. La fuente de los textos es Wikisource. &#8617;\n    \n    \n      En la versión original de esta lección se utilizó el diccionario por defecto que está en inglés. &#8617;\n    \n    \n      Si las palabras con acento o ñ no salen correctamente en tu línea de comandos es porque la codificación de caracteres no es la misma en los ficheros, en MALLET y en la línea de comandos. Los ficheros de muestra incluidos en esta lección están codificadas en UTF-8. La codificación en MALLET también es UTF-8 por defecto. Entonces es necesario cambiar la codificación de caracteres de la línea de comandos para evitar esos errores. Si utilizas Windows, teclea chcp 65001 en la línea de comandos  para definir la codificación como UTF-8 antes de ejecutar los comandos de MALLET. En Mac, la codificación por defecto suele ser UTF-8. &#8617;\n    \n    \n      Nótese que MALLET no reconoce palabras compuestas como New York y las trata como dos palabras separadas. Para evitar eso, sería necesario preprocesar el texto y conectar las varias partes de la palabra compuesta con un símbolo, por ejemplo una barra baja (New_York) para que MALLET las reconozca como tales. &#8617;\n    \n    \n      Si comparas los tópicos en la figura 10 con los de la figura 9, puedes ver el efecto del elemento aleatorio del topic modeling. Esas dos listas de tópicos son los resultados de dos pasadas diferentes y aunque los tópicos se parezcan no son exactamente iguales. &#8617;\n    \n    \n      Como en la línea de comandos, también en el programa de hoja de cálculo puede ser necesario cambiar la codificación de caracteres a UTF-8 para que las letras con acento o ñ salgan correctamente. Esto se puede hacer durante el proceso de importar los datos o ajustando las preferencias del programa. &#8617;\n    \n    \n      Para introducciones a topic modeling escritas en español, véanse la entrada de blog de José Calvo Tello Topic modeling: ¿qué, cómo, cuándo? y la presentación Text Mining con Topic Modeling de Borja Navarro-Colorado. &#8617;\n    \n  \n\n\nEsta lección explica qué es topic modeling y por qué podrías querer utilizarlo en tus investigaciones. Luego aprenderás cómo instalar y trabajar con MALLET, una caja de herramientas para procesamiento de lenguajes naturales (PLN) con la que topic modeling se puede llevar a la práctica.\n\n"
  },


  {
    "id": 40,
    "url": "http://localhost:4000/es/lecciones/trabajar-con-archivos-de-texto",
    "title": "Trabajar con archivos de texto en Python",
    "body": "\nTrabajar con archivos de texto en Python\n{% include toc.html %}\n\nObjetivos de la lección\n\nEn esta lección aprenderás a manipular archivos de texto utilizando Python. Esto incluye abrir, cerrar, leer desde y escribir en archivos .txt\n\nLas siguientes lecciones incluirán descargar páginas web desde Internet y reorganizar los contenidos en fragmentos de información útiles para el análisis. La mayor parte de todo este trabajo se hará usando código escrito en Python mediante Komodo Edit.\n\nTrabajar con archivos de texto\n\nPython hace muy sencillo el trabajo con archivos y texto. Empecemos por los archivos.\n\nCrear y escribir en un archivo de texto\n\nVamos a comenzar con una breve discusión acerca de terminología. En una lección previa, dependiendo del sistema operativo de tu computadora: Mac, Windows, Linux, viste cómo se envía información a la ventana de “comando de salida” en tu editor de texto mediante la utilización del comando print de Python.\n\nprint (‘Hola Mundo')\n\n\nEl lenguaje de programación Python es del tipo orientado a objetos. Esto quiere decir que está construido alrededor de un tipo especial de entidad, un objeto, que contiene a la vez datos así como una serie de métodos para acceder y alterar los datos. Una vez que se crea un objeto se puede interactuar con otros objetos.\n\nEn el ejemplo de arriba vimos un tipo de objeto, la cadena (string) “Hola Mundo”. La cadena es la secuencia de una serie de caracteres encerrados entre comillas. Puedes escribir una cadena de tres maneras distintas:\n\nmensaje1 = 'hola mundo'\nmensaje2 = \"hola mundo\"\nmensaje3 = \"\"\"Hola\nhola\nhola mundo\"\"\"\n\nLo que importa aquí es notar que, como se ve en los dos primeros ejemplos, se pueden utilizar comillas sencillas o dobles, pero nunca se debe mezclar los dos tipos en una misma cadena. En el tercer mensaje, las dobles comillas repetidas tres veces indican una cadena que se extiende por más de una línea.\n\nPor lo tanto los siguientes mensajes contienen errores:\n\nmensaje1 = \"hola mundo'\nmensaje2 = 'hola mundo\"\nmensaje3 = 'Su nombre es John O'Connor'\n\n\nCuenta el número de comillas sencillas en el mensaje3.  Para que esto trabaje correctamente tendremos que salvar el apóstrofe.\n\nmensaje3 = 'Su nombre es John O\\'Connor'\n\n\nO reescribir la frase como:\n\nmensaje3 = \"Su nombre es John O'Connor\"\n\nprint es un comando que imprime objetos en forma textual. Al combinar el comando print con una cadena de texto producimos una declaración.\n\nUtilizarás el comando print de esta forma en los casos en los que se quiera generar información que necesite ser manipulada inmediatamente. Algunas veces, sin embargo, crearás información que necesita ser guardada, enviarla a otra persona, o utilizar como datos de entrada (input) para un procesamiento posterior por otro programa o conjunto de programas. En estos casos querremos enviar información a archivos en el disco duro en vez de enviarla al panel de comando de salida. Escribe el siguiente programa en tu editor de texto y guárdalo como archivo-salida.py\n\n#archivo-salida.py\nf = open ('holamundo.txt','wb')\nf.write('hola mundo')\nf.close()\n\n\nEn Python, cualquier línea que inicia con un símbolo de almohadilla o numeral (#) se llama comentario y es ignorada por el intérprete de Python. Los comentarios están pensados para permitirle a los programadores comunicarse entre ellos (o para recordarse a sí mismos qué es lo que hace el código cuando se sientan frente a él algunos meses después). En un sentido lato, los programas son escritos y formados de una manera que hace más sencillo a los programadores trabajar en colectivo. El código que es más cercano a los requerimientos de la máquina se denomina de bajo nivel, mientras que el código que es más cercano al lenguaje propio de los seres humanos es llamado de alto nivel. Uno de los beneficios de utilizar un lenguaje de programación como Python es que es de mayor alto nivel, lo que hace más sencillo que podamos comunicarnos contigo (claro que con cierto costo en términos de eficiencia informática).\n\nEn este programa f es un objeto mientras que open, write y close son métodos. En otras palabras, open, write y close actúan sobre el objeto f que, en este caso, está definido como un archivo de texto .txt. Problamente, éste es un uso del término “método” que podrías esperar y de vez en cuando encontrarás que las palabras utilizadas en el contexto de la programación tienen un significado ligeramente (o completamente) distinto al del habla de la vida cotidiana. En este caso, conviene recordar que “método” significa fragmentos de código que realizan acciones. Ejecutan algo sobre una cosa y regresan un resultado. Puedes intentar imaginar esto utilizando algún referente del mundo real como, por ejemplo, dar órdenes a tu perro que ha sido educado previamente. Tu mascota (el objeto) entiende órdenes (i.e. tiene “métodos”) como “ladra”, “sentado”, “echado” y así. Discutiremos y aprenderemos cómo usar muchos otros métodos en tanto vayamos avanzando.\n\nf es el nombre de una variable que hemos escogido nosotros. Podríamos haberlo llamado de cualquier manera que se nos hubiera ocurrido. En Python, los nombres de las variables pueden construirse con letras mayúsculas, minúsculas o números. Pero no podemos utilizar los nombres de los comandos del lenguaje como variables. Por ejemplo, si intentamos nombrar a una variable “print”, el programa no responderá porque esa es una palabra reservada que es parte del lenguaje de programación.\n\nLos nombres de las variables en Python son también sensibles al uso de mayúsculas y minúsculas, lo que significa que trapa, Trapa o TRAPA serían representaciones de distintas variables.\n\nCuando ejecutas el programa que escribimos, el método open le dice a tu computadora que produzca un nuevo archivo de texto llamado holamundo.txt en la misma carpeta en la que creamos el programa archivo-salida.py. El parámetro w indica que pretendemos escribir contenido en este nuevo archivo utilizando Python.\n\nTen en cuenta que tanto el nombre del archivo como el parámetro están encerrados entre comillas sencillas con lo cual sabes que serán datos almacenados como cadenas. Si te olvidas de incluir las comillas el programa fallará.\n\nEn la línea siguiente tu programa escribe el mensaje “hola mundo” (que es otra cadena) en el archivo y luego lo cierra. (Para mayor información sobre estas declaraciones es importante ver la sección de file objects en las Referencias de la Biblioteca de Python).\n\nHaz doble clic en el botón “Ejecutar Python” que creaste en Komodo Edit para correr el programa (o el equivalente en cualquier editor de texto que hayas elegido usar: por ejemplo, haz clic en “#!” en TextWrangler). Y aunque nada estará escrito en el panel del comando de salida, verás un mensaje de estado que dirá algo como esto en Mac o Linux:\n\n`/usr/bin/python archivo-salida.py` returned 0.\n\n\nMientras que en Windows se verá:\n\n'C:\\Python27\\Python.exe archivo-salida.py'  returned 0\n\n\nEsto significa que se ejecutó el programa con éxito. Si utilizas File -&gt; Open -&gt; File en el Komodo Edit, se puede abrir el archivo holamundo.txt. Este debe contener el mensaje de una sola linea:\n\n¡Hola Mundo!\n\n\nDado que los archivos de texto plano incluyen la información mínima, tienden a ser de pequeño volumen, fáciles de intercambiar entre diferentes plataformas (por ejemplo, de Windows a Linux o Mac o viceversa), y fáciles de enviar de un programa informático a otro.  También pueden ser leídos en todos los editores de texto como Komodo Edit.\n\nLeer desde un archivo de texto\n\nPython también tiene métodos que nos permiten obtener información de los archivos. Escribe el siguiente programa en el editor de texto y guárdalo como archivo-entrada.py. Cuando hagas clic en “Ejecutar Python”, el programa abrirá el archivo de texto que acabas de crear, leerá el texto de una línea que contiene e imprimirá la información en el panel de “comando de salida”.\n\n# archivo-entrada.py\nf = open ('holamundo.txt','r')\nmensaje = f.read()\nprint(mensaje)\nf.close()\n\n\nEn este caso, el parámetro r se utiliza para indicar que estás abriendo un archivo para leer (read) la información que contiene. Los parámetros te permiten escoger entre una serie de diferentes opciones que permita un método en particular. Regresando al ejemplo de la mascota, el perro puede ser adiestrado para ladrar una vez si recibe un premio con sabor a res, y dos si recibe un premio con sabor a pollo. El sabor de la galleta de premio es el parámetro. Cada método es diferente en términos de qué parámetros aceptará. Por ejemplo, no puedes pedirle al perro que cante una ópera italiana -al menos que tu perro sea particularmente talentoso.  Puedes encontrar la posibilidad de parámetros para cada método en particular en el sitio web de Python, o incluso puedes descubrirlos tú mismo en cualquier buscador tecleando el método específico acompañado por la palabra “Python”.\n\nRead es otro método de archivo. El contenido del archivo (el mensaje de una sola línea) es copiado a message, que es como decidimos llamar a esa cadena de texto, y el comando print se utiliza para enviar el contenido recogido en message al panel de comando de salida.\n\nAnexar texto a un archivo de texto preexistente\n\nUna tercera opción es abrir un archivo preexistente y añadirle más información. Ten en cuenta que si abres un archivo mediante open y usas el método write, el programa sobrescribirá cualquier cosa que el archivo contenga. Por supuesto que esto no es ningún problema cuando se crea un nuevo archivo o cuando se desea sobre-escribir el contenido de un archivo existente, pero es totalmente indeseable cuando estás creando una lista larga de eventos o estás compilando una gran cantidad de datos en un archivo. Así que, en vez de ` write, vamos a usar el método  append, que es designado con una  a` .\n\nEscribe el siguiente programa en el editor de texto y guárdalo con el nombre de ` archivo-apendice.py. Cuando lo ejecutes, este programa abrirá el mismo archivo de texto  holamundo.txt` que creaste antes y añadirá un segundo “Hola Mundo” al archivo. La sintaxis ‘\\n’ representa una nueva línea de texto en el archivo.\n\n# archivo-apendice.py\nf = open('holamundo.txt','a')\nf.write('\\n' + 'Hola Mundo')\nf.close()\n\n\nDespués de que hayas ejecutado el programa, ve al archivo holamundo.txt y ábrelo para ver qué sucedió. Cierra el archivo de texto y vuelve a ejecutar el programa archivo-apendice.py las veces que quieras. Cuando abras nuevamente el archivo holamundo.txt verás que habrá una serie de líneas con el mensaje “Hola Mundo” repetido tantas veces como las que ejecutaste el programa.\n\nEn la siguiente sección discutiremos dos conceptos: modularidad y reutilización de código.\n\nLecturas recomendadas\n\n\n  Non-Programmer’s Tutorial for Python 2.6/Hello, World\n\n\n\nEn esta lección aprenderás a manipular archivos de texto utilizando Python.\n\n"
  },


  {
    "id": 41,
    "url": "http://localhost:4000/es/lecciones/trabajar-con-paginas-web",
    "title": "Descargar páginas web con Python",
    "body": "\nDescargar páginas web con Python\n{% include toc.html %}\n\nObjetivos de la lección\n\nEsta lección muestra qué es un Localizador de recursos uniforme (Uniform Resource Locator = URL) y explica cómo utilizar Python para descargar y guardar los contenidos de una página web en tu disco duro.\n\nAcerca de los URL\n\nUna página web es un archivo que está almacenado en otra computadora, una máquina conocida como servidor web. Cuando tú “vas” a una página web, lo que en realidad sucede es que tu computadora (el cliente) envía una solicitud al servidor (el alojamiento o host) a través de la red, y el servidor responde enviándote una copia de la página a tu máquina. Una manera de ir a una página web con tu navegador es seguir un enlace a alguna otra parte. También tienes la posibilidad de pegar o escribir un localizador de recursos uniforme (URL) directamente en tu navegador. El URL le indica a tu navegador dónde encontrar un recurso en línea especificando el servidor, directorio y nombre del archivo que tiene que ser recuperado, así como el tipo de protocolo que tu navegador y el servidor estarán de acuerdo en usar mientras intercambian información (como HTTP o protocolo de transferencia de hipertexto). La estructura básica de un URL es:\n\nprotocolo://dominio:puerto//ruta?consulta\n\n\nVeamos algunos ejemplos.\n\nhttp://oldbaileyonline.org\n\n\nEl tipo más básico de URL simplemente especifica el protocolo y el alojamiento. Si introduces este URL en tu navegador, te mostrará la página principal del sitio The Old Bailey Online. Por defecto, la página principal en un directorio se denomina índice, por lo general index.html.\n\nEl URL también pude incluir un número de puerto opcional. Sin entrar en detalles, el protocolo de red que subyace en el intercambio de información en la Internet permite a las computadoras conectarse de diferentes maneras. Los números de puerto se usan para distinguir estas diferentes formas de conexión. Dado que, por defecto, el puerto para HTTP es el número 80, el siguiente URL es equivalente al previo.\n\nhttp://oldbaileyonline.org:80\n\n\nComo sabes, generalmente hay muchas páginas en un determinado sitio web. Éstas están almacenadas en directorios del servidor y tú puedes especificar la ruta (path) a una página en particular. La página “Acerca de” del The Old Bailey Online tiene el siguiente URL:\n\nhttp://oldbaileyonline.org/static/Project.jsp\n\n\nPor último, muchas páginas web te permiten introducir consultas. El sitio web The Old Bailey Online, por ejemplo, está diseñado de tal manera que puedes solicitar una página en particular utilizando una cadena de consulta. EL siguiente URL te llevará a la página de resultados de búsqueda de registros de juicios criminales que contienen la palabra “arsenic” (arsénico)\n\nhttps://www.oldbaileyonline.org/search.jsp?form=searchHomePage&amp;_divs_fulltext=arsenic&amp;kwparse=and&amp;_persNames_surname=&amp;_persNames_given=&amp;_persNames_alias=&amp;_offences_offenceCategory_offenceSubcategory=&amp;_verdicts_verdictCategory_verdictSubcategory=&amp;_punishments_punishmentCategory_punishmentSubcategory=&amp;_divs_div0Type_div1Type=&amp;fromMonth=&amp;fromYear=&amp;toMonth=&amp;toYear=&amp;ref=&amp;submit.x=0&amp;submit.y=0\n\n\nEl fragmento de texto después de “?” representa la consulta. Puedes aprender más acerca de la construcción de consultas en Descarga de registros múltiples usando cadenas de consulta (en inglés).\n\nAbrir URLS con Python\n\nComo historiador digital a menudo querás utilizar los datos alojados en una base de datos académica en línea. Para obtener estos datos puedes abrir una URL a la vez y copiar y pegar su contenido a un archivo de texto, o puedes utilizar Python para hacer una cosecha por  procesamiento automático de las páginas web. Para hacer esto tienes que ser capaz de abrir cualquier URL con tus propios programas. El lenguaje Python incluye un número de formas estándar para hacer esto.\n\nComo ejemplo, vamos a trabajar con una tipo de archivo que podrás encontrar haciendo investigación histórica. Digamos que te interesan las relaciones étnicas en la Gran Bretaña del siglo XVIII. The Old Bailey Online (OBO) es una rica fuente que proporciona transcripciones de juicios de 1674 a 1913 y es un buen lugar para buscar documentación.\n\n{% include figure.html filename=”old-bailey.png” caption=”Página principal del sitio The Old Bailey Online” %}\n\nPara este ejemplo vamos a utilizar la relatoría del juicio de Benjamin Bowsey, un “moro negro” que fue procesado por romper la paz durante las revueltas de Gordon en 1780. El URL para esa entrada es:\n\nhttp://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33\n\n\nSi estudiamos el URL podemos aprender varias cosas. En primer lugar, OBO fue escrito en JSP (+JavaServer Pages, un lenguaje de programación que genera HTML), y es posible obtener entradas de procesos judiciales individuales haciendo uso de cadenas de consulta. A cada proceso se le asignó, aparentemente un número de identificación (ID) (id=t* en el URL), compuesto a partir de la fecha del juicio en formato (AAAA-MM-DD) y el número de proceso dentro de esa sesión de la corte, en este caso: 33. Si cambias 33 por 34 en tu navegador y presionas Enter, eso te deberá llevar al siguiente proceso. Desafortunadamente no todos los sitios web tienen estos URL tan legibles y fiables.\n\n{% include figure.html filename=”bowsey-trial-page.png” caption=”Página de la transcripción del juicio de Benjamin Bowsey, 1780” %}\n\nTómate unos minutos para ver la página del proceso contra Benjamin Bowsey. No estamos muy interesados en lo que dice la relatoría sino en la información que proporciona la página. Al final de la misma notarás que hay un enlace View as XML que te lleva a una versión de la página del texto profusamente etiquetado con XML que es muy útil para cierto tipo de investigaciones. También puedes ver un escaneo del documento original que fue transcrito para hacer construir esta fuente.\n\nAhora vamos a tratar de abrir la página usando Python. Copia el siguiente programa en Komodo Edit y guárdalo como abre-paginaweb.py Cuando ejecutes el programa abrirá la página del proceso judicial, leerá (read) su contenido en una cadena de texto de Python llamada contenidoWeb y luego te mostrará mediante print los primeros trescientos caracteres de la cadena en el panel de salida de comando. Usa el comando de Firefox Herramientas -&gt; Desarrollador web -&gt; Código fuente de esta página (Ctrl-U) para verificar que la fuente de la página de ese URL es la misma fuente que tu programa recupera. Consulta la biblioteca de referencias de Python para saber más de urllib2.\n\n# abre-paginaweb.py\n\nimport urllib.request, urllib.error, urllib.parse\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\ncontenidoWeb = respuesta.read()\n\nprint(contenidoWeb[0:300])\n\n\nEstas cinco líneas de código logran mucho rápidamente. Vamos a detenernos un momento para asegurarnos de que todo está claro y que puedes reconocer los bloques que permiten que este programa haga lo que queremos que haga.\n\nurl, respuesta y contenidoWeb son variables que nosotros mismos hemos llamado así.\n\nurl contiene el URL de la página web que queremos descargar. En este caso, el juicio contra Benjamien Bowsey.\n\nEn la línea siguiente invocamos a la función urlopen que está almacenada en un módulo de Python llamado urllib2.py y le hemos pedido a esa función que abra el sitio web en el URL que le especificamos. Entonces, guardamos el resultado de ese proceso en una variable denominada respuesta. Esta variable contiene una versión abierta del sitio web solicitado.\n\nUtilizamos entonces el método read, que ya usamos anteriormente, para copiar el contenido de esa página web abierta en una nueva variable llamada contenidoWeb.\n\nAsegúrate de que puedes reconocer las variables (hay 3), los módulos (1), los métodos (2) y los parámetros (1) antes de seguir adelante.\n\nAl ejecutar el programa, te darás cuenta que en el panel de salida se muestra algo etiquetado en HTML:\n\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\"&gt;\n&lt;head&gt;\n\t&lt;title&gt;Browse - Central Criminal Court&lt;/title&gt;\n\t&lt;meta http-equiv=\"content-type\" content=\n\n\nEl contenido del proceso judicial está mucho más adelante en la página. Lo que vemos aquí es solamente en código HTML de la parte superior del documento. Esto no es lo que necesitamos para una investigación histórica, pero no te preocupes: en breve aprenderás cómo quitar el exceso de etiquetas y obtener el contenido que estás buscando.\n\nGuardar una copia local de una página web\n\nDado que ya sabes lo suficiente acerca de escribir en archivos, resulta bastante sencillo modificar el programa anterior para que escriba el contenido de la cadena de texto contenidoWeb en un archivo local de nuestra computadora en vez de en el panel de salida. Copia el siguiente programa en Komodo Edit, guárdalo como guardar-paginaweb.py y ejecútalo. Abre en tu navegador el archivo creado en tu disco duro (obo-t17800628-33.html) para confirmar que la copia que guardaste es igual a la que está en línea.\n\n# guardar-paginaweb.py\n\nimport urllib.request, urllib.error, urllib.parse\n\nurl = 'http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&amp;div=t17800628-33'\n\nrespuesta = urllib.request.urlopen(url)\ncontenidoWeb = respuesta.read()\n\nf = open('obo-t17800628-33.html', 'wb')\nf.write(contenidoWeb)\nf.close\n\n\nAhora, si tu puedes guardar un solo archivo así de fácil, ¿es posible escribir un programa que te permita descargar un puñado de archivos? ¿Es posible incrementar la cantidad de IDs de los juicios y obtener copias de todos ellos en una sola descarga? Efectivamente. Puedes aprender cómo hacerlo en la lección Downloading Multiple Files using Query Strings, que te recomendamos ver una vez completadas las lecciones introductorias de esta serie.\n\nLecturas sugeridas\n\n\n  Lutz, Mark. “Ch. 4: Introducing Python Object Types”, Learning\nPython (O’Reilly, 1999).\n\n\nSicronización de código\n\nPara seguir a lo largo de las lecciones futuras es importante que tengas los archivos correctos y programas en el directorio “programming-historian” de tu disco duro. Al final de cada lección puedes descargar el archivo zip “python-es-lecciones” para asegurarte que tienes el código correcto.\n\n\n  python-es-lecciones1.zip (zip)\n\n\n\nEsta lección muestra qué es un Localizador de recursos uniforme (Uniform Resource Locator = URL) y explica cómo utilizar Python para descargar y guardar los contenidos de una página web en tu disco duro.\n\n"
  },


  {
    "id": 42,
    "url": "http://localhost:4000/es/lecciones/transformacion-datos-xml-xsl",
    "title": "Transformación de datos con XML y XSL para su reutilización",
    "body": "\nTransformación de datos con XML y XSL para su reutilización\n{% include toc.html %}\n\nIntroducción\n\nImagina que, con un día de antelación, un compañero de trabajo te llama por teléfono pidiéndote que lo sustituyas en un seminario centrado en Relaciones de esclavos en el Nuevo Mundo. Decides recopilar una selección de fuentes primarias para trabajar en clase, encuentras algunas páginas web y algunos libros con buenos materiales, pero escanearlo todo o copiar y pegar la información en un documento nuevo conlleva demasiado tiempo; además, el estilo de la bibliografía difiere y las citas son inconsistentes, así que empiezas a preguntarte si reunir todo este material tiene sentido. Una página web te permite descargar una versión XML de todo el material, pero son tantos los registros y hay tantos metadatos que no es fácil encontrar rápidamente la información que deseas.\n\nO quizás… has encontrado una edición antigua de Inscriptions of Roman Tripolitania (1952) y te gustaría hacer un análisis estadístico de la aparición de ciertas frases en determinados contextos. Por suerte, King’s College London ha publicado una versión digital del texto con imágenes, traducciones e información sobre la localización de las inscripciones. Puedes explorar el material con la función “Buscar en la página”, pero editar la información en el formato necesario para el análisis requiere tiempo.\n\nImagina ahora que estás empezando un proyecto nuevo consistente en el estudio de un catálogo de subastas de libros del siglo XVII; empiezas registrando los detalles de publicación y la lista de subastas en un documento Word o Excel. Un mes más tarde el vicerrector de tu universidad te invita a dar una charla. El decano de tu facultad sugiere que hagas unas diapositivas o notas para facilitar la comprensión del proyecto. Tienes ya algunas conclusiones preliminares, pero los datos están dispersos en varios lugares y unificar el formato de la información precisa más tiempo del que dispones.\n\nEn las tres situaciones descritas, conocer cómo funciona XML y XSL te habría ahorrado tiempo y esfuerzo. Con este tutorial aprenderás a convertir un conjunto de datos históricos procedentes de una base de datos XML1 (ya sea un solo documento o varios documentos interconectados) en otros formatos más adecuados para presentar (tablas, listas) o exponer información (párrafos). Tanto si quieres filtrar información contenida en una base de datos como si quieres añadir encabezados o paginación, XSL ofrece a los historiadores la posibilidad de reconfigurar datos a fin de acomodarlos a los cambios de la investigación o a las necesidades de la publicación.\n\nEste tutorial cubre los siguientes aspectos:\n\n\n  Editores: herramientas necesarias para crear hojas de estilo XSL\n  Procesadores: herramientas necesarias para aplicar las instrucciones de la hoja de estilo XSL a los archivos XML\n  Elección y preparación de datos XML: cómo conectar la base de datos con las instrucciones de transformación XSL\n\n\nEl tutorial también sirve como guía para crear las transformaciones más comunes:\n\n\n  Imprimir valores: cómo imprimir o presentar los datos\n  repeticiones for-each (repetir operaciones en bucle): cómo presentar datos concretos en cada uno de los objetos o registros existentes\n  Ordenar resultados: cómo presentar los datos en un determinado orden\n  Filtrar resultados: cómo seleccionar qué objetos o registros se quieren presentar\n\n\n¿Qué es XML?\n\nEl lenguaje de marcas extensible (eXtensible Markup Language, abreviado generalmente como XML) es un método muy flexible de codificación y estructuración de datos. Al contrario que el lenguaje de marcas de hipertexto (Hypertext Markup Language, abreviado como HTML), que tiene un vocabulario pre-determinado, XML es extensible; es decir, puede expandirse para incluir las etiquetas necesarias para, por ejemplo, identificar tantas secciones y sub-secciones como quieras.\n\nUna base de datos puede componerse de uno o más documentos XML con una estructura básica. Cada sección del archivo está contenida en un elemento, es decir, una categoría o nombre con el que se identifica el tipo de datos manejados. Así pues, como si fueran Matrioshkas, cada nivel de elementos está contenido en otro. El elemento raíz contiene el documento entero; y cada uno de los elementos contenidos en éste se considera un hijo (child). Análogamente, el elemento que contiene un elemento hijo se llama elemento padre (parent).\n\n&lt;raíz&gt;\n\t&lt;padre&gt;\n\t\t&lt;hijo&gt;&lt;/hijo&gt;\n\t&lt;/padre&gt;\n&lt;/raíz&gt;\n\n\nSegún las reglas de la base de datos, los elementos pueden tener valores (textuales o numéricos) o bien un número determinado de elementos hijos.\n\n&lt;raíz&gt;\n\t&lt;padre&gt;\n\t\t&lt;hijo_1&gt;valor&lt;/hijo_1&gt;\n\t\t&lt;hijo_2&gt;valor&lt;/hijo_2&gt;\n\t\t&lt;hijo_3&gt;valor&lt;/hijo_3&gt;\n\t&lt;/padre&gt;\n&lt;/raíz&gt;\n\n\nTambién pueden tener atributos, es decir, algo así como los metadatos del elemento. Los atributos ayudan a distinguir, por ejemplo, entre distintos tipos de valores sin tener que crear un nuevo tipo de elemento.\n\n&lt;raíz&gt;\n\t&lt;nombre&gt;\n\t\t&lt;apellido&gt;García&lt;/last&gt;\n\t\t&lt;nombre tipo=\"formal\"&gt;Cristina&lt;/first&gt;\n\t\t&lt;nombre tipo=\"informal\"&gt;Cris&lt;/first&gt;\n\t&lt;/nombre&gt;\n&lt;/raíz&gt;\n\n\nSi tienes acceso a una base de datos XML o bien almacenas datos en una, puedes utilizar XSL para ordenar, filtrar y presentar la información en (casi) todas las maneras imaginables. Por ejemplo, se podría abrir un archivo XML como Word (.docx) o Excel (.xslx), inspeccionarlo y, a continuación, eliminar la información añadida por Microsoft por defecto como la localización geográfica del creador del documento. Si quieres saber más sobre XML, te recomendamos leer una explicación más detallada sobre su estructura y uso en las Humanidades en la página web de la Text Encoding Initiative.\n\n¿Qué es XSL?\n\nEl lenguaje de hojas de estilo extensibles (eXtensible Stylesheet Language, abreviado como XSL) es el complemento natural de XML. En términos generales, proporciona instrucciones de presentación y formato, es decir, equivale a las Hojas de estilo en cascada (Cascading Stylesheets o CSS) necesarias para presentar archivos HTML. Ambos lenguajes permiten transformar el texto plano en un formato de texto enriquecido, así como determinar su diseño y apariencia tanto en pantalla como impreso, sin tener que alterar los archivos originales. En un nivel más avanzado, también permiten ordenar y filtrar la información según un criterio concreto y crear o visualizar otros datos derivados a partir del archivo original.\n\nAl separar los datos (XML) de las instrucciones de formato (XSL), es posible refinar y modificar la presentación sin correr el riesgo de corromper la estructura de los archivos. Asimismo, podemos crear más de una hoja de estilo de tal modo que se utilicen en función del objetivo para transformar un solo archivo fuente. A la práctica, esto significa que solo hay que actualizar los datos en un solo lugar y luego exportar distintos documentos.\n\nAlgunos programas necesarios o recomendados\n\nEditores\n\nUna de las ventajas de guardar datos en formato de texto sencillo es la facilidad de encontrar programas para visualizarlos y manipularlos. Para los propósitos de este tutorial, se recomienda utilizar un editor de texto sencillo como Notepad (Windows) o TextEdit (MAC OS). En cambio, no recomendamos el uso de procesadores de texto WYSIWYG (what you see is what you get, es decir, lo que ves es lo que obtienes) como Microsoft Word porque suelen añadir caracteres incompatibles con ASCII. Por ejemplo, el uso de comillas tipográficas aborta el proceso de transformación XSL. Este tutorial asume el uso de editores como Notepad o TextEdit.\n\nAunque estos editores proporcionan todo lo necesario, se puede utilizar también un editor más avanzado como Notepad++ o Atom.2 Estos editores mantienen el formato de texto sencillo, pero ofrecen esquemas de colores distintos (verde sobre negro o marrón sobre beige), así como la función de esconder secciones o de comentar trozos de código para desactivarlo de manera temporal. Para los usuarios más avanzados, que precisen realizar transformaciones de naturaleza compleja, se recomienda el uso de OxygenXML.\n\nProcesadores\n\nTras escoger nuestro editor favorito, a continuación hace falta conseguir un procesador de XML. Hay tres maneras de utilizar una hoja de estilo para transformar documentos XML:\n\n  mediante la línea de comandos;\n  mediante un transformador incluido en un programa o editor de XML;\n  o bien mediante el navegador web.\n\n\nLos navegadores Chrome y Safari oponen algunas resistencias de seguridad para realizar estas transformaciones; en cambio, otros navegadores como Internet Explorer y Firefox incluyen un procesador XSL 1.0 con el que es posible realizar todas las operaciones cubiertas por este tutorial. Antes de seguir adelante, te recomendamos descargar e instalar uno de estos dos navegadores, si aún no lo tienes en tu ordenador.\n\nCómo elegir y preparar datos en XML\n\nPara empezar a transformar XML, primero es necesario obtener un archivo bien formado.3 Muchas bases de datos históricas disponibles en línea están modeladas en XML y, a veces, ofrecen sus datos en abierto. Para realizar este tutorial utilizaremos la base de datos Scissors and Paste.\n\nLa base de datos Scissors and Paste Database es una colección colaborativa, en continuo crecimiento, que contiene noticias procedentes de periódicos británicos e imperiales de los siglos XVIII y XIX. Los dos objetivos originales del proyecto eran facilitar la comparación de reediciones aparecidas en distintos periódicos y detectar temas similares en distintas publicaciones inglesas. Como muchas bases de datos XML, Scissors and Paste contiene datos (el texto), información sobre el formato (como itálicas o justificación de los párrafos) y metadatos.4 Los metadatos recogen la paginación de la noticia, la fecha de impresión, algunos detalles adicionales sobre el periódico, los temas principales y una lista con las personas y lugares mencionados.\n\nEn 2015, la base de datos alcanzó las 350 noticias con metadatos. Aunque quizás algunos investigadores quieran acceder a toda la información, la mayoría están interesados en una porción de los datos como el año de publicación o el tema principal de la noticia. Gracias al uso de XSL, es posible filtrar la información innecesaria u ordenar el material de un modo que sea más útil para investigar. Por ejemplo, como imaginábamos en la introducción, quizás nos sería de utilidad preparar una lista de publicaciones o bien una tabla con las fechas, los títulos y la paginación de las noticias humorísticas contenidas en la base de datos. En ambos casos, podemos obtener los resultados sin muchos problemas utilizando hojas de estilo XSL.\n\nPara empezar a trabajar con la base de datos Scissors and Paste, descarga los archivos desde aquí. Abre el archivo ZIP para obtener la carpeta llamada scissorsandpaste-master. Puedes extraer los documentos utilizando un programa de descompresión, haciendo doble clic (en Mac) o bien arrastrando y dejando el directorio en el escritorio de tu ordenador.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-1.png” caption=”Figura 1: Cómo descargar los archivos” %}\n\nLa carpeta contiene tres documentos principales:\n\n\n  TEISAP.XML: el archivo XML\n  Transformers (Transformadores): una colección de hojas de estilo XSL\n  Outputs: archivos derivados de la base de datos utilizando las hojas de estilo XSL\n\n\nTambién encontrarás los siguientes documentos:\n\n\n  Un archivo Template (Plantilla) para los investigadores que quieran contribuir con más noticias\n  Un archivo README (Léeme) con información sobre la base de datos\n  Un archivo Cite (Cita), que explica cómo citar la base de datos\n  Un archivo License (Licencia) con los términos de uso\n\n\nTras finalizar este tutorial, te recomendamos explorar las otras hojas de estilo XSL contenidas en la carpeta Transformers y los archivos generados con elllas; de esta manera, podrás descubrir otras posibilidades y crear archivos adaptados a tus necesidades.\n\nLa información contenida en el archivo TEISAP.XML ha sido codificada según las recomendaciones de la Text-Encoding Initiative (TEI), gran parte de la cual corresponde a los metadatos. Sin embargo, en este tutorial utilizaremos una versión simplificada que cubre los datos históricos más importantes.5\n\nVe a la carpeta Outputs y continúa hasta la carpeta XML. Dentro encontrarás un directorio llamado Simplified; copia o traslada el archivo SAPsimple_es.xml a tu escritorio.\n\nAbre el archivo SAPsimple_es.xml con tu navegador favorito y examina su contenido. Puedes abrirlo eligiendo la opción Abrir como, arrastrando el documento al icono del navegador de tu escritorio o con un editor de texto sencillo como Notepad o TextEdit.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-2.png” caption=”Figura 2: Cómo visualizar el archivo XML” %}\n\nLa primera línea del archivo XML es &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;; esta línea indica la versión de XML utilizada (1.0) y el método de codificación del texto (UTF-8). En la segunda línea se encuentra la etiqueta de apertura &lt;raíz&gt; y, al final, la etiqueta de cierre &lt;/raíz&gt;. Esto quiere decir que &lt;raíz&gt;, como su nombre indica, es el elemento raíz que contiene todos los artículos de periódicos etiquetados con el elemento &lt;registro&gt;. Antes de continuar, localiza la etiqueta de cierre &lt;/registro&gt;.\n\nDentro de cada registro hay varios elementos hijos. La Text Encoding Initiative permite anidar centenares de elementos para modelar datos de muy distinta naturaleza. Además, la gracia de XML es que puedes dar nombre a tus elementos nuevos con bastante libertad. En la base de datos Scissors and Paste los registros contienen los siguientes:\n\n\n  identificador: número de identificación del registro\n  título: título del periódico\n  ciudad: ciudad del periódico\n  provincia: provincia o región del periódico\n  país: país del periódico\n  fecha: fecha del artículo en formato ISO6\n  año: año de la publicación\n  mes: mes de la publicación\n  día: día de la publicación\n  secciónPalabrasClave: sección que contiene las palabras claves\n  palabraClave: palabra clave que describe el artículo\n  titular: titular del artículo (opcional)\n  texto: sección que contiene el artículo\n  p: párrafo de texto\n\n\nHe aquí, pues, la tipología de datos que utilizaremos para crear otros archivos derivados. A fin de realizar una transformación con el navegador, hay que añadir una referencia a la hoja de estilo en el archivo XML. Así pues, abre SAPsimple_es.xml con un editor de texto e inspecciona el contenido.\n\nAñade una línea nueva debajo de &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;.  En esta nueva línea, escribe\n\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"miestilo.xsl\"?&gt;\n\n\ny luego guarda el archivo.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-3.png” caption=”Figura 3: Cómo añadir una referencia a la hoja de estilo en un archivo XML” %}\n\nLa línea recién creada apunta hacia el archivo XSL que en el apartado siguiente vamos a crear. De esta manera, se convertirá en la hoja de estilo con la transformación por defecto que debemos aplicar al documento XML. El nombre del archivo no importa, pero asegúrate de que coincide con el valor del enlace (href=\"miestilo.xsl\") contenido en la instrucción xml-stylesheet.\n\nCómo crear y probar las hojas de estilo XSL\n\nHa llegado la hora de crear una hoja de estilo XSL. Para ello, sitúate en el editor de texto, crea un archivo nuevo y guárdalo con el nombre miestilo.xsl (o bien con el nombre que hayas escogido en el paso anterior). Antes de continuar, asegúrate de que el archivo se ha guardado en el mismo directorio que contiene el archivo XML (por ejemplo, en tu Escritorio o bien en la carpeta Simplified).\n\nAñade las dos líneas siguientes al inicio del archivo XSL:\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"text\"/&gt;\n\n\nCon la primera línea declaramos que se trata de la versión 1.0 de XSL y que el uso del espacio de nombres (namespace, en inglés) es el estándar establecido por el Consorcio World Wide Web, cuya URI (Uniform Resource Identifier) figura en la instrucción. La segunda línea indica al procesador que queremos generar un archivo de textos simple; como alternativa, se podría escribir “xml” o “html”.\n\nCada vez que se abre un elemento &lt;elemento&gt;, es necesario cerrar con la etiqueta &lt;/elemento&gt;. De lo contrario, se producirá un error. Por tanto, hay que añadir al final del archivo lo siguiente:\n\n&lt;/xsl:stylesheet&gt;\n\n\nA continuación, escribiremos la instrucción principal para dar un formato adecuado al archivo de texto sencillo. En una línea nueva, inmediatamente después de &lt;xsl:output method=\"text\"/&gt; escribe\n\n&lt;xsl:template match=\"/\"&gt;\n&lt;/xsl:template&gt;\n\n\nDentro de estas dos etiquetas pondremos todas las instrucciones relativas al formato deseado.\n\nEl atributo match (que puede traducirse como hacer coincidir o emparejar) contiene una barra lateral / porque queremos que la instrucción se aplique a todo el contenido del archivo XML. Podríamos haber escrito “raíz” para indicar que solo queremos utilizar los datos contenidos en dicho elemento, pero esta preferencia podría crear problemas posteriores, así que es mejor utilizar la barra lateral / en la instrucción principal.\n\nTras esto, el archivo debería tener este aspecto:\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"text\"/&gt;\n&lt;xsl:template match=\"/\"&gt;\n&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nGuarda el archivo. En adelante, no olvides guardar los cambios realizados.\n\n\n  Nota de la autora: si utilizas TextEdit, no podrás guardar el archivo en formato XSL. Guárdalo como texto sencillo (.txt) y luego cierra el archivo. A continuación, localiza el archivo en tu ordenador y cámbiale el nombre sustituyendo la extensión .txt por .xsl. Abre el archivo con TextEdit y continúa.\n\n\nDentro de la instrucción que acabamos de crear, escribe &lt;xsl:value-of select=\"raíz\"/&gt;. No es necesario introducir una línea nueva, pero si lo haces será más fácil de leer. Te habrás dado cuenta de que no hemos incluido una etiqueta de cierre; esto se debe a que la instrucción &lt;xsl:value-of select=\"raíz\"/&gt; no tiene contenido y ya está cerrada gracias a la barra lateral  / situada al final.\n\nTras guardar el archivo, ábrelo con un navegador (Internet Explorer o Firefox) y utilízalo para transformar el archivo XML. La manera más sencilla de hacer esto es arrastrando el archivo XML (SAPsimple_es.xml) a la ventana del navegador; también es posible abrirlo mediante la pestaña Archivo/Abrir Archivo…\n\nEl resultado debería ser el texto con los saltos de línea existentes, peor sin los elementos XML, tal y como se percibe en la imagen de abajo.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-4.png” caption=”Figura 4: Output con texto inicial” %}\n\nSi, por el contrario, lo que obtienes es un texto sin formato, o bien un mensaje de error, retrocede y revisa el archivo XML y la hoja de estilo XSL. Es posible que un error (quizás tipográfico) haya impedido al procesador realizar la transformación necesaria para presentar el texto como deseamos.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-5.png” caption=”Figura 5: Output sin estructurar, es decir, erróneo” %}\n\nSi el resultado obtenido es satisfactorio, es decir, si has conseguido generar un texto sencillo con saltos de línea y márgenes, te recomendamos organizar tu escritorio para que puedas moverte con agilidad entre el editor de texto y el navegador. Por ejemplo, puedes disminuir la ventana del navegador hasta que quepa en una mitad de la pantalla y luego hacer lo mismo con el editor.\n\n{% include figure.html filename=”transformacion-datos-xml-xsl-6.png” caption=”Figure 6: Cómo organizar tu lugar de trabajo” %}\n\nCómo poblar un output\n\nLa línea de código &lt;xsl:value-of select=\"raíz\"/&gt; imprime la base de datos entera en formato de texto sencillo. Si examinas los componentes de la línea, sabrás por qué:\n\n\n  \n    xsl:value-of (literalmente, valor-de): es una instrucción que sirve para imprimir el valor de un elemento; es decir, el texto contenido entre la etiqueta de inicio y de cierre.\n  \n  \n    select=”raíz” (en español, selecciona=”raíz”): esta instrucción indica el elemento que contiene el valor que debería imprimirse. A menos que declares lo contrario, si apuntas hacia un elemento padre (parent) el procesador también imprimirá el valor de los elementos contenidos (children). Por tanto, al apuntar a raíz obtenemos el valor de identificador, título, etc.\n  \n\n\nCómo imprimir valores\n\nSi quieres imprimir el valor de un elemento en concreto, simplemente hay que sustituir “raíz” por el nombre del elemento. Por ejemplo, en nuestra hoja de estilo, reemplaza raíz por título. Guarda el archivo y refresca el navegador (normalmente, con ctrl+F5 or cmd+r) para ver los cambios.\n\nNo ha funcionado, ¿verdad? No debería porque no hemos dado al procesador todas las instrucciones que necesitaba.\n\nPadres e hijos\n\nEl elemento título no está situado en el nivel más alto de la jerarquía, así que debemos explicarle al procesador cómo llegar hasta él. El lenguaje con que se hace esto se conoce como XPATH y funciona de una manera similar al modo en que se estructuran las rutas de un ordenador. Así pues, sustituye título por raíz/registro/título:\n\n&lt;xsl:value-of select=\"raíz/registro/título\"/&gt;\n\n\nGuarda y refresca el navegador.\n\nAhora deberías obtener “Caledonian Mercury”, es decir, el primer título del documento XML. Sin embargo, tenemos más de 300 elementos título. ¿Qué ha ocurrido? Es muy sencillo: como no hemos especificado cuál título queríamos imprimir, el procesador ha asumido que solo nos interesaba el primero.\n\nRealizar repeticiones con for-each\n\nPara un ser humano quizás parezca normal querer el valor contenido en todos los elementos título, pero el procesador no sabe esto por defecto. Para remediar la situación, debemos repetir la operación en forma de bucle.\n\nUna repetición en forma de bucle indica al procesador que debería procesar todo el archivo y llevar a cabo la transformación indicada cada vez que la condición sea satisfactoria.\n\nAsí pues, crea una nueva línea después de &lt;xsl:template match=\"/\"&gt; e inserta &lt;xsl:for-each select=\"raíz/registro\"&gt;. Esta instrucción le indica al procesador que para cada registro situado dentro del elemento raíz debe realizar una determinada acción.\n\nA continuación, elimina raíz/registro de la instrucción &lt;xsl:value-of&gt;. Es decir, debería quedar solamente título porque esta operación ya está contextualizada mediante raíz/registro. Tras &lt;xsl:value-of&gt;, hay que terminar la operación con la etiqueta de cierre &lt;/xsl:for-each&gt;\n\nEn resumen, el archivo resultante debiera ser:\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"text\"/&gt;\n\n&lt;xsl:template match=\"/\"&gt;\n\n    &lt;xsl:for-each select=\"raíz/registro\"&gt;\n            &lt;xsl:value-of select=\"título\"/&gt;\n    &lt;/xsl:for-each&gt;\n\n&lt;/xsl:template&gt;\n\n&lt;/xsl:stylesheet&gt;\n\n\nAhora la instrucción template tiene tres líneas de código:\n\n\n  Una etiqueta de inicio para la repetición for-each\n  Una instrucción para que el valor de título se imprima\n  Una etiqueta de cierre para for-each\n\n\nGuarda el archivo y actualiza la ventana del navegador. Deberías obtener una masa de líneas de texto con el valor de cada uno de los elementos title. Puedes arreglar esto indicando al procesador que añada una nueva línea tras cada entrada.\n\nAl final de la línea que contiene value-of, hay que añadir &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt; para crear un salto de línea. &amp;#xA; es el código ISO 10646 con el que se representa un salto de línea; con el elemento &lt;xsl:text&gt; se declara que queremos imprimir el valor como texto sencillo.\n\nEn función del output que debamos generar, algunos caracteres especiales, el número de espacios o bien los saltos de línea a veces no se mantienen en el archivo resultante. Es por eso que se recomienda utilizar el elemento &lt;text&gt; para asegurarse de que el valor impreso no se ve alterado durante la transformación.\n\nGuarda el archivo y refresca el navegador para ver los cambios. Ahora deberías ver impreso el valor de los títulos de todos los registros contenidos en el documento.\n\nEjercicio A\n\n\n  Nota de la autora: las soluciones (posibles, porque hay más de una estrategia) se encuentran al final del tutorial.\n\n\nGenera un inventario de los registros que contenga el identificador, el título y la fecha.\n\nEjercicio B\n\nGenera un documento que contenga el texto de todos los artículos precedido por el número de identificador entre paréntesis cuadrados.\n\nAtributos\n\nNo todos los datos corresponden a los valores de los elementos. Algunos datos, en cambio, se almacenan como valores de los atributos de elementos. Por ejemplo, el elemento fecha tiene un atributo llamado cuándo que contiene el valor de la fecha del artículo.\n\n&lt;fecha cuándo=\"1789-01-05\"&gt;\n\n\nPara obtener el valor contenido en cuándo hay que hacer referencia a este atributo utilizando la expresión @cuándo.\n\n&lt;xsl:value-of select=\"fecha/@cuándo\"/&gt;\n\n\nEjercicio C\n\nCrea un inventario de registros en el que se liste el título del periódico seguido de la fecha de publicación.\n\nCómo ordenar los resultados\n\nEl archivo XML fue escrito según la información se iba recolectando, sin organizar los registros por fecha o título. A fin de organizarlos, podemos añadir la instrucción &lt;xsl:sort&gt; (literalmente, ordena o clasifica) al inicio de la repetición en bucle, es decir, inmediatamente después de &lt;xsl:for-each&gt;. Esta instrucción tiene varios atributos opcionales que modifican cómo los datos se ordenan en el documento resultante:\n\n\n  select (selecciona): el nombre del elemento que sirve para ordenar los datos\n  order (ordena): define si los datos se ordenan de manera ascendiente (el valor del atributo debe ser ascending, en inglés) o descendiente (el valor debe ser descending, en inglés)\n  data-type (tipo-de-dato): informa al procesador si los datos son textuales (textual) o numéricos (number)\n\n\nPor ejemplo, podemos escribir la siguiente instrucción para ordenar los datos a partir del elemento identificador en orden inverso:\n\n&lt;xsl:sort select=\"identificador\" order=\"descending\" data-type=\"number\"/&gt;\n\n\nEs decir, a modo de aclaración, se puede ordenar los resultados utilizando un elemento que no se desea imprimir en el output.\n\nEjercicio D\n\nGenera un documento con el texto de los artículos ordenados de más a menos recientes. Para ello, utiliza la función &lt;xsl:sort&gt; y trata las fechas como si fueran texto (text).\n\nCómo filtrar los resultados\n\nHasta el momento hemos impreso todos los registros contenidos en el documento XML. Ahora bien, si solo queremos seleccionar unos cuantos, necesitaremos filtrar los resultados mediante condiciones. Esto se consigue utilizando el elemento &lt;xsl:if&gt; (literalmente, si) y añadiendo la condición deseada en el atributo @test. Si el registro cumple con la condición, el procesador llevará a cabo la instrucción contenida en &lt;xsl:if&gt;. Si no la cumple, lo ignorará y seguirá adelante.\n\nAsí, para imprimir los identificadores de los registros de 1815 podemos escribir la siguiente plantilla\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n    &lt;xsl:output method=\"text\"/&gt;\n\n    &lt;xsl:template match=\"/\"&gt;\n        &lt;xsl:for-each select=\"raíz/registro\"&gt;\n            &lt;xsl:if test=\"fecha/año='1815'\"&gt;\n                &lt;xsl:value-of select=\"identificador\"/&gt;\n                &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n            &lt;/xsl:if&gt;\n        &lt;/xsl:for-each&gt;\n    &lt;/xsl:template&gt;\n\n&lt;/xsl:stylesheet&gt;\n\n\nSi queremos excluir el año 1815, en cambio, utilizaremos la expresión fecha/año != '1815' donde != significa que no es igual a.\n\nEjercicio E\n\nA modo de recapitulación, crea una lista de registros fechados a partir de 1789 ordenada del más reciente al más antiguo y que contenga el identificador, el título y la fecha separados por comas; cada registro debiera presentarse tras un salto de línea.\n\nCuando estés satisfecho con los resultados, guarda el archivo mediante la función Guardar como… del navegador con el nombre sap_itf.csv. De esta manera, obtendrás un archivo con los valores separados por comas que puede abrirse y manipularse como una hoja de cálculo con Excel o CALC.\n\nConclusión\n\nEsta lección ha cubierto el funcionamiento principal de XSL. Con la información proporcionada, resulta fácil generar varios outputs en distintos formatos: texto sencillo, valores separados por coma o por tabulaciones, o Markdown. También sería posible crear páginas web cambiando el método &lt;xsl:output&gt; a html y envolviendo las instrucciones &lt;xsl:value-of&gt; con las etiquetas HTML pertinentes.\n\nExisten muchas más instrucciones con las que transformar documentos XML a otros formatos y estructuras.7 Aunque algunas transformaciones más avanzadas requieren un procesador 2.0, las explicaciones de este tutorial satisfacen las necesidades más comunes de los historiadores. Para los usuarios más experimentados, se recomienda explorar el directorio transformers de la base de datos Scissors and Paste a fin de ver más ejemplos de cómo transformar datos estructurados con lenguaje XML.\n\nSoluciones\n\nIntroducción (Fuentes primarias)\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"html\"/&gt;\n&lt;xsl:template match=\"/\"&gt;\n    &lt;html&gt;\n        &lt;body&gt;\n\n            &lt;xsl:for-each select=\"raíz/registro\"&gt;\n\n                &lt;xsl:if test=\"secciónPalabrasClave/palabraClave = 'slave insurrections'\"&gt;\n\n                    &lt;h2&gt;\n                        &lt;i&gt;&lt;xsl:value-of select=\"título\"/&gt;&lt;/i&gt;, &lt;xsl:value-of select=\"substring(fecha/@cuándo, 9, 2)\"/&gt;\n                        &lt;xsl:text&gt;&amp;#32;&lt;/xsl:text&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '01'\"&gt;January&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '02'\"&gt;February&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '03'\"&gt;March&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '04'\"&gt;April&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '05'\"&gt;May&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '06'\"&gt;June&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '07'\"&gt;July&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '08'\"&gt;August&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '09'\"&gt;September&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '10'\"&gt;October&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '11'\"&gt;November&lt;/xsl:if&gt;\n                        &lt;xsl:if test=\"substring(fecha/@cuándo, 6, 2) = '12'\"&gt;December&lt;/xsl:if&gt;\n                        &lt;xsl:text&gt;&amp;#32;&lt;/xsl:text&gt;\n                        &lt;xsl:value-of select=\"substring(fecha/@cuándo, 1, 4)\"/&gt;\n                        &lt;xsl:text&gt;&amp;#xA;&amp;#xA;&lt;/xsl:text&gt;\n                    &lt;/h2&gt;\n\n                    &lt;xsl:for-each select=\"texto/p\"&gt;\n                        &lt;p&gt;\n                            &lt;xsl:value-of select=\".\"/&gt;\n                        &lt;/p&gt;\n                    &lt;/xsl:for-each&gt;\n\n                &lt;/xsl:if&gt;\n\n            &lt;/xsl:for-each&gt;\n\n        &lt;/body&gt;\n    &lt;/html&gt;\n&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nEjercicio A\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"text\"/&gt;\n&lt;xsl:template match=\"/\"&gt;\n    &lt;xsl:for-each select=\"raíz/registro\"&gt;\n        &lt;xsl:value-of select=\"identificador\"/&gt;, &lt;xsl:value-of select=\"título\"/&gt;, &lt;xsl:value-of select=\"fecha/año\"/&gt;&lt;xsl:text&gt;&amp;#xA;\t\t&lt;/xsl:text&gt;\n    &lt;/xsl:for-each&gt;\n&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nEjercicio B\n\n &lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n    &lt;xsl:output method=\"text\"/&gt;\n    &lt;xsl:template match=\"/\"&gt;\n        &lt;xsl:for-each select=\"raíz/registro\"&gt;\n            [&lt;xsl:value-of select=\"identificador\"/&gt;]\n            &lt;xsl:value-of select=\"texto\"/&gt;\n        &lt;/xsl:for-each&gt;\n    &lt;/xsl:template&gt;\n\t&lt;/xsl:stylesheet&gt;\n\n\nPara eliminar la sangría del texto, necesitarás hacerte cargo directo del espaciado introduciendo saltos de línea tras el identificador y cada párrafo. En el segundo bucle, utilizaremos .  para referirnos al contenido de p en select=\"texto/p\". Si pusiéramos una p el procesador interpretaría que queremos recuperar el contenido de texto/p/p, lo cual no existe.\n\n&lt;xsl:stylesheet version=\"2.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n\t&lt;xsl:output method=\"text\"/&gt;\n\t&lt;xsl:template match=\"/\"&gt;\n    \t&lt;xsl:for-each select=\"raíz/registro\"&gt;\n        \t&lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;[&lt;xsl:value-of select=\"identificador\"/&gt;]&lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n        \t&lt;xsl:for-each select=\"texto/p\"&gt;\n            \t&lt;xsl:value-of select=\".\"/&gt;\n            &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n        \t&lt;/xsl:for-each&gt;\n    \t&lt;/xsl:for-each&gt;\n\t&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nEjercicio C\n\n   &lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n    &lt;xsl:output method=\"text\"/&gt;\n    &lt;xsl:template match=\"/\"&gt;\n        &lt;xsl:for-each select=\"raíz/registro\"&gt;\n            &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n            \t&lt;xsl:value-of select=\"título\"/&gt;\n            &lt;xsl:text&gt;&amp;#32;&lt;/xsl:text&gt;\n            &lt;xsl:value-of select=\"fecha/@cuándo\"/&gt;\n        &lt;/xsl:for-each&gt;\n    &lt;/xsl:template&gt;\n\t&lt;/xsl:stylesheet&gt;\n\n\n&amp;#32; es el código HEX equivalente a un espacio. Aunque es posible añadir un espacio en la instrucción, es mejor utilizar el código HEX para asegurarnos que se mantendrá en el documento generado. También es posible utilizar una coma o cualquier otro separador.\n\nEjercicio D\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n&lt;xsl:output method=\"text\" /&gt;\n&lt;xsl:template match=\"/\"&gt;\n    &lt;xsl:for-each select=\"raíz/registro\"&gt;\n        &lt;xsl:sort select=\"fecha/@cuándo\" order=\"ascending\" data-type=\"text\"/&gt;\n        &lt;xsl:for-each select=\"texto/p\"&gt;\n            &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;&lt;xsl:value-of select=\".\"/&gt;\n        &lt;/xsl:for-each&gt;\n        &lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n    &lt;/xsl:for-each&gt;\n&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nEjercicio E\n\n&lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n\t&lt;xsl:output method=\"text\"/&gt;\n\t&lt;xsl:template match=\"/\"&gt;\n\t\t&lt;xsl:for-each select=\"raíz/registro\"&gt;\n\t\t\t&lt;xsl:sort select=\"fecha/@cuándo\" order=\"descending\" data-type=\"text\"/&gt;\n\t\t\t&lt;xsl:if test=\"fecha/año = '1789'\"&gt;\n\t\t\t\t&lt;xsl:value-of select=\"identificador\"/&gt;, &lt;xsl:value-of select=\"título\"/&gt;, &lt;xsl:value-of select=\"fecha/@cuándo\"/&gt;&lt;xsl:text&gt;&amp;#xA;&lt;/xsl:text&gt;\n\t\t\t&lt;/xsl:if&gt;\n\t\t&lt;/xsl:for-each&gt;\n\t&lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n\n\nBibliografía recomendada por el traductor\n\n\n  Hunter, David et al. Beginning XML. Indianapolis: Wiley Publishing, 2007 (cuarta edición). Impreso.\n  Riley, Jenn. Understanding Metadata: What is Metadata, and What is For? NISO, 2017. Web.\n  Tennison, Jeni. Beginning XSLT 2.0. From Novice to Professional. Nueva York: Apress, 2005. Impreso.\n\n\nNotas del traductor\n\n\n  \n    \n      Según Wikipedia, una base de datos XML es un programa “que da persistencia a datos almacenados en formato XML. Estos datos pueden ser interrogados, exportados y serializados”. Pueden distinguirse dos tipos: bases de datos habilitadas (por ejemplo, una basee de datos relacional clásica que acepta XML como formato de entrada y salida) y bases de datos nativas (es decir, que utilizan documentos XML como unidad de almacenamiento) como eXist o BaseX. En este tutorial, sin embargo, la autora, a menudo, no distingue entre el continente (el programario) y el contenido de la base de datos XML (los documentos). &#8617;\n    \n    \n      Otros editores recomendables son Sublime Text y Visual Studio Code. &#8617;\n    \n    \n      Text Encoding Initiative considera que un documento XML está bien formado cuando cumple tres reglas: 1. un solo elemento (o elemento raíz) contiene todo el documento; 2. todos los elementos están contenidos en el elemento raíz; y 3. las etiquetas de apertura y cierre marcan, respectivamente, el inicio y el fin de todos los elementos. Para más detalles sobre el funcionamiento de XML, aconsejamos Hunter et al. (2007). &#8617;\n    \n    \n      La National Information Standards Organization (NISO), nacida en Estados Unidos en 1983 en el ámbito de las bibliotecas, define los metadatos como “la información creada, almacenada y compartida para describir objetos y que nos permite interactuar con éstos a fin de obtener conocimiento” (Riley, 2017). &#8617;\n    \n    \n      En la versión española de este tutorial, hemos traducido al español los nombres de los elementos (pero no su contenido) y hemos adaptado las instrucciones XSL para que coincidan con los utilizados en el archivo fuente (input). En adelante, daremos por sentado que estás utilizando el archivo XML SAPsimple_es.xml. &#8617;\n    \n    \n      Más información en Wikipedia y en la página web de International Organization for Standardization. ISO es una organización internacional fundada en 1947 y establecida en Ginebra que tiene por misión la creación y mantenimiento de estándares. &#8617;\n    \n    \n      Para profundizar en el manejo de XSLT, recomendamos Tennison (2005) y la web Data2Type, una de las pocas webs multilingües que existen sobre el tema. &#8617;\n    \n  \n\n\nCon este tutorial aprenderás a convertir un conjunto de datos históricos procedentes de una base de datos XML (ya sea un solo documento o varios documentos interconectados) en otros formatos más adecuados para presentar (tablas, listas) o exponer información (párrafos).\n\n"
  },


  {
    "id": 43,
    "url": "http://localhost:4000/es/lecciones/ver-archivos-html",
    "title": "Para entender páginas web y HTML",
    "body": "\nPara entender páginas web y HTML\n{% include toc.html %}\n\n“Hola Mundo” en HTML\n\nVisualizar archivos HTML\n\nCuando trabajas con recursos en línea, la mayor parte del tiempo estás usando archivos que han sido etiquetados con HTML (Lenguaje de marcado de hípertexto): tu navegador de Internet sabe perfectamente cómo interpretar HTML, lenguaje fácil de manejar y comprender para los lectores humanos. La mayoría de los navegadores te permiten también ver el código fuente HTML de cada página que visitas. Las dos imágenes siguientes muestran una página web típica (en este caso la de Old Bailey Online, con la que trabajaremos en las siguientes lecciones), y la fuente HTML utilizada para generar dicha página y que puedes ver, en Firefox, con el menú Herramientas -&gt; Desarrollador web -&gt; Código fuente de esta página.\n\nCuando estás trabajando en el navegador, generalmente no necesitas o no quieres ver el código fuente de esa página web. Pero si estás escribiendo una página para ti mismo puede ser muy útil ver cómo otras personas logran un efecto particular en la página a través de ciertos etiquetados. También resulta importante conocer el código fuente HTML mientras escribes programas para manipular páginas web o extraer automáticamente información de los sitios en la web como, por ejemplo, los repositorios de datos digitales.\n\n{% include figure.html filename=”obo.png” caption=”Captura de pantalla de Old Bailey en línea” %}\n\n{% include figure.html filename=”obo-page-source.png” caption=”Fuente HTML de la página web de Old Bailey en línea” %}\n\n(Para aprender más acerca de HTML, encontrarás muy útil en este momento estudiar el tutorial de HTML ofrecido por W3Schools. No es necesario por ahora tener un conocimiento detallado del HTML para continuar leyendo esta lección, pero todo el tiempo que inviertas en aprender HTML va a repercutir ampliamente en tu trabajo y formación como historiador o humanista digital).\n\n“Hola Mundo” en HTML\n\nHTML es un lenguaje de etiquetado; en otras palabras, HTML es, simple y sencillamente, texto “marcado” con “etiquetas” que proveen al programa intérprete (generalmente un navegador web) con la información necesaria para ejecutar comandos o representar cosas en la pantalla de la computadora. Imagina que estás editando la entrada de una ficha bibliográfica en la que quieres indicar el título de un libro mediante la aplicación de cursivas. En HTML usarás etiquetas em (“em” es sinónimo de “énfasis” -por “emphasis”). De tal manera que parte de tu archivo HTML puede verse de la siguiente manera:\n\n... en Cohen y Rosenzweig &lt;em&gt;Digital History&lt;/em&gt;, por ejemplo\n\n\nLos archivos más simples de HTML consisten en etiquetas que indican el principio y el fin del conjunto del documento, y etiquetas que identifican un encabezado head y un cuerpo body en medio de dicho documento. La información respectiva al archivo, como los formatos de tipografía y otras características, normalmente se incluyen en el encabezado head, mientras que la información que aparecerá en la pantalla del navegador normalmente se inserta en el cuerpo del archivo body.\n\n&lt;html&gt;\n&lt;head&gt;&lt;/head&gt;\n&lt;body&gt;¡Hola Mundo!&lt;/body&gt;\n&lt;/html&gt;\n\n\nIntenta ahora crear algo de código HTML. Abre tu editor de texto y crea un nuevo archivo. Copia el código que está más abajo en tu editor. La primera línea le indica al navegador qué tipo de archivo es. La etiqueta htmlcontiene la dirección del texto establecida como ltr (izquierda a derecha) y el idioma o lang establecido como español de España. La etiqueta “meta” contiene información muy importante para que el navegador despliegue correctamente las tildes y acentos en español. La etiqueta title (título) en el encabezado (head) del documento HTML contiene elementos que normalmente se muestran en la barra superior de la ventana del navegador cuando esa página está siendo vista, y en las pestañas de Firefox.\n\n&lt;!doctype html&gt;\n&lt;html dir=\"ltr\" lang=\"es-ES\"&gt;\n\t&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"&gt;\n\n&lt;head&gt;\n    &lt;title&gt;&lt;!-- Inserta aquí el título --&gt;&lt;/title&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;!-- Inserta aquí el contenido --&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\nCambia las líneas:\n\n&lt;!-- Inserta aquí el título --&gt;\n\n\ne\n\n&lt;!-- Inserta aquí el contenido --&gt;\n\npor:\n\n¡Hola Mundo!\n\n\nSalva el archivo en tu carpeta programming-historian con el nombre hola-mundo.html. Ahora, ve al navegador de Firefox y selecciona Archivo -&gt; Nueva pestañay luego Archivo -&gt; Abrir archivo. Selecciona hola-mundo.html. Dependiendo de tu editor de texto puedes tener la opción view page in browser u open in browser. Una vez que has abierto el archivo tu mensaje deberá aparecer en el navegador. Nota la diferencia entre abrir un archivo HTML con un navegador como Firefox (que lo interpreta) y abrir el mismo archivo con tu editor de texto (que no lo interpreta).\n\nSugerencia de lecturas para aprender HTML:\n\n\n  W3Schools HTML Tutorial\n  W3Schools HTML5 Tutorial\n\n\n\nEsta lección te introduce a las estructuras de HTML y de páginas web.\n\n"
  }

]
